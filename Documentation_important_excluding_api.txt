Welcome to pycram

==================================
Welcome to pycram's documentation!
==================================

.. image:: ../images/pycram_logo.png
   :alt: Pycram Logo

What is PyCRAM?
===============

PyCRAM is the Python 3 re-implementation of `CRAM <https://github.com/cram2/cram>`_.
PyCRAM is a toolbox for designing, implementing and deploying software on autonomous robots.
The framework provides various tools and libraries for aiding in robot software development as well as geometric
reasoning and fast simulation mechanisms to develop cognition-enabled control programs that achieve high levels of robot
autonomy.

PyCRAM is developed in Python with support for the ROS middleware which is used for communication with different
software components as well as the robot.

This framework is tested with Ubuntu 20.04, ROS Noetic and Python 3.8


Simple Demonstration

PyCRAM allows the execution of the same high-level plan on different robot platforms. Below you can see an example of
this where the plan is executed on the PR2 and the IAIs Boxy.

.. list-table::
   :widths: 50 50
   :header-rows: 1

   *  - Boxy
      - PR2
   *  - .. image:: ../images/boxy.gif
            :alt: Boxy robot performing tasks using pycram
      - .. image:: ../images/pr2.gif
            :alt: PR2 robot performing tasks using pycram


The plan that both robots execute is a relatively simple pick and place plan:

 * They start at the world origin
 * park their arms
 * move to the counter
 * observe the object
 * pickup the object
 * move to the kitchen island
 * place the object
 * move to the world origin

The code for this plan can be seen below.

.. code-block:: python

    from pycram.world.bullet_world import BulletWorld
    from pycram.world_concepts.world_concepts import Object
    from pycram.process_module import simulated_robot
    from pycram.designators.motion_designator import *
    from pycram.designators.location_designator import *
    from pycram.designators.action_designator import *
    from pycram.designators.object_designator import *
    from pycram.datastructures.enums import ObjectType, Arms, Grasps

    world = BulletWorld()
    kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
    robot = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
    cereal = Object("cereal", ObjectType.BREAKFAST_CEREAL, "breakfast_cereal.stl", position=[1.4, 1, 0.95])

    cereal_desig = ObjectDesignatorDescription(names=["cereal"])
    kitchen_desig = ObjectDesignatorDescription(names=["kitchen"])
    robot_desig = ObjectDesignatorDescription(names=["pr2"]).resolve()

    with simulated_robot:
        ParkArmsAction([Arms.BOTH]).resolve().perform()

        MoveTorsoAction([0.3]).resolve().perform()

        pickup_pose = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot_desig).resolve()
        pickup_arm = pickup_pose.reachable_arms[0]

        NavigateAction(target_locations=[pickup_pose.pose]).resolve().perform()

        PickUpAction(object_designator_description=cereal_desig, arms=[pickup_arm], grasps=[Grasps.FRONT]).resolve().perform()

        ParkArmsAction([Arms.BOTH]).resolve().perform()

        place_island = SemanticCostmapLocation("kitchen_island_surface", kitchen_desig.resolve(), cereal_desig.resolve()).resolve()

        place_stand = CostmapLocation(place_island.pose, reachable_for=robot_desig, reachable_arm=pickup_arm).resolve()

        NavigateAction(target_locations=[place_stand.pose]).resolve().perform()

        PlaceAction(cereal_desig, target_locations=[place_island.pose], arms=[pickup_arm]).resolve().perform()

        ParkArmsAction([Arms.BOTH]).resolve().perform()

    world.exit()

|------
Designators


Designators are CRAMs and PyCRAMs way of representing actions, motions, objects and locations.

In general, PyCRAM-Designators consist of a description and a specified element.
Descriptions describe sets of designators and designators are one thing in the described set.
For example, such a description could describe an action where the robot moves to a location
from where it can grasp an object. The specific location in this case is not relevant as long
as the robot can reach the object.

The designator description will be resolved during runtime which results in a designator with
specific parameter, the resulting designator can also be performed to let the robot perform the
desired behaviour.

To stay on the example of an action designator which should move the robot to a location from
where it can grasp an object, we will create a NavigateAction description with a list of possible
poses.

.. code-block:: python

    poses = [Pose([1, 0, 0], [0, 0, 0, 1]), Pose([1.2, 0.2, 0], [0, 0, 1, 0])]
    NavigateAction(target_locations=poses)

This is a description of an action which moves the robot to a pose in the environment.
In this case the description describes a set of action designators which have a pose of the ``poses``
list as target location.

By resolving the description it will return a single designator with specific parameter.
This can look like this:

.. code-block:: python

    designator = NavigateAction(target_locations=poses).resolve()

The resolver will check the available parameter and return a designator with appropriate parameter
which can then be performed. The designator returned by the resolver will always be a sub-class
of the description, in this way the designator can be assigned the type of action it performs.
The resolved designator can also contain new parameter which might be relevant for performing the
designator and will be inferred while resolving. A resolved action designator for a navigate
action looks like this:

.. code-block:: python

    NavigateActionPerformable(robot_position=(Pose([0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 1.0]), target_location=Pose([1, 0, 0], [0, 0, 0, 1]))


A visual representation of the whole idea of designator and designator descriptions can be
seen in the following image.

.. image:: ../images/designators.png
   :alt: Schematic representation of Designators.



There are four types of designators in PyCRAM:

 - :mod:`pycram.designators.action_designator`
 - :mod:`pycram.designators.object_designator`
 - :mod:`pycram.designators.location_designator`
 - :mod:`pycram.designators.motion_designator`

Object Designator
=================

Object designators represent objects in (simulated) world.
The description of object designators can take names and types that the object should match.
The :meth:`~pycram.designator.ObjectDesignatorDescription.ground` method returns an object with all
its data attached that matches the description.
The :meth:`~pycram.designator.ObjectDesignatorDescription.__iter__` method iterates over all objects
that match the description.

Contributing Object Designators

Object Designators should always be part of an object designator description.
The general class structure is seen in :mod:`~pycram.designator.ObjectDesignatorDescription`.
New object description need to inherit from the general object description. If the object they ground to differs from
the base object, a `dataclass <https://docs.python.org/3/library/dataclasses.html>`_. should be created inside the new
description. The dataclass is one element that matches the description.
If ORM logging of the new objects is wanted a ``to_sql()`` and ``insert()`` method has to be implemented
(see :ref:`orm` for more details).


Action Designator
=================
Action designators describe complex actions that are executable for an agent. Action designators can be seen as higher
level plans that include failure handling and parametrization.
An action designator description always takes the parameter as a list of possible parameter, when
resolving the description to a single designator one parameter out of the given list will be picked.

Motion Designator
=================
Motion designators describe atomic actions that are executable for an agent. In contrast to action
designators there is no failure handling or other action designators. Furthermore, the :meth:`~pycram.designator.MotionDesignatorDescription.Motion.perform`
method passes the resolved motion designator to the respective Process Module for execution on the robot.

Another difference to action designator is that motion designators only take a single parameter instead of a
list, this parameter is also strictly typed.

Location Designator
===================
Location designator describe a set of locations in regards to specific constrains. These constrains can be things
like ``reachable`` or ``visible``. The pose returned by a location designator is a single pose of the set defined
by the constrains given to the location designator description.

Similar to object designator poses location designator also a :meth:`~pycram.designators.location_designator.CostmapLocation.__iter__`
method which can iterate over all possible solutions for this description.

Creating your own Designator
============================
Creating your own designator is fairly easy, you only need to extend the base class of the respective description.

 - :mod:`~pycram.designator.ActionDesignatorDescription`
 - :mod:`~pycram.designator.ObjectDesignatorDescription`
 - :mod:`~pycram.designator.LocationDesignatorDescription`
 - :mod:`~pycram.designator.BaseMotion`

Afterwards you need to implement your own ``ground`` method which is the default resolver and for location and object
designator it makes sense to also implement a ``__iter__`` method. The ``ground`` and ``__iter__`` methods should return
the designator sub-class so you also need to implement these with the parameter your designator needs.

The sub-class can already contain some parameters, this is usually the case if the parameter is the same for every designator
of this type. For example, :class:`~pycram.designator.LocationDesignatorDescription.Location`
contains a ``pose`` parameter since every location designator contains a resolved pose.

For action and motion designator the sub-class is also the place where the ``perform`` method is written which contains
the behaviour of the designator.

|------
Troubleshooting

This page contains the most common errors that could happen when using PyCRAM and how to resolve them.


Ros Init Exception

.. code-block:: Python

    ROSInitException: time is not initialized. Have you called init_node()

This exception usually occurs when trying to load an Object into the BulletWorld or when creating a Pose. The reason for
this exception is that the ROS node of PyCRAM could not be initialized, this is usually the case when the PyCRAM launch
file was not launched.

To solve this problem you just have to launch the ``ik_and_description`` file of PyCRAM. This can be done via the
following command.

.. code-block:: shell

    roslaunch pycram ik_and_description


Robot Description not Loaded

In PyCRAM a lot of things are base on the robot description that is currently loaded and in turn the robot description
that will be loaded depends on the robot description that is on the ROS parameter server at the time PyCRAM is started.

If you get an error that looks similar to the following exception the most likely case is that the robot description was
not loaded.

.. code-block:: python
   :emphasize-lines: 3

        763 with open(self.path) as f:
        764     self.urdf_object = URDF.from_xml_string(f.read())
    --> 765     if self.urdf_object.name == robot_description.name and not BulletWorld.robot:
        766         BulletWorld.robot = self
        768 self.links[self.urdf_object.get_root()] = -1

    AttributeError: 'NoneType' object has no attribute 'name'


There could be a few reasons for this behaviour:
   * The name of the URDF on the parameter server and the name in the PyCRAM robot description are different
      * The PyCRAM robot description is matched by the name of the robot in the URDF
      * You can check the assignment of the PyCRAM robot description in this function :func:`~pycram.robot_descriptions.update_robot_description` (there is a link to the source code)
   * You only started a roscore
   * You did not start the ``ik_and_description`` launch file


Stop Iteration

Stop iterations usually happen when you try to resolve a designator for which there is no solution or if you iterate over a
designator and reached the end of all possible solutions.

When you try to resolve a designator which has no solution the error will look something like this.

.. code-block:: python
   :emphasize-lines: 7

       753 def ground(self) -> Union[Object, bool]:
       754     """
       755     Return the first object from the bullet world that fits the description.
       756
       757     :return: A resolved object designator
       758     """
   --> 759     return next(iter(self))

   StopIteration:

If you encounter such an error the most likely reason is that you put the wrong arguments into your DesignatorDescription.
The best solution is to double check the input arguments of the DesignatorDescription.



BulletWorld crashes after loading an URDF

It can happen that the BulletWorld crashes when loading a URDF. This happens when loading a URDF with more than 127 links.
This is a limitation of PyBullet which can not deal with objects with more links.

Only real solution here is to either delete links such that you have at max 127 links or split up the URDF and load the
split parts individually.


Error when performing Actions or Motions

.. code-block:: python

        30 def perform(self):
        31     pm_manager = ProcessModuleManager.get_manager()
   ---> 32     return pm_manager.navigate().execute(self)

   AttributeError: 'NoneType' object has no attribute 'navigate'

If you get an error like this when trying to perform an action or motion designator, then you did not specify how the
designator should be executed. You can specify how the designator should be performed by using the simulated_robot or
real_robot environments. This is also explained in the `Action Designator Example <https://pycram.readthedocs.io/en/latest/notebooks/action_designator.html#Navigate-Action>`_.

.. code-block:: python

   with simulated_robot:
      NavigateAction([Pose()]).resolve().perform()

Missing pr2_arm_kinematics
==========================

Aptitudes autoremove likes to also remove the arm kinematics. The error message looks similar to this. Important is the
missing library libmoveit_kinematics_base.so. This can be fixed by reinstalling the missing libraries.

.. code-block:: shell

   process[pr2_left_arm_kinematics-3]: started with pid [26862]
   pr2_arm_kinematics_node: error while loading shared libraries: libmoveit_kinematics_base.so.1.1.12: cannot open shared object file: No such file or directory
   process[pr2_right_arm_kinematics-4]: started with pid [26863]
   [pr2_left_arm_kinematics-3] process has died [pid 26862, exit code 127, cmd ~/pycram/devel/lib/pr2_arm_kinematics/pr2_arm_kinematics_node __name:=pr2_left_arm_kinematics __log:=~/.ros/log/ba5e95de-384f-11ee-ab53-97c8787037e5/pr2_left_arm_kinematics-3.log].
   log file: ~/.ros/log/ba5e95de-384f-11ee-ab53-97c8787037e5/pr2_left_arm_kinematics-3*.log
   pr2_arm_kinematics_node: error while loading shared libraries: libmoveit_kinematics_base.so.1.1.12: cannot open shared object file: No such file or directory
   [pr2_right_arm_kinematics-4] process has died [pid 26863, exit code 127, cmd ~/pycram/devel/lib/pr2_arm_kinematics/pr2_arm_kinematics_node __name:=pr2_right_arm_kinematics __log:=~/.ros/log/ba5e95de-384f-11ee-ab53-97c8787037e5/pr2_right_arm_kinematics-4.log].
   log file: ~/.ros/log/ba5e95de-384f-11ee-ab53-97c8787037e5/pr2_right_arm_kinematics-4*.log
   IK server ready.


Reinstall the missing libraries with

.. code-block:: shell

    sudo apt-get install ros-noetic-moveit

Then rebuild your workspace.

|------
PyCRAM Introduction

```python
import pycram
```

# Bullet World

The BulletWorld is the internal simulation of PyCRAM. You can simulate different actions and reason about the outcome of
different actions.

It is possible to spawn objects and robots into the BulletWorld, these objects can come from URDF, OBJ or STL files.

A BulletWorld can be created by simply creating an object of the BulletWorld class.

```python
from pycram.worlds.bullet_world import BulletWorld
from pycram.world_concepts.world_object import Object
from pycram.datastructures.enums import ObjectType
from pycram.datastructures.pose import Pose

world = BulletWorld()
```

The BulletWorld allows to render images from arbitrary positions. In the following example we render images with the
camera at the position [0.3, 0, 1] and pointing towards [1, 0, 1], so we are looking upwards along the x-axis.

The renderer returns 3 different kinds of images which are also shown on the left side of the BulletWorld window. (If
these winodws are missing, click the BulletWorld window to focus it, and press "g") These images are:

* An RGB image which shows everything like it is rendered in the BulletWorld window, just from another perspective.
* A depth image which consists of distance values from the camera towards the objects in the field of view.
* A segmentation mask image which segments the image into the different objects displayed. The segmentation is done by
  assigning every pixel the unique id of the object that is displayed there.

```python
world.get_images_for_target(Pose([1, 0, 1], [0, 0, 0, 1]), Pose([0.3, 0, 1], [0, 0, 0, 1]))
```

## Objects

Everything that is located inside the BulletWorld is an Object.
Objects can be created from URDF, OBJ or STL files. Since everything is of type Object a robot might share the same
methods as a milk (with some limitations).

Signature:
Object:

* Name
* Type
* Filename or Filepath

Optional:

* Position
* Orientation
* World
* Color
* Ignore Cached Files

If there is only a filename and no path, PyCRAM will check in the resource directory if there is a matching file.

```python
milk = Object("Milk", ObjectType.MILK, "milk.stl")
```

Objects provide methods to change the position and rotation, change the color, attach other objects, set the state of
joints if the objects has any or get the position and orientation of a link.

These methods are the same for every Object, however since some Objects may not have joints or more than one link
methods related to these will not work.

```python
milk.set_position(Pose([1, 0, 0]))
```

To remove an Object from the BulletWorld just call the 'remove' method on the Object.

```python
milk.remove()
```

Since everything inside the BulletWorld is an Object, even a complex environment Object like the kitchen can be spawned
in the same way as the milk.

```python
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
```

## Costmaps

Costmaps are a way to get positions with respect to certain criterias.
The currently available costmaps are:

* {class}`~pycram.costmaps.OccupancyCostmap`
* {class}`~pycram.costmaps.VisibilityCostmap`
* {class}`~pycram.costmaps.SemanticCostmap`
* {class}`~pycram.costmaps.GaussianCostmap`

It is also possible to merge multiple costmaps to combine different criteria.

### Visibility Costmaps

Visibility costmaps determine every position, around a target position, from which the target is visible. Visibility
Costmaps are able to work with cameras that are movable in height for example, if the robot has a movable torso.

```python
import pycram.costmaps as cm

v = cm.VisibilityCostmap(1.27, 1.60, size=300, resolution=0.02, origin=Pose([0, 0, 0.1], [0, 0, 0, 1]))
```

```python
v.visualize()
```

```python
v.close_visualization()
```

### Occupancy Costmap

Is valid for every position where the robot can be placed without colliding with an object.

```python
o = cm.OccupancyCostmap(0.2, from_ros=False, size=300, resolution=0.02, origin=Pose([0, 0, 0.1], [0, 0, 0, 1]))
```

```python
s = cm.SemanticCostmap(kitchen, "kitchen_island_surface", size=100, resolution=0.02)

g = cm.GaussianCostmap(200, 15, resolution=0.02)
```

You can visualize the costmap in the BulletWorld to get an impression what information is actually contained in the
costmap. With this you could also check if the costmap was created correctly.
Visualization can be done via the 'visualize' method of each costmap.

```python
o.visualize()
```

```python
o.close_visualization()
```

It is also possible to combine two costmap, this will result in a new costmap with the same size which contains the
information of both previous costmaps. Combination is done by checking for each position in the two costmaps if they are
zero, in this case to same position in the new costmap will also be zero in any other case the new position will be the
normalized product of the two combined costmaps.

```python
ov = o + v
```

```python
ov.visualize()
```

```python
ov.close_visualization()
```

## Bullet World Reasoning

Allows for geometric reasoning in the BulletWorld. At the moment the following types of reasoning are supported:

* {meth}`~pycram.world_reasoning.stable`
* {meth}`~pycram.world_reasoning.contact`
* {meth}`~pycram.world_reasoning.visible`
* {meth}`~pycram.world_reasoning.occluding`
* {meth}`~pycram.world_reasoning.reachable`
* {meth}`~pycram.world_reasoning.blocking`
* {meth}`~pycram.world_reasoning.supporting`

To show the geometric reasoning we first spawn a robot as well as the milk Object again.

```python
import pycram.world_reasoning as btr

milk = Object("Milk", ObjectType.MILK, "milk.stl", pose=Pose([1, 0, 1]))
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
```

We start with testing for visibility

```python
milk.set_position(Pose([1, 0, 1]))
visible = btr.visible(milk, pr2.get_link_pose("wide_stereo_optical_frame"))
print(f"Milk visible: {visible}")
```

```python
milk.set_position(Pose([1, 0, 0.05]))

plane = BulletWorld.current_bullet_world.objects[0]
contact = btr.contact(milk, plane)
print(f"Milk is in contact with the floor: {contact}")
```

```python
milk.set_position(Pose([0.6, -0.5, 0.7]))

reachable = btr.reachable(milk, pr2, "r_gripper_tool_frame")
print(f"Milk is reachable for the PR2: {reachable}")
```

# Designators

Designators are symbolic descriptions of Actions, Motions, Objects or Locations. In PyCRAM the different types of
designators are represented by a class which takes a description, the description then tells the designator what to do.

For example, let's look at a Motion Designator to move the robot to a specific location.

## Motion Designators

When using a Motion Designator you need to specify which Process Module needs to be used, either the Process Module for
the real or the simulated robot. A Process Module is the interface between a real or simulated robot, and PyCRAM
designators. By exchanging the Process Module, one can quickly change the robot the plan is executed on, allowing PyCRAM
plans to be re-used across multiple robot platforms. This can be done either with a decorator which can be added to a
function and then every designator executed within this function, will be executed on the specified robot. The other
possibility is a "with" scope which wraps a code piece.

These two ways can also be combined, you could write a function which should be executed on the real robot and the
function contains a "with" scope which executes something on the simulated robot for reasoning purposes.

```python
from pycram.designators.motion_designator import *
from pycram.process_module import simulated_robot, with_simulated_robot

description = MoveMotion(target=Pose([1, 0, 0], [0, 0, 0, 1]))

with simulated_robot:
    description.perform()


```

```python
from pycram.process_module import with_simulated_robot


@with_simulated_robot
def move():
    MoveMotion(target=Pose([0, 0, 0], [0, 0, 0, 1])).perform()


move()
```

Other implemented Motion Designator descriptions are:

* Accessing
* Move TCP
* Looking
* Move Gripper
* Detecting
* Move Arm Joint
* World State Detecting

## Object Designators

An Object Designator represents objects. These objects could either be from the BulletWorld or the real world. Object
Designators are used, for example, by the PickUpAction to know which object should be picked up.

```python
from pycram.designators.object_designator import *

milk_desig = BelieveObject(names=["Milk"])
milk_desig.resolve()
```

## Location Designator

Location Designator can create a position in cartisian space from a symbolic desctiption

```python
from pycram.designators.object_designator import *

milk_desig = BelieveObject(names=["Milk"])
milk_desig.resolve()
```

## Location Designators

Location Designators can create a position in cartesian space from a symbolic description.

```python
from pycram.designators.location_designator import *
from pycram.designators.object_designator import *

robot_desig = BelieveObject(types=[ObjectType.ROBOT]).resolve()
milk_desig = BelieveObject(names=["Milk"]).resolve()
location_desig = CostmapLocation(target=milk_desig, visible_for=robot_desig)

print(f"Resolved: {location_desig.resolve()}")
print()

for pose in location_desig:
    print(pose)

```

# Action Designator

Action Designators are used to describe high-level actions. Action Designators are usually composed of other Designators
to describe the high-level action in detail.

```python
from pycram.designators.action_designator import *
from pycram.datastructures.enums import Arms

with simulated_robot:
    ParkArmsAction([Arms.BOTH]).resolve().perform()

```

# Making a simple plan

To get familiar with the PyCRAM Framework we will write a simple pick and place plan. This plan will let the robot grasp
a cereal box from the kitchen counter and place it on the kitchen island. This is a simple pick and place plan.

```python
from pycram.designators.object_designator import *

cereal = Object("cereal", ObjectType.BREAKFAST_CEREAL, "breakfast_cereal.stl", pose=Pose([1.4, 1, 0.95]))

```

```python
cereal_desig = ObjectDesignatorDescription(names=["cereal"])
kitchen_desig = ObjectDesignatorDescription(names=["kitchen"])
robot_desig = ObjectDesignatorDescription(names=["pr2"]).resolve()
with simulated_robot:
    ParkArmsAction([Arms.BOTH]).resolve().perform()

    MoveTorsoAction([0.3]).resolve().perform()

    pickup_pose = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot_desig).resolve()
    pickup_arm = pickup_pose.reachable_arms[0]

    NavigateAction(target_locations=[pickup_pose.pose]).resolve().perform()

    PickUpAction(object_designator_description=cereal_desig, arms=[pickup_arm], grasps=["front"]).resolve().perform()

    ParkArmsAction([Arms.BOTH]).resolve().perform()

    place_island = SemanticCostmapLocation("kitchen_island_surface", kitchen_desig.resolve(),
                                           cereal_desig.resolve()).resolve()

    place_stand = CostmapLocation(place_island.pose, reachable_for=robot_desig, reachable_arm=pickup_arm).resolve()

    NavigateAction(target_locations=[place_stand.pose]).resolve().perform()

    PlaceAction(cereal_desig, target_locations=[place_island.pose], arms=[pickup_arm]).resolve().perform()

    ParkArmsAction([Arms.BOTH]).resolve().perform()



```

# Task Trees

Task trees are a hierarchical representation of all Actions involved in a plan. The Task tree can later be used to
inspect and restructure the execution order of Actions in the plan.

```python
import pycram.task
import anytree

tt = pycram.task.task_tree
print(anytree.RenderTree(tt))
```

```python
from anytree.dotexport import RenderTreeGraph, DotExporter

RenderTreeGraph(tt).to_picture("tree.png")
```

# ORM

```python
import sqlalchemy.orm
import pycram.orm.base
import pycram.orm.action_designator

# set description of what we are doing
pycram.orm.base.ProcessMetaData().description = "Tutorial for getting familiar with the ORM."

engine = sqlalchemy.create_engine("sqlite+pysqlite:///:memory:", echo=False)
session = sqlalchemy.orm.Session(bind=engine)
pycram.orm.base.Base.metadata.create_all(engine)
session.commit()

tt.insert(session)
```

```python
from sqlalchemy import select

navigations = session.scalars(select(pycram.orm.action_designator.NavigateAction)).all()
print(*navigations, sep="\n")
```

```python
navigations = (session.scalars(
    select(pycram.orm.action_designator.NavigateAction, pycram.orm.base.Position, pycram.orm.base.Quaternion).
    join(pycram.orm.action_designator.NavigateAction.pose).
    join(pycram.orm.base.Pose.position).
    join(pycram.orm.base.Pose.orientation)).all())
print(*navigations, sep="\n")
```

The world can also be closed with the 'exit' method

```python
world.exit()
```

|------
Bullet World

This Notebook will show you the basics of working with the PyCRAM BulletWorld.

First we need to import and create a BulletWorld.

```python
from pycram.worlds.bullet_world import BulletWorld
from pycram.datastructures.pose import Pose
from pycram.datastructures.enums import ObjectType, WorldMode

world = BulletWorld(mode=WorldMode.GUI)
```

This new window is the BulletWorld, PyCRAMs internal physics simulation. You can use the mouse to move the camera
around:

* Press the left mouse button to rotate the camera
* Press the right mouse button to move the camera
* Press the middle mouse button (scroll wheel) and move the mouse up or down to zoom

At the moment the BulletWorld only contains a floor, this is spawned by default when creating the BulletWorld.
Furthermore, the gravity is set to 9.8 $m^2$, which is the same gravitation as the one on earth.

To spawn new things in the BulletWorld we need to import the Object class and create and instance of it.

```python
from pycram.world_concepts.world_object import Object

milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([0, 0, 1]))
```

<!-- #region -->
As you can see this spawns a milk floating in the air. What we did here was create a new Object which has the name "
milk" as well as the type {attr}`~pycram.datastructures.enums.ObjectType.MILK`, is spawned from the file "milk.stl" and is at the position [0, 0, 1].

The type of an Object can either be from the enum ObjectType or a string. However, it is recommended to use the enum
since this would make for a more consistent naming of types which makes it easier to work with types. But since the
types of the enum might not fit your case you can also use strings.

The first three of these parameters are required while the position is optional. As you can see it was sufficient to
only specify the filename for PyCRAM to spawn the milk mesh. When only providing a filename, PyCRAM will search in its
resource directory for a matching file and use it.

For a complete list of all parameters that can be used to crate an Object please check the documentation.

Since the Object is spawned, we can now interact with it. First we want to move it around and change its orientation
<!-- #endregion -->

```python
milk.set_position(Pose([1, 1, 1]))
```

```python
milk.set_orientation(Pose(orientation=[1, 0, 0, 1]))
```

```python
milk.set_pose(Pose([0, 0, 1], [0, 0, 0, 1]))
```

In the same sense as setting the position or orientation, you can also get the position and orientation.

```python
print(f"Position: \n{milk.get_position()}")

print(f"Orientation: \n{milk.get_orientation()}")

print(f"Pose: \n{milk.get_pose()}")
```

## Attachments

You can attach Objects to each other simply by calling the attach method on one of them and providing the other as
parameter. Since attachments are bi-directional it doesn't matter on which Object you call the method.

First we need another Object

```python
cereal = Object("cereal", ObjectType.BREAKFAST_CEREAL, "breakfast_cereal.stl", pose=Pose([1, 0, 1]))
```

```python
milk.attach(cereal)
```

Now since they are attached to each other, if we move one of them the other will move in conjunction.

```python
milk.set_position(Pose([1, 1, 1]))
```

In the same way the Object can also be detached, just call the detach method on one of the two attached Objects.

```python
cereal.detach(milk)
```

## Links and Joints

Objects spawned from mesh files do not have links or joints, but if you spawn things from a URDF like a robot they will
have a lot of links and joints. Every Object has two dictionaries as attributes, namely ```links``` and ```joints```
which contain every link or joint as key and a unique id, used by PyBullet, as value.

We will see this at the example of the PR2:

```python
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
print(pr2.links)
```

For links there are similar methods available as for the pose. However, you can only **get** the position and
orientation of a link.

```python
print(f"Position: \n{pr2.get_link_position('torso_lift_link')}")

print(f"Orientation: \n{pr2.get_link_orientation('torso_lift_link')}")

print(f"Pose: \n{pr2.get_link_pose('torso_lift_link')}")
```

Methods available for joints are:

* {meth}`~pycram.world_concepts.world_object.Object.get_joint_position`
* {meth}`~pycram.world_concepts.world_object.Object.set_joint_position`
* {meth}`~pycram.world_concepts.world_object.Object.get_joint_limits`

We will see how these methods work at the example of the torso_lift_joint:

```python
print(f"Joint limits: {pr2.get_joint_limits('torso_lift_joint')}")

print(f"Current Joint state: {pr2.get_joint_position('torso_lift_joint')}")

pr2.set_joint_position("torso_lift_joint", 0.2)

print(f"New Joint state: {pr2.get_joint_position('torso_lift_joint')}")
```

## Misc Methods

There are a few methods that don't fit any category but could be helpful anyway. The first two are {meth}`~pycram.description.Link.get_color`
and {meth}`~pycram.description.Link.set_color`, as the name implies they can be used to get or set the color for specific links or the whole
Object.

```python
print(f"Pr2 forearm color: {pr2.get_link_color('r_forearm_link')}")
```

```python
pr2.set_link_color("r_forearm_link", [1, 0, 0])
```

Lastly, there is {meth}`~pycram.description.Link.get_axis_aligned_bounding_box`, AABB stands for *A*xis *A*ligned *B*ounding *B*ox. This method returns two points in
world coordinates which span a rectangle representing the AABB.

```python
pr2.get_axis_aligned_bounding_box()
```

To close the BulletWorld again please use the {meth}`~pycram.datastructures.world.World.exit` method since it will also terminate threads running in the
background

```python
world.exit()
```

|------
Plan Language

The PyCRAM plan language is a way to structure the execution of your plan. In generally the plan language allows to
execute designators either sequential or in parallel. Furthermore, exceptions that occur during execution of a plan with
the plan language do not interrupt the execution instead they are caught and saved to a dictionary for later analysis.
All language expressions return a State, this can either be SUCCEDED or FAILED.

There are 4 language expressions:

| Expression | Name             | Description                                                                                                                                                                                                                                                                                | 
|------------|------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| +          | **Sequential**   | Executes the designators one after another, if one of the designators raises an exception the execution is aborted and the state FAILED will be returned.                                                                                                                                  |
| -          | **Try In Order** | Executes the designators one after another, if one designator raises an exception the exception is caught and saved but the execution is not interrupted and the other designators are executed. Returns the state SUCCEDED if at least one designator can be executed without exception. |
| *          | **Repeat**       | Repeat the previous language expression a number of time. Has to be used with a language expression and an integer.                                                                                                                                                                        | 
| \|         | **Parallel**     | Executes all designators in parallel. For each designator there will be a new thread created and the designator is executed in this thread. If one of the designators raises an exception the returned state will be FAILED.                                                               |
| ^          | **Try All**      | Executes all designators in parallel with a designated thread for each designator. Returns the state SUCCEDED if at least one designator can be executed without an exception                                                                                                              |
| >>         | **Monitor**      | Monitors the execution of the attached langauge expression, will interrupt the execution as soon as a given condition is fulfilled.                                                                                                                                                        | 

The Sequential expression is the only one which aborts the execution once an error is raised.

When using the plan language a tree structure of the plan is created where the language expressions are nodes and
designators are leafs. This tree uses AnyTree (like the task tree) and can be rendered with the anytree Renderer.

## Sequential

This language expression allows to execute designators one after another, if one of the designators raises an exception
the execution will be aborted and the state FAILED will be returned.

We will start with a simple example that uses an action designator for moving the robot and parking its arms.

```python
import time

from pycram.designators.action_designator import *
from pycram.datastructures.pose import Pose
from pycram.datastructures.enums import Arms

navigate = NavigateAction([Pose([1, 1, 0])])
park = ParkArmsAction([Arms.BOTH])

plan = navigate + park
```

With this simple plan created we can inspect it and render the created tree structure.

```python
from anytree import RenderTree

print(RenderTree(plan))
```

As you can see there is the root node which is the language expression and then there are the leafs which are the
designators. When executing this plan the Sequential node will try to execute the NavigateAction and if that is finished
without any error the ParkArmsAction will be executed.

The plan can be executed by wrapping it inside a ```with simulated_robot``` environment and calling perform on the
plan.

If you are performing a plan with a simulated robot, you need a BulletWorld.

```python
from pycram.worlds.bullet_world import BulletWorld
from pycram.world_concepts.world_object import Object
from pycram.datastructures.enums import ObjectType

world = BulletWorld()
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
```

```python
from pycram.process_module import simulated_robot

world.reset_bullet_world()

with simulated_robot:
    plan.perform()
```

## Try In Order

Try in order is similar to Sequential, it also executes all designators one after another but the key difference is that
an exception in one of the designators does not terminate the whole execution. Furthermore, the state FAILED will only
be returned if all designator executions raise an error.

Besides the described difference in behaviour this language expression can be used in the same way as Sequential.

```python
from pycram.designators.action_designator import *
from pycram.datastructures.pose import Pose
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot

world.reset_bullet_world()

navigate = NavigateAction([Pose([1, 1, 0])])
park = ParkArmsAction([Arms.BOTH])

plan = navigate - park

with simulated_robot:
    plan.perform()
```

## Parallel

Parallel executes all designator at once in dedicated threads. The execution of other designators is not aborted when a
exception is raised, this is the case since threads can not be killed from the outside and this would also cause
unforeseen problems. The state returned will be SUCCEDED if all designators could be executed without an exception raised
in any other case FAILED will be returned.

Since executing designators in parallel can get chaotic especially with complex actions like PickUp or Transport. For
this reason not all action designators can be used in parallel and try all expressions. The list of action designator
that cannot be used in language expressions can be seen in {attr}`~pycram.language.Language.parallel_blocklist`.

Designators that cannot be used in parallel and try all:

* PickUpAction
* PlaceAction
* OpenAction
* CloseAction
* TransportAction

Using the parallel expressions works like Sequential and TryInOrder.

```python
from pycram.designators.action_designator import *
from pycram.datastructures.pose import Pose
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot

world.reset_world()

navigate = NavigateAction([Pose([1, 1, 0])])
park = ParkArmsAction([Arms.BOTH])

plan = navigate | park

with simulated_robot:
    plan.perform()
```

## Try All

TryAll is to Parallel what TryInOrder is to Sequential, meaning TryAll will also execute all designators in parallel but
will return SUCCEEDED if at least one designator is executed without raising an exception.

TryAll can be used like any other language expression.

```python
from pycram.designators.action_designator import *
from pycram.datastructures.pose import Pose
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot

world.reset_bullet_world()

navigate = NavigateAction([Pose([1, 1, 0])])
park = ParkArmsAction([Arms.BOTH])

plan = navigate ^ park

with simulated_robot:
    plan.perform()
```

## Combination of Expressions

You can also combine different language expressions to further structure your plans. If you combine sequential and
parallel expression please keep in mind that sequential expressions bind stringer than parallel ones. For example:

```
navigate | park + move_torso
```

In this case 'park' and 'move_torso' would form a Sequential expression and 'naviagte' would form a Parallel expression
with Sequential. You can try this yourself in the following cell.

```python
from pycram.designators.action_designator import *
from pycram.datastructures.pose import Pose
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot

world.reset_world()

navigate = NavigateAction([Pose([1, 1, 0])])
park = ParkArmsAction([Arms.BOTH])
move_torso = MoveTorsoAction([0.3])

plan = navigate | park + move_torso

with simulated_robot:
    plan.perform()
```

## Code Objects

You can not only use designators in the plan language but also python code. For this there is the {class}`~pycram.language.Code`  object
which takes a callable and the arguments for this callable. This allows you to execute arbitrary code in a plan.

The callable that is used in the {class}`~pycram.language.Code` object can either be a lambda expression or, for more complex code, a
function. If you use a function you can provide parameters as keyword-arguments.

```python
from pycram.designators.action_designator import *
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot
from pycram.language import Code


def code_test(param):
    print("-" * 20)
    print(param)


park = ParkArmsAction([Arms.BOTH])
code = Code(lambda: print("This is from the code object"))
code_func = Code(code_test, {"param": "Code function"})

plan = park | code | code_func

with simulated_robot:
    plan.perform()
```

## Exception Handling

If an exception is raised during the execution of a designator when it is used in a language expression the exception
will be caught and saved to a dictionary. In general all designators in a language expression are executed regardless
of exceptions raised, the only exception from this is the Sequential expression which stops after it encountered an
exception.

The language will only catch exceptions that are of type {class}`~pycram.plan_failures.PlanFailure` meaning errors that are defined in
plan_failures.py in PyCRAM. This also means normal Python errors, such as KeyError, will interrupt the execution of your
designators.

We will see how exceptions are handled at a simple example.

```python
from pycram.designators.action_designator import *
from pycram.process_module import simulated_robot
from pycram.language import Code
from pycram.plan_failures import PlanFailure


def code_test():
    raise PlanFailure


navigate = NavigateAction([Pose([1, 1, 0])])
code_func = Code(code_test)

plan = navigate | code_func

with simulated_robot:
    plan.perform()

print(plan.exceptions)
```

## Repeat

Repeat simply repeats a language expression a number of times. As all other language expressions Repeat captures
exceptions that occur during execution and saves them to the dictionary in the root of the plan.

Since Repeat uses the \* operator you should keep in mind that it will be evaluated before any other operator, so use
parentheses to ensure the correct structure of your plan.

You can see an example of how to use Repeat below.

```python
from pycram.designators.action_designator import *
from pycram.process_module import simulated_robot

move_torso_up = MoveTorsoAction([0.3])
move_torso_down = MoveTorsoAction([0.])

plan = (move_torso_up + move_torso_down) * 5

with simulated_robot:
    plan.perform()
```

## Monitor

Monitor allows to monitor the execution of a language expression and interrupt it as soon as a given condition is
fulfilled. The condition can either be a Callable which returns a boolean or a Fluent.
When executed the Monitor will create a separate thread which will check if the condition is satisfied with a frequency
of 10 Hz. If the condition is satisfied the execution of the language expression will be interrupted.

For the example on how Monitors work we will use the previous example with the robot moving up and down. We will use a
Monitor to interrupt the execution after 2 seconds instead of executing the whole plan 5 times.

```python
from pycram.designators.action_designator import *
from pycram.process_module import simulated_robot
from pycram.language import Monitor
import time

move_torso_up = MoveTorsoAction([0.3])
move_torso_down = MoveTorsoAction([0.])


def monitor_func():
    time.sleep(2)
    return True


plan = (move_torso_up + move_torso_down) * 5 >> Monitor(monitor_func)

with simulated_robot:
    plan.perform()
```

If you are finished with this example you can close the world with the cell below.

```python
world.exit()
```

|------
Action Designator

This example will show the different kinds of Action Designators that are available. We will see how to create Action
Designators and what they do.

Action Designators are high-level descriptions of actions which the robot should execute.

Action Designators are created from an Action Designator Description, which describes the type of action as well as the
parameter for this action. Parameter are given as a list of possible parameters.
For example, if you want to describe the robot moving to a table you would need a
{meth}`~pycram.designators.action_designator.NavigateAction` and a list of poses that are near the table. The Action
Designator Description will then pick one of the poses and return a performable Action Designator which contains the
picked pose.


<!-- #endregion -->

## Navigate Action

We will start with a simple example of the {meth}`~pycram.designators.action_designator.NavigateAction`.

First, we need a BulletWorld with a robot.

```python
from pycram.worlds.bullet_world import BulletWorld
from pycram.world_concepts.world_object import Object
from pycram.datastructures.enums import ObjectType, WorldMode

world = BulletWorld(WorldMode.GUI)
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
```

To move the robot we need to create a description and resolve it to an actual Designator. The description of navigation
only needs a list of possible poses.

```python
from pycram.designators.action_designator import NavigateAction
from pycram.datastructures.pose import Pose

pose = Pose([1, 0, 0], [0, 0, 0, 1])

# This is the Designator Description
navigate_description = NavigateAction(target_locations=[pose])

# This is the performable Designator
navigate_designator = navigate_description.resolve()
```

What we now did was: create the pose where we want to move the robot, create a description describing a navigation with
a list of possible poses (in this case the list contains only one pose) and create an action designator from the
description. The action designator contains the pose picked from the list of possible poses and can be performed.

```python
from pycram.process_module import simulated_robot

with simulated_robot:
    navigate_designator.perform()
```

Every designator that is performed needs to be in an environment that specifies where to perform the designator either
on the real robot or the simulated one. This environment is called {meth}`~pycram.process_module.simulated_robot`  similar there is also
a {meth}`~pycram.process_module.real_robot` environment.

There are also decorators which do the same thing but for whole methods, they are called {meth}`~pycram.process_module.with_real_robot` 
and {meth}`~pycram.process_module.with_simulated_robot`.

## Move Torso

This action designator moves the torso up or down, specifically it sets the torso joint to a given value.

We start again by creating a description and resolving it to a designator. Afterwards, the designator is performed in
a {meth}`~pycram.process_module.simulated_robot` environment.

```python
from pycram.designators.action_designator import MoveTorsoAction
from pycram.process_module import simulated_robot

torso_pose = 0.2

torso_desig = MoveTorsoAction([torso_pose]).resolve()

with simulated_robot:
    torso_desig.perform()
```

## Set Gripper

As the name implies, this action designator is used to open or close the gripper.

The procedure is similar to the last time, but this time we will shorten it a bit.

```python
from pycram.designators.action_designator import SetGripperAction
from pycram.process_module import simulated_robot
from pycram.datastructures.enums import GripperState, Arms

gripper = Arms.RIGHT
motion = GripperState.OPEN

with simulated_robot:
    SetGripperAction(grippers=[gripper], motions=[motion]).resolve().perform()
```

## Park Arms

Park arms is used to move one or both arms into the default parking position.

```python
from pycram.designators.action_designator import ParkArmsAction
from pycram.process_module import simulated_robot
from pycram.datastructures.enums import Arms

with simulated_robot:
    ParkArmsAction([Arms.BOTH]).resolve().perform()
```

## Pick Up and Place

Since these two are dependent on each other, meaning you can only place something when you picked it up beforehand, they
will be shown together.

These action designators use object designators, which will not be further explained in this tutorial so please check
the example on object designators for more details.

To start we need an environment in which we can pick up and place things as well as an object to pick up.

```python
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))

world.reset_world()
```

```python
from pycram.designators.action_designator import PickUpAction, PlaceAction, ParkArmsAction, MoveTorsoAction,

NavigateAction
from pycram.designators.object_designator import BelieveObject
from pycram.process_module import simulated_robot
from pycram.datastructures.enums import Arms, Grasp
from pycram.datastructures.pose import Pose

milk_desig = BelieveObject(names=["milk"])
arm = Arms.RIGHT

with simulated_robot:
    ParkArmsAction([Arms.BOTH]).resolve().perform()

    MoveTorsoAction([0.3]).resolve().perform()

    NavigateAction([Pose([0.78, 1, 0.0],
                         [0.0, 0.0, 0.014701099828940344, 0.9998919329926708])]).resolve().perform()

    PickUpAction(object_designator_description=milk_desig,
                 arms=[arm],
                 grasps=[Grasp.RIGHT]).resolve().perform()

    NavigateAction([Pose([-1.90, 0.78, 0.0],
                         [0.0, 0.0, 0.16439898301071468, 0.9863939245479175])]).resolve().perform()

    PlaceAction(object_designator_description=milk_desig,
                target_locations=[Pose([-1.20, 1.0192, 0.9624],
                                       # [0.0, 0.0, 0.6339889056055381, 0.7733421413379024])], 
                                       [0, 0, 0, 1])],
                arms=[arm]).resolve().perform()
```

```python
world.reset_world()
```

## Look At

Look at lets the robot look at a specific point, for example if it should look at an object for detecting.

```python
from pycram.designators.action_designator import LookAtAction
from pycram.process_module import simulated_robot
from pycram.datastructures.pose import Pose

target_location = Pose([1, 0, 0.5], [0, 0, 0, 1])
with simulated_robot:
    LookAtAction(targets=[target_location]).resolve().perform()
```

## Detect

Detect is used to detect objects in the field of vision (FOV) of the robot. We will use the milk used in the pick
up/place example, if you didn't execute that example you can spawn the milk with the following cell. The detect
designator will return a resolved instance of an ObjectDesignatorDescription.

```python
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))
```

```python
from pycram.designators.action_designator import DetectAction, LookAtAction, ParkArmsAction, NavigateAction
from pycram.designators.object_designator import BelieveObject
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot
from pycram.datastructures.pose import Pose

milk_desig = BelieveObject(names=["milk"])

with simulated_robot:
    ParkArmsAction([Arms.BOTH]).resolve().perform()

    NavigateAction([Pose([0, 1, 0], [0, 0, 0, 1])]).resolve().perform()

    LookAtAction(targets=[milk_desig.resolve().pose]).resolve().perform()

    obj_desig = DetectAction(milk_desig).resolve().perform()

    print(obj_desig)
```

## Transporting

Transporting can transport an object from its current position to another target position. It is similar to the Pick and
Place plan used in the Pick-up and Place example. Since we need an Object which we can transport we spawn a milk, you
don't need to do this if you already have spawned it in a previous example.

```python
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))
```

```python
from pycram.designators.action_designator import *
from pycram.designators.object_designator import *
from pycram.process_module import simulated_robot
from pycram.datastructures.pose import Pose
from pycram.datastructures.enums import Arms

milk_desig = BelieveObject(names=["milk"])

description = TransportAction(milk_desig,
                              [Arms.LEFT],
                              [Pose([-1.35, 0.78, 0.95],
                                    [0.0, 0.0, 0.16439898301071468, 0.9863939245479175])])
with simulated_robot:
    MoveTorsoAction([0.2]).resolve().perform()
    description.resolve().perform()
```

## Opening

Opening allows the robot to open a drawer, the drawer is identified by an ObjectPart designator which describes the
handle of the drawer that should be grasped.

For the moment this designator works only in the apartment environment, therefore we remove the kitchen and spawn the
apartment.

```python
kitchen.remove()
```

```python
apartment = Object("apartment", ObjectType.ENVIRONMENT, "apartment.urdf")
```

```python
from pycram.designators.action_designator import *
from pycram.designators.object_designator import *
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot
from pycram.datastructures.pose import Pose

apartment_desig = BelieveObject(names=["apartment"]).resolve()
handle_deisg = ObjectPart(names=["handle_cab10_t"], part_of=apartment_desig)

with simulated_robot:
    MoveTorsoAction([0.25]).resolve().perform()
    ParkArmsAction([Arms.BOTH]).resolve().perform()
    NavigateAction([Pose([1.7474915981292725, 2.6873629093170166, 0.0],
                         [-0.0, 0.0, 0.5253598267689507, -0.850880163370435])]).resolve().perform()
    OpenAction(handle_deisg, [Arms.RIGHT]).resolve().perform()
```

## Closing

Closing lets the robot close an open drawer, like opening the drawer is identified by an ObjectPart designator
describing the handle to be grasped.

This action designator only works in the apartment environment for the moment, therefore we remove the kitchen and spawn
the apartment. Additionally, we open the drawer such that we can close it with the action designator.

```python
kitchen.remove()
```

```python
apartment = Object("apartment", ObjectType.ENVIRONMENT, "apartment.urdf")
apartment.set_joint_state("cabinet10_drawer_top_joint", 0.4)
```

```python
from pycram.designators.action_designator import *
from pycram.designators.object_designator import *
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot
from pycram.datastructures.pose import Pose

apartment_desig = BelieveObject(names=["apartment"]).resolve()
handle_deisg = ObjectPart(names=["handle_cab10_t"], part_of=apartment_desig)

with simulated_robot:
    MoveTorsoAction([0.25]).resolve().perform()
    ParkArmsAction([Arms.BOTH]).resolve().perform()
    NavigateAction([Pose([1.7474915981292725, 2.8073629093170166, 0.0],
                         [-0.0, 0.0, 0.5253598267689507, -0.850880163370435])]).resolve().perform()
    CloseAction(handle_deisg, [Arms.RIGHT]).resolve().perform()
```

```python
world.exit()
```

|------
Object Designator

Object designators are used to describe objects located in the BulletWorld or the real environment and then resolve them
during runtime to concrete objects.

Object designators are different from the Object class in bullet_world.py in the way that they just describe an object
and do not create objects or provide methods to manipulate them. Nevertheless, object designators contain a reference to
the BulletWorld object.

An Object designator takes two parameters, of which at least one has to be provided. These parameters are:

* A list of names
* A list of types

Object Designators work similar to Location designators, they get constrains describing a set of objects and when
resolved return a specific instance.

For all following examples we need a BulletWorld, so let's create one.

```python
from pycram.worlds.bullet_world import BulletWorld
from pycram.world_concepts.world_object import Object
from pycram.datastructures.enums import ObjectType, WorldMode
from pycram.datastructures.pose import Pose

world = BulletWorld(WorldMode.GUI)
```

## Believe Object

This object designator is used to describe objects that are located in the BulletWorld. So objects that are in the
belief state, hence the name. In the future when there is a perception interface, there will be a ```RealObject```
description which will be used to describe objects in the real world.

Since {meth}`~pycram.designators.object_designator.BelieveObject` describes Objects in the BulletWorld we create a few.

```python
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))
cereal = Object("froot_loops", ObjectType.BREAKFAST_CEREAL, "breakfast_cereal.stl", pose=Pose([1.3, 0.9, 0.95]))
spoon = Object("spoon", ObjectType.SPOON, "spoon.stl", pose=Pose([1.3, 1.1, 0.87]))
```

Now that we have objects we can create an object designator to describe them. For the start we want an object designator
only describing the milk. Since all objects have unique names we can create an object designator using a list with only
the name of the object.

```python
from pycram.designators.object_designator import BelieveObject

object_description = BelieveObject(names=["milk"])

print(object_description.resolve())
```

You can also use the type to describe objects, so now we want to have an object designator that describes every food in
the world.

```python
from pycram.designators.object_designator import BelieveObject

object_description = BelieveObject(types=[ObjectType.MILK, ObjectType.BREAKFAST_CEREAL])

print(object_description.resolve())
```

## Object Part

Part of object designators can be used to describe something as part of another object. For example, you could describe
a specific drawer as part of the kitchen. This is necessary since the drawer is no single BulletWorld Object but rather
a link of the kitchen which is a BulletWorld Object.

For this example we need just need the kitchen, if you didn't spawn it in the previous example you can spawn it with the
following cell.

```python
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
```

```python
from pycram.designators.object_designator import ObjectPart, BelieveObject

kitchen_desig = BelieveObject(names=["kitchen"]).resolve()

object_description = ObjectPart(names=["sink_area_left_upper_drawer_main"], part_of=kitchen_desig)

print(object_description.resolve())
```

## Object Designators as Generators

Similar to location designators object designators can be used as generators to iterate through every object that they
are describing. We will see this at the example of an object designator describing every type of food.

For this we need some objects, so if you didn't already spawn them you can use the next cell for this.

```python
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))
cereal = Object("froot_loops", ObjectType.BREAKFAST_CEREAL, "breakfast_cereal.stl", pose=Pose([1.3, 0.9, 0.95]))
spoon = Object("spoon", ObjectType.SPOON, "spoon.stl", pose=Pose([1.3, 1.1, 0.87]))
```

```python
from pycram.designators.object_designator import BelieveObject

object_description = BelieveObject(types=[ObjectType.MILK, ObjectType.BREAKFAST_CEREAL])

for obj in object_description:
    print(obj, "\n")
```

To close the world use the following exit function.

```python
world.exit()
```

|------
Location Designator

This example will show you what location designators are, how to use them and what they are capable of.

Location Designators are used to semantically describe locations in the world. You could, for example, create a location
designator that describes every position where a robot can be placed without colliding with the environment. Location
designator can describe locations for:

* Visibility
* Reachability
* Occupancy
* URDF Links (for example a table)

To find locations that fit the given constrains, location designator create Costmaps. Costmaps are a 2D distribution
that have a value greater than 0 for every position that fits the costmap criteria.

Location designators work similar to other designators, meaning you have to create a location designator description
which describes the location. This description can then be resolved to the actual 6D pose on runtime.

## Occupancy

We will start with a simple location designator that describes a location where the robot can be placed without
colliding with the environment. To do this we need a BulletWorld since the costmaps are mostly created from the current
state of the BulletWorld.

```python
from pycram.worlds.bullet_world import BulletWorld
from pycram.world_concepts.world_object import Object
from pycram.datastructures.enums import ObjectType, WorldMode
from pycram.datastructures.pose import Pose

world = BulletWorld()
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
```

Next up we will create the location designator description, the {meth}`~pycram.designators.location_designator.CostmapLocation` that we will be using needs a
target as a parameter. This target describes what the location designator is for, this could either be a pose or object
that the robot should be able to see or reach.

In this case we only want poses where the robot can be placed, this is the default behaviour of the location designator
which we will be extending later.

```python
from pycram.designators.location_designator import CostmapLocation

target = kitchen.get_pose()

location_description = CostmapLocation(target)

pose = location_description.resolve()

print(pose)
```

## Reachable

Next we want to locations from where the robot can reach a specific point, like an object the robot should pick up. This
can also be done with the {meth}`~pycram.designators.location_designator.CostmapLocation` description, but this time we need to provide an additional argument.
The additional argument is the robo which should be able to reach the pose.

Since a robot is needed we will use the PR2 and use a milk as a target point for the robot to reach. The torso of the
PR2 will be set to 0.2 since otherwise the arms of the robot will be too low to reach on the countertop.

```python
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
pr2.set_joint_state("torso_lift_joint", 0.2)
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))

```

```python
from pycram.designators.location_designator import CostmapLocation
from pycram.designators.object_designator import BelieveObject

target = BelieveObject(names=["milk"]).resolve()
robot_desig = BelieveObject(names=["pr2"]).resolve()

location_description = CostmapLocation(target=target, reachable_for=robot_desig)

print(location_description.resolve())
```

As you can see we get a pose near the countertop where the robot can be placed without colliding with it. Furthermore,
we get a list of arms with which the robot can reach the given object.

## Visibile

The {meth}`~pycram.designators.location_designator.CostmapLocation` can also find position from which the robot can see a given object or location. This is very
similar to how reachable locations are described, meaning we provide a object designator or a pose and a robot
designator but this time we use the ```visible_for``` parameter.

For this example we need the milk as well as the PR2, so if you did not spawn them during the previous location
designator you can spawn them with the following cell.

```python
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))
```

```python
from pycram.designators.location_designator import CostmapLocation
from pycram.designators.object_designator import BelieveObject

target = BelieveObject(names=["milk"]).resolve()
robot_desig = BelieveObject(names=["pr2"]).resolve()

location_description = CostmapLocation(target=target, visible_for=robot_desig)

print(location_description.resolve())
```

## Semantic

Semantic location designator are used to create location descriptions for semantic entities, like a table. An example of
this is: You have a robot that picked up an object and should place it on a table. Semantic location designator then
allows to find poses that are on this table.

Semantic location designator need an object from which the target entity is a part and the URDF link representing the
entity. In this case we want a position on the kitchen island, so we have to provide the kitchen object designator since
the island is a part of the kitchen and the link name of the island surface.

For this example we need the kitchen as well as the milk. If you spawned them in one of the previous examples you don't
need to execute the following cell.

```python
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
milk = Object("milk", ObjectType.MILK, "milk.stl")
```

```python
from pycram.designators.location_designator import SemanticCostmapLocation
from pycram.designators.object_designator import BelieveObject

kitchen_desig = BelieveObject(names=["kitchen"]).resolve()
milk_desig = BelieveObject(names=["milk"]).resolve()

location_description = SemanticCostmapLocation(urdf_link_name="kitchen_island_surface",
                                               part_of=kitchen_desig,
                                               for_object=milk_desig)

print(location_description.resolve())
```

## Location Designator as Generator

Location designator descriptions implement an iter method, so they can be used as generators which generate valid poses
for the location described in the description. This can be useful if the first pose does not work for some reason.

We will see this at the example of a location designator for visibility. For this example we need the milk, if you
already have a milk spawned in you world you can ignore the following cell.

```python
milk = Object("milk", ObjectType.MILK, "milk.stl")
```

```python
from pycram.designators.location_designator import CostmapLocation
from pycram.designators.object_designator import BelieveObject

target = BelieveObject(names=["milk"]).resolve()
robot_desig = BelieveObject(names=["pr2"]).resolve()

location_description = CostmapLocation(target=target, visible_for=robot_desig)

for pose in location_description:
    print(pose.pose)
```

## Accessing Locations

Accessing describes a location from which the robot can open a drawer. The drawer is specified by a ObjetcPart
designator which describes the handle of the drawer.

At the moment this location designator only works in the apartment environment, so please remove the kitchen if you
spawned it in a previous example. Furthermore, we need a robot, so we also spawn the PR2 if it isn't spawned already.

```python
kitchen.remove()
```

```python
apartment = Object("apartment", ObjectType.ENVIRONMENT, "apartment.urdf")
```

```python
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
pr2.set_joint_state("torso_lift_joint", 0.25)
```

```python
from pycram.designators.object_designator import *
from pycram.designators.location_designator import *

apartment_desig = BelieveObject(names=["apartment"])
handle_desig = ObjectPart(names=["handle_cab10_t"], part_of=apartment_desig.resolve())
robot_desig = BelieveObject(names=["pr2"])

access_location = AccessingLocation(handle_desig.resolve(), robot_desig.resolve()).resolve()
print(access_location.pose)
```

## Giskard Location

Some robots like the HSR or the Stretch2 need a full-body ik solver to utilize the whole body. For this case robots
the {meth}`~pycram.designators.specialized_designators.location.giskard_location.GiskardLocation` can be used. This location designator uses giskard as an ik solver to find a pose for the
robot to reach a target pose.

**Note:** The GiskardLocation relies on Giskard, therefore Giskard needs to run in order for this Location Designator to
work.

```python
from pycram.designators.specialized_designators.location.giskard_location import GiskardLocation

robot_desig = BelieveObject(names=["pr2"]).resolve()

loc = GiskardLocation(target=Pose([1, 1, 1]), reachable_for=robot_desig).resolve()
print(loc.pose)
```

If you are finished with this example you can close the world with the following cell:

```python
world.exit()
```

|------
Motion Designator

Motion designators are similar to action designators, but unlike action designators, motion designators represent atomic
low-level motions. Motion designators only take the parameter that they should execute and not a list of possible
parameters, like the other designators. Like action designators, motion designators can be performed, performing motion
designator verifies the parameter and passes the designator to the respective process module.

Since motion designators perform a motion on the robot, we need a robot which we can use. Therefore, we will create a
BulletWorld as well as a PR2 robot.

```python
from pycram.worlds.bullet_world import BulletWorld
from pycram.world_concepts.world_object import Object
from pycram.datastructures.enums import ObjectType, WorldMode

world = BulletWorld(WorldMode.GUI)
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
```

## Move

Move is used to let the robot drive to the given target pose. Motion designator are used in the same way as the other
designator, first create a description then resolve it to the actual designator and lastly, perform the resolved
designator.

```python
from pycram.datastructures.pose import Pose
from pycram.designators.motion_designator import MoveMotion
from pycram.process_module import simulated_robot

with simulated_robot:
    motion_description = MoveMotion(target=Pose([1, 0, 0], [0, 0, 0, 1]))

    motion_description.perform()
```

```python
world.reset_world()
```

## MoveTCP

MoveTCP is used to move the tool center point (TCP) of the given arm to the target position specified by the parameter.
Like any designator we start by creating a description and then resolving and performing it.

```python
from pycram.designators.motion_designator import MoveTCPMotion
from pycram.process_module import simulated_robot
from pycram.datastructures.enums import Arms

with simulated_robot:
    motion_description = MoveTCPMotion(target=Pose([0.5, 0.6, 0.6], [0, 0, 0, 1]), arm=Arms.LEFT)

    motion_description.perform()
```

## Looking

Looking motion designator adjusts the robot state such that the cameras point towards the target pose. Although this
motion designator takes the target as position and orientation, in reality only the position is used.

```python
from pycram.designators.motion_designator import LookingMotion
from pycram.process_module import simulated_robot

with simulated_robot:
    motion_description = LookingMotion(target=Pose([1, 1, 1], [0, 0, 0, 1]))

    motion_description.perform()
```

## Move Gripper

Move gripper moves the gripper of an arm to one of two states. The states can be {attr}`~pycram.datastructures.enums.GripperState.OPEN`  and {attr}`~pycram.datastructures.enums.GripperState.CLOSE`, which open
and close the gripper respectively.

```python
from pycram.designators.motion_designator import MoveGripperMotion
from pycram.process_module import simulated_robot
from pycram.datastructures.enums import Arms, GripperState

with simulated_robot:
    motion_description = MoveGripperMotion(motion=GripperState.OPEN, gripper=Arms.LEFT)

    motion_description.perform()
```

## Detecting

This is the motion designator implementation of detecting, if an object with the given object type is in the field of
view (FOV) this motion designator will return an object designator describing the object.

Since we need an object that we can detect, we will spawn a milk for this.

```python
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.5, 0, 1]))
```

```python
from pycram.designators.motion_designator import DetectingMotion, LookingMotion
from pycram.process_module import simulated_robot

with simulated_robot:
    LookingMotion(target=Pose([1.5, 0, 1], [0, 0, 0, 1])).perform()

    motion_description = DetectingMotion(object_type=ObjectType.MILK)

    obj = motion_description.perform()

    print(obj)
```

## Move Arm Joints

This motion designator moves one or both arms. Movement targets are a dictionary with joint name as key and target pose
as value.

```python
from pycram.designators.motion_designator import MoveArmJointsMotion
from pycram.process_module import simulated_robot

with simulated_robot:
    motion_description = MoveArmJointsMotion(right_arm_poses={"r_shoulder_pan_joint": -0.7})

    motion_description.perform()
```

## World State Detecting

World state detecting is also used to detect objects, however, the object is not required to be in the FOV of the robot.
As long as the object is somewhere in the belief state (BulletWorld) a resolved object designator will be returned.

Sine we want to detect something we will spawn an object that we can detect. If you already spawned the milk from the
previous example, you can skip this step.

```python
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([-1, 0, 1]))
```

```python
from pycram.designators.motion_designator import WorldStateDetectingMotion
from pycram.process_module import simulated_robot

with simulated_robot:
    motion_description = WorldStateDetectingMotion(object_type=ObjectType.MILK)

    obj = motion_description.perform()

    print(obj)
```

## Move Joints

Move joints can move any number of joints of the robot, the designator takes two lists as parameter. The first list are
the names of all joints that should be moved and the second list are the positions to which the joints should be moved.

```python
from pycram.designators.motion_designator import MoveJointsMotion
from pycram.process_module import simulated_robot

with simulated_robot:
    motion_description = MoveJointsMotion(names=["torso_lift_joint", "r_shoulder_pan_joint"], positions=[0.2, -1.2])

    motion_description.perform()
```

The following cell can be used after testing the examples, to close the BulletWorld.

```python
world.exit()
```

|------
Hands on Object Relational Mapping in PyCram

This tutorial will walk you through the serialization of a minimal plan in pycram.
First we will import sqlalchemy, create an in memory database and connect a session to it.

```python
import sqlalchemy
import sqlalchemy.orm

engine = sqlalchemy.create_engine("sqlite+pysqlite:///:memory:", echo=False)
session = sqlalchemy.orm.Session(bind=engine)
session
```

Next we create the database schema using the sqlalchemy functionality. For that we need to import the base class of pycram.orm.

```python
import pycram.orm.base
import pycram.orm.action_designator
pycram.orm.base.Base.metadata.create_all(engine)
session.commit()
```

Next we will write a simple plan where the robot parks his arms and then moves somewhere. We will construct a TaskTree around it such that we can serialize it later. As usual, we first create a world and then define the plan. By doing so, we obtain the task tree.

```python
from pycram.designators.action_designator import *
from pycram.designators.location_designator import *
from pycram.process_module import simulated_robot
from pycram.datastructures.enums import Arms, ObjectType, Grasp, WorldMode
from pycram.tasktree import with_tree
import pycram.tasktree
from pycram.worlds.bullet_world import BulletWorld
from pycram.world_concepts.world_object import Object
from pycram.designators.object_designator import *
from pycram.datastructures.pose import Pose
import anytree

world = BulletWorld(WorldMode.GUI)
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))
cereal = Object("cereal", ObjectType.BREAKFAST_CEREAL, "breakfast_cereal.stl", pose=Pose([1.3, 0.7, 0.95]))
milk_desig = ObjectDesignatorDescription(names=["milk"])
cereal_desig = ObjectDesignatorDescription(names=["cereal"])
robot_desig = ObjectDesignatorDescription(names=["pr2"]).resolve()
kitchen_desig = ObjectDesignatorDescription(names=["kitchen"])

@with_tree
def plan():
    with simulated_robot:
        ParkArmsActionPerformable(Arms.BOTH).perform()
        MoveTorsoAction([0.2]).resolve().perform()
        pickup_pose = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot_desig).resolve()
        pickup_arm = pickup_pose.reachable_arms[0]
        NavigateAction(target_locations=[pickup_pose.pose]).resolve().perform()
        PickUpAction(object_designator_description=cereal_desig, arms=[pickup_arm], grasps=[Grasp.FRONT]).resolve().perform()
        ParkArmsAction([Arms.BOTH]).resolve().perform()

        place_island = SemanticCostmapLocation("kitchen_island_surface", kitchen_desig.resolve(),
                                           cereal_desig.resolve()).resolve()

        place_stand = CostmapLocation(place_island.pose, reachable_for=robot_desig, reachable_arm=pickup_arm).resolve()

        NavigateAction(target_locations=[place_stand.pose]).resolve().perform()

        PlaceAction(cereal_desig, target_locations=[place_island.pose], arms=[pickup_arm]).resolve().perform()

        ParkArmsActionPerformable(Arms.BOTH).perform()

plan()

# set description of what we are doing
pycram.orm.base.ProcessMetaData().description = "Tutorial for getting familiar with the ORM."
task_tree = pycram.tasktree.task_tree
print(anytree.RenderTree(task_tree))
```

Next we serialize the task tree by recursively inserting from its root.

```python
task_tree.root.insert(session)
```

We can look at our experiment (Process)MetaData to get some context on the data we just created.

```python
from sqlalchemy import select

print(*session.scalars(select(pycram.orm.base.ProcessMetaData)).all())
```

Lastly we can look at various table to see how the structures got logged.
For example, we can get all the navigate actions that occurred.

```python
navigations = session.scalars(select(pycram.orm.action_designator.NavigateAction)).all()
print(*navigations, sep="\n")
```

Due to the inheritance mapped in the ORM package, we can also obtain all executed actions with just one query. 

```python
actions = session.scalars(select(pycram.orm.action_designator.Action)).all()
print(*actions, sep="\n")
```

Of course all relational algebra operators, such as filtering and joining also work in pycram.orm queries. Let's say we need all the poses of objects, that were picked up by a robot. Since we defined a relationship between the PickUpAction table and the Object table and between the Object table and the Pose table in the ORM class schema, we can just use the join operator without any further specification:

```python
object_actions = (session.scalars(select(pycram.orm.base.Pose)
                  .join(pycram.orm.action_designator.PickUpAction.object)
                  .join(pycram.orm.object_designator.Object.pose))
                  .all())
print(*object_actions, sep="\n")

```

Did you notice, that for the joins we did not join the tables together in a typical sql kind of way, but rather used the relationships defined in the ORM classes and wrote joins like PickUpAction.object or Object.pose? This is because the ORM package automatically creates the joins for us, so we only have to join on the attributes that hold the relationship. This is a huge advantage over writing sql queries by hand, since we do not have to worry about the join conditions. 
This is a strong tool, but it is crucial to use it properly. Very important to note: The order of the joins matters! For instance, if we joined the Pose table with the Object table first, and placed the join between the PickUpAction table and the Object table second, sqlalchemy would have selected the Pose not from the join between all three tables, but rather from a join between the Pose and the Object table + from a join between the PickUpAction table and the Object table. These mistakes can lead to wrong results or even to errors (the above-mentioned example would actually lead to an error due to the Object table being accessed twice in two separate joins in the same query and therefore the column names of the Object tables would have been ambiguous and could not be used by sqlalchemy to join).

Make sure to check out the other examples of ORM querying.


If we want to filter for all successful tasks we can just add the filter operator:

```python
from pycram.orm.tasktree import TaskTreeNode

successful_tasks = session.scalars(select(TaskTreeNode).where(TaskTreeNode.status == "SUCCEEDED"))
print(*successful_tasks, sep="\n")
```

As expected all but the root node succeeded, since the root node is still running.

Writing an extension to the ORM package is also done with ease. We need to create a new ActionDesignator class and its ORM equivalent, where we define our new table. Let's say we want to log all the things the robot says. We will create a new ActionDesignator class called Saying and its ORM equivalent called ORMSaying. 

```python
from sqlalchemy.orm import Mapped, mapped_column, Session
from pycram.orm.action_designator import Action
from dataclasses import dataclass


# define ORM class from pattern in every pycram.orm class
class ORMSaying(Action):

    id: Mapped[int] = mapped_column(sqlalchemy.ForeignKey(f'{Action.__tablename__}.id'), primary_key=True, init=False)
    # since we do not want to add any custom specifications to our column, we don't even need to define mapped_column, sqlalchemy does this internally.
    text: Mapped[str] 

# define brand new action designator

@dataclass 
class SayingActionPerformable(ActionDesignatorDescription.Action):
    
    text: str
        
    @with_tree
    def perform(self) -> None:
        print(self.text)

    def to_sql(self) -> ORMSaying:
        return ORMSaying(self.text)

    def insert(self, session: Session, *args, **kwargs) -> ORMSaying:
        action = super().insert(session)
        session.add(action)
        session.commit()
        return action

```

Now we got our new ActionDesignator called Saying and its ORM version. Since this class got created after all other classes got inserted into the database (in the beginning of the notebook) we have to insert it manually. 

```python
ORMSaying.metadata.create_all(bind=engine)
```

Now we can create and insert a Saying action. Since this is the last part where we interact with the BulletWorld, we can also close it.

```python
# create a saying action and insert it
SayingActionPerformable("Patchie, Patchie; Where is my Patchie?").perform()
pycram.tasktree.task_tree.root.insert(session)
session.commit()

world.exit()
```

It is notable that committing the object to the session fills its primary key. Hence, there is no worries about assigning unique IDs manually.
Finally, we can double-check that our object exists in the database.

```python
session.scalars(select(ORMSaying)).all()
```

|------
Pose

Poses in PyCRAM are represented by the Pose class which inherits from the PoseStamped message of ROS. This makes PyCRAMs
poses compatible with everything in ROS like services, topics or TF.

This notebook will provide an overview about poses, how to use them and what they can do. We will start by simply
creating a pose.

Before we start a few words about naming convention of Poses in PyCRAM. Naming convention is similar to the PoseStamped
message so if you are familiar with that this should be easy.

* **Position:** A position means the position in cartesian space, so the x, y, and z coordinates.
* **Orientation:** An orientation is the rotation in all three axes represented as a quaternion with x, y, z, w.
* **Pose:** A pose is the combination of a position and an orientation. Poses in PyCRAM also contain a frame of
  reference to which the position and orientation are relative.

```python
from pycram.datastructures.pose import Pose

example_pose = Pose([1, 2, 3], [0, 0, 0, 1], "map")
print(example_pose)
```

As you can see we created the ```example_pose``` with a position of ```[1, 2, 3]``` and an orientation
of ```[0, 0, 0, 1]``` in the frame ```map```. But we don't need to provide all these parameters for a Pose, in case
there is no parameter the Pose will use default parameter.

```python
from pycram.datastructures.pose import Pose

default_pose = Pose()
print(default_pose)
```

In case no parameter is provided the defualt parameter are:

* position: ```[0, 0, 0]```
* orientation: ```[o, 0, 0, 1]```
* frame: ```map```

The following example will show how to access the data stored in a pose.

```python
from pycram.datastructures.pose import Pose

example_pose = Pose([1, 2, 3], [0, 0, 0, 1], "map")

print(f"Access to a component of the position: {example_pose.position.y}")

print(f"Access to a component of the rotation: {example_pose.orientation.x}")

print(f"Get the whole position as geometry_msgs/Pose:\n{example_pose.position}")

print(f"You can also get position or orientation as a list: {example_pose.position_as_list()}")

print(f"Same with the whole pose: {example_pose.to_list()}")

print(f"Access the reference frame: {example_pose.frame}")
```

## Editing a pose

You can also edit the data saved in a Pose, similar to how you access it.

```python
from pycram.datastructures.pose import Pose

example_pose = Pose([1, 2, 3], [0, 0, 0, 1], "map")

# Edit a single component of the position 
example_pose.position.x = 3
print(f"Edit only one component:\n{example_pose.position}", "\n")

# Edit the whole position
example_pose.position = [0, 0, 1]
print(f"Edit the whole position:\n{example_pose.position}", "\n")

example_pose.frame = "new_frame"
print(f"Set a new frame:\n{example_pose.frame}", "\n")

example_pose.set_position([3, 2, 1])
print(f"Set the position via method:\n{example_pose.position}", "\n")
```

## Copy Poses

You can also copy Poses to create a new Pose with the same data. This can be useful if you have a method which would
need to alter the Pose, since poses are passed by reference to a method every change done to the Pose in the method
would affect the instanced passed to the method.

```python
from pycram.datastructures.pose import Pose

example_pose = Pose([1, 2, 3], [0, 0, 0, 1], "map")

copy_pose = example_pose.copy()

print(example_pose, "\n")
print(copy_pose)
```

## Convert to Transform

PyCRAM also has its own transform at which we will take a look in the next section. However, here we will take a look at
how to convert a Pose into a Transform.

For this example we will take a Pose which represents the current pose of a milk object and convert it into a Transform
which represents the transformation from the ```map``` frame to the ```milk``` frame.

```python
from pycram.datastructures.pose import Pose

milk_pose = Pose([3, 4, 1], [1, 0, 0, 1], "map")

milk_transform = milk_pose.to_transform("milk")

print(milk_transform)
```

# Transforms

Transforms are similar to Poses but instead of representing a Pose in a frame of reference they represent a
transformation from one frame of reference to another. For this purpose Transforms have an additional parameter
called ```child_frame_id``` which is the frame of reference to which the Transform is pointing.

Transforms in PyCRAM inherit from the TransformStamped message of ROS which makes them, like Poses, compatible to ROS
services and topics that expect a TransformStamped message. Therefore, the naming conventions of Transforms are the same
as of TransformStamped which.

* **Translation:** The vector describing the transformation in cartesian space.
* **Rotation:** The quaternion describing the transformation of rotation.
* **Transform:** The combination of translation and rotation

```python
from pycram.datastructures.pose import Transform

example_transform = Transform([1, 2, 2], [0, 0, 0, 1], "map", "object")

print(example_transform)
```

Transforms have the same methods to get and set values as Poses have, therefore only a short showcase will be given. For
more details please look at the Pose example or the API documentation.

```python
from pycram.datastructures.pose import Transform

example_transform = Transform([2, 5, 1], [0, 0, 1, 1], "map", "object")

print(f"Access the rotation:\n{example_transform.rotation}", "\n")

print(f"Access the child_frane: {example_transform.child_frame_id}", "\n")

# changing translation and rotation is exactly like with Poses.

example_transform.translation = [1, 1, 1]
print(f"New translation:\n{example_transform.translation}")
```

## Convert to Pose and Copy

Analog to Poses Transforms have a method that converts a Transform to a Pose, in this process the ```child_frame_id```
will be lost.

Also like in Poses Transforms have a ```copy``` method which creates an exact copy of this Transform.

```python
from pycram.datastructures.pose import Transform

milk_transform = Transform([1, 1, 1], [0, 0, 0, 1], "map", "milk")

milk_pose = milk_transform.to_pose()

print(f"The converted pose:\n{milk_pose}", "\n")

example_transform = Transform([1, 1, 1], [0, 0, 0, 1], "map", "milk")

copy_transform = example_transform.copy()

print(f"The copied transform:\n{copy_transform}")
```

## Operations on Transforms

Transforms have, unlike Poses, operations that can be done. These operations are:

* Multiplication
* Invert
* InverseTimes

### Multiplication

We will first take a look at the multiplication of Transforms. We will use an example were we have two Transforms, the
first from ```map``` to a ```hand``` frame and the second from the ```hand``` to a ```milk``` frame. By multiplying
these two we get the Transform from ```map``` to ```milk``` frame.

```python
from pycram.datastructures.pose import Transform

map_to_hand = Transform([1, 1, 1], [0, 0, 0, 1], "map", "hand")

hand_to_milk = Transform([0.1, 0.05, 0], [0, 0, 0, 1], "hand", "milk")

map_to_milk = map_to_hand * hand_to_milk

print(map_to_milk)
```

### Invert

This inverts a Transform, so in we have a transform from ```map``` to ```milk``` then inverting it results in a
Transform from ```milk``` to ```map``` .

```python
from pycram.datastructures.pose import Transform

map_to_milk = Transform([1, 1, 0.5], [0, 0, 0, 1], "map", "milk")

milk_to_map = map_to_milk.invert()

print(milk_to_map)
```

### Inverse Times

Inverse times combines the inverting and multiplication of Transforms, this results in a 'minus' for Transforms. We will
again use the example of a hand holding a milk, but this time we have the Transforms from ```map``` to ```milk```
and ```hand``` to ```milk```.

```python
from pycram.datastructures.pose import Transform

map_to_milk = Transform([1.1, 1.05, 1], [0, 0, 0, 1], "map", "milk")

hand_to_milk = Transform([0.1, 0.05, 0], [0, 0, 0, 1], "hand", "milk")

map_to_milk = map_to_milk.inverse_times(hand_to_milk)

print(map_to_milk)
```

|------
Robot Description

(robot_description_header)=
The robot description contains semantic information about the robot which can not be extracted from the URDF in a
general way. This inludes kinematic chains, end-effectors, cameras and their parameter, etc.

In genral a Robot Description consists a number of different descriptions, these are:

* RobotDescription
* KinematicChainDescription
* EndEffectorDescription
* CameraDescription

In this example we will create a robot description step-by-step and describe the different components on the way. The
robot we will use as an example will be the PR2, the complete PR2 description can also be seen in
{meth}`pycram.robot_descriptions.pr2_description`.

## Robot Description Class

We start by creating an instance of the {class}`~pycram.robot_description.RobotDescription` class, this will serve as a
the main component to which all other descriptions will be added.

To initialize a {class}`~pycram.robot_description.RobotDescription` we need a few parameter which are:

* Name
* base_link
* torso_link
* torso_joint
* Path to a URDF file

```python
from pycram.robot_description import RobotDescription
import rospkg

rospack = rospkg.RosPack()
filename = rospack.get_path('pycram') + '/resources/robots/' + "pr2" + '.urdf'

pr2_description = RobotDescription("pr2", "base_link", "torso_lift_link", "torso_lift_joint", filename)
```

## Kinematic Chain Description

The kinematic chain description describes a chain of links and joints of the robot which might be interesting when
working with the robot. An example of such a chain would be the arm of the robot, when programming for the robot it is
important to know which links and joints exactly make up the arm, however, these can not be extracted from the URDF
automatically.

The kinematic chain is based upon the URDF, meaning when initializing the description one only needs to specify the
first and last link of the chain.

We will now create the kinematic chain description for the right arm of the PR2. For initializing
the {class}`~pycram.robot_description.KinematicChainDescription` the following parameter are needed:

* Name
* first link
* last link
* URDF object
* Arm type

The arm type specifies which arm this kinematic chain describes, this is needed when one wants to access only the arms
of the robot.

```python
from pycram.robot_description import KinematicChainDescription
from pycram.datastructures.enums import Arms

right_arm = KinematicChainDescription("right", "torso_lift_link", "r_wrist_roll_link",
                                      pr2_description.urdf_object, arm_type=Arms.RIGHT)
```

The created {class}`~pycram.robot_description.KinematicChainDescription` can now be added to the robot description.

```python
pr2_description.add_kinematic_chain_description(right_arm)
```

## End Effector Description

Since kinematic chains only describe a moveable chain of links and joints like arms these do not represent end-effectors
which can be used to do manipulation tasks.

To represent end-effectors we will create an {class}`~pycram.robot_description.EndEffectorDescription` which contains the information of the respective
end-effector. When creating an {class}`~pycram.robot_description.EndEffectorDescription` we need the following parameter:

* Name
* first link
* tool_frame
* URDF object

You might have noticed that the end-efftor only has a first link but no last link, this is the case since end-effectors
are at the end of the arms. Therefore, all links and joints below a certain link can be seen as part of the
end-effector.

```python
from pycram.robot_description import EndEffectorDescription

right_gripper = EndEffectorDescription("right_gripper", "r_gripper_palm_link", "r_gripper_tool_frame",
                                       pr2_description.urdf_object)
```

The gripper can no be added to the previously created {class}`~pycram.robot_description.KinematicChainDescription`.

```python
right_arm.end_effector = right_gripper
```

## Camera Description

The camera description contains all parameters of a camera, which is mounted on the robot. The parameter for
the {class}`~pycram.robot_description.CameraDescription` are:

* Name
* Link name
* minimal height
* maximal height
* horizontal angle
* vertical angle

```python
from pycram.robot_description import CameraDescription
from pycram.datastructures.enums import Grasp

camera = CameraDescription("kinect_camera", "wide_stereo_optical_frame", 1.27,
                           1.60, 0.99483, 0.75049)
```

The finished camera description can now be added to the robot description.

```python
pr2_description.add_camera_description(camera)
```

## Grasps

Grasps define how a robot interacts with objects. The grasps defined in the robot description define for each grasp (
right, left, top, front) the orientation of the end-effector, relative to the base_frame of the robot, to achieve the
respective grasp.

```python
pr2_description.add_grasp_orientations({Grasp.FRONT: [0, 0, 0, 1],
                                        Grasp.LEFT: [0, 0, -1, 1],
                                        Grasp.RIGHT: [0, 0, 1, 1],
                                        Grasp.TOP: [0, 1, 0, 1]})
```

## Register Robot Description

Lastly, you need to register the robot description to the {class}`~pycram.robot_description.RobotDescriptionManager`. As you can see the code to
register the robot description has to be executed at the start of PyCRAM, if you put your file with the robot
description in the {class}`pycram.robot_descriptions` directory it will be executed upon the start of PyCRAM.

```python
from pycram.robot_description import RobotDescriptionManager

rdm = RobotDescriptionManager()
rdm.register_description(pr2_description)
```
