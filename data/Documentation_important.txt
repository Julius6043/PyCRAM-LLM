Welcome to pycram

==================================
Welcome to pycram's documentation!
==================================

.. image:: ../images/pycram_logo.png
   :alt: Pycram Logo

What is PyCRAM?
===============

PyCRAM is the Python 3 re-implementation of `CRAM <https://github.com/cram2/cram>`_.
PyCRAM is a toolbox for designing, implementing and deploying software on autonomous robots.
The framework provides various tools and libraries for aiding in robot software development as well as geometric
reasoning and fast simulation mechanisms to develop cognition-enabled control programs that achieve high levels of robot
autonomy.

PyCRAM is developed in Python with support for the ROS middleware which is used for communication with different
software components as well as the robot.

This framework is tested with Ubuntu 20.04, ROS Noetic and Python 3.8


Simple Demonstration

PyCRAM allows the execution of the same high-level plan on different robot platforms. Below you can see an example of
this where the plan is executed on the PR2 and the IAIs Boxy.

.. list-table::
   :widths: 50 50
   :header-rows: 1

   *  - Boxy
      - PR2
   *  - .. image:: ../images/boxy.gif
            :alt: Boxy robot performing tasks using pycram
      - .. image:: ../images/pr2.gif
            :alt: PR2 robot performing tasks using pycram


The plan that both robots execute is a relatively simple pick and place plan:

 * They start at the world origin
 * park their arms
 * move to the counter
 * observe the object
 * pickup the object
 * move to the kitchen island
 * place the object
 * move to the world origin

The code for this plan can be seen below.

.. code-block:: python

    from pycram.world.bullet_world import BulletWorld
    from pycram.world_concepts.world_concepts import Object
    from pycram.process_module import simulated_robot
    from pycram.designators.motion_designator import *
    from pycram.designators.location_designator import *
    from pycram.designators.action_designator import *
    from pycram.designators.object_designator import *
    from pycram.datastructures.enums import ObjectType, Arms, Grasps

    world = BulletWorld()
    kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
    robot = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
    cereal = Object("cereal", ObjectType.BREAKFAST_CEREAL, "breakfast_cereal.stl", position=[1.4, 1, 0.95])

    cereal_desig = ObjectDesignatorDescription(names=["cereal"])
    kitchen_desig = ObjectDesignatorDescription(names=["kitchen"])
    robot_desig = ObjectDesignatorDescription(names=["pr2"]).resolve()

    with simulated_robot:
        ParkArmsAction([Arms.BOTH]).resolve().perform()

        MoveTorsoAction([0.3]).resolve().perform()

        pickup_pose = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot_desig).resolve()
        pickup_arm = pickup_pose.reachable_arms[0]

        NavigateAction(target_locations=[pickup_pose.pose]).resolve().perform()

        PickUpAction(object_designator_description=cereal_desig, arms=[pickup_arm], grasps=[Grasps.FRONT]).resolve().perform()

        ParkArmsAction([Arms.BOTH]).resolve().perform()

        place_island = SemanticCostmapLocation("kitchen_island_surface", kitchen_desig.resolve(), cereal_desig.resolve()).resolve()

        place_stand = CostmapLocation(place_island.pose, reachable_for=robot_desig, reachable_arm=pickup_arm).resolve()

        NavigateAction(target_locations=[place_stand.pose]).resolve().perform()

        PlaceAction(cereal_desig, target_locations=[place_island.pose], arms=[pickup_arm]).resolve().perform()

        ParkArmsAction([Arms.BOTH]).resolve().perform()

    world.exit()

|------
Designators


Designators are CRAMs and PyCRAMs way of representing actions, motions, objects and locations.

In general, PyCRAM-Designators consist of a description and a specified element.
Descriptions describe sets of designators and designators are one thing in the described set.
For example, such a description could describe an action where the robot moves to a location
from where it can grasp an object. The specific location in this case is not relevant as long
as the robot can reach the object.

The designator description will be resolved during runtime which results in a designator with
specific parameter, the resulting designator can also be performed to let the robot perform the
desired behaviour.

To stay on the example of an action designator which should move the robot to a location from
where it can grasp an object, we will create a NavigateAction description with a list of possible
poses.

.. code-block:: python

    poses = [Pose([1, 0, 0], [0, 0, 0, 1]), Pose([1.2, 0.2, 0], [0, 0, 1, 0])]
    NavigateAction(target_locations=poses)

This is a description of an action which moves the robot to a pose in the environment.
In this case the description describes a set of action designators which have a pose of the ``poses``
list as target location.

By resolving the description it will return a single designator with specific parameter.
This can look like this:

.. code-block:: python

    designator = NavigateAction(target_locations=poses).resolve()

The resolver will check the available parameter and return a designator with appropriate parameter
which can then be performed. The designator returned by the resolver will always be a sub-class
of the description, in this way the designator can be assigned the type of action it performs.
The resolved designator can also contain new parameter which might be relevant for performing the
designator and will be inferred while resolving. A resolved action designator for a navigate
action looks like this:

.. code-block:: python

    NavigateActionPerformable(robot_position=(Pose([0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 1.0]), target_location=Pose([1, 0, 0], [0, 0, 0, 1]))


A visual representation of the whole idea of designator and designator descriptions can be
seen in the following image.

.. image:: ../images/designators.png
   :alt: Schematic representation of Designators.



There are four types of designators in PyCRAM:

 - :mod:`pycram.designators.action_designator`
 - :mod:`pycram.designators.object_designator`
 - :mod:`pycram.designators.location_designator`
 - :mod:`pycram.designators.motion_designator`

Object Designator
=================

Object designators represent objects in (simulated) world.
The description of object designators can take names and types that the object should match.
The :meth:`~pycram.designator.ObjectDesignatorDescription.ground` method returns an object with all
its data attached that matches the description.
The :meth:`~pycram.designator.ObjectDesignatorDescription.__iter__` method iterates over all objects
that match the description.

Contributing Object Designators

Object Designators should always be part of an object designator description.
The general class structure is seen in :mod:`~pycram.designator.ObjectDesignatorDescription`.
New object description need to inherit from the general object description. If the object they ground to differs from
the base object, a `dataclass <https://docs.python.org/3/library/dataclasses.html>`_. should be created inside the new
description. The dataclass is one element that matches the description.
If ORM logging of the new objects is wanted a ``to_sql()`` and ``insert()`` method has to be implemented
(see :ref:`orm` for more details).


Action Designator
=================
Action designators describe complex actions that are executable for an agent. Action designators can be seen as higher
level plans that include failure handling and parametrization.
An action designator description always takes the parameter as a list of possible parameter, when
resolving the description to a single designator one parameter out of the given list will be picked.

Motion Designator
=================
Motion designators describe atomic actions that are executable for an agent. In contrast to action
designators there is no failure handling or other action designators. Furthermore, the :meth:`~pycram.designator.MotionDesignatorDescription.Motion.perform`
method passes the resolved motion designator to the respective Process Module for execution on the robot.

Another difference to action designator is that motion designators only take a single parameter instead of a
list, this parameter is also strictly typed.

Location Designator
===================
Location designator describe a set of locations in regards to specific constrains. These constrains can be things
like ``reachable`` or ``visible``. The pose returned by a location designator is a single pose of the set defined
by the constrains given to the location designator description.

Similar to object designator poses location designator also a :meth:`~pycram.designators.location_designator.CostmapLocation.__iter__`
method which can iterate over all possible solutions for this description.

Creating your own Designator
============================
Creating your own designator is fairly easy, you only need to extend the base class of the respective description.

 - :mod:`~pycram.designator.ActionDesignatorDescription`
 - :mod:`~pycram.designator.ObjectDesignatorDescription`
 - :mod:`~pycram.designator.LocationDesignatorDescription`
 - :mod:`~pycram.designator.BaseMotion`

Afterwards you need to implement your own ``ground`` method which is the default resolver and for location and object
designator it makes sense to also implement a ``__iter__`` method. The ``ground`` and ``__iter__`` methods should return
the designator sub-class so you also need to implement these with the parameter your designator needs.

The sub-class can already contain some parameters, this is usually the case if the parameter is the same for every designator
of this type. For example, :class:`~pycram.designator.LocationDesignatorDescription.Location`
contains a ``pose`` parameter since every location designator contains a resolved pose.

For action and motion designator the sub-class is also the place where the ``perform`` method is written which contains
the behaviour of the designator.

|------
Troubleshooting

This page contains the most common errors that could happen when using PyCRAM and how to resolve them.


Ros Init Exception

.. code-block:: Python

    ROSInitException: time is not initialized. Have you called init_node()

This exception usually occurs when trying to load an Object into the BulletWorld or when creating a Pose. The reason for
this exception is that the ROS node of PyCRAM could not be initialized, this is usually the case when the PyCRAM launch
file was not launched.

To solve this problem you just have to launch the ``ik_and_description`` file of PyCRAM. This can be done via the
following command.

.. code-block:: shell

    roslaunch pycram ik_and_description


Robot Description not Loaded

In PyCRAM a lot of things are base on the robot description that is currently loaded and in turn the robot description
that will be loaded depends on the robot description that is on the ROS parameter server at the time PyCRAM is started.

If you get an error that looks similar to the following exception the most likely case is that the robot description was
not loaded.

.. code-block:: python
   :emphasize-lines: 3

        763 with open(self.path) as f:
        764     self.urdf_object = URDF.from_xml_string(f.read())
    --> 765     if self.urdf_object.name == robot_description.name and not BulletWorld.robot:
        766         BulletWorld.robot = self
        768 self.links[self.urdf_object.get_root()] = -1

    AttributeError: 'NoneType' object has no attribute 'name'


There could be a few reasons for this behaviour:
   * The name of the URDF on the parameter server and the name in the PyCRAM robot description are different
      * The PyCRAM robot description is matched by the name of the robot in the URDF
      * You can check the assignment of the PyCRAM robot description in this function :func:`~pycram.robot_descriptions.update_robot_description` (there is a link to the source code)
   * You only started a roscore
   * You did not start the ``ik_and_description`` launch file


Stop Iteration

Stop iterations usually happen when you try to resolve a designator for which there is no solution or if you iterate over a
designator and reached the end of all possible solutions.

When you try to resolve a designator which has no solution the error will look something like this.

.. code-block:: python
   :emphasize-lines: 7

       753 def ground(self) -> Union[Object, bool]:
       754     """
       755     Return the first object from the bullet world that fits the description.
       756
       757     :return: A resolved object designator
       758     """
   --> 759     return next(iter(self))

   StopIteration:

If you encounter such an error the most likely reason is that you put the wrong arguments into your DesignatorDescription.
The best solution is to double check the input arguments of the DesignatorDescription.



BulletWorld crashes after loading an URDF

It can happen that the BulletWorld crashes when loading a URDF. This happens when loading a URDF with more than 127 links.
This is a limitation of PyBullet which can not deal with objects with more links.

Only real solution here is to either delete links such that you have at max 127 links or split up the URDF and load the
split parts individually.


Error when performing Actions or Motions

.. code-block:: python

        30 def perform(self):
        31     pm_manager = ProcessModuleManager.get_manager()
   ---> 32     return pm_manager.navigate().execute(self)

   AttributeError: 'NoneType' object has no attribute 'navigate'

If you get an error like this when trying to perform an action or motion designator, then you did not specify how the
designator should be executed. You can specify how the designator should be performed by using the simulated_robot or
real_robot environments. This is also explained in the `Action Designator Example <https://pycram.readthedocs.io/en/latest/notebooks/action_designator.html#Navigate-Action>`_.

.. code-block:: python

   with simulated_robot:
      NavigateAction([Pose()]).resolve().perform()

Missing pr2_arm_kinematics
==========================

Aptitudes autoremove likes to also remove the arm kinematics. The error message looks similar to this. Important is the
missing library libmoveit_kinematics_base.so. This can be fixed by reinstalling the missing libraries.

.. code-block:: shell

   process[pr2_left_arm_kinematics-3]: started with pid [26862]
   pr2_arm_kinematics_node: error while loading shared libraries: libmoveit_kinematics_base.so.1.1.12: cannot open shared object file: No such file or directory
   process[pr2_right_arm_kinematics-4]: started with pid [26863]
   [pr2_left_arm_kinematics-3] process has died [pid 26862, exit code 127, cmd ~/pycram/devel/lib/pr2_arm_kinematics/pr2_arm_kinematics_node __name:=pr2_left_arm_kinematics __log:=~/.ros/log/ba5e95de-384f-11ee-ab53-97c8787037e5/pr2_left_arm_kinematics-3.log].
   log file: ~/.ros/log/ba5e95de-384f-11ee-ab53-97c8787037e5/pr2_left_arm_kinematics-3*.log
   pr2_arm_kinematics_node: error while loading shared libraries: libmoveit_kinematics_base.so.1.1.12: cannot open shared object file: No such file or directory
   [pr2_right_arm_kinematics-4] process has died [pid 26863, exit code 127, cmd ~/pycram/devel/lib/pr2_arm_kinematics/pr2_arm_kinematics_node __name:=pr2_right_arm_kinematics __log:=~/.ros/log/ba5e95de-384f-11ee-ab53-97c8787037e5/pr2_right_arm_kinematics-4.log].
   log file: ~/.ros/log/ba5e95de-384f-11ee-ab53-97c8787037e5/pr2_right_arm_kinematics-4*.log
   IK server ready.


Reinstall the missing libraries with

.. code-block:: shell

    sudo apt-get install ros-noetic-moveit

Then rebuild your workspace.

|------
PyCRAM Introduction

```python
import pycram
```

# Bullet World

The BulletWorld is the internal simulation of PyCRAM. You can simulate different actions and reason about the outcome of
different actions.

It is possible to spawn objects and robots into the BulletWorld, these objects can come from URDF, OBJ or STL files.

A BulletWorld can be created by simply creating an object of the BulletWorld class.

```python
from pycram.worlds.bullet_world import BulletWorld
from pycram.world_concepts.world_object import Object
from pycram.datastructures.enums import ObjectType
from pycram.datastructures.pose import Pose

world = BulletWorld()
```

The BulletWorld allows to render images from arbitrary positions. In the following example we render images with the
camera at the position [0.3, 0, 1] and pointing towards [1, 0, 1], so we are looking upwards along the x-axis.

The renderer returns 3 different kinds of images which are also shown on the left side of the BulletWorld window. (If
these winodws are missing, click the BulletWorld window to focus it, and press "g") These images are:

* An RGB image which shows everything like it is rendered in the BulletWorld window, just from another perspective.
* A depth image which consists of distance values from the camera towards the objects in the field of view.
* A segmentation mask image which segments the image into the different objects displayed. The segmentation is done by
  assigning every pixel the unique id of the object that is displayed there.

```python
world.get_images_for_target(Pose([1, 0, 1], [0, 0, 0, 1]), Pose([0.3, 0, 1], [0, 0, 0, 1]))
```

## Objects

Everything that is located inside the BulletWorld is an Object.
Objects can be created from URDF, OBJ or STL files. Since everything is of type Object a robot might share the same
methods as a milk (with some limitations).

Signature:
Object:

* Name
* Type
* Filename or Filepath

Optional:

* Position
* Orientation
* World
* Color
* Ignore Cached Files

If there is only a filename and no path, PyCRAM will check in the resource directory if there is a matching file.

```python
milk = Object("Milk", ObjectType.MILK, "milk.stl")
```

Objects provide methods to change the position and rotation, change the color, attach other objects, set the state of
joints if the objects has any or get the position and orientation of a link.

These methods are the same for every Object, however since some Objects may not have joints or more than one link
methods related to these will not work.

```python
milk.set_position(Pose([1, 0, 0]))
```

To remove an Object from the BulletWorld just call the 'remove' method on the Object.

```python
milk.remove()
```

Since everything inside the BulletWorld is an Object, even a complex environment Object like the kitchen can be spawned
in the same way as the milk.

```python
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
```

## Costmaps

Costmaps are a way to get positions with respect to certain criterias.
The currently available costmaps are:

* {class}`~pycram.costmaps.OccupancyCostmap`
* {class}`~pycram.costmaps.VisibilityCostmap`
* {class}`~pycram.costmaps.SemanticCostmap`
* {class}`~pycram.costmaps.GaussianCostmap`

It is also possible to merge multiple costmaps to combine different criteria.

### Visibility Costmaps

Visibility costmaps determine every position, around a target position, from which the target is visible. Visibility
Costmaps are able to work with cameras that are movable in height for example, if the robot has a movable torso.

```python
import pycram.costmaps as cm

v = cm.VisibilityCostmap(1.27, 1.60, size=300, resolution=0.02, origin=Pose([0, 0, 0.1], [0, 0, 0, 1]))
```

```python
v.visualize()
```

```python
v.close_visualization()
```

### Occupancy Costmap

Is valid for every position where the robot can be placed without colliding with an object.

```python
o = cm.OccupancyCostmap(0.2, from_ros=False, size=300, resolution=0.02, origin=Pose([0, 0, 0.1], [0, 0, 0, 1]))
```

```python
s = cm.SemanticCostmap(kitchen, "kitchen_island_surface", size=100, resolution=0.02)

g = cm.GaussianCostmap(200, 15, resolution=0.02)
```

You can visualize the costmap in the BulletWorld to get an impression what information is actually contained in the
costmap. With this you could also check if the costmap was created correctly.
Visualization can be done via the 'visualize' method of each costmap.

```python
o.visualize()
```

```python
o.close_visualization()
```

It is also possible to combine two costmap, this will result in a new costmap with the same size which contains the
information of both previous costmaps. Combination is done by checking for each position in the two costmaps if they are
zero, in this case to same position in the new costmap will also be zero in any other case the new position will be the
normalized product of the two combined costmaps.

```python
ov = o + v
```

```python
ov.visualize()
```

```python
ov.close_visualization()
```

## Bullet World Reasoning

Allows for geometric reasoning in the BulletWorld. At the moment the following types of reasoning are supported:

* {meth}`~pycram.world_reasoning.stable`
* {meth}`~pycram.world_reasoning.contact`
* {meth}`~pycram.world_reasoning.visible`
* {meth}`~pycram.world_reasoning.occluding`
* {meth}`~pycram.world_reasoning.reachable`
* {meth}`~pycram.world_reasoning.blocking`
* {meth}`~pycram.world_reasoning.supporting`

To show the geometric reasoning we first spawn a robot as well as the milk Object again.

```python
import pycram.world_reasoning as btr

milk = Object("Milk", ObjectType.MILK, "milk.stl", pose=Pose([1, 0, 1]))
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
```

We start with testing for visibility

```python
milk.set_position(Pose([1, 0, 1]))
visible = btr.visible(milk, pr2.get_link_pose("wide_stereo_optical_frame"))
print(f"Milk visible: {visible}")
```

```python
milk.set_position(Pose([1, 0, 0.05]))

plane = BulletWorld.current_bullet_world.objects[0]
contact = btr.contact(milk, plane)
print(f"Milk is in contact with the floor: {contact}")
```

```python
milk.set_position(Pose([0.6, -0.5, 0.7]))

reachable = btr.reachable(milk, pr2, "r_gripper_tool_frame")
print(f"Milk is reachable for the PR2: {reachable}")
```

# Designators

Designators are symbolic descriptions of Actions, Motions, Objects or Locations. In PyCRAM the different types of
designators are represented by a class which takes a description, the description then tells the designator what to do.

For example, let's look at a Motion Designator to move the robot to a specific location.

## Motion Designators

When using a Motion Designator you need to specify which Process Module needs to be used, either the Process Module for
the real or the simulated robot. A Process Module is the interface between a real or simulated robot, and PyCRAM
designators. By exchanging the Process Module, one can quickly change the robot the plan is executed on, allowing PyCRAM
plans to be re-used across multiple robot platforms. This can be done either with a decorator which can be added to a
function and then every designator executed within this function, will be executed on the specified robot. The other
possibility is a "with" scope which wraps a code piece.

These two ways can also be combined, you could write a function which should be executed on the real robot and the
function contains a "with" scope which executes something on the simulated robot for reasoning purposes.

```python
from pycram.designators.motion_designator import *
from pycram.process_module import simulated_robot, with_simulated_robot

description = MoveMotion(target=Pose([1, 0, 0], [0, 0, 0, 1]))

with simulated_robot:
    description.perform()


```

```python
from pycram.process_module import with_simulated_robot


@with_simulated_robot
def move():
    MoveMotion(target=Pose([0, 0, 0], [0, 0, 0, 1])).perform()


move()
```

Other implemented Motion Designator descriptions are:

* Accessing
* Move TCP
* Looking
* Move Gripper
* Detecting
* Move Arm Joint
* World State Detecting

## Object Designators

An Object Designator represents objects. These objects could either be from the BulletWorld or the real world. Object
Designators are used, for example, by the PickUpAction to know which object should be picked up.

```python
from pycram.designators.object_designator import *

milk_desig = BelieveObject(names=["Milk"])
milk_desig.resolve()
```

## Location Designator

Location Designator can create a position in cartisian space from a symbolic desctiption

```python
from pycram.designators.object_designator import *

milk_desig = BelieveObject(names=["Milk"])
milk_desig.resolve()
```

## Location Designators

Location Designators can create a position in cartesian space from a symbolic description.

```python
from pycram.designators.location_designator import *
from pycram.designators.object_designator import *

robot_desig = BelieveObject(types=[ObjectType.ROBOT]).resolve()
milk_desig = BelieveObject(names=["Milk"]).resolve()
location_desig = CostmapLocation(target=milk_desig, visible_for=robot_desig)

print(f"Resolved: {location_desig.resolve()}")
print()

for pose in location_desig:
    print(pose)

```

# Action Designator

Action Designators are used to describe high-level actions. Action Designators are usually composed of other Designators
to describe the high-level action in detail.

```python
from pycram.designators.action_designator import *
from pycram.datastructures.enums import Arms

with simulated_robot:
    ParkArmsAction([Arms.BOTH]).resolve().perform()

```

# Making a simple plan

To get familiar with the PyCRAM Framework we will write a simple pick and place plan. This plan will let the robot grasp
a cereal box from the kitchen counter and place it on the kitchen island. This is a simple pick and place plan.

```python
from pycram.designators.object_designator import *

cereal = Object("cereal", ObjectType.BREAKFAST_CEREAL, "breakfast_cereal.stl", pose=Pose([1.4, 1, 0.95]))

```

```python
cereal_desig = ObjectDesignatorDescription(names=["cereal"])
kitchen_desig = ObjectDesignatorDescription(names=["kitchen"])
robot_desig = ObjectDesignatorDescription(names=["pr2"]).resolve()
with simulated_robot:
    ParkArmsAction([Arms.BOTH]).resolve().perform()

    MoveTorsoAction([0.3]).resolve().perform()

    pickup_pose = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot_desig).resolve()
    pickup_arm = pickup_pose.reachable_arms[0]

    NavigateAction(target_locations=[pickup_pose.pose]).resolve().perform()

    PickUpAction(object_designator_description=cereal_desig, arms=[pickup_arm], grasps=["front"]).resolve().perform()

    ParkArmsAction([Arms.BOTH]).resolve().perform()

    place_island = SemanticCostmapLocation("kitchen_island_surface", kitchen_desig.resolve(),
                                           cereal_desig.resolve()).resolve()

    place_stand = CostmapLocation(place_island.pose, reachable_for=robot_desig, reachable_arm=pickup_arm).resolve()

    NavigateAction(target_locations=[place_stand.pose]).resolve().perform()

    PlaceAction(cereal_desig, target_locations=[place_island.pose], arms=[pickup_arm]).resolve().perform()

    ParkArmsAction([Arms.BOTH]).resolve().perform()



```

# Task Trees

Task trees are a hierarchical representation of all Actions involved in a plan. The Task tree can later be used to
inspect and restructure the execution order of Actions in the plan.

```python
import pycram.task
import anytree

tt = pycram.task.task_tree
print(anytree.RenderTree(tt))
```

```python
from anytree.dotexport import RenderTreeGraph, DotExporter

RenderTreeGraph(tt).to_picture("tree.png")
```

# ORM

```python
import sqlalchemy.orm
import pycram.orm.base
import pycram.orm.action_designator

# set description of what we are doing
pycram.orm.base.ProcessMetaData().description = "Tutorial for getting familiar with the ORM."

engine = sqlalchemy.create_engine("sqlite+pysqlite:///:memory:", echo=False)
session = sqlalchemy.orm.Session(bind=engine)
pycram.orm.base.Base.metadata.create_all(engine)
session.commit()

tt.insert(session)
```

```python
from sqlalchemy import select

navigations = session.scalars(select(pycram.orm.action_designator.NavigateAction)).all()
print(*navigations, sep="\n")
```

```python
navigations = (session.scalars(
    select(pycram.orm.action_designator.NavigateAction, pycram.orm.base.Position, pycram.orm.base.Quaternion).
    join(pycram.orm.action_designator.NavigateAction.pose).
    join(pycram.orm.base.Pose.position).
    join(pycram.orm.base.Pose.orientation)).all())
print(*navigations, sep="\n")
```

The world can also be closed with the 'exit' method

```python
world.exit()
```

|------
Bullet World

This Notebook will show you the basics of working with the PyCRAM BulletWorld.

First we need to import and create a BulletWorld.

```python
from pycram.worlds.bullet_world import BulletWorld
from pycram.datastructures.pose import Pose
from pycram.datastructures.enums import ObjectType, WorldMode

world = BulletWorld(mode=WorldMode.GUI)
```

This new window is the BulletWorld, PyCRAMs internal physics simulation. You can use the mouse to move the camera
around:

* Press the left mouse button to rotate the camera
* Press the right mouse button to move the camera
* Press the middle mouse button (scroll wheel) and move the mouse up or down to zoom

At the moment the BulletWorld only contains a floor, this is spawned by default when creating the BulletWorld.
Furthermore, the gravity is set to 9.8 $m^2$, which is the same gravitation as the one on earth.

To spawn new things in the BulletWorld we need to import the Object class and create and instance of it.

```python
from pycram.world_concepts.world_object import Object

milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([0, 0, 1]))
```

<!-- #region -->
As you can see this spawns a milk floating in the air. What we did here was create a new Object which has the name "
milk" as well as the type {attr}`~pycram.datastructures.enums.ObjectType.MILK`, is spawned from the file "milk.stl" and is at the position [0, 0, 1].

The type of an Object can either be from the enum ObjectType or a string. However, it is recommended to use the enum
since this would make for a more consistent naming of types which makes it easier to work with types. But since the
types of the enum might not fit your case you can also use strings.

The first three of these parameters are required while the position is optional. As you can see it was sufficient to
only specify the filename for PyCRAM to spawn the milk mesh. When only providing a filename, PyCRAM will search in its
resource directory for a matching file and use it.

For a complete list of all parameters that can be used to crate an Object please check the documentation.

Since the Object is spawned, we can now interact with it. First we want to move it around and change its orientation
<!-- #endregion -->

```python
milk.set_position(Pose([1, 1, 1]))
```

```python
milk.set_orientation(Pose(orientation=[1, 0, 0, 1]))
```

```python
milk.set_pose(Pose([0, 0, 1], [0, 0, 0, 1]))
```

In the same sense as setting the position or orientation, you can also get the position and orientation.

```python
print(f"Position: \n{milk.get_position()}")

print(f"Orientation: \n{milk.get_orientation()}")

print(f"Pose: \n{milk.get_pose()}")
```

## Attachments

You can attach Objects to each other simply by calling the attach method on one of them and providing the other as
parameter. Since attachments are bi-directional it doesn't matter on which Object you call the method.

First we need another Object

```python
cereal = Object("cereal", ObjectType.BREAKFAST_CEREAL, "breakfast_cereal.stl", pose=Pose([1, 0, 1]))
```

```python
milk.attach(cereal)
```

Now since they are attached to each other, if we move one of them the other will move in conjunction.

```python
milk.set_position(Pose([1, 1, 1]))
```

In the same way the Object can also be detached, just call the detach method on one of the two attached Objects.

```python
cereal.detach(milk)
```

## Links and Joints

Objects spawned from mesh files do not have links or joints, but if you spawn things from a URDF like a robot they will
have a lot of links and joints. Every Object has two dictionaries as attributes, namely ```links``` and ```joints```
which contain every link or joint as key and a unique id, used by PyBullet, as value.

We will see this at the example of the PR2:

```python
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
print(pr2.links)
```

For links there are similar methods available as for the pose. However, you can only **get** the position and
orientation of a link.

```python
print(f"Position: \n{pr2.get_link_position('torso_lift_link')}")

print(f"Orientation: \n{pr2.get_link_orientation('torso_lift_link')}")

print(f"Pose: \n{pr2.get_link_pose('torso_lift_link')}")
```

Methods available for joints are:

* {meth}`~pycram.world_concepts.world_object.Object.get_joint_position`
* {meth}`~pycram.world_concepts.world_object.Object.set_joint_position`
* {meth}`~pycram.world_concepts.world_object.Object.get_joint_limits`

We will see how these methods work at the example of the torso_lift_joint:

```python
print(f"Joint limits: {pr2.get_joint_limits('torso_lift_joint')}")

print(f"Current Joint state: {pr2.get_joint_position('torso_lift_joint')}")

pr2.set_joint_position("torso_lift_joint", 0.2)

print(f"New Joint state: {pr2.get_joint_position('torso_lift_joint')}")
```

## Misc Methods

There are a few methods that don't fit any category but could be helpful anyway. The first two are {meth}`~pycram.description.Link.get_color`
and {meth}`~pycram.description.Link.set_color`, as the name implies they can be used to get or set the color for specific links or the whole
Object.

```python
print(f"Pr2 forearm color: {pr2.get_link_color('r_forearm_link')}")
```

```python
pr2.set_link_color("r_forearm_link", [1, 0, 0])
```

Lastly, there is {meth}`~pycram.description.Link.get_axis_aligned_bounding_box`, AABB stands for *A*xis *A*ligned *B*ounding *B*ox. This method returns two points in
world coordinates which span a rectangle representing the AABB.

```python
pr2.get_axis_aligned_bounding_box()
```

To close the BulletWorld again please use the {meth}`~pycram.datastructures.world.World.exit` method since it will also terminate threads running in the
background

```python
world.exit()
```

|------
Plan Language

The PyCRAM plan language is a way to structure the execution of your plan. In generally the plan language allows to
execute designators either sequential or in parallel. Furthermore, exceptions that occur during execution of a plan with
the plan language do not interrupt the execution instead they are caught and saved to a dictionary for later analysis.
All language expressions return a State, this can either be SUCCEDED or FAILED.

There are 4 language expressions:

| Expression | Name             | Description                                                                                                                                                                                                                                                                                | 
|------------|------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| +          | **Sequential**   | Executes the designators one after another, if one of the designators raises an exception the execution is aborted and the state FAILED will be returned.                                                                                                                                  |
| -          | **Try In Order** | Executes the designators one after another, if one designator raises an exception the exception is caught and saved but the execution is not interrupted and the other designators are executed. Returns the state SUCCEDED if at least one designator can be executed without exception. |
| *          | **Repeat**       | Repeat the previous language expression a number of time. Has to be used with a language expression and an integer.                                                                                                                                                                        | 
| \|         | **Parallel**     | Executes all designators in parallel. For each designator there will be a new thread created and the designator is executed in this thread. If one of the designators raises an exception the returned state will be FAILED.                                                               |
| ^          | **Try All**      | Executes all designators in parallel with a designated thread for each designator. Returns the state SUCCEDED if at least one designator can be executed without an exception                                                                                                              |
| >>         | **Monitor**      | Monitors the execution of the attached langauge expression, will interrupt the execution as soon as a given condition is fulfilled.                                                                                                                                                        | 

The Sequential expression is the only one which aborts the execution once an error is raised.

When using the plan language a tree structure of the plan is created where the language expressions are nodes and
designators are leafs. This tree uses AnyTree (like the task tree) and can be rendered with the anytree Renderer.

## Sequential

This language expression allows to execute designators one after another, if one of the designators raises an exception
the execution will be aborted and the state FAILED will be returned.

We will start with a simple example that uses an action designator for moving the robot and parking its arms.

```python
import time

from pycram.designators.action_designator import *
from pycram.datastructures.pose import Pose
from pycram.datastructures.enums import Arms

navigate = NavigateAction([Pose([1, 1, 0])])
park = ParkArmsAction([Arms.BOTH])

plan = navigate + park
```

With this simple plan created we can inspect it and render the created tree structure.

```python
from anytree import RenderTree

print(RenderTree(plan))
```

As you can see there is the root node which is the language expression and then there are the leafs which are the
designators. When executing this plan the Sequential node will try to execute the NavigateAction and if that is finished
without any error the ParkArmsAction will be executed.

The plan can be executed by wrapping it inside a ```with simulated_robot``` environment and calling perform on the
plan.

If you are performing a plan with a simulated robot, you need a BulletWorld.

```python
from pycram.worlds.bullet_world import BulletWorld
from pycram.world_concepts.world_object import Object
from pycram.datastructures.enums import ObjectType

world = BulletWorld()
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
```

```python
from pycram.process_module import simulated_robot

world.reset_bullet_world()

with simulated_robot:
    plan.perform()
```

## Try In Order

Try in order is similar to Sequential, it also executes all designators one after another but the key difference is that
an exception in one of the designators does not terminate the whole execution. Furthermore, the state FAILED will only
be returned if all designator executions raise an error.

Besides the described difference in behaviour this language expression can be used in the same way as Sequential.

```python
from pycram.designators.action_designator import *
from pycram.datastructures.pose import Pose
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot

world.reset_bullet_world()

navigate = NavigateAction([Pose([1, 1, 0])])
park = ParkArmsAction([Arms.BOTH])

plan = navigate - park

with simulated_robot:
    plan.perform()
```

## Parallel

Parallel executes all designator at once in dedicated threads. The execution of other designators is not aborted when a
exception is raised, this is the case since threads can not be killed from the outside and this would also cause
unforeseen problems. The state returned will be SUCCEDED if all designators could be executed without an exception raised
in any other case FAILED will be returned.

Since executing designators in parallel can get chaotic especially with complex actions like PickUp or Transport. For
this reason not all action designators can be used in parallel and try all expressions. The list of action designator
that cannot be used in language expressions can be seen in {attr}`~pycram.language.Language.parallel_blocklist`.

Designators that cannot be used in parallel and try all:

* PickUpAction
* PlaceAction
* OpenAction
* CloseAction
* TransportAction

Using the parallel expressions works like Sequential and TryInOrder.

```python
from pycram.designators.action_designator import *
from pycram.datastructures.pose import Pose
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot

world.reset_world()

navigate = NavigateAction([Pose([1, 1, 0])])
park = ParkArmsAction([Arms.BOTH])

plan = navigate | park

with simulated_robot:
    plan.perform()
```

## Try All

TryAll is to Parallel what TryInOrder is to Sequential, meaning TryAll will also execute all designators in parallel but
will return SUCCEEDED if at least one designator is executed without raising an exception.

TryAll can be used like any other language expression.

```python
from pycram.designators.action_designator import *
from pycram.datastructures.pose import Pose
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot

world.reset_bullet_world()

navigate = NavigateAction([Pose([1, 1, 0])])
park = ParkArmsAction([Arms.BOTH])

plan = navigate ^ park

with simulated_robot:
    plan.perform()
```

## Combination of Expressions

You can also combine different language expressions to further structure your plans. If you combine sequential and
parallel expression please keep in mind that sequential expressions bind stringer than parallel ones. For example:

```
navigate | park + move_torso
```

In this case 'park' and 'move_torso' would form a Sequential expression and 'naviagte' would form a Parallel expression
with Sequential. You can try this yourself in the following cell.

```python
from pycram.designators.action_designator import *
from pycram.datastructures.pose import Pose
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot

world.reset_world()

navigate = NavigateAction([Pose([1, 1, 0])])
park = ParkArmsAction([Arms.BOTH])
move_torso = MoveTorsoAction([0.3])

plan = navigate | park + move_torso

with simulated_robot:
    plan.perform()
```

## Code Objects

You can not only use designators in the plan language but also python code. For this there is the {class}`~pycram.language.Code`  object
which takes a callable and the arguments for this callable. This allows you to execute arbitrary code in a plan.

The callable that is used in the {class}`~pycram.language.Code` object can either be a lambda expression or, for more complex code, a
function. If you use a function you can provide parameters as keyword-arguments.

```python
from pycram.designators.action_designator import *
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot
from pycram.language import Code


def code_test(param):
    print("-" * 20)
    print(param)


park = ParkArmsAction([Arms.BOTH])
code = Code(lambda: print("This is from the code object"))
code_func = Code(code_test, {"param": "Code function"})

plan = park | code | code_func

with simulated_robot:
    plan.perform()
```

## Exception Handling

If an exception is raised during the execution of a designator when it is used in a language expression the exception
will be caught and saved to a dictionary. In general all designators in a language expression are executed regardless
of exceptions raised, the only exception from this is the Sequential expression which stops after it encountered an
exception.

The language will only catch exceptions that are of type {class}`~pycram.plan_failures.PlanFailure` meaning errors that are defined in
plan_failures.py in PyCRAM. This also means normal Python errors, such as KeyError, will interrupt the execution of your
designators.

We will see how exceptions are handled at a simple example.

```python
from pycram.designators.action_designator import *
from pycram.process_module import simulated_robot
from pycram.language import Code
from pycram.plan_failures import PlanFailure


def code_test():
    raise PlanFailure


navigate = NavigateAction([Pose([1, 1, 0])])
code_func = Code(code_test)

plan = navigate | code_func

with simulated_robot:
    plan.perform()

print(plan.exceptions)
```

## Repeat

Repeat simply repeats a language expression a number of times. As all other language expressions Repeat captures
exceptions that occur during execution and saves them to the dictionary in the root of the plan.

Since Repeat uses the \* operator you should keep in mind that it will be evaluated before any other operator, so use
parentheses to ensure the correct structure of your plan.

You can see an example of how to use Repeat below.

```python
from pycram.designators.action_designator import *
from pycram.process_module import simulated_robot

move_torso_up = MoveTorsoAction([0.3])
move_torso_down = MoveTorsoAction([0.])

plan = (move_torso_up + move_torso_down) * 5

with simulated_robot:
    plan.perform()
```

## Monitor

Monitor allows to monitor the execution of a language expression and interrupt it as soon as a given condition is
fulfilled. The condition can either be a Callable which returns a boolean or a Fluent.
When executed the Monitor will create a separate thread which will check if the condition is satisfied with a frequency
of 10 Hz. If the condition is satisfied the execution of the language expression will be interrupted.

For the example on how Monitors work we will use the previous example with the robot moving up and down. We will use a
Monitor to interrupt the execution after 2 seconds instead of executing the whole plan 5 times.

```python
from pycram.designators.action_designator import *
from pycram.process_module import simulated_robot
from pycram.language import Monitor
import time

move_torso_up = MoveTorsoAction([0.3])
move_torso_down = MoveTorsoAction([0.])


def monitor_func():
    time.sleep(2)
    return True


plan = (move_torso_up + move_torso_down) * 5 >> Monitor(monitor_func)

with simulated_robot:
    plan.perform()
```

If you are finished with this example you can close the world with the cell below.

```python
world.exit()
```

|------
Action Designator

This example will show the different kinds of Action Designators that are available. We will see how to create Action
Designators and what they do.

Action Designators are high-level descriptions of actions which the robot should execute.

Action Designators are created from an Action Designator Description, which describes the type of action as well as the
parameter for this action. Parameter are given as a list of possible parameters.
For example, if you want to describe the robot moving to a table you would need a
{meth}`~pycram.designators.action_designator.NavigateAction` and a list of poses that are near the table. The Action
Designator Description will then pick one of the poses and return a performable Action Designator which contains the
picked pose.


<!-- #endregion -->

## Navigate Action

We will start with a simple example of the {meth}`~pycram.designators.action_designator.NavigateAction`.

First, we need a BulletWorld with a robot.

```python
from pycram.worlds.bullet_world import BulletWorld
from pycram.world_concepts.world_object import Object
from pycram.datastructures.enums import ObjectType, WorldMode

world = BulletWorld(WorldMode.GUI)
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
```

To move the robot we need to create a description and resolve it to an actual Designator. The description of navigation
only needs a list of possible poses.

```python
from pycram.designators.action_designator import NavigateAction
from pycram.datastructures.pose import Pose

pose = Pose([1, 0, 0], [0, 0, 0, 1])

# This is the Designator Description
navigate_description = NavigateAction(target_locations=[pose])

# This is the performable Designator
navigate_designator = navigate_description.resolve()
```

What we now did was: create the pose where we want to move the robot, create a description describing a navigation with
a list of possible poses (in this case the list contains only one pose) and create an action designator from the
description. The action designator contains the pose picked from the list of possible poses and can be performed.

```python
from pycram.process_module import simulated_robot

with simulated_robot:
    navigate_designator.perform()
```

Every designator that is performed needs to be in an environment that specifies where to perform the designator either
on the real robot or the simulated one. This environment is called {meth}`~pycram.process_module.simulated_robot`  similar there is also
a {meth}`~pycram.process_module.real_robot` environment.

There are also decorators which do the same thing but for whole methods, they are called {meth}`~pycram.process_module.with_real_robot` 
and {meth}`~pycram.process_module.with_simulated_robot`.

## Move Torso

This action designator moves the torso up or down, specifically it sets the torso joint to a given value.

We start again by creating a description and resolving it to a designator. Afterwards, the designator is performed in
a {meth}`~pycram.process_module.simulated_robot` environment.

```python
from pycram.designators.action_designator import MoveTorsoAction
from pycram.process_module import simulated_robot

torso_pose = 0.2

torso_desig = MoveTorsoAction([torso_pose]).resolve()

with simulated_robot:
    torso_desig.perform()
```

## Set Gripper

As the name implies, this action designator is used to open or close the gripper.

The procedure is similar to the last time, but this time we will shorten it a bit.

```python
from pycram.designators.action_designator import SetGripperAction
from pycram.process_module import simulated_robot
from pycram.datastructures.enums import GripperState, Arms

gripper = Arms.RIGHT
motion = GripperState.OPEN

with simulated_robot:
    SetGripperAction(grippers=[gripper], motions=[motion]).resolve().perform()
```

## Park Arms

Park arms is used to move one or both arms into the default parking position.

```python
from pycram.designators.action_designator import ParkArmsAction
from pycram.process_module import simulated_robot
from pycram.datastructures.enums import Arms

with simulated_robot:
    ParkArmsAction([Arms.BOTH]).resolve().perform()
```

## Pick Up and Place

Since these two are dependent on each other, meaning you can only place something when you picked it up beforehand, they
will be shown together.

These action designators use object designators, which will not be further explained in this tutorial so please check
the example on object designators for more details.

To start we need an environment in which we can pick up and place things as well as an object to pick up.

```python
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))

world.reset_world()
```

```python
from pycram.designators.action_designator import PickUpAction, PlaceAction, ParkArmsAction, MoveTorsoAction,

NavigateAction
from pycram.designators.object_designator import BelieveObject
from pycram.process_module import simulated_robot
from pycram.datastructures.enums import Arms, Grasp
from pycram.datastructures.pose import Pose

milk_desig = BelieveObject(names=["milk"])
arm = Arms.RIGHT

with simulated_robot:
    ParkArmsAction([Arms.BOTH]).resolve().perform()

    MoveTorsoAction([0.3]).resolve().perform()

    NavigateAction([Pose([0.78, 1, 0.0],
                         [0.0, 0.0, 0.014701099828940344, 0.9998919329926708])]).resolve().perform()

    PickUpAction(object_designator_description=milk_desig,
                 arms=[arm],
                 grasps=[Grasp.RIGHT]).resolve().perform()

    NavigateAction([Pose([-1.90, 0.78, 0.0],
                         [0.0, 0.0, 0.16439898301071468, 0.9863939245479175])]).resolve().perform()

    PlaceAction(object_designator_description=milk_desig,
                target_locations=[Pose([-1.20, 1.0192, 0.9624],
                                       # [0.0, 0.0, 0.6339889056055381, 0.7733421413379024])], 
                                       [0, 0, 0, 1])],
                arms=[arm]).resolve().perform()
```

```python
world.reset_world()
```

## Look At

Look at lets the robot look at a specific point, for example if it should look at an object for detecting.

```python
from pycram.designators.action_designator import LookAtAction
from pycram.process_module import simulated_robot
from pycram.datastructures.pose import Pose

target_location = Pose([1, 0, 0.5], [0, 0, 0, 1])
with simulated_robot:
    LookAtAction(targets=[target_location]).resolve().perform()
```

## Detect

Detect is used to detect objects in the field of vision (FOV) of the robot. We will use the milk used in the pick
up/place example, if you didn't execute that example you can spawn the milk with the following cell. The detect
designator will return a resolved instance of an ObjectDesignatorDescription.

```python
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))
```

```python
from pycram.designators.action_designator import DetectAction, LookAtAction, ParkArmsAction, NavigateAction
from pycram.designators.object_designator import BelieveObject
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot
from pycram.datastructures.pose import Pose

milk_desig = BelieveObject(names=["milk"])

with simulated_robot:
    ParkArmsAction([Arms.BOTH]).resolve().perform()

    NavigateAction([Pose([0, 1, 0], [0, 0, 0, 1])]).resolve().perform()

    LookAtAction(targets=[milk_desig.resolve().pose]).resolve().perform()

    obj_desig = DetectAction(milk_desig).resolve().perform()

    print(obj_desig)
```

## Transporting

Transporting can transport an object from its current position to another target position. It is similar to the Pick and
Place plan used in the Pick-up and Place example. Since we need an Object which we can transport we spawn a milk, you
don't need to do this if you already have spawned it in a previous example.

```python
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))
```

```python
from pycram.designators.action_designator import *
from pycram.designators.object_designator import *
from pycram.process_module import simulated_robot
from pycram.datastructures.pose import Pose
from pycram.datastructures.enums import Arms

milk_desig = BelieveObject(names=["milk"])

description = TransportAction(milk_desig,
                              [Arms.LEFT],
                              [Pose([-1.35, 0.78, 0.95],
                                    [0.0, 0.0, 0.16439898301071468, 0.9863939245479175])])
with simulated_robot:
    MoveTorsoAction([0.2]).resolve().perform()
    description.resolve().perform()
```

## Opening

Opening allows the robot to open a drawer, the drawer is identified by an ObjectPart designator which describes the
handle of the drawer that should be grasped.

For the moment this designator works only in the apartment environment, therefore we remove the kitchen and spawn the
apartment.

```python
kitchen.remove()
```

```python
apartment = Object("apartment", ObjectType.ENVIRONMENT, "apartment.urdf")
```

```python
from pycram.designators.action_designator import *
from pycram.designators.object_designator import *
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot
from pycram.datastructures.pose import Pose

apartment_desig = BelieveObject(names=["apartment"]).resolve()
handle_deisg = ObjectPart(names=["handle_cab10_t"], part_of=apartment_desig)

with simulated_robot:
    MoveTorsoAction([0.25]).resolve().perform()
    ParkArmsAction([Arms.BOTH]).resolve().perform()
    NavigateAction([Pose([1.7474915981292725, 2.6873629093170166, 0.0],
                         [-0.0, 0.0, 0.5253598267689507, -0.850880163370435])]).resolve().perform()
    OpenAction(handle_deisg, [Arms.RIGHT]).resolve().perform()
```

## Closing

Closing lets the robot close an open drawer, like opening the drawer is identified by an ObjectPart designator
describing the handle to be grasped.

This action designator only works in the apartment environment for the moment, therefore we remove the kitchen and spawn
the apartment. Additionally, we open the drawer such that we can close it with the action designator.

```python
kitchen.remove()
```

```python
apartment = Object("apartment", ObjectType.ENVIRONMENT, "apartment.urdf")
apartment.set_joint_state("cabinet10_drawer_top_joint", 0.4)
```

```python
from pycram.designators.action_designator import *
from pycram.designators.object_designator import *
from pycram.datastructures.enums import Arms
from pycram.process_module import simulated_robot
from pycram.datastructures.pose import Pose

apartment_desig = BelieveObject(names=["apartment"]).resolve()
handle_deisg = ObjectPart(names=["handle_cab10_t"], part_of=apartment_desig)

with simulated_robot:
    MoveTorsoAction([0.25]).resolve().perform()
    ParkArmsAction([Arms.BOTH]).resolve().perform()
    NavigateAction([Pose([1.7474915981292725, 2.8073629093170166, 0.0],
                         [-0.0, 0.0, 0.5253598267689507, -0.850880163370435])]).resolve().perform()
    CloseAction(handle_deisg, [Arms.RIGHT]).resolve().perform()
```

```python
world.exit()
```

|------
Object Designator

Object designators are used to describe objects located in the BulletWorld or the real environment and then resolve them
during runtime to concrete objects.

Object designators are different from the Object class in bullet_world.py in the way that they just describe an object
and do not create objects or provide methods to manipulate them. Nevertheless, object designators contain a reference to
the BulletWorld object.

An Object designator takes two parameters, of which at least one has to be provided. These parameters are:

* A list of names
* A list of types

Object Designators work similar to Location designators, they get constrains describing a set of objects and when
resolved return a specific instance.

For all following examples we need a BulletWorld, so let's create one.

```python
from pycram.worlds.bullet_world import BulletWorld
from pycram.world_concepts.world_object import Object
from pycram.datastructures.enums import ObjectType, WorldMode
from pycram.datastructures.pose import Pose

world = BulletWorld(WorldMode.GUI)
```

## Believe Object

This object designator is used to describe objects that are located in the BulletWorld. So objects that are in the
belief state, hence the name. In the future when there is a perception interface, there will be a ```RealObject```
description which will be used to describe objects in the real world.

Since {meth}`~pycram.designators.object_designator.BelieveObject` describes Objects in the BulletWorld we create a few.

```python
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))
cereal = Object("froot_loops", ObjectType.BREAKFAST_CEREAL, "breakfast_cereal.stl", pose=Pose([1.3, 0.9, 0.95]))
spoon = Object("spoon", ObjectType.SPOON, "spoon.stl", pose=Pose([1.3, 1.1, 0.87]))
```

Now that we have objects we can create an object designator to describe them. For the start we want an object designator
only describing the milk. Since all objects have unique names we can create an object designator using a list with only
the name of the object.

```python
from pycram.designators.object_designator import BelieveObject

object_description = BelieveObject(names=["milk"])

print(object_description.resolve())
```

You can also use the type to describe objects, so now we want to have an object designator that describes every food in
the world.

```python
from pycram.designators.object_designator import BelieveObject

object_description = BelieveObject(types=[ObjectType.MILK, ObjectType.BREAKFAST_CEREAL])

print(object_description.resolve())
```

## Object Part

Part of object designators can be used to describe something as part of another object. For example, you could describe
a specific drawer as part of the kitchen. This is necessary since the drawer is no single BulletWorld Object but rather
a link of the kitchen which is a BulletWorld Object.

For this example we need just need the kitchen, if you didn't spawn it in the previous example you can spawn it with the
following cell.

```python
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
```

```python
from pycram.designators.object_designator import ObjectPart, BelieveObject

kitchen_desig = BelieveObject(names=["kitchen"]).resolve()

object_description = ObjectPart(names=["sink_area_left_upper_drawer_main"], part_of=kitchen_desig)

print(object_description.resolve())
```

## Object Designators as Generators

Similar to location designators object designators can be used as generators to iterate through every object that they
are describing. We will see this at the example of an object designator describing every type of food.

For this we need some objects, so if you didn't already spawn them you can use the next cell for this.

```python
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))
cereal = Object("froot_loops", ObjectType.BREAKFAST_CEREAL, "breakfast_cereal.stl", pose=Pose([1.3, 0.9, 0.95]))
spoon = Object("spoon", ObjectType.SPOON, "spoon.stl", pose=Pose([1.3, 1.1, 0.87]))
```

```python
from pycram.designators.object_designator import BelieveObject

object_description = BelieveObject(types=[ObjectType.MILK, ObjectType.BREAKFAST_CEREAL])

for obj in object_description:
    print(obj, "\n")
```

To close the world use the following exit function.

```python
world.exit()
```

|------
Location Designator

This example will show you what location designators are, how to use them and what they are capable of.

Location Designators are used to semantically describe locations in the world. You could, for example, create a location
designator that describes every position where a robot can be placed without colliding with the environment. Location
designator can describe locations for:

* Visibility
* Reachability
* Occupancy
* URDF Links (for example a table)

To find locations that fit the given constrains, location designator create Costmaps. Costmaps are a 2D distribution
that have a value greater than 0 for every position that fits the costmap criteria.

Location designators work similar to other designators, meaning you have to create a location designator description
which describes the location. This description can then be resolved to the actual 6D pose on runtime.

## Occupancy

We will start with a simple location designator that describes a location where the robot can be placed without
colliding with the environment. To do this we need a BulletWorld since the costmaps are mostly created from the current
state of the BulletWorld.

```python
from pycram.worlds.bullet_world import BulletWorld
from pycram.world_concepts.world_object import Object
from pycram.datastructures.enums import ObjectType, WorldMode
from pycram.datastructures.pose import Pose

world = BulletWorld()
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
```

Next up we will create the location designator description, the {meth}`~pycram.designators.location_designator.CostmapLocation` that we will be using needs a
target as a parameter. This target describes what the location designator is for, this could either be a pose or object
that the robot should be able to see or reach.

In this case we only want poses where the robot can be placed, this is the default behaviour of the location designator
which we will be extending later.

```python
from pycram.designators.location_designator import CostmapLocation

target = kitchen.get_pose()

location_description = CostmapLocation(target)

pose = location_description.resolve()

print(pose)
```

## Reachable

Next we want to locations from where the robot can reach a specific point, like an object the robot should pick up. This
can also be done with the {meth}`~pycram.designators.location_designator.CostmapLocation` description, but this time we need to provide an additional argument.
The additional argument is the robo which should be able to reach the pose.

Since a robot is needed we will use the PR2 and use a milk as a target point for the robot to reach. The torso of the
PR2 will be set to 0.2 since otherwise the arms of the robot will be too low to reach on the countertop.

```python
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
pr2.set_joint_state("torso_lift_joint", 0.2)
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))

```

```python
from pycram.designators.location_designator import CostmapLocation
from pycram.designators.object_designator import BelieveObject

target = BelieveObject(names=["milk"]).resolve()
robot_desig = BelieveObject(names=["pr2"]).resolve()

location_description = CostmapLocation(target=target, reachable_for=robot_desig)

print(location_description.resolve())
```

As you can see we get a pose near the countertop where the robot can be placed without colliding with it. Furthermore,
we get a list of arms with which the robot can reach the given object.

## Visibile

The {meth}`~pycram.designators.location_designator.CostmapLocation` can also find position from which the robot can see a given object or location. This is very
similar to how reachable locations are described, meaning we provide a object designator or a pose and a robot
designator but this time we use the ```visible_for``` parameter.

For this example we need the milk as well as the PR2, so if you did not spawn them during the previous location
designator you can spawn them with the following cell.

```python
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))
```

```python
from pycram.designators.location_designator import CostmapLocation
from pycram.designators.object_designator import BelieveObject

target = BelieveObject(names=["milk"]).resolve()
robot_desig = BelieveObject(names=["pr2"]).resolve()

location_description = CostmapLocation(target=target, visible_for=robot_desig)

print(location_description.resolve())
```

## Semantic

Semantic location designator are used to create location descriptions for semantic entities, like a table. An example of
this is: You have a robot that picked up an object and should place it on a table. Semantic location designator then
allows to find poses that are on this table.

Semantic location designator need an object from which the target entity is a part and the URDF link representing the
entity. In this case we want a position on the kitchen island, so we have to provide the kitchen object designator since
the island is a part of the kitchen and the link name of the island surface.

For this example we need the kitchen as well as the milk. If you spawned them in one of the previous examples you don't
need to execute the following cell.

```python
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
milk = Object("milk", ObjectType.MILK, "milk.stl")
```

```python
from pycram.designators.location_designator import SemanticCostmapLocation
from pycram.designators.object_designator import BelieveObject

kitchen_desig = BelieveObject(names=["kitchen"]).resolve()
milk_desig = BelieveObject(names=["milk"]).resolve()

location_description = SemanticCostmapLocation(urdf_link_name="kitchen_island_surface",
                                               part_of=kitchen_desig,
                                               for_object=milk_desig)

print(location_description.resolve())
```

## Location Designator as Generator

Location designator descriptions implement an iter method, so they can be used as generators which generate valid poses
for the location described in the description. This can be useful if the first pose does not work for some reason.

We will see this at the example of a location designator for visibility. For this example we need the milk, if you
already have a milk spawned in you world you can ignore the following cell.

```python
milk = Object("milk", ObjectType.MILK, "milk.stl")
```

```python
from pycram.designators.location_designator import CostmapLocation
from pycram.designators.object_designator import BelieveObject

target = BelieveObject(names=["milk"]).resolve()
robot_desig = BelieveObject(names=["pr2"]).resolve()

location_description = CostmapLocation(target=target, visible_for=robot_desig)

for pose in location_description:
    print(pose.pose)
```

## Accessing Locations

Accessing describes a location from which the robot can open a drawer. The drawer is specified by a ObjetcPart
designator which describes the handle of the drawer.

At the moment this location designator only works in the apartment environment, so please remove the kitchen if you
spawned it in a previous example. Furthermore, we need a robot, so we also spawn the PR2 if it isn't spawned already.

```python
kitchen.remove()
```

```python
apartment = Object("apartment", ObjectType.ENVIRONMENT, "apartment.urdf")
```

```python
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
pr2.set_joint_state("torso_lift_joint", 0.25)
```

```python
from pycram.designators.object_designator import *
from pycram.designators.location_designator import *

apartment_desig = BelieveObject(names=["apartment"])
handle_desig = ObjectPart(names=["handle_cab10_t"], part_of=apartment_desig.resolve())
robot_desig = BelieveObject(names=["pr2"])

access_location = AccessingLocation(handle_desig.resolve(), robot_desig.resolve()).resolve()
print(access_location.pose)
```

## Giskard Location

Some robots like the HSR or the Stretch2 need a full-body ik solver to utilize the whole body. For this case robots
the {meth}`~pycram.designators.specialized_designators.location.giskard_location.GiskardLocation` can be used. This location designator uses giskard as an ik solver to find a pose for the
robot to reach a target pose.

**Note:** The GiskardLocation relies on Giskard, therefore Giskard needs to run in order for this Location Designator to
work.

```python
from pycram.designators.specialized_designators.location.giskard_location import GiskardLocation

robot_desig = BelieveObject(names=["pr2"]).resolve()

loc = GiskardLocation(target=Pose([1, 1, 1]), reachable_for=robot_desig).resolve()
print(loc.pose)
```

If you are finished with this example you can close the world with the following cell:

```python
world.exit()
```

|------
Motion Designator

Motion designators are similar to action designators, but unlike action designators, motion designators represent atomic
low-level motions. Motion designators only take the parameter that they should execute and not a list of possible
parameters, like the other designators. Like action designators, motion designators can be performed, performing motion
designator verifies the parameter and passes the designator to the respective process module.

Since motion designators perform a motion on the robot, we need a robot which we can use. Therefore, we will create a
BulletWorld as well as a PR2 robot.

```python
from pycram.worlds.bullet_world import BulletWorld
from pycram.world_concepts.world_object import Object
from pycram.datastructures.enums import ObjectType, WorldMode

world = BulletWorld(WorldMode.GUI)
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
```

## Move

Move is used to let the robot drive to the given target pose. Motion designator are used in the same way as the other
designator, first create a description then resolve it to the actual designator and lastly, perform the resolved
designator.

```python
from pycram.datastructures.pose import Pose
from pycram.designators.motion_designator import MoveMotion
from pycram.process_module import simulated_robot

with simulated_robot:
    motion_description = MoveMotion(target=Pose([1, 0, 0], [0, 0, 0, 1]))

    motion_description.perform()
```

```python
world.reset_world()
```

## MoveTCP

MoveTCP is used to move the tool center point (TCP) of the given arm to the target position specified by the parameter.
Like any designator we start by creating a description and then resolving and performing it.

```python
from pycram.designators.motion_designator import MoveTCPMotion
from pycram.process_module import simulated_robot
from pycram.datastructures.enums import Arms

with simulated_robot:
    motion_description = MoveTCPMotion(target=Pose([0.5, 0.6, 0.6], [0, 0, 0, 1]), arm=Arms.LEFT)

    motion_description.perform()
```

## Looking

Looking motion designator adjusts the robot state such that the cameras point towards the target pose. Although this
motion designator takes the target as position and orientation, in reality only the position is used.

```python
from pycram.designators.motion_designator import LookingMotion
from pycram.process_module import simulated_robot

with simulated_robot:
    motion_description = LookingMotion(target=Pose([1, 1, 1], [0, 0, 0, 1]))

    motion_description.perform()
```

## Move Gripper

Move gripper moves the gripper of an arm to one of two states. The states can be {attr}`~pycram.datastructures.enums.GripperState.OPEN`  and {attr}`~pycram.datastructures.enums.GripperState.CLOSE`, which open
and close the gripper respectively.

```python
from pycram.designators.motion_designator import MoveGripperMotion
from pycram.process_module import simulated_robot
from pycram.datastructures.enums import Arms, GripperState

with simulated_robot:
    motion_description = MoveGripperMotion(motion=GripperState.OPEN, gripper=Arms.LEFT)

    motion_description.perform()
```

## Detecting

This is the motion designator implementation of detecting, if an object with the given object type is in the field of
view (FOV) this motion designator will return an object designator describing the object.

Since we need an object that we can detect, we will spawn a milk for this.

```python
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.5, 0, 1]))
```

```python
from pycram.designators.motion_designator import DetectingMotion, LookingMotion
from pycram.process_module import simulated_robot

with simulated_robot:
    LookingMotion(target=Pose([1.5, 0, 1], [0, 0, 0, 1])).perform()

    motion_description = DetectingMotion(object_type=ObjectType.MILK)

    obj = motion_description.perform()

    print(obj)
```

## Move Arm Joints

This motion designator moves one or both arms. Movement targets are a dictionary with joint name as key and target pose
as value.

```python
from pycram.designators.motion_designator import MoveArmJointsMotion
from pycram.process_module import simulated_robot

with simulated_robot:
    motion_description = MoveArmJointsMotion(right_arm_poses={"r_shoulder_pan_joint": -0.7})

    motion_description.perform()
```

## World State Detecting

World state detecting is also used to detect objects, however, the object is not required to be in the FOV of the robot.
As long as the object is somewhere in the belief state (BulletWorld) a resolved object designator will be returned.

Sine we want to detect something we will spawn an object that we can detect. If you already spawned the milk from the
previous example, you can skip this step.

```python
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([-1, 0, 1]))
```

```python
from pycram.designators.motion_designator import WorldStateDetectingMotion
from pycram.process_module import simulated_robot

with simulated_robot:
    motion_description = WorldStateDetectingMotion(object_type=ObjectType.MILK)

    obj = motion_description.perform()

    print(obj)
```

## Move Joints

Move joints can move any number of joints of the robot, the designator takes two lists as parameter. The first list are
the names of all joints that should be moved and the second list are the positions to which the joints should be moved.

```python
from pycram.designators.motion_designator import MoveJointsMotion
from pycram.process_module import simulated_robot

with simulated_robot:
    motion_description = MoveJointsMotion(names=["torso_lift_joint", "r_shoulder_pan_joint"], positions=[0.2, -1.2])

    motion_description.perform()
```

The following cell can be used after testing the examples, to close the BulletWorld.

```python
world.exit()
```

|------
Hands on Object Relational Mapping in PyCram

This tutorial will walk you through the serialization of a minimal plan in pycram.
First we will import sqlalchemy, create an in memory database and connect a session to it.

```python
import sqlalchemy
import sqlalchemy.orm

engine = sqlalchemy.create_engine("sqlite+pysqlite:///:memory:", echo=False)
session = sqlalchemy.orm.Session(bind=engine)
session
```

Next we create the database schema using the sqlalchemy functionality. For that we need to import the base class of pycram.orm.

```python
import pycram.orm.base
import pycram.orm.action_designator
pycram.orm.base.Base.metadata.create_all(engine)
session.commit()
```

Next we will write a simple plan where the robot parks his arms and then moves somewhere. We will construct a TaskTree around it such that we can serialize it later. As usual, we first create a world and then define the plan. By doing so, we obtain the task tree.

```python
from pycram.designators.action_designator import *
from pycram.designators.location_designator import *
from pycram.process_module import simulated_robot
from pycram.datastructures.enums import Arms, ObjectType, Grasp, WorldMode
from pycram.tasktree import with_tree
import pycram.tasktree
from pycram.worlds.bullet_world import BulletWorld
from pycram.world_concepts.world_object import Object
from pycram.designators.object_designator import *
from pycram.datastructures.pose import Pose
import anytree

world = BulletWorld(WorldMode.GUI)
pr2 = Object("pr2", ObjectType.ROBOT, "pr2.urdf")
kitchen = Object("kitchen", ObjectType.ENVIRONMENT, "kitchen.urdf")
milk = Object("milk", ObjectType.MILK, "milk.stl", pose=Pose([1.3, 1, 0.9]))
cereal = Object("cereal", ObjectType.BREAKFAST_CEREAL, "breakfast_cereal.stl", pose=Pose([1.3, 0.7, 0.95]))
milk_desig = ObjectDesignatorDescription(names=["milk"])
cereal_desig = ObjectDesignatorDescription(names=["cereal"])
robot_desig = ObjectDesignatorDescription(names=["pr2"]).resolve()
kitchen_desig = ObjectDesignatorDescription(names=["kitchen"])

@with_tree
def plan():
    with simulated_robot:
        ParkArmsActionPerformable(Arms.BOTH).perform()
        MoveTorsoAction([0.2]).resolve().perform()
        pickup_pose = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot_desig).resolve()
        pickup_arm = pickup_pose.reachable_arms[0]
        NavigateAction(target_locations=[pickup_pose.pose]).resolve().perform()
        PickUpAction(object_designator_description=cereal_desig, arms=[pickup_arm], grasps=[Grasp.FRONT]).resolve().perform()
        ParkArmsAction([Arms.BOTH]).resolve().perform()

        place_island = SemanticCostmapLocation("kitchen_island_surface", kitchen_desig.resolve(),
                                           cereal_desig.resolve()).resolve()

        place_stand = CostmapLocation(place_island.pose, reachable_for=robot_desig, reachable_arm=pickup_arm).resolve()

        NavigateAction(target_locations=[place_stand.pose]).resolve().perform()

        PlaceAction(cereal_desig, target_locations=[place_island.pose], arms=[pickup_arm]).resolve().perform()

        ParkArmsActionPerformable(Arms.BOTH).perform()

plan()

# set description of what we are doing
pycram.orm.base.ProcessMetaData().description = "Tutorial for getting familiar with the ORM."
task_tree = pycram.tasktree.task_tree
print(anytree.RenderTree(task_tree))
```

Next we serialize the task tree by recursively inserting from its root.

```python
task_tree.root.insert(session)
```

We can look at our experiment (Process)MetaData to get some context on the data we just created.

```python
from sqlalchemy import select

print(*session.scalars(select(pycram.orm.base.ProcessMetaData)).all())
```

Lastly we can look at various table to see how the structures got logged.
For example, we can get all the navigate actions that occurred.

```python
navigations = session.scalars(select(pycram.orm.action_designator.NavigateAction)).all()
print(*navigations, sep="\n")
```

Due to the inheritance mapped in the ORM package, we can also obtain all executed actions with just one query. 

```python
actions = session.scalars(select(pycram.orm.action_designator.Action)).all()
print(*actions, sep="\n")
```

Of course all relational algebra operators, such as filtering and joining also work in pycram.orm queries. Let's say we need all the poses of objects, that were picked up by a robot. Since we defined a relationship between the PickUpAction table and the Object table and between the Object table and the Pose table in the ORM class schema, we can just use the join operator without any further specification:

```python
object_actions = (session.scalars(select(pycram.orm.base.Pose)
                  .join(pycram.orm.action_designator.PickUpAction.object)
                  .join(pycram.orm.object_designator.Object.pose))
                  .all())
print(*object_actions, sep="\n")

```

Did you notice, that for the joins we did not join the tables together in a typical sql kind of way, but rather used the relationships defined in the ORM classes and wrote joins like PickUpAction.object or Object.pose? This is because the ORM package automatically creates the joins for us, so we only have to join on the attributes that hold the relationship. This is a huge advantage over writing sql queries by hand, since we do not have to worry about the join conditions. 
This is a strong tool, but it is crucial to use it properly. Very important to note: The order of the joins matters! For instance, if we joined the Pose table with the Object table first, and placed the join between the PickUpAction table and the Object table second, sqlalchemy would have selected the Pose not from the join between all three tables, but rather from a join between the Pose and the Object table + from a join between the PickUpAction table and the Object table. These mistakes can lead to wrong results or even to errors (the above-mentioned example would actually lead to an error due to the Object table being accessed twice in two separate joins in the same query and therefore the column names of the Object tables would have been ambiguous and could not be used by sqlalchemy to join).

Make sure to check out the other examples of ORM querying.


If we want to filter for all successful tasks we can just add the filter operator:

```python
from pycram.orm.tasktree import TaskTreeNode

successful_tasks = session.scalars(select(TaskTreeNode).where(TaskTreeNode.status == "SUCCEEDED"))
print(*successful_tasks, sep="\n")
```

As expected all but the root node succeeded, since the root node is still running.

Writing an extension to the ORM package is also done with ease. We need to create a new ActionDesignator class and its ORM equivalent, where we define our new table. Let's say we want to log all the things the robot says. We will create a new ActionDesignator class called Saying and its ORM equivalent called ORMSaying. 

```python
from sqlalchemy.orm import Mapped, mapped_column, Session
from pycram.orm.action_designator import Action
from dataclasses import dataclass


# define ORM class from pattern in every pycram.orm class
class ORMSaying(Action):

    id: Mapped[int] = mapped_column(sqlalchemy.ForeignKey(f'{Action.__tablename__}.id'), primary_key=True, init=False)
    # since we do not want to add any custom specifications to our column, we don't even need to define mapped_column, sqlalchemy does this internally.
    text: Mapped[str] 

# define brand new action designator

@dataclass 
class SayingActionPerformable(ActionDesignatorDescription.Action):
    
    text: str
        
    @with_tree
    def perform(self) -> None:
        print(self.text)

    def to_sql(self) -> ORMSaying:
        return ORMSaying(self.text)

    def insert(self, session: Session, *args, **kwargs) -> ORMSaying:
        action = super().insert(session)
        session.add(action)
        session.commit()
        return action

```

Now we got our new ActionDesignator called Saying and its ORM version. Since this class got created after all other classes got inserted into the database (in the beginning of the notebook) we have to insert it manually. 

```python
ORMSaying.metadata.create_all(bind=engine)
```

Now we can create and insert a Saying action. Since this is the last part where we interact with the BulletWorld, we can also close it.

```python
# create a saying action and insert it
SayingActionPerformable("Patchie, Patchie; Where is my Patchie?").perform()
pycram.tasktree.task_tree.root.insert(session)
session.commit()

world.exit()
```

It is notable that committing the object to the session fills its primary key. Hence, there is no worries about assigning unique IDs manually.
Finally, we can double-check that our object exists in the database.

```python
session.scalars(select(ORMSaying)).all()
```

|------
Pose

Poses in PyCRAM are represented by the Pose class which inherits from the PoseStamped message of ROS. This makes PyCRAMs
poses compatible with everything in ROS like services, topics or TF.

This notebook will provide an overview about poses, how to use them and what they can do. We will start by simply
creating a pose.

Before we start a few words about naming convention of Poses in PyCRAM. Naming convention is similar to the PoseStamped
message so if you are familiar with that this should be easy.

* **Position:** A position means the position in cartesian space, so the x, y, and z coordinates.
* **Orientation:** An orientation is the rotation in all three axes represented as a quaternion with x, y, z, w.
* **Pose:** A pose is the combination of a position and an orientation. Poses in PyCRAM also contain a frame of
  reference to which the position and orientation are relative.

```python
from pycram.datastructures.pose import Pose

example_pose = Pose([1, 2, 3], [0, 0, 0, 1], "map")
print(example_pose)
```

As you can see we created the ```example_pose``` with a position of ```[1, 2, 3]``` and an orientation
of ```[0, 0, 0, 1]``` in the frame ```map```. But we don't need to provide all these parameters for a Pose, in case
there is no parameter the Pose will use default parameter.

```python
from pycram.datastructures.pose import Pose

default_pose = Pose()
print(default_pose)
```

In case no parameter is provided the defualt parameter are:

* position: ```[0, 0, 0]```
* orientation: ```[o, 0, 0, 1]```
* frame: ```map```

The following example will show how to access the data stored in a pose.

```python
from pycram.datastructures.pose import Pose

example_pose = Pose([1, 2, 3], [0, 0, 0, 1], "map")

print(f"Access to a component of the position: {example_pose.position.y}")

print(f"Access to a component of the rotation: {example_pose.orientation.x}")

print(f"Get the whole position as geometry_msgs/Pose:\n{example_pose.position}")

print(f"You can also get position or orientation as a list: {example_pose.position_as_list()}")

print(f"Same with the whole pose: {example_pose.to_list()}")

print(f"Access the reference frame: {example_pose.frame}")
```

## Editing a pose

You can also edit the data saved in a Pose, similar to how you access it.

```python
from pycram.datastructures.pose import Pose

example_pose = Pose([1, 2, 3], [0, 0, 0, 1], "map")

# Edit a single component of the position 
example_pose.position.x = 3
print(f"Edit only one component:\n{example_pose.position}", "\n")

# Edit the whole position
example_pose.position = [0, 0, 1]
print(f"Edit the whole position:\n{example_pose.position}", "\n")

example_pose.frame = "new_frame"
print(f"Set a new frame:\n{example_pose.frame}", "\n")

example_pose.set_position([3, 2, 1])
print(f"Set the position via method:\n{example_pose.position}", "\n")
```

## Copy Poses

You can also copy Poses to create a new Pose with the same data. This can be useful if you have a method which would
need to alter the Pose, since poses are passed by reference to a method every change done to the Pose in the method
would affect the instanced passed to the method.

```python
from pycram.datastructures.pose import Pose

example_pose = Pose([1, 2, 3], [0, 0, 0, 1], "map")

copy_pose = example_pose.copy()

print(example_pose, "\n")
print(copy_pose)
```

## Convert to Transform

PyCRAM also has its own transform at which we will take a look in the next section. However, here we will take a look at
how to convert a Pose into a Transform.

For this example we will take a Pose which represents the current pose of a milk object and convert it into a Transform
which represents the transformation from the ```map``` frame to the ```milk``` frame.

```python
from pycram.datastructures.pose import Pose

milk_pose = Pose([3, 4, 1], [1, 0, 0, 1], "map")

milk_transform = milk_pose.to_transform("milk")

print(milk_transform)
```

# Transforms

Transforms are similar to Poses but instead of representing a Pose in a frame of reference they represent a
transformation from one frame of reference to another. For this purpose Transforms have an additional parameter
called ```child_frame_id``` which is the frame of reference to which the Transform is pointing.

Transforms in PyCRAM inherit from the TransformStamped message of ROS which makes them, like Poses, compatible to ROS
services and topics that expect a TransformStamped message. Therefore, the naming conventions of Transforms are the same
as of TransformStamped which.

* **Translation:** The vector describing the transformation in cartesian space.
* **Rotation:** The quaternion describing the transformation of rotation.
* **Transform:** The combination of translation and rotation

```python
from pycram.datastructures.pose import Transform

example_transform = Transform([1, 2, 2], [0, 0, 0, 1], "map", "object")

print(example_transform)
```

Transforms have the same methods to get and set values as Poses have, therefore only a short showcase will be given. For
more details please look at the Pose example or the API documentation.

```python
from pycram.datastructures.pose import Transform

example_transform = Transform([2, 5, 1], [0, 0, 1, 1], "map", "object")

print(f"Access the rotation:\n{example_transform.rotation}", "\n")

print(f"Access the child_frane: {example_transform.child_frame_id}", "\n")

# changing translation and rotation is exactly like with Poses.

example_transform.translation = [1, 1, 1]
print(f"New translation:\n{example_transform.translation}")
```

## Convert to Pose and Copy

Analog to Poses Transforms have a method that converts a Transform to a Pose, in this process the ```child_frame_id```
will be lost.

Also like in Poses Transforms have a ```copy``` method which creates an exact copy of this Transform.

```python
from pycram.datastructures.pose import Transform

milk_transform = Transform([1, 1, 1], [0, 0, 0, 1], "map", "milk")

milk_pose = milk_transform.to_pose()

print(f"The converted pose:\n{milk_pose}", "\n")

example_transform = Transform([1, 1, 1], [0, 0, 0, 1], "map", "milk")

copy_transform = example_transform.copy()

print(f"The copied transform:\n{copy_transform}")
```

## Operations on Transforms

Transforms have, unlike Poses, operations that can be done. These operations are:

* Multiplication
* Invert
* InverseTimes

### Multiplication

We will first take a look at the multiplication of Transforms. We will use an example were we have two Transforms, the
first from ```map``` to a ```hand``` frame and the second from the ```hand``` to a ```milk``` frame. By multiplying
these two we get the Transform from ```map``` to ```milk``` frame.

```python
from pycram.datastructures.pose import Transform

map_to_hand = Transform([1, 1, 1], [0, 0, 0, 1], "map", "hand")

hand_to_milk = Transform([0.1, 0.05, 0], [0, 0, 0, 1], "hand", "milk")

map_to_milk = map_to_hand * hand_to_milk

print(map_to_milk)
```

### Invert

This inverts a Transform, so in we have a transform from ```map``` to ```milk``` then inverting it results in a
Transform from ```milk``` to ```map``` .

```python
from pycram.datastructures.pose import Transform

map_to_milk = Transform([1, 1, 0.5], [0, 0, 0, 1], "map", "milk")

milk_to_map = map_to_milk.invert()

print(milk_to_map)
```

### Inverse Times

Inverse times combines the inverting and multiplication of Transforms, this results in a 'minus' for Transforms. We will
again use the example of a hand holding a milk, but this time we have the Transforms from ```map``` to ```milk```
and ```hand``` to ```milk```.

```python
from pycram.datastructures.pose import Transform

map_to_milk = Transform([1.1, 1.05, 1], [0, 0, 0, 1], "map", "milk")

hand_to_milk = Transform([0.1, 0.05, 0], [0, 0, 0, 1], "hand", "milk")

map_to_milk = map_to_milk.inverse_times(hand_to_milk)

print(map_to_milk)
```

|------
Robot Description

(robot_description_header)=
The robot description contains semantic information about the robot which can not be extracted from the URDF in a
general way. This inludes kinematic chains, end-effectors, cameras and their parameter, etc.

In genral a Robot Description consists a number of different descriptions, these are:

* RobotDescription
* KinematicChainDescription
* EndEffectorDescription
* CameraDescription

In this example we will create a robot description step-by-step and describe the different components on the way. The
robot we will use as an example will be the PR2, the complete PR2 description can also be seen in
{meth}`pycram.robot_descriptions.pr2_description`.

## Robot Description Class

We start by creating an instance of the {class}`~pycram.robot_description.RobotDescription` class, this will serve as a
the main component to which all other descriptions will be added.

To initialize a {class}`~pycram.robot_description.RobotDescription` we need a few parameter which are:

* Name
* base_link
* torso_link
* torso_joint
* Path to a URDF file

```python
from pycram.robot_description import RobotDescription
import rospkg

rospack = rospkg.RosPack()
filename = rospack.get_path('pycram') + '/resources/robots/' + "pr2" + '.urdf'

pr2_description = RobotDescription("pr2", "base_link", "torso_lift_link", "torso_lift_joint", filename)
```

## Kinematic Chain Description

The kinematic chain description describes a chain of links and joints of the robot which might be interesting when
working with the robot. An example of such a chain would be the arm of the robot, when programming for the robot it is
important to know which links and joints exactly make up the arm, however, these can not be extracted from the URDF
automatically.

The kinematic chain is based upon the URDF, meaning when initializing the description one only needs to specify the
first and last link of the chain.

We will now create the kinematic chain description for the right arm of the PR2. For initializing
the {class}`~pycram.robot_description.KinematicChainDescription` the following parameter are needed:

* Name
* first link
* last link
* URDF object
* Arm type

The arm type specifies which arm this kinematic chain describes, this is needed when one wants to access only the arms
of the robot.

```python
from pycram.robot_description import KinematicChainDescription
from pycram.datastructures.enums import Arms

right_arm = KinematicChainDescription("right", "torso_lift_link", "r_wrist_roll_link",
                                      pr2_description.urdf_object, arm_type=Arms.RIGHT)
```

The created {class}`~pycram.robot_description.KinematicChainDescription` can now be added to the robot description.

```python
pr2_description.add_kinematic_chain_description(right_arm)
```

## End Effector Description

Since kinematic chains only describe a moveable chain of links and joints like arms these do not represent end-effectors
which can be used to do manipulation tasks.

To represent end-effectors we will create an {class}`~pycram.robot_description.EndEffectorDescription` which contains the information of the respective
end-effector. When creating an {class}`~pycram.robot_description.EndEffectorDescription` we need the following parameter:

* Name
* first link
* tool_frame
* URDF object

You might have noticed that the end-efftor only has a first link but no last link, this is the case since end-effectors
are at the end of the arms. Therefore, all links and joints below a certain link can be seen as part of the
end-effector.

```python
from pycram.robot_description import EndEffectorDescription

right_gripper = EndEffectorDescription("right_gripper", "r_gripper_palm_link", "r_gripper_tool_frame",
                                       pr2_description.urdf_object)
```

The gripper can no be added to the previously created {class}`~pycram.robot_description.KinematicChainDescription`.

```python
right_arm.end_effector = right_gripper
```

## Camera Description

The camera description contains all parameters of a camera, which is mounted on the robot. The parameter for
the {class}`~pycram.robot_description.CameraDescription` are:

* Name
* Link name
* minimal height
* maximal height
* horizontal angle
* vertical angle

```python
from pycram.robot_description import CameraDescription
from pycram.datastructures.enums import Grasp

camera = CameraDescription("kinect_camera", "wide_stereo_optical_frame", 1.27,
                           1.60, 0.99483, 0.75049)
```

The finished camera description can now be added to the robot description.

```python
pr2_description.add_camera_description(camera)
```

## Grasps

Grasps define how a robot interacts with objects. The grasps defined in the robot description define for each grasp (
right, left, top, front) the orientation of the end-effector, relative to the base_frame of the robot, to achieve the
respective grasp.

```python
pr2_description.add_grasp_orientations({Grasp.FRONT: [0, 0, 0, 1],
                                        Grasp.LEFT: [0, 0, -1, 1],
                                        Grasp.RIGHT: [0, 0, 1, 1],
                                        Grasp.TOP: [0, 1, 0, 1]})
```

## Register Robot Description

Lastly, you need to register the robot description to the {class}`~pycram.robot_description.RobotDescriptionManager`. As you can see the code to
register the robot description has to be executed at the start of PyCRAM, if you put your file with the robot
description in the {class}`pycram.robot_descriptions` directory it will be executed upon the start of PyCRAM.

```python
from pycram.robot_description import RobotDescriptionManager

rdm = RobotDescriptionManager()
rdm.register_description(pr2_description)
```

|------
pycram.designators.action_designator
### **Classes**

#### **MoveTorsoAction**
- **Description**: Action Designator for Moving the torso of the robot up and down.

#### **SetGripperAction**
- **Description**: Set the gripper state of the robot.

#### **ReleaseAction**
- **Description**: Releases an Object from the robot.

#### **GripAction**
- **Description**: Grip an object with the robot.

#### **ParkArmsAction**
- **Description**: Park the arms of the robot.

#### **PickUpAction**
- **Description**: Designator to let the robot pick up an object.

#### **PlaceAction**
- **Description**: Places an Object at a position using an arm.

#### **NavigateAction**
- **Description**: Navigates the Robot to a position.

#### **TransportAction**
- **Description**: Transports an object to a position using an arm.

#### **LookAtAction**
- **Description**: Lets the robot look at a position.

#### **DetectAction**
- **Description**: Detects an object that fits the object description and returns an object designator describing the object.

#### **OpenAction**
- **Description**: Opens a container like object.

#### **CloseAction**
- **Description**: Closes a container like object.

#### **GraspingAction**
- **Description**: Grasps an object described by the given Object Designator description.

#### **ActionAbstract**
- **Description**: Base class for performable actions.

#### **MoveTorsoActionPerformable**
- **Description**: Move the torso of the robot up and down.

#### **SetGripperActionPerformable**
- **Description**: Set the gripper state of the robot.

#### **ReleaseActionPerformable**
- **Description**: Releases an Object from the robot.

#### **GripActionPerformable**
- **Description**: Grip an object with the robot.

#### **ParkArmsActionPerformable**
- **Description**: Park the arms of the robot.

#### **PickUpActionPerformable**
- **Description**: Let the robot pick up an object.

#### **PlaceActionPerformable**
- **Description**: Places an Object at a position using an arm.

#### **NavigateActionPerformable**
- **Description**: Navigates the Robot to a position.

#### **TransportActionPerformable**
- **Description**: Transports an object to a position using an arm.

#### **LookAtActionPerformable**
- **Description**: Lets the robot look at a position.

#### **DetectActionPerformable**
- **Description**: Detects an object that fits the object description and returns an object designator describing the object.

#### **OpenActionPerformable**
- **Description**: Opens a container like object.

#### **CloseActionPerformable**
- **Description**: Closes a container like object.

#### **GraspingActionPerformable**
- **Description**: Grasps an object described by the given Object Designator description.

#### **FaceAtPerformable**
- **Description**: Turn the robot chassis such that it faces the pose and then perform a look at action.

#### **MoveAndPickUpPerformable**
- **Description**: Navigate to standing position, turn towards the object, and pick it up.

---

### **Module Contents**

#### **pycram.designators.action_designator.MoveTorsoAction**
- **Inherits**: `pycram.designator.ActionDesignatorDescription`
- **Description**: Action Designator for Moving the torso of the robot up and down.
- **Attributes**:
  - **positions**: `List[float]`
- **Methods**:
  - **ground()**: Returns a `MoveTorsoActionPerformable`.
  - **__iter__()**: Iterates over possible values and returns a `MoveTorsoActionPerformable`.

#### **pycram.designators.action_designator.SetGripperAction**
- **Inherits**: `pycram.designator.ActionDesignatorDescription`
- **Description**: Set the gripper state of the robot.
- **Attributes**:
  - **grippers**: `List[pycram.datastructures.enums.GripperState]`
  - **motions**: `List[pycram.datastructures.enums.Arms]`
- **Methods**:
  - **ground()**: Returns a `SetGripperActionPerformable`.
  - **__iter__()**: Iterates over possible combinations and returns a `SetGripperActionPerformable`.

#### **pycram.designators.action_designator.ReleaseAction**
- **Inherits**: `pycram.designator.ActionDesignatorDescription`
- **Description**: Releases an Object from the robot.
- **Attributes**:
  - **grippers**: `List[pycram.datastructures.enums.Arms]`
  - **object_designator_description**
- **Methods**:
  - **ground()**: Returns a `ReleaseActionPerformable`.

#### **pycram.designators.action_designator.GripAction**
- **Inherits**: `pycram.designator.ActionDesignatorDescription`
- **Description**: Grip an object with the robot.
- **Attributes**:
  - **grippers**: `List[pycram.datastructures.enums.Arms]`
  - **object_designator_description**: `pycram.designators.object_designator.ObjectDesignatorDescription`
  - **efforts**: `List[float]`
- **Methods**:
  - **ground()**: Returns a `GripActionPerformable`.

#### **pycram.designators.action_designator.ParkArmsAction**
- **Inherits**: `pycram.designator.ActionDesignatorDescription`
- **Description**: Park the arms of the robot.
- **Attributes**:
  - **arms**: `List[pycram.datastructures.enums.Arms]`
- **Methods**:
  - **ground()**: Returns a `ParkArmsActionPerformable`.

#### **pycram.designators.action_designator.PickUpAction**
- **Inherits**: `pycram.designator.ActionDesignatorDescription`
- **Description**: Designator to let the robot pick up an object.
- **Attributes**:
  - **object_designator_description**: `Union[pycram.designators.object_designator.ObjectDesignatorDescription, pycram.designators.object_designator.Object]`
  - **arms**: `List[pycram.datastructures.enums.Arms]`
  - **grasps**: `List[pycram.datastructures.enums.Grasp]`
- **Methods**:
  - **ground()**: Returns a `PickUpActionPerformable`.

#### **pycram.designators.action_designator.PlaceAction**
- **Inherits**: `pycram.designator.ActionDesignatorDescription`
- **Description**: Places an Object at a position using an arm.
- **Attributes**:
  - **object_designator_description**: `Union[pycram.designators.object_designator.ObjectDesignatorDescription, pycram.designators.object_designator.Object]`
  - **target_locations**: `List[pycram.datastructures.pose.Pose]`
  - **arms**: `List[pycram.datastructures.enums.Arms]`
- **Methods**:
  - **ground()**: Returns a `PlaceActionPerformable`.

#### **pycram.designators.action_designator.NavigateAction**
- **Inherits**: `pycram.designator.ActionDesignatorDescription`
- **Description**: Navigates the Robot to a position.
- **Attributes**:
  - **target_locations**: `List[pycram.datastructures.pose.Pose]`
- **Methods**:
  - **ground()**: Returns a `NavigateActionPerformable`.

#### **pycram.designators.action_designator.TransportAction**
- **Inherits**: `pycram.designator.ActionDesignatorDescription`
- **Description**: Transports an object to a position using an arm.
- **Attributes**:
  - **object_designator_description**: `Union[pycram.designators.object_designator.ObjectDesignatorDescription, pycram.designators.object_designator.Object]`
  - **arms**: `List[pycram.datastructures.enums.Arms]`
  - **target_locations**: `List[pycram.datastructures.pose.Pose]`
- **Methods**:
  - **ground()**: Returns a `TransportActionPerformable`.

#### **pycram.designators.action_designator.LookAtAction**
- **Inherits**: `pycram.designator.ActionDesignatorDescription`
- **Description**: Lets the robot look at a position.
- **Attributes**:
  - **targets**: `List[pycram.datastructures.pose.Pose]`
- **Methods**:
  - **ground()**: Returns a `LookAtActionPerformable`.

#### **pycram.designators.action_designator.DetectAction**
- **Inherits**: `pycram.designator.ActionDesignatorDescription`
- **Description**: Detects an object that fits the object description and returns an object designator describing the object.
- **Attributes**:
  - **object_designator_description**: `pycram.designators.object_designator.ObjectDesignatorDescription`
- **Methods**:
  - **ground()**: Returns a `DetectActionPerformable`.

#### **pycram.designators.action_designator.OpenAction**
- **Inherits**: `pycram.designator.ActionDesignatorDescription`
- **Description**: Opens a container like object.
- **Attributes**:
  - **object_designator_description**: `pycram.designators.object_designator.ObjectPart`
  - **

arms**: `List[pycram.datastructures.enums.Arms]`
- **Methods**:
  - **ground()**: Returns an `OpenActionPerformable`.

#### **pycram.designators.action_designator.CloseAction**
- **Inherits**: `pycram.designator.ActionDesignatorDescription`
- **Description**: Closes a container like object.
- **Attributes**:
  - **object_designator_description**: `pycram.designators.object_designator.ObjectPart`
  - **arms**: `List[pycram.datastructures.enums.Arms]`
- **Methods**:
  - **ground()**: Returns a `CloseActionPerformable`.

#### **pycram.designators.action_designator.GraspingAction**
- **Inherits**: `pycram.designator.ActionDesignatorDescription`
- **Description**: Grasps an object described by the given Object Designator description.
- **Attributes**:
  - **arms**: `List[pycram.datastructures.enums.Arms]`
  - **object_description**: `Union[pycram.designators.object_designator.ObjectDesignatorDescription, pycram.designators.object_designator.ObjectPart]`
- **Methods**:
  - **ground()**: Returns a `GraspingActionPerformable`.

#### **pycram.designators.action_designator.ActionAbstract**
- **Inherits**: `pycram.designator.ActionDesignatorDescription.Action, abc.ABC`
- **Description**: Base class for performable actions.
- **Attributes**:
  - **orm_class**: `Type[pycram.orm.action_designator.Action]`
- **Methods**:
  - **abstract perform()**: Must be overwritten by each action.
  - **to_sql()**: Converts the action to its ORM equivalent.
  - **insert(session: sqlalchemy.orm.Session, **kwargs)**: Inserts the action into the database.

#### **pycram.designators.action_designator.MoveTorsoActionPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Move the torso of the robot up and down.
- **Attributes**:
  - **position**: `float`
- **Methods**:
  - **perform()**: Overwritten by each action.

#### **pycram.designators.action_designator.SetGripperActionPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Set the gripper state of the robot.
- **Attributes**:
  - **gripper**: `pycram.datastructures.enums.Arms`
  - **motion**: `pycram.datastructures.enums.GripperState`
- **Methods**:
  - **perform()**: Overwritten by each action.

#### **pycram.designators.action_designator.ReleaseActionPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Releases an Object from the robot.
- **Attributes**:
  - **gripper**: `pycram.datastructures.enums.Arms`
  - **object_designator**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`
- **Methods**:
  - **perform()**: Overwritten by each action.

#### **pycram.designators.action_designator.GripActionPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Grip an object with the robot.
- **Attributes**:
  - **gripper**: `pycram.datastructures.enums.Arms`
  - **object_designator**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`
  - **effort**: `float`
- **Methods**:
  - **perform()**: Overwritten by each action.

#### **pycram.designators.action_designator.ParkArmsActionPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Park the arms of the robot.
- **Attributes**:
  - **arm**: `pycram.datastructures.enums.Arms`
- **Methods**:
  - **perform()**: Overwritten by each action.

#### **pycram.designators.action_designator.PickUpActionPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Let the robot pick up an object.
- **Attributes**:
  - **object_designator**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`
  - **arm**: `pycram.datastructures.enums.Arms`
  - **grasp**: `pycram.datastructures.enums.Grasp`
  - **object_at_execution**: `Optional[pycram.designators.object_designator.ObjectDesignatorDescription.Object]`
- **Methods**:
  - **perform()**: Overwritten by each action.

#### **pycram.designators.action_designator.PlaceActionPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Places an Object at a position using an arm.
- **Attributes**:
  - **object_designator**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`
  - **arm**: `pycram.datastructures.enums.Arms`
  - **target_location**: `pycram.datastructures.pose.Pose`
- **Methods**:
  - **perform()**: Overwritten by each action.

#### **pycram.designators.action_designator.NavigateActionPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Navigates the Robot to a position.
- **Attributes**:
  - **target_location**: `pycram.datastructures.pose.Pose`
- **Methods**:
  - **perform()**: Overwritten by each action.

#### **pycram.designators.action_designator.TransportActionPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Transports an object to a position using an arm.
- **Attributes**:
  - **object_designator**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`
  - **arm**: `pycram.datastructures.enums.Arms`
  - **target_location**: `pycram.datastructures.pose.Pose`
- **Methods**:
  - **perform()**: Overwritten by each action.

#### **pycram.designators.action_designator.LookAtActionPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Lets the robot look at a position.
- **Attributes**:
  - **target**: `pycram.datastructures.pose.Pose`
- **Methods**:
  - **perform()**: Overwritten by each action.

#### **pycram.designators.action_designator.DetectActionPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Detects an object that fits the object description and returns an object designator describing the object.
- **Attributes**:
  - **object_designator**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`
- **Methods**:
  - **perform()**: Overwritten by each action.

#### **pycram.designators.action_designator.OpenActionPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Opens a container like object.
- **Attributes**:
  - **object_designator**: `pycram.designators.object_designator.ObjectPart.Object`
  - **arm**: `pycram.datastructures.enums.Arms`
- **Methods**:
  - **perform()**: Overwritten by each action.

#### **pycram.designators.action_designator.CloseActionPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Closes a container like object.
- **Attributes**:
  - **object_designator**: `pycram.designators.object_designator.ObjectPart.Object`
  - **arm**: `pycram.datastructures.enums.Arms`
- **Methods**:
  - **perform()**: Overwritten by each action.

#### **pycram.designators.action_designator.GraspingActionPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Grasps an object described by the given Object Designator description.
- **Attributes**:
  - **arm**: `pycram.datastructures.enums.Arms`
  - **object_desig**: `Union[pycram.designators.object_designator.ObjectDesignatorDescription.Object, pycram.designators.object_designator.ObjectPart.Object]`
- **Methods**:
  - **perform()**: Overwritten by each action.

#### **pycram.designators.action_designator.FaceAtPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Turn the robot chassis such that it faces the pose and then perform a look at action.
- **Attributes**:
  - **pose**: `pycram.datastructures.pose.Pose`
- **Methods**:
  - **perform()**: Overwritten by each action.

#### **pycram.designators.action_designator.MoveAndPickUpPerformable**
- **Inherits**: `ActionAbstract`
- **Description**: Navigate to standing position, turn towards the object, and pick it up.
- **Attributes**:
  - **standing_position**: `pycram.datastructures.pose.Pose`
  - **object_designator**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`
  - **arm**: `pycram.datastructures.enums.Arms`
  - **grasp**: `pycram.datastructures.enums

.Grasp`
- **Methods**:
  - **perform()**: Overwritten by each action.

|------
pycram.datastructures.pose
### Classes

**Pose**
- Pose representation for PyCRAM, this class extends the PoseStamped ROS message from geometry_msgs. Thus making it compatible with every ROS service and message expecting a PoseStamped message.

**Transform**
- Represents a Transformation from one TF frame to another in PyCRAM. Like with Poses, this class inherits from the ROS message TransformStamped from geometry_msgs, making it compatible with ROS services and messages requiring a TransformStamped message.

### Functions

**get_normalized_quaternion(→ geometry_msgs.msg.Quaternion)**
- Normalizes a given quaternion such that it has a magnitude of 1.

### Module Contents

**pycram.datastructures.pose.get_normalized_quaternion(quaternion: numpy.ndarray) → geometry_msgs.msg.Quaternion**
- Normalizes a given quaternion such that it has a magnitude of 1.

  **Parameters:**
  - quaternion: The quaternion that should be normalized

  **Returns:**
  - The normalized quaternion

**class pycram.datastructures.pose.Pose(position: typing_extensions.Optional[typing_extensions.List[float]] = None, orientation: typing_extensions.Optional[typing_extensions.List[float]] = None, frame: str = 'map', time: rospy.Time = None)**
- Bases: geometry_msgs.msg.PoseStamped
- Pose representation for PyCRAM, this class extends the PoseStamped ROS message from geometry_msgs, making it compatible with every ROS service and message expecting a PoseStamped message.

  **Naming convention for Poses:**
  - Pose: Instances of this class, representing a cartesian position and a quaternion for orientation
  - Position: Only the cartesian position in xyz
  - Orientation: Only the quaternion as xyzw

  **Properties:**
  - **frame:** str
    - Property for the frame_id such that it is easier accessible. Instead of Pose.header.frame_id, it is Pose.frame
    - **Returns:** The TF frame of this Pose

  - **position:** geometry_msgs.msg.Point
    - Property that points to the position of this pose

  - **orientation:** geometry_msgs.msg.Quaternion
    - Property that points to the orientation of this pose

  **Methods:**
  - **static from_pose_stamped(pose_stamped: geometry_msgs.msg.PoseStamped) → Pose**
    - Converts a geometry_msgs/PoseStamped message to a Pose object. Should be used for compatibility with ROS.

    **Parameters:**
    - pose_stamped: The pose stamped message which should be converted

    **Returns:**
    - A Pose object with the same information as the given message

  - **to_list() → typing_extensions.List[typing_extensions.List[float]]**
    - Returns the position and orientation of this pose as a list containing two lists.

    **Returns:**
    - The position and orientation as lists

  - **to_transform(child_frame: str) → Transform**
    - Converts this pose to a Transform from the TF frame of the pose to the given child_frame.

    **Parameters:**
    - child_frame: Child frame id to which the Transform points

    **Returns:**
    - A new Transform

  - **copy() → Pose**
    - Creates a deep copy of this pose.

    **Returns:**
    - A copy of this pose

  - **position_as_list() → typing_extensions.List[float]**
    - Returns only the position as a list of xyz.

    **Returns:**
    - The position as a list

  - **orientation_as_list() → typing_extensions.List[float]**
    - Returns only the orientation as a list of a quaternion

    **Returns:**
    - The orientation as a quaternion with xyzw

  - **dist(other_pose: Pose) → float**
    - Calculates the Euclidean distance between this Pose and the given one. For distance calculation, only the position is used.

    **Parameters:**
    - other_pose: Pose to which the distance should be calculated

    **Returns:**
    - The distance between the Poses

  - **__eq__(other: Pose) → bool**
    - Overloads the ‘==’ operator to check for equality between two Poses. Only compares the position, orientation, and frame. Timestamps of Poses are not taken into account.

    **Parameters:**
    - other: Other pose which should be compared

    **Returns:**
    - True if both Poses have the same position, orientation, and frame. False otherwise

  - **set_position(new_position: typing_extensions.List[float]) → None**
    - Sets the position of this Pose to the given position. Position has to be given as a vector in cartesian space.

    **Parameters:**
    - new_position: New position as a vector of xyz

  - **set_orientation(new_orientation: typing_extensions.List[float]) → None**
    - Sets the orientation to the given quaternion. The new orientation has to be given as a quaternion.

    **Parameters:**
    - new_orientation: New orientation as a quaternion with xyzw

  - **to_sql() → pycram.orm.base.Pose**

  - **insert(session: sqlalchemy.orm.Session) → pycram.orm.base.Pose**

  - **multiply_quaternions(quaternion: typing_extensions.List) → None**
    - Multiply the quaternion of this Pose with the given quaternion. The result will be the new orientation of this Pose.

    **Parameters:**
    - quaternion: The quaternion by which the orientation of this Pose should be multiplied

  - **set_orientation_from_euler(axis: typing_extensions.List, euler_angles: typing_extensions.List[float]) → None**
    - Convert axis-angle to quaternion.

    **Parameters:**
    - axis: (x, y, z) tuple representing rotation axis.
    - angle: rotation angle in degree

    **Returns:**
    - The quaternion representing the axis angle

**class pycram.datastructures.pose.Transform(translation: typing_extensions.Optional[typing_extensions.List[float]] = None, rotation: typing_extensions.Optional[typing_extensions.List[float]] = None, frame: typing_extensions.Optional[str] = 'map', child_frame: typing_extensions.Optional[str] = '', time: rospy.Time = None)**
- Bases: geometry_msgs.msg.TransformStamped
- Represents a Transformation from one TF frame to another in PyCRAM. Like with Poses, this class inherits from the ROS message TransformStamped from geometry_msgs, making it compatible with ROS services and messages requiring a TransformStamped message.

  **Naming Convention for Transforms:**
  - Transform: Instances of this class, representing a translation and rotation from frame_id to child_frame_id
  - Translation: A vector representing the conversion in cartesian space
  - Rotation: A quaternion representing the conversion of rotation between both frames

  **Properties:**
  - **frame:** str
    - Property for the frame_id such that it is easier accessible. Instead of Pose.header.frame_id, it is Pose.frame

    **Returns:**
    - The TF frame of this Pose

  - **translation:** None
    - Property that points to the translation of this Transform

  - **rotation:** None
    - Property that points to the rotation of this Transform

  **Methods:**
  - **classmethod from_pose_and_child_frame(pose: Pose, child_frame_name: str) → Transform**

  - **static from_transform_stamped(transform_stamped: geometry_msgs.msg.TransformStamped) → Transform**
    - Creates a Transform instance from a geometry_msgs/TransformStamped message. Should be used for compatibility with ROS.

    **Parameters:**
    - transform_stamped: The transform stamped message that should be converted

    **Returns:**
    - A Transform with the same information as the transform stamped message

  - **copy() → Transform**
    - Creates a deep copy of this pose.

    **Returns:**
    - A copy of this pose

  - **translation_as_list() → typing_extensions.List[float]**
    - Returns the translation of this Transform as a list.

    **Returns:**
    - The translation as a list of xyz

  - **rotation_as_list() → typing_extensions.List[float]**
    - Returns the rotation of this Transform as a list representing a quaternion.

    **Returns:**
    - The rotation of this Transform as a list with xyzw

  - **to_pose() → Pose**
    - Converts this Transform to a Pose, in this process the child_frame_id is lost.

    **Returns:**
    - A new pose with the same translation as position and rotation as orientation

  - **invert() → Transform**
    - Inverts this Transform. The new Transform points from the child_frame_id to the frame_id.

    **Returns:**
    - A new inverted Transform

  - **__mul__(other: Transform) → typing_extensions.Union[Transform, None]**
    - Multiplies this Transform with another one. The resulting Transform points from the frame_id of this Transform to the child_frame_id of the other Transform.

    **Parameters:**
    - other: The Transform which should be multiplied with this one.

    **Returns:**
    - The resulting Transform from the multiplication

  - **inverse_times(other_transform: Transform) → Transform**
    - Like a ‘minus’ for Transforms, subtracts the other_transform from this one.

    **Parameters:**
    - other_transform: Transform which should be subtracted from this one

    **Returns:**
    - The resulting Transform from the calculation

  - **__eq__(other: Transform) → bool**
    - Overloads the ‘==’ operator to check for equality between two Transforms. Only compares the translation, rotation, frame, and child frame. Timestamps of Poses are not taken into account.

    **Parameters:**
    - other: Other pose which should be compared

    **Returns:**
    - True if both Transforms have the same translation, rotation, frame, and child frame. False otherwise

  - **set_translation(new_translation: typing_extensions.List[float]) → None**
    - Sets the translation of this Transform to the newly given one. Translation has to be a vector in cartesian space.

    **Parameters:**
    - new_translation: The new translation as a vector with xyz.

  - **set_rotation(new_rotation: typing_extensions.List[float]) → None**
    - Sets the rotation of this Transform to the newly given one. Rotation has to be a quaternion.

    **Parameters:**
    - new_rotation: The new rotation as a quaternion with xyzw

|------
pycram.designators.location_designator 
===========================================

### **Classes**

- **Location**  
  Default location designator which only wraps a pose.

- **ObjectRelativeLocation**  
  Location relative to an object.

- **CostmapLocation**  
  Uses Costmaps to create locations for complex constraints.

- **AccessingLocation**  
  Location designator that describes poses used for opening drawers.

- **SemanticCostmapLocation**  
  Locations over semantic entities, like a table surface.

**Module Contents**  
### **Location**  
Bases: `pycram.designator.LocationDesignatorDescription`

Default location designator which only wraps a pose.

- **Class Location**  
  Bases: `pycram.designator.LocationDesignatorDescription.Location`

  Resolved location that represents a specific point in the world which satisfies the constraints of the location designator description.

  - **Attributes:**
    - **pose**: `pycram.datastructures.pose.Pose`

  - **Methods:**
    - **ground() → Location**  
      Default specialized designator that returns a resolved designator containing the pose given in `__init__`.
      - **Returns:** A resolved designator.

### **ObjectRelativeLocation**  
Bases: `pycram.designator.LocationDesignatorDescription`

Location relative to an object.

- **Class Location**  
  Bases: `pycram.designator.LocationDesignatorDescription.Location`

  Resolved location that represents a specific point in the world which satisfies the constraints of the location designator description.

  - **Attributes:**
    - **relative_pose**: `pycram.datastructures.pose.Pose`  
      Pose relative to the object.
    - **reference_object**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`  
      Object to which the pose is relative.

  - **Methods:**
    - **ground() → Location**  
      Default specialized designator that returns a resolved location based on the description input. The resolved location is the first result from the iteration of this instance.
      - **Returns:** A resolved location.

    - **__iter__() → typing_extensions.Iterable[Location]**  
      Iterates over all possible solutions for a resolved location relative to the given object.
      - **Yields:** An instance of `ObjectRelativeLocation.Location` with the relative pose.

### **CostmapLocation**  
Bases: `pycram.designator.LocationDesignatorDescription`

Uses Costmaps to create locations for complex constraints.

- **Class Location**  
  Bases: `pycram.designator.LocationDesignatorDescription.Location`

  Resolved location that represents a specific point in the world which satisfies the constraints of the location designator description.

  - **Attributes:**
    - **reachable_arms**: `typing_extensions.List[pycram.datastructures.enums.Arms]`  
      List of arms with which the pose can be reached, used when the `reachable_for` parameter is applied.

  - **Methods:**
    - **ground() → Location**  
      Default specialized designator that returns the first result from the iteration of this instance.
      - **Returns:** A resolved location.

    - **__iter__()**  
      Generates positions from a costmap based on given constraints and returns them. The generation is based on a costmap created by merging costmaps, each for a different purpose. The base is always an occupancy costmap, with additional costmaps (e.g., visibility or Gaussian) merged according to the constraints. The generator produces pose candidates from the costmap. Each candidate is validated against the constraints, and valid poses are yielded.
      - **Yields:** An instance of `CostmapLocation.Location` with a valid position that satisfies the given constraints.

### **AccessingLocation**  
Bases: `pycram.designator.LocationDesignatorDescription`

Location designator that describes poses used for opening drawers.

- **Class Location**  
  Bases: `pycram.designator.LocationDesignatorDescription.Location`

  Resolved location that represents a specific point in the world which satisfies the constraints of the location designator description.

  - **Attributes:**
    - **arms**: `typing_extensions.List[pycram.datastructures.enums.Arms]`  
      List of arms that can be used for accessing from this pose.

  - **Methods:**
    - **ground() → Location**  
      Default specialized designator for this location designator, returning the first element from the iteration.
      - **Returns:** A location designator for a pose from which the drawer can be opened.

    - **__iter__() → Location**  
      Creates poses from which the robot can open the drawer specified by the `ObjectPart` designator describing the handle. Poses are validated by checking if the robot can grasp the handle while the drawer is closed and if the handle can be grasped when the drawer is open.
      - **Yields:** A location designator containing the pose and the arms that can be used.

### **SemanticCostmapLocation**  
Bases: `pycram.designator.LocationDesignatorDescription`

Locations over semantic entities, like a table surface.

- **Class Location**  
  Bases: `pycram.designator.LocationDesignatorDescription.Location`

  Resolved location that represents a specific point in the world which satisfies the constraints of the location designator description.

  - **Attributes:**
    - **urdf_link_name**: `str`
    - **part_of**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`
    - **for_object**: `typing_extensions.Optional[pycram.designators.object_designator.ObjectDesignatorDescription.Object]`

  - **Methods:**
    - **ground() → Location**  
      Default specialized designator that returns the first element of the iterator of this instance.
      - **Returns:** A resolved location.

    - **__iter__()**  
      Creates a costmap on top of a link of an object and generates positions from it. If there is a specific object for which the position should be found, a height offset will be calculated to ensure that the bottom of the object is at the position in the costmap, not the origin of the object, which is usually in the center.
      - **Yields:** An instance of `SemanticCostmapLocation.Location` with the valid position from the costmap.

|------
pycram.designators.object_designator  
====================================

Classes  


- **BelieveObject**: Description for Objects that are only believed in.
- **ObjectPart**: Object Designator Descriptions for Objects that are part of some other object.
- **LocatedObject**: Description for KnowRob located objects.
- **RealObject**: Object designator representing an object in the real world, when resolving this object designator description ]

Module Contents  

**pycram.designators.object_designator.BelieveObject**  
Bases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription`

Description for objects that are only believed in.

- **class Object**  
  Bases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription.Object`

  Concrete object that is believed in.

  - **to_sql() → pycram.orm.object_designator.BelieveObject**  
    Creates an ORM object that corresponds to this description.
    - **Returns:** The created ORM object.

  - **insert(session: sqlalchemy.orm.session.Session) → pycram.orm.object_designator.BelieveObject**  
    Adds and commits this and all related objects to the session. Auto-incrementing primary keys and foreign keys have to be filled by this method.
    - **Parameters:** 
      - **session:** Session with a database that is used to add and commit the objects
    - **Returns:** The completely instanced ORM object.

**pycram.designators.object_designator.ObjectPart**  
Bases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription`

Object Designator Description for objects that are part of some other object.

- **class Object**  
  Bases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription.Object`

  A single element that fits the description.

  - **Attributes:**
    - **part_pose:** `pycram.external_interfaces.robokudo.Pose`

  - **to_sql() → pycram.orm.object_designator.ObjectPart**  
    Creates an ORM object that corresponds to this description.
    - **Returns:** The created ORM object.

  - **insert(session: sqlalchemy.orm.session.Session) → pycram.orm.object_designator.ObjectPart**  
    Adds and commits this and all related objects to the session. Auto-incrementing primary keys and foreign keys have to be filled by this method.
    - **Parameters:** 
      - **session:** Session with a database that is used to add and commit the objects
    - **Returns:** The completely instanced ORM object.

  - **ground() → Object**  
    Default specialized designator, returns the first result of the iterator of this instance.
    - **Returns:** A resolved object designator.

  - **__iter__()**  
    Iterates through every possible solution for the given input parameter.
    - **Yields:** A resolved object designator.

  - **Additional Attributes:**
    - **type:** `pycram.external_interfaces.robokudo.Optional[str]`
    - **names:** `pycram.external_interfaces.robokudo.Optional[pycram.external_interfaces.robokudo.List[str]]`
    - **part_of**

**pycram.designators.object_designator.LocatedObject**  
Bases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription`

Description for KnowRob located objects.  
**Currently has no specialized designators.**

- **class Object**  
  Bases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription.Object`

  A single element that fits the description.

  - **Attributes:**
    - **reference_frame:** `str`
      - Reference frame in which the position is given.
    - **timestamp:** `float`
      - Timestamp at which the position was valid.
    - **Additional Attributes:**
      - **reference_frames:** `pycram.external_interfaces.robokudo.List[str]`
      - **timestamps:** `pycram.external_interfaces.robokudo.List[float]`

**pycram.designators.object_designator.RealObject**  
Bases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription`

Object designator representing an object in the real world. When resolving this object designator description, RoboKudo is queried to perceive an object fitting the given criteria. Afterward, the specialized designator tries to match the found object to an object in the world.

- **class Object**  
  Bases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription.Object`

  A single element that fits the description.

  - **Attributes:**
    - **pose:** `pycram.external_interfaces.robokudo.Pose`
      - Pose of the perceived object.
    - **types:** `pycram.external_interfaces.robokudo.Optional[pycram.external_interfaces.robokudo.List[str]]`
    - **names:** `pycram.external_interfaces.robokudo.Optional[pycram.external_interfaces.robokudo.List[str]]`
    - **world_object:** `pycram.world_concepts.world_object.Object`

  - **__iter__()**  
    Queries RoboKudo for objects that fit the description and then iterates over all World objects that have the same type to match a World object to the real object.
    - **Yields:** A resolved object designator with reference to the world object.
  
|------
pycram.designators.motion_designator  
==========================================

### **Classes**

- **MoveMotion**  
  Moves the robot to a designated location.

- **MoveTCPMotion**  
  Moves the Tool Center Point (TCP) of the robot.

- **LookingMotion**  
  Lets the robot look at a point.

- **MoveGripperMotion**  
  Opens or closes the gripper.

- **DetectingMotion**  
  Tries to detect an object in the Field of View (FOV) of the robot.

- **MoveArmJointsMotion**  
  Moves the joints of each arm into the given position.

- **WorldStateDetectingMotion**  
  Detects an object based on the world state.

- **MoveJointsMotion**  
  Moves any joint on the robot.

- **OpeningMotion**  
  Designator for opening a container.

- **ClosingMotion**  
  Designator for closing a container.

- **TalkingMotion**  
  Talking Motion, lets the robot say a sentence.

**Module Contents**  

### **Class Details**

#### **MoveMotion**
   Bases: `pycram.designator.BaseMotion`  
   Moves the robot to a designated location.

- **Attributes:**
  - `target`: `pycram.datastructures.pose.Pose`  
    Location to which the robot should be moved.

- **Methods:**
  - `perform()`: Passes this designator to the process module for execution.
  - `to_sql() -> pycram.orm.motion_designator.MoveMotion`: Creates an ORM object corresponding to this description.
  - `insert(session, *args, **kwargs) -> pycram.orm.motion_designator.MoveMotion`: Adds and commits this and all related objects to the session.

#### **MoveTCPMotion**
   Bases: `pycram.designator.BaseMotion`  
   Moves the Tool Center Point (TCP) of the robot.

- **Attributes:**
  - `target`: `pycram.datastructures.pose.Pose`  
    Target pose to which the TCP should be moved.
  - `arm`: `pycram.datastructures.enums.Arms`  
    Arm with the TCP that should be moved to the target.
  - `allow_gripper_collision`: `typing_extensions.Optional[bool] = None`  
    If the gripper can collide with something.

- **Methods:**
  - `perform()`: Passes this designator to the process module for execution.
  - `to_sql() -> pycram.orm.motion_designator.MoveTCPMotion`: Creates an ORM object corresponding to this description.
  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.MoveTCPMotion`: Adds and commits this and all related objects to the session.

#### **LookingMotion**
   Bases: `pycram.designator.BaseMotion`  
   Lets the robot look at a point.

- **Attributes:**
  - `target`: `pycram.datastructures.pose.Pose`  

- **Methods:**
  - `perform()`: Passes this designator to the process module for execution.
  - `to_sql() -> pycram.orm.motion_designator.LookingMotion`: Creates an ORM object corresponding to this description.
  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.LookingMotion`: Adds and commits this and all related objects to the session.

#### **MoveGripperMotion**
   Bases: `pycram.designator.BaseMotion`  
   Opens or closes the gripper.

- **Attributes:**
  - `motion`: `pycram.datastructures.enums.GripperState`  
    Motion that should be performed, either 'open' or 'close'.
  - `gripper`: `pycram.datastructures.enums.Arms`  
    Name of the gripper that should be moved.
  - `allow_gripper_collision`: `typing_extensions.Optional[bool] = None`  
    If the gripper is allowed to collide with something.

- **Methods:**
  - `perform()`: Passes this designator to the process module for execution.
  - `to_sql() -> pycram.orm.motion_designator.MoveGripperMotion`: Creates an ORM object corresponding to this description.
  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.MoveGripperMotion`: Adds and commits this and all related objects to the session.

#### **DetectingMotion**
   Bases: `pycram.designator.BaseMotion`  
   Tries to detect an object in the FOV of the robot.

- **Attributes:**
  - `object_type`: `pycram.datastructures.enums.ObjectType`  
    Type of the object that should be detected.

- **Methods:**
  - `perform()`: Passes this designator to the process module for execution.
  - `to_sql() -> pycram.orm.motion_designator.DetectingMotion`: Creates an ORM object corresponding to this description.
  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.DetectingMotion`: Adds and commits this and all related objects to the session.

#### **MoveArmJointsMotion**
   Bases: `pycram.designator.BaseMotion`  
   Moves the joints of each arm into the given position.

- **Attributes:**
  - `left_arm_poses`: `typing_extensions.Optional[typing_extensions.Dict[str, float]] = None`  
    Target positions for the left arm joints.
  - `right_arm_poses`: `typing_extensions.Optional[typing_extensions.Dict[str, float]] = None`  
    Target positions for the right arm joints.

- **Methods:**
  - `perform()`: Passes this designator to the process module for execution.
  - `to_sql() -> pycram.orm.motion_designator.Motion`: Creates an ORM object corresponding to this description.
  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.Motion`: Adds and commits this and all related objects to the session.

#### **WorldStateDetectingMotion**
   Bases: `pycram.designator.BaseMotion`  
   Detects an object based on the world state.

- **Attributes:**
  - `object_type`: `pycram.datastructures.enums.ObjectType`  
    Object type that should be detected.

- **Methods:**
  - `perform()`: Passes this designator to the process module for execution.
  - `to_sql() -> pycram.orm.motion_designator.Motion`: Creates an ORM object corresponding to this description.
  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.Motion`: Adds and commits this and all related objects to the session.

#### **MoveJointsMotion**
   Bases: `pycram.designator.BaseMotion`  
   Moves any joint on the robot.

- **Attributes:**
  - `names`: `list`  
    List of joint names that should be moved.
  - `positions`: `list`  
    Target positions of joints, should correspond to the list of names.

- **Methods:**
  - `perform()`: Passes this designator to the process module for execution.
  - `to_sql() -> pycram.orm.motion_designator.Motion`: Creates an ORM object corresponding to this description.
  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.Motion`: Adds and commits this and all related objects to the session.

#### **OpeningMotion**
   Bases: `pycram.designator.BaseMotion`  
   Designator for opening a container.

- **Attributes:**
  - `object_part`: `pycram.designators.object_designator.ObjectPart.Object`  
    Object designator for the drawer handle.
  - `arm`: `pycram.datastructures.enums.Arms`  
    Arm that should be used.

- **Methods:**
  - `perform()`: Passes this designator to the process module for execution.
  - `to_sql() -> pycram.orm.motion_designator.OpeningMotion`: Creates an ORM object corresponding to this description.
  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.OpeningMotion`: Adds and commits this and all related objects to the session.

#### **ClosingMotion**
   Bases: `pycram.designator.BaseMotion`  
   Designator for closing a container.

- **Attributes:**
  - `object_part`: `pycram.designators.object_designator.ObjectPart.Object`  
    Object designator for the drawer handle.
  - `arm`: `pycram.datastructures.enums.Arms`  
    Arm that should be used.

- **Methods:**
  - `perform()`: Passes this designator to the process module for execution.
  - `to_sql() -> pycram.orm.motion_designator.ClosingMotion`: Creates an ORM object corresponding to this description.
  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.ClosingMotion`: Adds and commits this and all related objects to the session.

#### **TalkingMotion**
   Bases: `pycram.designator.BaseMotion`  
   Talking Motion, lets the robot say a sentence.

- **Attributes:**
  - `cmd`: `str`  
    Sentence that the robot should say.

- **Methods:**
  - `perform()`: Passes this designator to the process module for execution.
  - `to_sql() -> pycram.orm.motion_designator.Motion`: Creates an ORM object corresponding to this description.
  -

 `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.Motion`: Adds and commits this and all related objects to the session.

|------
pycram.costmaps 
====================================

**Attributes**  

- **cmap**

**Classes**  

- **Rectangle**  
  A rectangle described by lower and upper x and y values.

- **Costmap**  
  The base class of all Costmaps, implementing the visualization of costmaps.

- **OccupancyCostmap**  
  Represents a map of the environment where obstacles or inaccessible positions for a robot have a value of -1.

- **VisibilityCostmap**  
  Represents the visibility of a specific point for every position around it.

- **GaussianCostmap**  
  Represents 2D Gaussian distributions around the origin with a given mean and sigma.

- **SemanticCostmap**  
  Represents a 2D distribution over a link of an object, such as a table surface.

**Functions**  


- **plot_grid(data: numpy.ndarray) → None**  
  An auxiliary method only used for debugging. It plots a 2D numpy array using Matplotlib.

**Module Contents** 

### **Rectangle**

A rectangle described by lower and upper x and y values.

- **Attributes:**
  - **x_lower**: float
  - **x_upper**: float
  - **y_lower**: float
  - **y_upper**: float

- **Methods:**
  - **translate(x: float, y: float)**  
    Translates the rectangle by x and y.

  - **scale(x_factor: float, y_factor: float)**  
    Scales the rectangle by x_factor and y_factor.

### **Costmap**  
Bases: Costmap

The base class of all Costmaps, implementing the visualization of costmaps in the World.

- **Attributes:**
  - **world**
  - **resolution**: float
  - **size**: int
  - **height**: int
  - **width**: int
  - **local_transformer**
  - **origin**: pycram.datastructures.pose.Pose
  - **map**: numpy.ndarray
  - **vis_ids**: typing_extensions.List[int] = []

- **Methods:**
  - **visualize() → None**  
    Visualizes a costmap in the BulletWorld by subdividing the costmap into rectangles, which are then visualized as pybullet visual shapes.

  - **_chunks(lst: typing_extensions.List, n: int) → typing_extensions.List**  
    Yields successive n-sized chunks from lst.

    - **Parameters:**
      - **lst**: The list from which chunks should be yielded.
      - **n**: Size of the chunks.
    - **Returns:** A list of size n from lst.

  - **close_visualization() → None**  
    Removes the visualization from the World.

  - **_find_consecutive_line(start: typing_extensions.Tuple[int, int], map: numpy.ndarray) → int**  
    Finds the number of consecutive entries in the costmap that are greater than zero.

    - **Parameters:**
      - **start**: The indices in the costmap from which the consecutive line should be found.
      - **map**: The costmap in which the line should be found.
    - **Returns:** The length of the consecutive line of entries greater than zero.

  - **_find_max_box_height(start: typing_extensions.Tuple[int, int], length: int, map: numpy.ndarray) → int**  
    Finds the maximum height for a rectangle with a given width in a costmap.

    - **Parameters:**
      - **start**: The indices in the costmap from which the method should start.
      - **length**: The given width for the rectangle.
      - **map**: The costmap in which the search should be conducted.
    - **Returns:** The height of the rectangle.

  - **merge(other_cm: Costmap) → Costmap**  
    Merges the values of two costmaps and returns a new costmap with the merged values of both inputs. To merge two costmaps, they must fulfill three constraints:
    1. Same size.
    2. Same x and y coordinates in the origin.
    3. Same resolution.

    - **Parameters:**
      - **other_cm**: The other costmap to be merged.
    - **Returns:** A new costmap with merged values.

  - **__add__(other: Costmap) → Costmap**  
    Overloads the "+" operator for merging Costmaps. Ensures that 'other' is a Costmap and raises a ValueError if not. Refer to **merge** for more information.

    - **Parameters:**
      - **other**: Another Costmap.
    - **Returns:** A new Costmap with merged values from both Costmaps.

  - **partitioning_rectangles() → typing_extensions.List[Rectangle]**  
    Partitions the map attached to this costmap into rectangles. The rectangles are axis-aligned, exhaustive, and disjoint.

    - **Returns:** A list containing the partitioning rectangles.

### **OccupancyCostmap**  
Bases: Costmap

Represents a map of the environment where obstacles or inaccessible positions for a robot have a value of -1.

- **Attributes:**
  - **world**

- **Methods:**
  - **_calculate_diff_origin(height: int, width: int) → pycram.datastructures.pose.Pose**  
    Calculates the difference between the origin of the costmap as stated by the metadata and the actual middle of the costmap used by PyCRAM for visualization.

    - **Parameters:**
      - **height**: The height of the costmap.
      - **width**: The width of the costmap.
    - **Returns:** The difference between the actual origin and center of the costmap.

  - **_get_map() → numpy.ndarray**  
    Receives the map array from the map server and converts it into a numpy array.

    - **Returns:** The costmap as a numpy array.

  - **_get_map_metadata() → nav_msgs.msg.MapMetaData**  
    Receives metadata about the costmap from the map server. Metadata includes height, width, origin, and resolution.

    - **Returns:** The metadata for the costmap array.

  - **_convert_map(map: numpy.ndarray) → numpy.ndarray**  
    Converts the Occupancy Map from ROS to be consistent with PyCRAM's handling of costmaps. Valid cells for a robot are set to one, and others to zero, considering the distance to obstacle parameter.

    - **Parameters:**
      - **map**: The map to be converted, represented as a 2D numpy array.
    - **Returns:** The converted map as a 2D numpy array.

  - **create_sub_map(sub_origin: pycram.datastructures.pose.Pose, size: int) → Costmap**  
    Creates a smaller map centered around a specified point with the size "size". The resolution remains the same.

    - **Parameters:**
      - **sub_origin**: The point in the global coordinate frame around which the sub-costmap should be centered.
      - **size**: The size the sub-costmap should have.
    - **Returns:** The sub-costmap as a 2D numpy array.

  - **_create_from_world(size: int, resolution: float) → numpy.ndarray**  
    Creates an Occupancy Costmap for the specified World. Marks every position as valid that has no object above it, applying the distance to obstacle parameter afterward.

    - **Parameters:**
      - **size**: The size of the costmap. Specifies the length of one side of the costmap, created as a square.
      - **resolution**: The resolution of the costmap, determining how much meter a pixel represents.

  - **_chunks(lst: typing_extensions.List, n: int) → typing_extensions.List**  
    Yields successive n-sized chunks from lst.

    - **Parameters:**
      - **lst**: The list from which chunks should be yielded.
      - **n**: Size of the chunks.
    - **Returns:** A list of size n from lst.

### **VisibilityCostmap**  
Bases: Costmap

Represents the visibility of a specific point for every position around it. Refer to the PhD Thesis (page 173) for a detailed explanation.

- **Attributes:**
  - **world**
  - **map**
  - **size**
  - **resolution**
  - **max_height**: float
  - **min_height**: float
  - **origin**: pycram.datastructures.pose.Pose

- **Methods:**
  - **_create_images() → typing_extensions.List[numpy.ndarray]**  
    Creates four depth images in every direction around the point for which the costmap should be created. The depth images represent the distance to the next object in meters.

    - **Returns:** A list of four depth images, represented as 2D arrays.

  - **_depth_buffer_to_meter(buffer: numpy.ndarray) → numpy.ndarray**  
    Converts the depth images generated by the World to represent each position in meters.

    - **Returns:** The depth image in meters.

  - **_generate_map()**  
    Generates the resulting density map using the algorithm in Lorenz Mösenlechner's PhD Thesis (page 178). The map is then saved to `self.map`.

### **GaussianCostmap**  
Bases: Costmap

Gaussian Costmaps are 2D Gaussian distributions around the origin with the given mean and sigma.

- **Attributes:**
  - **gau**: numpy.ndarray
  - **map**: numpy.ndarray
  - **size**: float
  - **origin**: pycram.datas

tructures.pose.Pose

- **Methods:**
  - **_gaussian_window(mean: int, std: float) → numpy.ndarray**  
    Creates a window of values with a Gaussian distribution of size "mean" and standard deviation "std". Code is based on Scipy.

### **SemanticCostmap**  
Bases: Costmap

Semantic Costmaps represent a 2D distribution over a link of an object, such as a table surface.

- **Attributes:**
  - **world**: pycram.datastructures.world.World
  - **object**: pycram.world_concepts.world_object.Object
  - **link**: pycram.description.Link
  - **resolution**: float
  - **origin**: pycram.datastructures.pose.Pose
  - **height**: int = 0
  - **width**: int = 0
  - **map**: numpy.ndarray = []

- **Methods:**
  - **generate_map() → None**  
    Generates the semantic costmap according to the provided parameters using the axis-aligned bounding box (AABB) for the link. The height and width of the final Costmap correspond to the x and y sizes of the AABB.

  - **get_aabb_for_link() → pycram.datastructures.dataclasses.AxisAlignedBoundingBox**  
    Returns the AABB of the link provided when creating the costmap. The object is rotated to align the link in the identity orientation.


|------
pycram.plan_failures  
====================================

### **Exceptions**

- **PlanFailure**  
  Implementation of plan failures.

- **NotALanguageExpression**  
  Implementation of plan failures.

- **FailureDiagnosis**  
  Implementation of plan failures.

- **LowLevelFailure**  
  Failure thrown by low-level modules: robot or projection PMs.

- **ActionlibActionTimeout**  
  Failure thrown by low-level modules: robot or projection PMs.

- **HighLevelFailure**  
  Failure thrown by high-level modules, i.e., plans.

- **DeliveringFailed**  
  Thrown when a delivering plan completely gives up.

- **ManipulationLowLevelFailure**  
  Thrown when a low-level, i.e., hardware-related, failure is detected in a manipulation action.

- **EnvironmentManipulationGoalNotReached**  
  Thrown when the door/drawer opening/closing goal is still not reached.

- **EnvironmentManipulationImpossible**  
  Thrown when environment manipulation cannot be achieved.

- **EnvironmentUnreachable**  
  Thrown when environment manipulation is in collision or unreachable.

- **FetchingFailed**  
  Thrown when a fetching plan completely gives up.

- **GripperLowLevelFailure**  
  Thrown when a failure involving the gripper hardware occurs.

- **GripperClosedCompletely**  
  Thrown when the gripper closes completely, despite not being expected to do so (e.g., because it should have grasped something).

- **GripperGoalNotReached**  
  Thrown when the gripper does not reach its goal.

- **LookingHighLevelFailure**  
  High-level failure produced when looking for an object, i.e., it is not a hardware issue but one relating to the looking task, its parameters, and how they relate to the environment.

- **ManipulationGoalInCollision**  
  Thrown when executing a manipulation action results in a collision.

- **ManipulationGoalNotReached**  
  Thrown when, after executing the action, the goal is still not reached.

- **IKError**  
  Thrown when no inverse kinematics solution could be found.

- **ManipulationPoseUnreachable**  
  Thrown when no IK solution can be found.

- **NavigationHighLevelFailure**  
  High-level failure produced while navigating the robot, i.e., it is not a hardware issue but one relating to the navigation task, its parameters, and how they relate to the environment.

- **NavigationGoalInCollision**  
  Navigation goal cannot be reached because the goal itself is already occupied by some other object.

- **NavigationLowLevelFailure**  
  Low-level failure produced while navigating the robot, i.e., some kind of hardware issue.

- **NavigationGoalNotReached**  
  Thrown when the base moved as a result of the navigation action, but the goal was not reached.

- **NavigationPoseUnreachable**  
  Thrown when the goal pose for navigation is computed to be unreachable.

- **ObjectNowhereToBeFound**  
  Thrown when the robot cannot find an object of a given description in its surroundings.

- **ObjectUndeliverable**  
  Thrown when no base positioning can assure a reachable pose to place the object from.

- **ObjectUnfetchable**  
  Thrown when no base positioning can assure a reachable pose to grasp the object from.

- **ObjectUnreachable**  
  Thrown when no IK solution is found for a particular base pose.

- **PerceptionLowLevelFailure**  
  Low-level failure produced while perceiving, i.e., some kind of hardware issue.

- **PerceptionObjectNotFound**  
  Thrown when an attempt to find an object by perception fails -- and this can still be interpreted as the robot not looking in the right direction, as opposed to the object being absent.

- **PerceptionObjectNotInWorld**  
  Thrown when an attempt to find an object by perception fails -- and this is because the object can be assumed absent or perhaps is known to be absent due to the setup of a simulation.

- **SearchingFailed**  
  Thrown when a searching plan completely gives up.

- **TorsoLowLevelFailure**  
  Low-level failure produced while moving the torso, i.e., some kind of hardware issue.

- **TorsoGoalNotReached**  
  Thrown when the torso moved as a result of a torso action, but the goal was not reached.

- **TorsoGoalUnreachable**  
  Thrown when the goal for the torso is computed to be unreachable.

- **Task**  
  Implementation of plan failures.

- **Grasping**  

- **Looking**  

- **ObjectPoseMisestimation**  
  Implementation of plan failures.

- **SuccessfulCompletion**  
  Implementation of plan failures.

- **ObjectNotFound**  
  Implementation of plan failures.

- **LocomotorFailure**  
  Implementation of plan failures.

- **ArmFailure**  
  Implementation of plan failures.

- **ObjectLost**  
  Implementation of plan failures.

- **SensorFailure**  
  Implementation of plan failures.

- **IllPosedGoalFailure**  
  Implementation of plan failures.

- **CapabilityAbsenceFailure**  
  Implementation of plan failures.

- **ReachabilityFailure**  
  Implementation of plan failures.

- **TorsoFailure**  
  Implementation of plan failures.

- **ConfigurationNotReached**  
  Implementation of plan failures.

- **Timeout**  
  Implementation of plan failures.

- **EndEffectorFailure**  
  Implementation of plan failures.

- **ObjectUnavailable**  
  Implementation of plan failures.

- **SustainedFailure**  
  Implementation of plan failures.

- **ReasoningError**  
  Implementation of plan failures.

- **CollisionError**  
  Implementation of plan failures.

**Module Contents**  

### **py:exception:: PlanFailure(*args, **kwargs)**  
Bases: `Exception`

Implementation of plan failures.

### **py:exception:: NotALanguageExpression(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: FailureDiagnosis(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: LowLevelFailure(*args, **kwargs)**  
Bases: `FailureDiagnosis`

Failure thrown by low-level modules: robot or projection PMs.

### **py:exception:: ActionlibActionTimeout(*args, **kwargs)**  
Bases: `LowLevelFailure`

Failure thrown by low-level modules: robot or projection PMs.

### **py:exception:: HighLevelFailure(*args, **kwargs)**  
Bases: `FailureDiagnosis`

Failure thrown by high-level modules, i.e., plans.

### **py:exception:: DeliveringFailed(*args, **kwargs)**  
Bases: `HighLevelFailure`

Thrown when a delivering plan completely gives up.

### **py:exception:: ManipulationLowLevelFailure(*args, **kwargs)**  
Bases: `LowLevelFailure`

Thrown when a low-level, i.e., hardware-related, failure is detected in a manipulation action.

### **py:exception:: EnvironmentManipulationGoalNotReached(*args, **kwargs)**  
Bases: `ManipulationLowLevelFailure`

Thrown when the door/drawer opening/closing goal is still not reached.

### **py:exception:: EnvironmentManipulationImpossible(*args, **kwargs)**  
Bases: `HighLevelFailure`

Thrown when environment manipulation cannot be achieved.

### **py:exception:: EnvironmentUnreachable(*args, **kwargs)**  
Bases: `HighLevelFailure`

Thrown when environment manipulation is in collision or unreachable.

### **py:exception:: FetchingFailed(*args, **kwargs)**  
Bases: `HighLevelFailure`

Thrown when a fetching plan completely gives up.

### **py:exception:: GripperLowLevelFailure(*args, **kwargs)**  
Bases: `LowLevelFailure`

Thrown when a failure involving the gripper hardware occurs.

### **py:exception:: GripperClosedCompletely(*args, **kwargs)**  
Bases: `GripperLowLevelFailure`

Thrown when the gripper closes completely, despite not being expected to do so (e.g., because it should have grasped something).

### **py:exception:: GripperGoalNotReached(*args, **kwargs)**  
Bases: `GripperLowLevelFailure`

Thrown when the gripper does not reach its goal.

### **py:exception:: LookingHighLevelFailure(*args, **kwargs)**  
Bases: `HighLevelFailure`

High-level failure produced when looking for an object, i.e., it is not a hardware issue but one relating to the looking task, its parameters, and how they relate to the environment.

### **py:exception:: ManipulationGoalInCollision(*args, **kwargs)**  
Bases: `HighLevelFailure`

Thrown when executing a manipulation action results in a collision.

### **py:exception:: ManipulationGoalNotReached(*args, **kwargs)**  
Bases: `ManipulationLowLevelFailure`

Thrown when, after executing the action, the goal is still not reached.

### **py:exception:: IKError(pose, base_frame, tip_frame)**  
Bases: `PlanFailure`

Thrown when no inverse kinematics solution could be found.
- **Attributes:**
  - **message**

### **py:exception:: ManipulationPoseUnreachable(*args, **kwargs)**  
Bases: `ManipulationLowLevelFailure`

Thrown when no IK solution can be found.

### **py:exception:: NavigationHighLevelFailure(*args, **kwargs)**  
Bases: `HighLevelFailure`

High-level failure produced while navigating the robot, i.e., it is not a hardware issue but one relating to the navigation task, its parameters, and how they relate to the environment.

### **py:exception:: Navigation

GoalInCollision(*args, **kwargs)**  
Bases: `NavigationHighLevelFailure`

Navigation goal cannot be reached because the goal itself is already occupied by some other object.

### **py:exception:: NavigationLowLevelFailure(*args, **kwargs)**  
Bases: `LowLevelFailure`

Low-level failure produced while navigating the robot, i.e., some kind of hardware issue.

### **py:exception:: NavigationGoalNotReached(*args, **kwargs)**  
Bases: `NavigationLowLevelFailure`

Thrown when the base moved as a result of the navigation action, but the goal was not reached.

### **py:exception:: NavigationPoseUnreachable(*args, **kwargs)**  
Bases: `NavigationLowLevelFailure`

Thrown when the goal pose for navigation is computed to be unreachable.

### **py:exception:: ObjectNowhereToBeFound(*args, **kwargs)**  
Bases: `HighLevelFailure`

Thrown when the robot cannot find an object of a given description in its surroundings.

### **py:exception:: ObjectUndeliverable(*args, **kwargs)**  
Bases: `HighLevelFailure`

Thrown when no base positioning can assure a reachable pose to place the object from.

### **py:exception:: ObjectUnfetchable(*args, **kwargs)**  
Bases: `HighLevelFailure`

Thrown when no base positioning can assure a reachable pose to grasp the object from.

### **py:exception:: ObjectUnreachable(*args, **kwargs)**  
Bases: `HighLevelFailure`

Thrown when no IK solution is found for a particular base pose.

### **py:exception:: PerceptionLowLevelFailure(*args, **kwargs)**  
Bases: `LowLevelFailure`

Low-level failure produced while perceiving, i.e., some kind of hardware issue.

### **py:exception:: PerceptionObjectNotFound(*args, **kwargs)**  
Bases: `PerceptionLowLevelFailure`

Thrown when an attempt to find an object by perception fails -- and this can still be interpreted as the robot not looking in the right direction, as opposed to the object being absent.

### **py:exception:: PerceptionObjectNotInWorld(*args, **kwargs)**  
Bases: `PerceptionLowLevelFailure`

Thrown when an attempt to find an object by perception fails -- and this is because the object can be assumed absent or perhaps is known to be absent due to the setup of a simulation.

### **py:exception:: SearchingFailed(*args, **kwargs)**  
Bases: `HighLevelFailure`

Thrown when a searching plan completely gives up.

### **py:exception:: TorsoLowLevelFailure(*args, **kwargs)**  
Bases: `LowLevelFailure`

Low-level failure produced while moving the torso, i.e., some kind of hardware issue.

### **py:exception:: TorsoGoalNotReached(*args, **kwargs)**  
Bases: `TorsoLowLevelFailure`

Thrown when the torso moved as a result of a torso action, but the goal was not reached.

### **py:exception:: TorsoGoalUnreachable(*args, **kwargs)**  
Bases: `TorsoLowLevelFailure`

Thrown when the goal for the torso is computed to be unreachable.

### **py:exception:: Task(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: Grasping(*args, **kwargs)**  
Bases: `Task`

Implementation of plan failures.

### **py:exception:: Looking(*args, **kwargs)**  
Bases: `Task`

Implementation of plan failures.

### **py:exception:: ObjectPoseMisestimation(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: SuccessfulCompletion(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: ObjectNotFound(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: LocomotorFailure(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: ArmFailure(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: ObjectLost(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: SensorFailure(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: IllPosedGoalFailure(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: CapabilityAbsenceFailure(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: ReachabilityFailure(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: TorsoFailure(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: ConfigurationNotReached(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: Timeout(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: EndEffectorFailure(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: ObjectUnavailable(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: SustainedFailure(*args, **kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: ReasoningError(**kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

### **py:exception:: CollisionError(**kwargs)**  
Bases: `PlanFailure`

Implementation of plan failures.

|------
pycram.world_reasoning  

### **Functions**

- **stable(obj: pycram.world_concepts.world_object.Object) → bool**  
  Checks if an object is stable in the world. Stability means that its position will not change after simulating physics in the World. This is done by simulating the world for 10 seconds and comparing the previous coordinates with the coordinates after the simulation.

  - **Parameters:**
    - **obj**: The object to be checked.
  - **Returns:** True if the object is stable in the world; False otherwise.

- **contact(object1: pycram.world_concepts.world_object.Object, object2: pycram.world_concepts.world_object.Object, return_links: bool = False) → typing_extensions.Union[bool, typing_extensions.Tuple[bool, typing_extensions.List]]**  
  Checks if two objects are in contact. If `return_links` is True, the output will also contain a list of tuples where the first element is the link name of `object1`, and the second element is the link name of `object2`.

  - **Parameters:**
    - **object1**: The first object.
    - **object2**: The second object.
    - **return_links**: If the respective links on the objects in contact should be returned.
  - **Returns:** True if the two objects are in contact; False otherwise. If links are returned, a list of links in contact.

- **get_visible_objects(camera_pose: pycram.datastructures.pose.Pose, front_facing_axis: typing_extensions.Optional[typing_extensions.List[float]] = None) → typing_extensions.Tuple[numpy.ndarray, pycram.datastructures.pose.Pose]**  
  Returns a segmentation mask of the objects visible from the given camera pose and the front-facing axis.

  - **Parameters:**
    - **camera_pose**: The pose of the camera in the world coordinate frame.
    - **front_facing_axis**: The axis of the camera frame that faces the front of the robot, given as a list of xyz.
  - **Returns:** A segmentation mask of the visible objects and the pose of the point exactly 2 meters in front of the camera in the direction of the front-facing axis with respect to the world coordinate frame.

- **visible(obj: pycram.world_concepts.world_object.Object, camera_pose: pycram.datastructures.pose.Pose, front_facing_axis: typing_extensions.Optional[typing_extensions.List[float]] = None, threshold: float = 0.8) → bool**  
  Checks if an object is visible from a given position. This is achieved by rendering the object alone and counting the visible pixels, then rendering the complete scene and comparing the visible pixels with the absolute count of pixels.

  - **Parameters:**
    - **obj**: The object for which visibility should be checked.
    - **camera_pose**: The pose of the camera in the map frame.
    - **front_facing_axis**: The axis of the camera frame that faces the front of the robot, given as a list of xyz.
    - **threshold**: The minimum percentage of the object that needs to be visible for this method to return True.
  - **Returns:** True if the object is visible from the camera position; False otherwise.

- **occluding(obj: pycram.world_concepts.world_object.Object, camera_pose: pycram.datastructures.pose.Pose, front_facing_axis: typing_extensions.Optional[typing_extensions.List[float]] = None) → typing_extensions.List[pycram.world_concepts.world_object.Object]**  
  Lists all objects that are occluding the given object. This works similarly to the `visible` function. First, the object alone will be rendered and the position of its pixels in the picture will be saved. Afterward, the complete scene will be rendered, and the saved pixel positions will be compared to the actual pixels. If another object is visible in one of the saved pixel positions, it will be marked as occluding.

  - **Parameters:**
    - **obj**: The object for which occlusion should be checked.
    - **camera_pose**: The pose of the camera in the world coordinate frame.
    - **front_facing_axis**: The axis of the camera frame that faces the front of the robot, given as a list of xyz.
  - **Returns:** A list of occluding objects.

- **reachable(pose_or_object: typing_extensions.Union[pycram.world_concepts.world_object.Object, pycram.datastructures.pose.Pose], robot: pycram.world_concepts.world_object.Object, gripper_name: str, threshold: float = 0.01) → bool**  
  Checks if the robot can reach a given position. To determine this, inverse kinematics are calculated and applied. Afterward, the distance between the position and the given end effector is calculated. If it is smaller than the threshold, the reasoning query returns True; otherwise, it returns False.

  - **Parameters:**
    - **pose_or_object**: The position and rotation or object for which reachability should be checked.
    - **robot**: The robot that should reach for the position.
    - **gripper_name**: The name of the end effector.
    - **threshold**: The threshold between the end effector and the position.
  - **Returns:** True if the end effector is closer than the threshold to the target position; False otherwise.

- **blocking(pose_or_object: typing_extensions.Union[pycram.world_concepts.world_object.Object, pycram.datastructures.pose.Pose], robot: pycram.world_concepts.world_object.Object, gripper_name: str, grasp: str = None) → typing_extensions.Union[typing_extensions.List[pycram.world_concepts.world_object.Object], None]**  
  Checks if any objects are blocking another object when a robot tries to pick it up. This works similarly to the `reachable` function. First, the inverse kinematics between the robot and the object will be calculated and applied. Then it will be checked if the robot is in contact with any object except the given one. If the given pose or object is not reachable, None will be returned.

  - **Parameters:**
    - **pose_or_object**: The object or pose for which blocking objects should be found.
    - **robot**: The robot object that reaches for the object.
    - **gripper_name**: The name of the end effector of the robot.
    - **grasp**: The grasp type with which the object should be grasped.
  - **Returns:** A list of objects the robot is in collision with when reaching for the specified object, or None if the pose or object is not reachable.

- **supporting(object1: pycram.world_concepts.world_object.Object, object2: pycram.world_concepts.world_object.Object) → bool**  
  Checks if one object is supporting another object. An object supports another object if they are in contact and the second object is above the first one (e.g., a bottle will be supported by a table).

  - **Parameters:**
    - **object1**: The object that is supported.
    - **object2**: The object that supports the first object.
  - **Returns:** True if the second object is in contact with the first one and is above it; False otherwise.

- **link_pose_for_joint_config(obj: pycram.world_concepts.world_object.Object, joint_config: typing_extensions.Dict[str, float], link_name: str) → pycram.datastructures.pose.Pose**  
  Returns the pose a link would be in if the given joint configuration were applied to the object. This is done by using the respective object in the prospection world and applying the joint configuration to this one. After applying the joint configuration, the link position is taken from there.

  - **Parameters:**
    - **obj**: The object of which the link is a part.
    - **joint_config**: Dictionary with the goal joint configuration.
    - **link_name**: Name of the link for which the pose should be returned.
  - **Returns:** The pose of the link after applying the joint configuration.

|------
pycram.language


### **Classes**

- **Language**  
  Parent class for language expressions. Implements operators as well as methods to reduce the resulting language tree.

- **Repeat**  
  Executes all children a given number of times.

- **Monitor**  
  Monitors a Language Expression and interrupts it when the given condition is evaluated to True.

- **Sequential**  
  Executes all children sequentially; an exception while executing a child does not terminate the whole process.

- **TryInOrder**  
  Executes all children sequentially; an exception while executing a child does not terminate the whole process.

- **Parallel**  
  Executes all children in parallel by creating a thread for each child and executing them in the respective threads. All exceptions during execution will be caught, saved to a list, and returned upon completion.

- **TryAll**  
  Executes all children in parallel by creating a thread for each child and executing them in the respective threads. All exceptions during execution will be caught, saved to a list, and returned upon completion.

- **Code**  
  Executable code block in a plan.

**Module Contents**  

### **Language**  
Bases: `anytree.NodeMixin`

Parent class for language expressions. Implements operators as well as methods to reduce the resulting language tree.

- **Attributes:**
  - **parallel_blocklist**: `['PickUpAction', 'PlaceAction', 'OpenAction', 'CloseAction', 'TransportAction', 'GraspingAction']`
  - **do_not_use_giskard**: `['SetGripperAction', 'MoveGripperMotion', 'DetectAction', 'DetectingMotion']`
  - **block_list**: `typing_extensions.List[int]`  
    List of thread IDs which should be blocked from execution.
  - **parent**
  - **exceptions**
  - **state**: `None`
  - **executing_thread**
  - **threads**: `typing_extensions.List[threading.Thread]`
  - **interrupted**: `False`
  - **name**

- **Methods:**
  - **resolve() → Language**  
    Dummy method for compatibility with designator descriptions.
    - **Returns:** Self-reference.
    
  - **perform()**  
    This method should be overwritten in subclasses to implement the behavior of the language expression regarding each child.
    
  - **__add__(other: Language) → Sequential**  
    Language expression for sequential execution.
    - **Parameters:** `other`: Another Language expression.
    - **Returns:** A `Sequential` object which is the new root node of the language tree.
    
  - **__sub__(other: Language) → TryInOrder**  
    Language expression for trying in order.
    - **Parameters:** `other`: Another Language expression.
    - **Returns:** A `TryInOrder` object which is the new root node of the language tree.
    
  - **__or__(other: Language) → Parallel**  
    Language expression for parallel execution.
    - **Parameters:** `other`: Another Language expression.
    - **Returns:** A `Parallel` object which is the new root node of the language tree.
    
  - **__xor__(other: Language) → TryAll**  
    Language expression for trying all executions.
    - **Parameters:** `other`: Another Language expression.
    - **Returns:** A `TryAll` object which is the new root node of the language tree.
    
  - **__rshift__(other: Language)**  
    Operator for Monitors, making the Monitor the parent of the other expression.
    - **Parameters:** `other`: Another Language expression.
    - **Returns:** The Monitor, which is now the new root node.
    
  - **__mul__(other: int)**  
    Language expression for repeated execution. The other attribute of this operator must be an integer.
    - **Parameters:** `other`: An integer stating how often the Language expression should be repeated.
    - **Returns:** A `Repeat` object which is the new root node of the language tree.
    
  - **__rmul__(other: int)**  
    Language expression for repeated execution. The other attribute of this operator must be an integer. This is the reversed operator of `__mul__`, allowing you to write:
    
    ```python
    2 * ParkAction()
    ```
    - **Parameters:** `other`: An integer stating how often the Language expression should be repeated.
    - **Returns:** A `Repeat` object which is the new root node of the language tree.
    
  - **simplify() → Language**  
    Simplifies the language tree by merging nodes that have a parent-child relation and are of the same type.
    
  - **merge_nodes(node1: anytree.Node, node2: anytree.Node) → None**  
    Merges `node1` with `node2` in a tree. The children of `node2` will be re-parented to `node1`, and `node2` will be deleted from the tree.
    - **Parameters:** 
      - **node1**: Node that should be left in the tree.
      - **node2**: Node whose children should be appended to `node1` and then deleted.
    
  - **interrupt() → None**  
    Base method for interrupting the execution of a Language expression. To be overwritten in a sub-class.

### **Repeat**  
Bases: `Language`

Executes all children a given number of times.

- **Attributes:**
  - **repeat**: `int`

- **Methods:**
  - **perform()**  
    Executes all children in a loop as often as stated on initialization.
    
  - **interrupt() → None**  
    Stops the execution of this language expression by setting the `interrupted` variable to True, adding this thread to the block_list in ProcessModule, and interrupting the current Giskard goal.

### **Monitor**  
Bases: `Language`

Monitors a Language Expression and interrupts it when the given condition is evaluated to True.

- **Attributes:**
  - **kill_event**
  - **exception_queue**

- **Methods:**
  - **perform() → typing_extensions.Tuple[pycram.datastructures.enums.State, typing_extensions.Any]**  
    Starts a new thread that checks the condition and then performs the attached language expression.
    - **Returns:** The state of the attached language expression, and a list of the results of the children.
    
  - **interrupt() → None**  
    Calls interrupt for each child.

### **Sequential**  
Bases: `Language`

Executes all children sequentially; an exception while executing a child does not terminate the whole process.

- **Methods:**
  - **perform() → typing_extensions.Tuple[pycram.datastructures.enums.State, typing_extensions.List[typing_extensions.Any]]**  
    Calls `perform()` on each child sequentially.
    - **Returns:** The state and list of results.
    
  - **interrupt() → None**  
    Interrupts the execution of this language expression by setting the `interrupted` variable to True and calling interrupt on the current Giskard goal.

### **TryInOrder**  
Bases: `Language`

Executes all children sequentially; an exception while executing a child does not terminate the whole process.

- **Methods:**
  - **perform() → typing_extensions.Tuple[pycram.datastructures.enums.State, typing_extensions.List[typing_extensions.Any]]**  
    Calls `perform()` on each child sequentially and catches raised exceptions.
    - **Returns:** The state and list of results.
    
  - **interrupt() → None**  
    Interrupts the execution of this language expression by setting the `interrupted` variable to True, adding the current thread to the block_list in Language, and interrupting the current Giskard goal.

### **Parallel**  
Bases: `Language`

Executes all children in parallel by creating a thread for each child and executing them in the respective threads.

- **Methods:**
  - **perform() → typing_extensions.Tuple[pycram.datastructures.enums.State, typing_extensions.List[typing_extensions.Any]]**  
    Creates a new thread for each child and calls `perform()` of the child in the respective thread.
    - **Returns:** The state and list of results.
    
  - **interrupt() → None**  
    Interrupts the execution of this language expression by setting the `interrupted` variable to True, adding the thread ID of all parallel execution threads to the block_list in Language, and interrupting the current Giskard goal.

### **TryAll**  
Bases: `Language`

Executes all children in parallel by creating a thread for each child and executing them in the respective threads.

- **Methods:**
  - **perform() → typing_extensions.Tuple[pycram.datastructures.enums.State, typing_extensions.List[typing_extensions.Any]]**  
    Creates a new thread for each child and executes all children in their respective threads.
    - **Returns:** The state and list of results.
    
  - **interrupt() → None**  
    Interrupts the execution of this language expression by setting the `interrupted` variable to True, adding the thread ID of all parallel execution threads to the block_list in Language, and interrupting the current Giskard goal.

### **Code**  
Bases: `Language`

Executable code block in a plan.

- **Attributes:**
  - **function**: `typing_extensions.Callable`  
  - **kwargs**: `typing_extensions.Dict[str, typing_extensions.Any]`

- **Methods:**
  - **perform**  
    This method should be overwritten in subclasses to implement the behavior of the language expression regarding each child.
    
  - **execute() → typing_extensions.Any**  
    Executes the code with its arguments.
   

 - **Returns:** `State.SUCCEEDED`, and anything that the function associated with this object returns.
    
  - **interrupt() → None**  
    Base method for interrupting the execution of a Language expression. To be overwritten in a sub-class.

|------
pycram.pose_generator_and_validator  
========================================

### **Classes**

- **PoseGenerator**  
  Creates pose candidates from a given costmap. The generator selects the highest values (amount specified by `number_of_samples`) and returns the corresponding positions. Orientations are calculated such that the robot faces the center of the costmap.

### **Functions**

- **visibility_validator(→ bool)**  
  Validates if the robot can see the target position from a given pose candidate.

- **_in_contact(→ bool)**  
  Checks if a given robot is in contact with a given object.

- **reachability_validator(→ typing_extensions.Tuple[bool, ...])**  
  Validates if a target position is reachable for a pose candidate.

- **collision_check(robot, allowed_collision)**  
  Checks if a given robot collides with any object within the world that it is not allowed to collide with.

**Module Contents**  

### **PoseGenerator**  
Bases: `pycram.costmaps.Costmap`

Creates pose candidates from a given costmap. The generator selects the highest values, the amount is given by `number_of_samples`, and returns the corresponding positions. Orientations are calculated such that the robot faces the center of the costmap.

- **Attributes:**
  - **current_orientation_generator**: `None`  
    If no orientation generator is given, this generator is used to generate the orientation of the robot.
  - **override_orientation_generator**: `None`  
    Overrides the orientation generator with a custom generator, which will be used regardless of the `current_orientation_generator`.
  - **costmap**
  - **number_of_samples**
  - **orientation_generator**

- **Methods:**
  - **__iter__() → typing_extensions.Iterable**  
    A generator that creates pose candidates from a given costmap. The generator selects the highest 100 values and returns the corresponding positions. Orientations are calculated such that the robot faces the center of the costmap.
    - **Yield:** A tuple of position and orientation.
    
  - **height_generator() → float**  
    - **Static Method**
    
  - **generate_orientation(position: typing_extensions.List[float], origin: pycram.datastructures.pose.Pose) → typing_extensions.List[float]**  
    Generates the orientation for a given position in a costmap. The orientation is calculated such that the robot faces the origin of the costmap. This is done by calculating the arctan between the position in the costmap and the origin of the costmap.
    - **Parameters:**
      - **position:** The position in the costmap (already converted to the world coordinate frame).
      - **origin:** The origin of the costmap (the point which the robot should face).
    - **Returns:** A quaternion of the calculated orientation.

### **visibility_validator**  
Validates if the robot can see the target position from a given pose candidate. The target position can either be a position in the world coordinate system or an object in the World. The validation is done by shooting a ray from the camera to the target position and checking that it does not collide with anything else.

- **Parameters:**
  - **pose:** The pose candidate to be validated.
  - **robot:** The robot object for which this should be validated.
  - **object_or_pose:** The target position or object for which the pose candidate should be validated.
  - **world:** The World instance in which this should be validated.
- **Returns:** `True` if the target is visible for the robot, otherwise `None`.

### **_in_contact**  
Checks if a given robot is in contact with a given object.

- **Parameters:**
  - **robot:** The robot object that should be checked for contact.
  - **obj:** The object that should be checked for contact with the robot.
  - **allowed_collision:** A dictionary containing the allowed collisions for links of each object in the world.
  - **allowed_robot_links:** A list of links of the robot that are allowed to be in contact with the object.
- **Returns:** `True` if the robot is in contact with the object, otherwise `False`.

### **reachability_validator**  
Validates if a target position is reachable for a pose candidate. This is done by asking the IK solver if there is a valid solution if the robot stands at the position of the pose candidate. If there is a solution, the validator returns `True`, otherwise `False`.

- **Parameters:**
  - **pose:** The pose candidate for which reachability should be validated.
  - **robot:** The robot object in the World for which reachability should be validated.
  - **target:** The target position or object instance that should be the target for reachability.
  - **allowed_collision:** A dictionary of objects with which the robot is allowed to collide. Each object correlates to a list of links of which this object consists.
- **Returns:** A tuple containing `True` if the target is reachable for the robot, otherwise `False`, and a list of results.

### **collision_check**  
Checks if a given robot collides with any object within the world that it is not allowed to collide with. This is done by iterating over every object within the world and checking if the robot collides with it. Note that the floor will be ignored. If there is a collision with an object not within the allowed collision list, the function returns `True`, otherwise `False`.

- **Parameters:**
  - **robot:** The robot object in the (Bullet)World where it should be checked for collisions.
  - **allowed_collision:** A dictionary of objects with which the robot is allowed to collide. Each object correlates to a list of links of which this object consists.
- **Returns:** `True` if the target is reachable for the robot, otherwise `False`.

|------
pycram.robot_descriptions.pr2_description  
==============================================

### **Attributes**

- **rospack**  
- **filename**  
- **pr2_description**  
- **left_arm**  
- **left_gripper**  
- **right_arm**  
- **right_gripper**  
- **camera**  
- **rdm**  

**Module Contents**  

- **pycram.robot_descriptions.pr2_description.rospack**  
- **pycram.robot_descriptions.pr2_description.filename**  
- **pycram.robot_descriptions.pr2_description.pr2_description**  
- **pycram.robot_descriptions.pr2_description.left_arm**  
- **pycram.robot_descriptions.pr2_description.left_gripper**  
- **pycram.robot_descriptions.pr2_description.right_arm**  
- **pycram.robot_descriptions.pr2_description.right_gripper**  
- **pycram.robot_descriptions.pr2_description.camera**  
- **pycram.robot_descriptions.pr2_description.rdm**  

|------
pycram.object_descriptors.generic 
======================================

### **Classes**

- **LinkDescription**  
  A class that represents a link description of an object.

- **JointDescription**  
  A class that represents the description of a joint.

- **ObjectDescription**  
  A generic description of an object in the environment. This description can be applied to any object.

**Module Contents**  

### **LinkDescription**  
Bases: `pycram.description.LinkDescription`

A class that represents a link description of an object.

- **Attributes:**
  - **parsed_description**: `pycram.datastructures.dataclasses.BoxVisualShape`
  - **_name**: `str`

- **Properties:**
  - **geometry**: `typing_extensions.Union[pycram.datastructures.dataclasses.VisualShape, None]`  
    Returns the geometry type of the collision element of this link.
  - **origin**: `pycram.datastructures.pose.Pose`  
    Returns the origin of this entity.
  - **name**: `str`  
    Returns the name of this entity.
  - **color**: `pycram.datastructures.dataclasses.Color`

### **JointDescription**  
Bases: `pycram.description.JointDescription`

A class that represents the description of a joint.

- **Properties:**
  - **type**: `pycram.datastructures.enums.JointType`  
    Returns the type of this joint.
  - **axis**: `geometry_msgs.msg.Point`  
    Returns the axis of this joint, for example, the rotation axis for a revolute joint.
  - **has_limits**: `bool`  
    Checks if this joint has limits.  
    - **Returns:** `True` if the joint has limits, `False` otherwise.
  - **lower_limit**: `typing_extensions.Union[float, None]`  
    Returns the lower limit of this joint, or `None` if the joint has no limits.
  - **upper_limit**: `typing_extensions.Union[float, None]`  
    Returns the upper limit of this joint, or `None` if the joint has no limits.
  - **parent_link_name**: `str`  
    Returns the name of the parent link of this joint.
  - **child_link_name**: `str`  
    Returns the name of the child link of this joint.
  - **origin**: `pycram.datastructures.pose.Pose`  
    Returns the origin of this entity.
  - **name**: `str`  
    Returns the name of this entity.

### **ObjectDescription**  
Bases: `pycram.description.ObjectDescription`

A generic description of an object in the environment. This description can be applied to any object. The current use case involves perceiving objects using RoboKudo and spawning them with specified size and color.

- **Classes:**
  - **Link**  
    Bases: `pycram.description.ObjectDescription.Link`, `LinkDescription`  
    Represents a link of an Object in the World.
  - **RootLink**  
    Bases: `pycram.description.ObjectDescription.RootLink`, `Link`  
    Represents the root link of an Object in the World. It differs from the normal `AbstractLink` class in that the pose and the `tf_frame` is the same as that of the object.
  - **Joint**  
    Bases: `pycram.description.ObjectDescription.Joint`, `JointDescription`  
    Represents a joint of an Object in the World.

- **Attributes:**
  - **_links**

- **Methods:**
  - **load_description(path: str) → typing_extensions.Any**  
    Loads the description from the file at the given path.  
    - **Parameters:**  
      - **path:** The path to the source file. If only a filename is provided, the resources directories will be searched.
  - **generate_from_mesh_file(path: str, name: str) → str**  
    - **Class Method**  
    Generates a description file from one of the mesh types defined in the mesh extensions and returns the path of the generated file.  
    - **Parameters:**  
      - **path:** The path to the .obj file.  
      - **name:** The name of the object.  
    - **Returns:** The path of the generated description file.
  - **generate_from_description_file(path: str) → str**  
    - **Class Method**  
    Preprocesses the given file and returns the preprocessed description string.  
    - **Parameters:**  
      - **path:** The path of the file to preprocess.  
    - **Returns:** The preprocessed description string.
  - **generate_from_parameter_server(name: str) → str**  
    - **Class Method**  
    Preprocesses the description from the ROS parameter server and returns the preprocessed description string.  
    - **Parameters:**  
      - **name:** The name of the description on the parameter server.  
    - **Returns:** The preprocessed description string.
  - **get_link_by_name(link_name: str) → LinkDescription**  
    Returns the link description with the given name.
  - **get_joint_by_name(joint_name: str) → JointDescription**  
    Returns the joint description with the given name.
  - **get_root() → str**  
    Returns the name of the root link of this object.
  - **get_chain(start_link_name: str, end_link_name: str) → typing_extensions.List[str]**  
    Returns the chain of links from `start_link_name` to `end_link_name`.

- **Properties:**
  - **shape_data**: `typing_extensions.List[float]`
  - **color**: `pycram.datastructures.dataclasses.Color`
  - **links**: `typing_extensions.List[LinkDescription]`  
    Returns a list of link descriptions of this object.
  - **joints**: `typing_extensions.List[JointDescription]`  
    Returns a list of joint descriptions of this object.
  - **origin**: `pycram.datastructures.pose.Pose`  
    Returns the origin of this entity.
  - **name**: `str`  
    Returns the name of this entity.

|------
pycram.datastructures.dataclasses  
======================================

### **Classes**

- **Color**  
  Dataclass for storing rgba_color as an RGBA value.

- **AxisAlignedBoundingBox**  
  Dataclass for storing an axis-aligned bounding box.

- **CollisionCallbacks**  

- **MultiBody**  

- **VisualShape**  
  Helper class that provides a standard way to create an ABC using inheritance.

- **BoxVisualShape**  
  Helper class that provides a standard way to create an ABC using inheritance.

- **SphereVisualShape**  
  Helper class that provides a standard way to create an ABC using inheritance.

- **CapsuleVisualShape**  
  Helper class that provides a standard way to create an ABC using inheritance.

- **CylinderVisualShape**  
  Helper class that provides a standard way to create an ABC using inheritance.

- **MeshVisualShape**  
  Helper class that provides a standard way to create an ABC using inheritance.

- **PlaneVisualShape**  
  Helper class that provides a standard way to create an ABC using inheritance.

- **State**  
  Helper class that provides a standard way to create an ABC using inheritance.

- **LinkState**  
  Helper class that provides a standard way to create an ABC using inheritance.

- **JointState**  
  Helper class that provides a standard way to create an ABC using inheritance.

- **ObjectState**  
  Helper class that provides a standard way to create an ABC using inheritance.

- **WorldState**  
  Helper class that provides a standard way to create an ABC using inheritance.

**Module Contents**  

### **Functions**

#### `get_point_as_list(point: pycram.datastructures.pose.Point) -> typing_extensions.List[float]`
   Returns the point as a list.
   - **Parameters:**
     - `point`: The point.
   - **Returns:**  
     The point as a list.

### **Class Details**

#### **Color**
   Dataclass for storing rgba_color as an RGBA value. The values are stored as floats between 0 and 1. The default rgba_color is white. 'A' stands for the opacity.

- **Attributes:**
  - `R`: `float = 1`
  - `G`: `float = 1`
  - `B`: `float = 1`
  - `A`: `float = 1`

- **Methods:**
  - `from_list(color: typing_extensions.List[float])`: Sets the rgba_color from a list of RGBA values.
  - `from_rgb(rgb: typing_extensions.List[float])`: Sets the rgba_color from a list of RGB values.
  - `from_rgba(rgba: typing_extensions.List[float])`: Sets the rgba_color from a list of RGBA values.
  - `get_rgba() -> typing_extensions.List[float]`: Returns the rgba_color as a list of RGBA values.
  - `get_rgb() -> typing_extensions.List[float]`: Returns the rgba_color as a list of RGB values.

#### **AxisAlignedBoundingBox**
   Dataclass for storing an axis-aligned bounding box.

- **Attributes:**
  - `min_x`: `float`
  - `min_y`: `float`
  - `min_z`: `float`
  - `max_x`: `float`
  - `max_y`: `float`
  - `max_z`: `float`

- **Methods:**
  - `from_min_max(min_point: typing_extensions.List[float], max_point: typing_extensions.List[float])`: Sets the axis-aligned bounding box from a minimum and maximum point.
  - `get_min_max_points() -> typing_extensions.Tuple[pycram.datastructures.pose.Point, pycram.datastructures.pose.Point]`: Returns the axis-aligned bounding box as a tuple of minimum and maximum points.
  - `get_min_point() -> pycram.datastructures.pose.Point`: Returns the axis-aligned bounding box as a minimum point.
  - `get_max_point() -> pycram.datastructures.pose.Point`: Returns the axis-aligned bounding box as a maximum point.
  - `get_min_max() -> typing_extensions.Tuple[typing_extensions.List[float], typing_extensions.List[float]]`: Returns the axis-aligned bounding box as a tuple of minimum and maximum points.
  - `get_min() -> typing_extensions.List[float]`: Returns the minimum point of the axis-aligned bounding box.
  - `get_max() -> typing_extensions.List[float]`: Returns the maximum point of the axis-aligned bounding box.

#### **CollisionCallbacks**
- **Attributes:**
  - `on_collision_cb`: `typing_extensions.Callable`
  - `no_collision_cb`: `typing_extensions.Optional[typing_extensions.Callable] = None`

#### **MultiBody**
- **Attributes:**
  - `base_visual_shape_index`: `int`
  - `base_pose`: `pycram.datastructures.pose.Pose`
  - `link_visual_shape_indices`: `typing_extensions.List[int]`
  - `link_poses`: `typing_extensions.List[pycram.datastructures.pose.Pose]`
  - `link_masses`: `typing_extensions.List[float]`
  - `link_inertial_frame_poses`: `typing_extensions.List[pycram.datastructures.pose.Pose]`
  - `link_parent_indices`: `typing_extensions.List[int]`
  - `link_joint_types`: `typing_extensions.List[pycram.datastructures.enums.JointType]`
  - `link_joint_axis`: `typing_extensions.List[pycram.datastructures.pose.Point]`
  - `link_collision_shape_indices`: `typing_extensions.List[int]`

#### **VisualShape**
   Bases: `abc.ABC`
   Helper class that provides a standard way to create an ABC using inheritance.

- **Attributes:**
  - `rgba_color`: `Color`
  - `visual_frame_position`: `typing_extensions.List[float]`

- **Methods:**
  - `shape_data() -> typing_extensions.Dict[str, typing_extensions.Any]`: Abstract method to return the shape data of the visual shape (e.g. half extents for a box, radius for a sphere).
  - **Properties:**
    - `visual_geometry_type`: `pycram.datastructures.enums.Shape`: Abstract property to return the visual geometry type of the visual shape (e.g. box, sphere).

#### **BoxVisualShape**
   Bases: `VisualShape`
   Helper class that provides a standard way to create an ABC using inheritance.

- **Attributes:**
  - `half_extents`: `typing_extensions.List[float]`

- **Methods:**
  - `shape_data() -> typing_extensions.Dict[str, typing_extensions.List[float]]`: Returns the shape data of the visual shape (e.g. half extents for a box, radius for a sphere).
  - **Properties:**
    - `visual_geometry_type`: `pycram.datastructures.enums.Shape`: Returns the visual geometry type of the visual shape (e.g. box, sphere).
    - `size`: `typing_extensions.List[float]`

#### **SphereVisualShape**
   Bases: `VisualShape`
   Helper class that provides a standard way to create an ABC using inheritance.

- **Attributes:**
  - `radius`: `float`

- **Methods:**
  - `shape_data() -> typing_extensions.Dict[str, float]`: Returns the shape data of the visual shape (e.g. radius for a sphere).
  - **Properties:**
    - `visual_geometry_type`: `pycram.datastructures.enums.Shape`: Returns the visual geometry type of the visual shape (e.g. sphere).

#### **CapsuleVisualShape**
   Bases: `VisualShape`
   Helper class that provides a standard way to create an ABC using inheritance.

- **Attributes:**
  - `radius`: `float`
  - `length`: `float`

- **Methods:**
  - `shape_data() -> typing_extensions.Dict[str, float]`: Returns the shape data of the visual shape (e.g. radius and length for a capsule).
  - **Properties:**
    - `visual_geometry_type`: `pycram.datastructures.enums.Shape`: Returns the visual geometry type of the visual shape (e.g. capsule).

#### **CylinderVisualShape**
   Bases: `CapsuleVisualShape`
   Helper class that provides a standard way to create an ABC using inheritance.

- **Properties:**
  - `visual_geometry_type`: `pycram.datastructures.enums.Shape`: Returns the visual geometry type of the visual shape (e.g. cylinder).

#### **MeshVisualShape**
   Bases: `VisualShape`
   Helper class that provides a standard way to create an ABC using inheritance.

- **Attributes:**
  - `scale`: `typing_extensions.List[float]`
  - `file_name`: `str`

- **Methods:**
  - `shape_data() -> typing_extensions.Dict[str, typing_extensions.Union[typing_extensions.List[float], str]]`: Returns the shape data of the visual shape (e.g. scale and file name for a mesh).
  - **Properties:**
    - `visual_geometry_type`: `pycram.datastructures.enums.Shape`: Returns the visual geometry type of the visual shape (e.g. mesh).

#### **PlaneVisualShape**
   Bases: `VisualShape`
   Helper class that provides a standard way to create an ABC using inheritance.

- **Attributes:**
  - `normal`: `typing_extensions.List[float]`

- **Methods:**
  - `shape_data() -> typing_extensions.Dict[str, typing_extensions.List[float]]`: Returns the shape data of the visual shape (e.g. normal vector for a plane).
  - **Properties:**
    - `visual_geometry_type`: `pycram.datas

tructures.enums.Shape`: Returns the visual geometry type of the visual shape (e.g. plane).

#### **State**
   Bases: `abc.ABC`
   Helper class that provides a standard way to create an ABC using inheritance.

#### **LinkState**
   Bases: `State`
   Helper class that provides a standard way to create an ABC using inheritance.

- **Attributes:**
  - `constraint_ids`: `typing_extensions.Dict[pycram.description.Link, int]`

#### **JointState**
   Bases: `State`
   Helper class that provides a standard way to create an ABC using inheritance.

- **Attributes:**
  - `position`: `float`

#### **ObjectState**
   Bases: `State`
   Helper class that provides a standard way to create an ABC using inheritance.

- **Attributes:**
  - `pose`: `pycram.datastructures.pose.Pose`
  - `attachments`: `typing_extensions.Dict[pycram.world_concepts.world_object.Object, pycram.world_concepts.constraints.Attachment]`
  - `link_states`: `typing_extensions.Dict[int, LinkState]`
  - `joint_states`: `typing_extensions.Dict[int, JointState]`

#### **WorldState**
   Bases: `State`
   Helper class that provides a standard way to create an ABC using inheritance.

- **Attributes:**
  - `simulator_state_id`: `int`
  - `object_states`: `typing_extensions.Dict[str, ObjectState]`

|------
pycram.datastructures.enums 
================================

Module holding all enums of PyCRAM.

### **Classes**

- **ExecutionType**  
  Enum for Execution Process Module types.

- **Arms**  
  Enum for Arms.

- **TaskStatus**  
  Enum for readable descriptions of a tasks' status.

- **JointType**  
  Enum for readable joint types.

- **Grasp**  
  Enum for Grasp orientations.

- **ObjectType**  
  Enum for Object types to make it easier to identify different objects.

- **State**  
  Enumeration that describes the result of a language expression.

- **Shape**  
  Enum for visual shapes of objects.

- **WorldMode**  
  Enum for the different modes of the world.

- **AxisIdentifier**  
  Enum for translating the axis name to a vector along that axis.

- **GripperState**  
  Enum for the different motions of the gripper.

- **GripperType**  
  Enum for the different types of grippers.

- **PerceptionTechniques**  
  Enum for techniques used in perception tasks.

- **ImageEnum**  
  Enum for image switch views on the HSRB display.

**Module Contents**  

### **Class Details**

#### **ExecutionType**
   Bases: `enum.Enum`  
   Enum for Execution Process Module types.

- **Attributes:**
  - `REAL`
  - `SIMULATED`
  - `SEMI_REAL`

#### **Arms**
   Bases: `enum.Enum`  
   Enum for Arms.

- **Attributes:**
  - `LEFT`
  - `RIGHT`
  - `BOTH`

#### **TaskStatus**
   Bases: `enum.Enum`  
   Enum for readable descriptions of a tasks' status.

- **Attributes:**
  - `CREATED` = 0
  - `RUNNING` = 1
  - `SUCCEEDED` = 2
  - `FAILED` = 3

#### **JointType**
   Bases: `enum.Enum`  
   Enum for readable joint types.

- **Attributes:**
  - `REVOLUTE` = 0
  - `PRISMATIC` = 1
  - `SPHERICAL` = 2
  - `PLANAR` = 3
  - `FIXED` = 4
  - `UNKNOWN` = 5
  - `CONTINUOUS` = 6
  - `FLOATING` = 7

#### **Grasp**
   Bases: `enum.Enum`  
   Enum for Grasp orientations.

- **Attributes:**
  - `FRONT` = 0
  - `LEFT` = 1
  - `RIGHT` = 2
  - `TOP` = 3

#### **ObjectType**
   Bases: `enum.Enum`  
   Enum for Object types to make it easier to identify different objects.

- **Attributes:**
  - `METALMUG`
  - `PRINGLES`
  - `MILK`
  - `SPOON`
  - `BOWL`
  - `BREAKFAST_CEREAL`
  - `JEROEN_CUP`
  - `ROBOT`
  - `ENVIRONMENT`
  - `GENERIC_OBJECT`
  - `HUMAN`

#### **State**
   Bases: `enum.Enum`  
   Enumeration that describes the result of a language expression.

- **Attributes:**
  - `SUCCEEDED` = 1
  - `FAILED` = 0
  - `RUNNING` = 2
  - `INTERRUPTED` = 3

#### **Shape**
   Bases: `enum.Enum`  
   Enum for visual shapes of objects.

- **Attributes:**
  - `SPHERE` = 2
  - `BOX` = 3
  - `CYLINDER` = 4
  - `MESH` = 5
  - `PLANE` = 6
  - `CAPSULE` = 7

#### **WorldMode**
   Bases: `enum.Enum`  
   Enum for the different modes of the world.

- **Attributes:**
  - `GUI` = 'GUI'
  - `DIRECT` = 'DIRECT'

#### **AxisIdentifier**
   Bases: `enum.Enum`  
   Enum for translating the axis name to a vector along that axis.

- **Attributes:**
  - `X` = (1, 0, 0)
  - `Y` = (0, 1, 0)
  - `Z` = (0, 0, 1)

#### **GripperState**
   Bases: `enum.Enum`  
   Enum for the different motions of the gripper.

- **Attributes:**
  - `OPEN`
  - `CLOSE`

#### **GripperType**
   Bases: `enum.Enum`  
   Enum for the different types of grippers.

- **Attributes:**
  - `PARALLEL`
  - `SUCTION`
  - `FINGER`
  - `HYDRAULIC`
  - `PNEUMATIC`
  - `CUSTOM`

#### **PerceptionTechniques**
   Bases: `enum.Enum`  
   Enum for techniques used in perception tasks.

- **Attributes:**
  - `ALL`
  - `HUMAN`
  - `TYPES`

#### **ImageEnum**
   Bases: `enum.Enum`  
   Enum for image switch views on the HSRB display.

- **Attributes:**
  - `HI` = 0
  - `TALK` = 1
  - `DISH` = 2
  - `DONE` = 3
  - `DROP` = 4
  - `HANDOVER` = 5
  - `ORDER` = 6
  - `PICKING` = 7
  - `PLACING` = 8
  - `REPEAT` = 9
  - `SEARCH` = 10
  - `WAVING` = 11
  - `FOLLOWING` = 12
  - `DRIVINGBACK` = 13
  - `PUSHBUTTONS` = 14
  - `FOLLOWSTOP` = 15
  - `JREPEAT` = 16
  - `SOFA` = 17
  - `INSPECT` = 18
  - `CHAIR` = 37
