{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to use Costmaps for robot positioning in PyCRAM?"}, {"role": "assistant", "content": "### Using Costmaps for Robot Positioning in PyCRAM\n\nCostmaps in PyCRAM are essential tools for determining optimal positions for robot actions based on various criteria like visibility, occupancy, and more. This guide will explore how to create and utilize costmaps for robot positioning.\n\n#### 1. Introduction to Costmaps\n\nCostmaps provide a way to evaluate positions in the simulation based on different criteria. PyCRAM supports several types of costmaps, including:\n\n- `OccupancyCostmap`: Determines where the robot can be placed without colliding with objects.\n- `VisibilityCostmap`: Determines positions from which a target is visible.\n- `SemanticCostmap`: Maps positions based on semantic labels, like identifying specific surfaces.\n- `GaussianCostmap`: Generates a costmap with a Gaussian distribution.\n\n#### 2. Creating a Visibility Costmap\n\nVisibility costmaps are used to find positions where a target object is visible. Here’s how to create and visualize a visibility costmap:\n\n```python\nimport pycram.costmaps as cm\nfrom pycram.datastructures.pose import Pose\n\n# Create a visibility costmap\nv = cm.VisibilityCostmap(1.27, 1.60, size=300, resolution=0.02, origin=Pose([0, 0, 0.1], [0, 0, 0, 1]))\n\n# Visualize the costmap\nv.visualize()\n```\n\nTo close the visualization:\n\n```python\nv.close_visualization()\n```\n\n#### 3. Creating an Occupancy Costmap\n\nOccupancy costmaps ensure that the robot is positioned without collisions.\n\n```python\n# Create an occupancy costmap\no = cm.OccupancyCostmap(0.2, from_ros=False, size=300, resolution=0.02, origin=Pose([0, 0, 0.1], [0, 0, 0, 1]))\n\n# Visualize the costmap\no.visualize()\n```\n\n#### 4. Combining Costmaps\n\nYou can combine multiple costmaps to consider different criteria simultaneously:\n\n```python\n# Combine visibility and occupancy costmaps\nov = o + v\nov.visualize()\n```\n\n#### 5. Using Costmaps in Robot Positioning\n\nCostmaps can be used to determine the robot's position when performing tasks. For example, when picking up an object, you might want to find a position that is both reachable and has good visibility:\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.datastructures.enums import ObjectType\n\n# Define the robot and target objects\nrobot_desig = BelieveObject(types=[ObjectType.ROBOT]).resolve()\ntarget_desig = BelieveObject(names=[\"Milk\"]).resolve()\n\n# Create a location designator based on the combined costmap\nlocation_desig = CostmapLocation(target=target_desig, visible_for=robot_desig)\n\n# Resolve the best position for the robot\nbest_position = location_desig.resolve()\nprint(f\"Best Position: {best_position}\")\n```\n\n#### 6. Best Practices and Considerations\n\n- **Resolution and Size**: Choose the resolution and size of costmaps based on the specific needs of the task. Higher resolutions provide more detail but require more computation.\n- **Combination of Costmaps**: When combining costmaps, ensure that the criteria do not conflict, as this might lead to suboptimal positioning.\n- **Visualization**: Always visualize your costmaps to verify that they correctly represent the environment and meet your task’s requirements.\n\n### Conclusion\n\nCostmaps are powerful tools in PyCRAM for determining optimal robot positions based on various criteria. By using and combining different types of costmaps, you can ensure that your robot operates effectively within its environment."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to use action designators in PyCRAM?"}, {"role": "assistant", "content": "### Using Action Designators in PyCRAM\n\nAction designators in PyCRAM represent high-level actions that a robot can perform. They encapsulate complex behaviors, often composed of multiple motion designators and other logic, to achieve specific goals. This guide will walk you through the process of using action designators in PyCRAM.\n\n#### 1. Introduction to Action Designators\n\nAction designators are symbolic representations of complex robot actions. They provide a high-level interface for defining robot tasks, abstracting away the low-level details of motion planning and execution. Some common action designators in PyCRAM include:\n\n- `NavigateAction`: Navigates the robot to a specific location.\n- `PickUpAction`: Picks up an object.\n- `PlaceAction`: Places an object at a specific location.\n- `OpenAction`: Opens a container-like object.\n- `CloseAction`: Closes a container-like object.\n\n#### 2. Creating and Resolving Action Designators\n\nAction designators are created from action designator descriptions, which specify the type of action and its parameters. These parameters are typically provided as lists of possible values, allowing for flexibility in planning. For example, a `NavigateAction` description might include a list of possible target locations. When resolved, the action designator description selects a specific parameter from the list and returns a performable action designator.\n\nHere's an example of creating and resolving a `NavigateAction` designator:\n\n```python\nfrom pycram.designators.action_designator import NavigateAction\nfrom pycram.datastructures.pose import Pose\n\n# Create a list of possible target locations\ntarget_locations = [Pose([1, 0, 0], [0, 0, 0, 1]), Pose([2, 1, 0], [0, 0, 0, 1])]\n\n# Create a NavigateAction description\nnavigate_description = NavigateAction(target_locations=target_locations)\n\n# Resolve the description to a performable action designator\nnavigate_designator = navigate_description.resolve()\n\n# Print the resolved designator (will show the chosen target location)\nprint(navigate_designator)\n```\n\n#### 3. Performing Action Designators\n\nOnce you have a resolved action designator, you can perform it to execute the action. Performing an action designator typically involves the following steps:\n\n- Verifying the parameters of the designator.\n- Selecting the appropriate process module based on whether the robot is simulated or real.\n- Executing the action using the selected process module.\n\nHere's an example of performing the `NavigateAction` designator created in the previous step:\n\n```python\nfrom pycram.process_module import simulated_robot\n\n# Perform the NavigateAction designator in a simulated environment\nwith simulated_robot:\n    navigate_designator.perform()\n```\n\n#### 4. Combining Action Designators\n\nYou can combine multiple action designators using PyCRAM's plan language to create more complex robot behaviors. The plan language provides operators for sequential execution (`+`), parallel execution (`|`), and more. For example, you could create a plan that navigates the robot to a table, picks up an object, and then places it at another location.\n\n#### 5. Best Practices and Considerations\n\n- **Parameterization**: Use lists of possible parameters in action designator descriptions to allow for flexibility in planning.\n- **Process Modules**: Ensure that the correct process module is selected based on the robot's environment (simulated or real).\n- **Error Handling**: Handle potential errors during action execution using PyCRAM's plan language or custom error handling mechanisms.\n\n### Conclusion\n\nAction designators are a powerful tool in PyCRAM for defining and executing complex robot behaviors. By understanding how to create, resolve, and perform action designators, you can build sophisticated robot control programs that achieve high levels of autonomy."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to create and use object designators in PyCRAM?"}, {"role": "assistant", "content": "### Creating and Using Object Designators in PyCRAM\n\nObject designators in PyCRAM are symbolic representations of objects in the robot's world. They allow you to refer to objects without needing to know their exact physical properties or locations. This guide will explain how to create and use object designators in PyCRAM.\n\n#### 1. Introduction to Object Designators\n\nObject designators provide a way to abstractly represent objects in the robot's environment. They are defined by descriptions that specify criteria for identifying objects, such as their names, types, or other attributes. When resolved, an object designator description returns a specific object instance that matches the criteria.\n\n#### 2. Types of Object Designators\n\nPyCRAM supports different types of object designators, including:\n\n- `BelieveObject`: Represents objects that are part of the robot's internal belief state, typically objects spawned in the simulation.\n- `ObjectPart`: Represents specific parts or components of other objects, like the handle of a drawer.\n- `RealObject`: Represents objects perceived in the real world using sensors.\n\n#### 3. Creating a BelieveObject Designator\n\n`BelieveObject` designators are used to refer to objects that exist in the simulation. Here's an example of creating a `BelieveObject` designator for an object named \"Milk\":\n\n```python\nfrom pycram.designators.object_designator import BelieveObject\n\n# Create a BelieveObject designator for an object named \"Milk\"\nmilk_desig = BelieveObject(names=[\"Milk\"])\n\n# Resolve the designator to get the actual object instance\nmilk_object = milk_desig.resolve()\n\n# Print the object instance\nprint(milk_object)\n```\n\n#### 4. Creating an ObjectPart Designator\n\n`ObjectPart` designators are used to refer to specific parts of other objects. For example, to refer to the handle of a drawer named \"drawer1\", you would create an `ObjectPart` designator like this:\n\n```python\nfrom pycram.designators.object_designator import ObjectPart, BelieveObject\n\n# Assuming 'drawer1' is a BelieveObject designator for the drawer\ndrawer1_desig = BelieveObject(names=[\"drawer1\"]).resolve()\n\n# Create an ObjectPart designator for the handle of 'drawer1'\nhandle_desig = ObjectPart(names=[\"handle\"], part_of=drawer1_desig)\n\n# Resolve the designator to get the handle object\nhandle_object = handle_desig.resolve()\n\n# Print the handle object\nprint(handle_object)\n```\n\n#### 5. Using Object Designators in Actions\n\nObject designators are often used as parameters for action designators. For example, the `PickUpAction` designator requires an object designator to specify the object to be picked up.\n\n```python\nfrom pycram.designators.action_designator import PickUpAction\nfrom pycram.datastructures.enums import Arms\n\n# Assuming 'milk_desig' is a BelieveObject designator for the milk carton\n\n# Create a PickUpAction designator\npickup_action = PickUpAction(object_designator_description=milk_desig, arms=[Arms.RIGHT], grasps=[\"front\"])\n\n# Resolve and perform the pickup action\npickup_action.resolve().perform()\n```\n\n#### 6. Object Designators as Generators\n\nObject designator descriptions can also be used as generators to iterate through all objects that match the description. This is useful when you need to consider multiple candidate objects.\n\n```python\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.datastructures.enums import ObjectType\n\n# Create a BelieveObject designator for all objects of type 'ObjectType.MILK'\nmilk_desig = BelieveObject(types=[ObjectType.MILK])\n\n# Iterate through all milk objects\nfor milk_object in milk_desig:\n    print(milk_object)\n```\n\n### Conclusion\n\nObject designators are a crucial part of PyCRAM, providing a flexible and abstract way to represent and manipulate objects in the robot's world. By understanding how to create and use different types of object designators, you can effectively define and execute complex robot tasks involving object manipulation."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to define and use the plan language in PyCRAM?"}, {"role": "assistant", "content": "### Defining and Using the Plan Language in PyCRAM\n\nPyCRAM's plan language provides a structured and expressive way to define complex robot behaviors by combining individual actions and motions. It allows you to specify the order of execution, handle potential failures, and even execute actions in parallel. This guide will introduce you to the core concepts and syntax of PyCRAM's plan language.\n\n#### 1. Introduction to the Plan Language\n\nThe plan language uses a set of operators to combine designators, representing actions, motions, objects, and locations, into a coherent plan. It allows you to create plans that are more than just a linear sequence of actions, enabling branching, looping, and parallel execution.\n\n#### 2. Language Expressions\n\nPyCRAM's plan language supports the following expressions:\n\n| Expression | Name             | Description                                                                                                                                                                                                                                                                                |\n|------------|------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `+`          | **Sequential**   | Executes designators one after another. If one designator raises an exception, the execution is aborted, and the state `FAILED` is returned.                                                                                                                                  |\n| `-`          | **Try In Order** | Executes designators sequentially. If a designator raises an exception, the exception is caught and saved, but the execution continues with the next designator. Returns `SUCCEEDED` if at least one designator executes without an exception.                                      |\n| `*`          | **Repeat**       | Repeats the preceding language expression a specified number of times. Must be used with a language expression and an integer.                                                                                                                                                                        |\n| `|`         | **Parallel**     | Executes all designators in parallel, each in a separate thread. If any designator raises an exception, the returned state is `FAILED`. However, all designators are executed regardless of exceptions.                                                                              |\n| `^`          | **Try All**      | Executes all designators in parallel. Returns `SUCCEEDED` if at least one designator executes without an exception.                                                                                                                                                                            |\n| `>>`         | **Monitor**      | Monitors the execution of the attached language expression and interrupts it when a given condition is met. The condition can be a callable returning a boolean value or a Fluent.                                                                                                    |\n\n#### 3. Example: Sequential Execution\n\n```python\nfrom pycram.designators.action_designator import NavigateAction, ParkArmsAction\nfrom pycram.datastructures.pose import Pose\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\n\n# Create designators\nnavigate_designator = NavigateAction(target_locations=[Pose([1, 0, 0], [0, 0, 0, 1])]).resolve()\npark_designator = ParkArmsAction([Arms.BOTH]).resolve()\n\n# Define a sequential plan\nplan = navigate_designator + park_designator\n\n# Execute the plan in a simulated environment\nwith simulated_robot:\n    plan.perform()\n```\n\nThis plan will first navigate the robot to the specified pose and then park its arms. If either action fails, the plan will return `FAILED`.\n\n#### 4. Example: Parallel Execution\n\n```python\nfrom pycram.designators.action_designator import NavigateAction, MoveTorsoAction\nfrom pycram.datastructures.pose import Pose\nfrom pycram.process_module import simulated_robot\n\n# Create designators\nnavigate_designator = NavigateAction(target_locations=[Pose([1, 0, 0], [0, 0, 0, 1])]).resolve()\nmove_torso_designator = MoveTorsoAction([0.3]).resolve()\n\n# Define a parallel plan\nplan = navigate_designator | move_torso_designator\n\n# Execute the plan in a simulated environment\nwith simulated_robot:\n    plan.perform()\n```\n\nThis plan will execute both actions simultaneously. The robot will navigate to the target location while also moving its torso to the specified height.\n\n#### 5. Error Handling\n\nThe plan language automatically catches and stores exceptions of type `PlanFailure` that occur during designator execution. These exceptions can be accessed through the `exceptions` attribute of the plan object. This allows you to analyze the reasons for plan failures and implement appropriate recovery strategies.\n\n#### 6. Best Practices and Considerations\n\n- **Choose the Right Expression**: Select the language expression that best suits the desired behavior and error handling requirements.\n- **Avoid Conflicts**: When using parallel execution, ensure that the actions do not interfere with each other.\n- **Handle Exceptions**: Analyze the `exceptions` attribute to understand and address plan failures.\n\n### Conclusion\n\nPyCRAM's plan language provides a powerful and flexible way to define complex robot behaviors. By understanding its expressions and error handling mechanisms, you can create robust and adaptable robot control programs."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to create and use motion designators in PyCRAM?"}, {"role": "assistant", "content": "### Creating and Using Motion Designators in PyCRAM\n\nMotion designators in PyCRAM represent atomic, low-level motions that a robot can perform. They are the building blocks for more complex actions and provide a direct interface to the robot's control mechanisms. This guide will explain how to create and use motion designators in PyCRAM.\n\n#### 1. Introduction to Motion Designators\n\nMotion designators encapsulate specific robot movements, such as moving the base, controlling the gripper, or adjusting joint angles. They are typically executed by process modules, which translate the high-level motion commands into low-level control signals for the robot.\n\n#### 2. Types of Motion Designators\n\nPyCRAM provides a variety of motion designators, including:\n\n- `MoveMotion`: Moves the robot base to a specific pose.\n- `MoveTCPMotion`: Moves the robot's tool center point (TCP) to a specific pose.\n- `LookingMotion`: Orients the robot's head or camera to look at a specific point.\n- `MoveGripperMotion`: Opens or closes the robot's gripper.\n- `MoveArmJointsMotion`: Moves the robot's arm joints to specific positions.\n- `MoveJointsMotion`: Moves any joint of the robot to a specific position.\n- `OpeningMotion`: Opens a container-like object (typically requires grasping the handle first).\n- `ClosingMotion`: Closes a container-like object.\n\n#### 3. Creating and Performing Motion Designators\n\nMotion designators are created by instantiating the corresponding motion designator class with the desired parameters. For example, to create a `MoveTCPMotion` designator that moves the right arm's TCP to a specific pose, you would use the following code:\n\n```python\nfrom pycram.designators.motion_designator import MoveTCPMotion\nfrom pycram.datastructures.pose import Pose\nfrom pycram.datastructures.enums import Arms\n\n# Create a MoveTCPMotion designator\nmove_tcp_designator = MoveTCPMotion(target=Pose([0.5, 0.6, 0.7], [0, 0, 0, 1]), arm=Arms.RIGHT)\n```\n\nTo perform the motion designator, you need to use it within a context that specifies whether the robot is simulated or real. This is done using the `simulated_robot` or `real_robot` context managers, or the corresponding decorators `with_simulated_robot` and `with_real_robot`.\n\n```python\nfrom pycram.process_module import simulated_robot\n\n# Perform the MoveTCPMotion designator in a simulated environment\nwith simulated_robot:\n    move_tcp_designator.perform()\n```\n\n#### 4. Example: Combining Motion Designators\n\nYou can combine motion designators with action designators and other language expressions to create complex robot behaviors. For example, you could create a plan that navigates the robot to a table, opens a drawer, picks up an object, and then closes the drawer.\n\n#### 5. Best Practices and Considerations\n\n- **Parameter Verification**: Ensure that the parameters provided to motion designators are valid and within the robot's capabilities.\n- **Process Module Selection**: Choose the appropriate process module based on the robot's environment (simulated or real).\n- **Error Handling**: Handle potential errors during motion execution, such as collisions or unreachable poses.\n\n### Conclusion\n\nMotion designators are the fundamental building blocks for robot control in PyCRAM. By understanding how to create and use them, you can build complex and sophisticated robot behaviors that achieve specific tasks and goals."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to set up and configure a robot description in PyCRAM?"}, {"role": "assistant", "content": "### Setting Up and Configuring a Robot Description in PyCRAM\n\nRobot descriptions in PyCRAM provide essential information about the robot's structure, capabilities, and kinematic properties that are not directly available from the URDF (Unified Robot Description Format). This guide will walk you through the process of setting up and configuring a robot description in PyCRAM.\n\n#### 1. Introduction to Robot Descriptions\n\nRobot descriptions in PyCRAM encapsulate semantic information about the robot, such as its kinematic chains, end-effectors, cameras, and grasp configurations. This information is crucial for planning and executing robot actions effectively. The robot description is typically defined in a separate Python file and loaded into PyCRAM at startup.\n\n#### 2. Creating a Robot Description\n\nTo create a robot description, you need to instantiate the `RobotDescription` class and provide the following parameters:\n\n- `name`: The name of the robot.\n- `base_link`: The name of the robot's base link.\n- `torso_link`: The name of the robot's torso link (if it has one).\n- `torso_joint`: The name of the robot's torso joint (if it has one).\n- `urdf_path`: The path to the robot's URDF file.\n\nHere's an example of creating a robot description for a PR2 robot:\n\n```python\nfrom pycram.robot_description import RobotDescription\nimport rospkg\n\n# Get the path to the PR2 URDF file\nrospack = rospkg.RosPack()\nfilename = rospack.get_path('pycram') + '/resources/robots/' + \"pr2\" + '.urdf'\n\n# Create a RobotDescription instance\npr2_description = RobotDescription(\"pr2\", \"base_link\", \"torso_lift_link\", \"torso_lift_joint\", filename)\n```\n\n#### 3. Defining Kinematic Chains\n\nKinematic chains represent interconnected links and joints that form a functional unit, such as an arm or a leg. To define a kinematic chain, you need to create a `KinematicChainDescription` instance and specify the following:\n\n- `name`: The name of the kinematic chain.\n- `start_link`: The name of the first link in the chain.\n- `end_link`: The name of the last link in the chain.\n- `urdf_object`: The URDF object of the robot.\n- `arm_type`: The type of arm (e.g., `Arms.LEFT`, `Arms.RIGHT`) if the chain represents an arm.\n\n```python\nfrom pycram.robot_description import KinematicChainDescription\nfrom pycram.datastructures.enums import Arms\n\n# Create a KinematicChainDescription for the right arm\nright_arm = KinematicChainDescription(\"right\", \"torso_lift_link\", \"r_wrist_roll_link\", pr2_description.urdf_object, arm_type=Arms.RIGHT)\n\n# Add the kinematic chain to the robot description\npr2_description.add_kinematic_chain_description(right_arm)\n```\n\n#### 4. Defining End-Effectors\n\nEnd-effectors are devices attached to the end of a kinematic chain, such as grippers or tools. To define an end-effector, you need to create an `EndEffectorDescription` instance and provide the following:\n\n- `name`: The name of the end-effector.\n- `start_link`: The name of the root link of the end-effector.\n- `tool_frame`: The name of the tool frame link in the URDF.\n- `urdf_object`: The URDF object of the robot.\n\n```python\nfrom pycram.robot_description import EndEffectorDescription\n\n# Create an EndEffectorDescription for the right gripper\nright_gripper = EndEffectorDescription(\"right_gripper\", \"r_gripper_palm_link\", \"r_gripper_tool_frame\", pr2_description.urdf_object)\n\n# Add the end-effector to the kinematic chain\nright_arm.end_effector = right_gripper\n```\n\n#### 5. Defining Cameras\n\nCameras are sensors that provide visual information about the environment. To define a camera, you need to create a `CameraDescription` instance and specify the following:\n\n- `name`: The name of the camera.\n- `camera_link`: The name of the camera link in the URDF.\n- `minimal_height`: The minimum height of the camera.\n- `maximal_height`: The maximum height of the camera.\n\n```python\nfrom pycram.robot_description import CameraDescription\n\n# Create a CameraDescription for the head camera\ncamera = CameraDescription(\"head_camera\", \"wide_stereo_optical_frame\", 1.27, 1.60)\n\n# Add the camera to the robot description\npr2_description.add_camera_description(camera)\n```\n\n#### 6. Defining Grasps\n\nGrasps define the robot's hand orientations for interacting with objects. To define grasps, you can use the `add_grasp_orientation` or `add_grasp_orientations` methods of the `RobotDescription` class. Each grasp is associated with a `Grasp` enum value (e.g., `Grasp.FRONT`, `Grasp.LEFT`) and a quaternion representing the hand orientation.\n\n```python\nfrom pycram.datastructures.enums import Grasp\n\n# Add grasp orientations to the robot description\npr2_description.add_grasp_orientations({\n    Grasp.FRONT: [0, 0, 0, 1],\n    Grasp.LEFT: [0, 0, -1, 1],\n    Grasp.RIGHT: [0, 0, 1, 1],\n    Grasp.TOP: [0, 1, 0, 1]\n})\n```\n\n#### 7. Registering the Robot Description\n\nFinally, you need to register the robot description with the `RobotDescriptionManager` to make it available to PyCRAM.\n\n```python\nfrom pycram.robot_description import RobotDescriptionManager\n\n# Register the robot description\nrdm = RobotDescriptionManager()\nrdm.register_description(pr2_description)\n```\n\n### Conclusion\n\nSetting up a robot description in PyCRAM is essential for providing the framework with the necessary information to plan and execute robot actions effectively. By defining kinematic chains, end-effectors, cameras, and grasps, you enable PyCRAM to reason about the robot's capabilities and interact with its environment in a meaningful way."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "What are the different types of costmaps in PyCRAM and how do they work?"}, {"role": "assistant", "content": "### Types of Costmaps in PyCRAM and Their Functionality\n\nCostmaps in PyCRAM are two-dimensional representations of the robot's environment, encoding information about obstacles, free space, and other relevant features. They are used by location designators to find suitable positions for the robot to perform tasks. PyCRAM supports several types of costmaps, each tailored to specific planning criteria. Let's explore these costmap types and their functionality:\n\n#### 1. Occupancy Costmap (`OccupancyCostmap`)\n\n- **Purpose**: Represents the occupancy state of the environment, indicating areas that are occupied by obstacles and areas that are free.\n- **Functionality**: Each cell in the costmap represents a small area in the environment. The cell value indicates the probability of that area being occupied. Values range from 0 (free) to 1 (occupied), with intermediate values representing uncertainty.\n- **Usage**: Used for basic collision avoidance and finding positions where the robot can be placed without colliding with obstacles.\n\n#### 2. Visibility Costmap (`VisibilityCostmap`)\n\n- **Purpose**: Represents the visibility of a target point from different positions in the environment.\n- **Functionality**: Calculates the visibility of a target point by simulating rays cast from the camera at different positions. Cells in the costmap represent the visibility score, with higher values indicating better visibility.\n- **Usage**: Used for finding positions where the robot has a clear line of sight to a target object or location.\n\n#### 3. Semantic Costmap (`SemanticCostmap`)\n\n- **Purpose**: Maps positions based on semantic labels, such as identifying specific surfaces (e.g., table, countertop, floor).\n- **Functionality**: Assigns semantic labels to cells in the costmap based on the object or surface they represent. This allows the robot to reason about the environment in terms of objects and their properties.\n- **Usage**: Used for tasks that require knowledge of object types or surfaces, such as placing an object on a table or navigating to a specific room.\n\n#### 4. Gaussian Costmap (`GaussianCostmap`)\n\n- **Purpose**: Generates a costmap with a Gaussian distribution centered around a specific point.\n- **Functionality**: Creates a costmap where the cost decreases as the distance from the center point increases, following a Gaussian distribution. This can be used to represent areas of preference or importance.\n- **Usage**: Used for tasks where the robot needs to be close to a specific point but with some flexibility in positioning, such as approaching a table or a person.\n\n#### 5. Combining Costmaps\n\nPyCRAM allows you to combine multiple costmaps to consider different criteria simultaneously. For example, you can combine a visibility costmap and an occupancy costmap to find positions that are both visible and collision-free. The combination is typically done by adding the cost values of the individual costmaps, resulting in a new costmap that reflects the combined criteria.\n\n#### 6. Visualizing Costmaps\n\nPyCRAM provides methods for visualizing costmaps in the BulletWorld, allowing you to inspect and verify their correctness. This visualization helps in understanding how the costmaps represent the environment and how they influence robot positioning.\n\n### Conclusion\n\nCostmaps are a fundamental tool in PyCRAM for robot positioning and planning. By understanding the different types of costmaps and their functionality, you can effectively use them to guide your robot's actions and achieve complex tasks in a variety of environments."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to implement error handling and recovery in PyCRAM plans?"}, {"role": "assistant", "content": "### Implementing Error Handling and Recovery in PyCRAM Plans\n\nRobust error handling and recovery are crucial for creating reliable and adaptable robot control programs. PyCRAM provides mechanisms for handling exceptions, monitoring plan execution, and implementing recovery strategies. This guide will explore how to implement error handling and recovery in PyCRAM plans.\n\n#### 1. Exception Handling with the Plan Language\n\nPyCRAM's plan language automatically catches and stores exceptions of type `PlanFailure` that occur during designator execution. These exceptions can be accessed through the `exceptions` attribute of the plan object. This allows you to analyze the reasons for plan failures and implement appropriate recovery strategies.\n\nHere's an example of how to access exceptions caught by the plan language:\n\n```python\nfrom pycram.designators.action_designator import NavigateAction\nfrom pycram.datastructures.pose import Pose\nfrom pycram.process_module import simulated_robot\n\n# Create a NavigateAction designator with an unreachable target\nnavigate_designator = NavigateAction(target_locations=[Pose([100, 100, 100], [0, 0, 0, 1])]).resolve()\n\n# Define a simple plan\nplan = navigate_designator\n\n# Execute the plan in a simulated environment\nwith simulated_robot:\n    plan.perform()\n\n# Print the caught exceptions\nprint(plan.exceptions)\n```\n\n#### 2. Using Monitors for Plan Monitoring\n\nMonitors in PyCRAM allow you to continuously check for specific conditions during plan execution and interrupt the plan if necessary. This is useful for detecting and responding to unexpected events or situations.\n\nHere's an example of using a `Monitor` to interrupt a plan if the robot's battery level falls below a threshold:\n\n```python\nfrom pycram.language import Monitor\nfrom pycram.process_module import simulated_robot\n\n# Define a function that checks the battery level\ndef check_battery():\n    # Replace this with actual battery level retrieval\n    battery_level = 0.2\n    if battery_level < 0.3:\n        return True\n    return False\n\n# Create a Monitor that checks the battery level every 0.1 seconds\nbattery_monitor = Monitor(condition=check_battery)\n\n# Define a plan that will be monitored\nplan = # Your plan here\n\n# Attach the monitor to the plan\nplan = plan >> battery_monitor\n\n# Execute the monitored plan in a simulated environment\nwith simulated_robot:\n    plan.perform()\n```\n\n#### 3. Implementing Recovery Strategies\n\nOnce you have identified a plan failure, you can implement recovery strategies to handle the situation. Recovery strategies can involve retrying the failed action, choosing an alternative action, or requesting human intervention.\n\nHere's an example of a simple recovery strategy that retries a failed navigation action:\n\n```python\nfrom pycram.designators.action_designator import NavigateAction\nfrom pycram.datastructures.pose import Pose\nfrom pycram.process_module import simulated_robot\nfrom pycram.plan_failures import NavigationGoalNotReached\n\n# Define a function that attempts navigation and retries if necessary\ndef navigate_with_retry(target_pose, max_retries=3):\n    for i in range(max_retries):\n        try:\n            NavigateAction(target_locations=[target_pose]).resolve().perform()\n            return True\n        except NavigationGoalNotReached:\n            print(f\"Navigation failed, retrying ({i+1}/{max_retries})\")\n    return False\n\n# Define a target pose\ntarget_pose = Pose([1, 0, 0], [0, 0, 0, 1])\n\n# Execute the navigation with retry strategy in a simulated environment\nwith simulated_robot:\n    success = navigate_with_retry(target_pose)\n    if success:\n        print(\"Navigation successful\")\n    else:\n        print(\"Navigation failed after retries\")\n```\n\n#### 4. Best Practices and Considerations\n\n- **Anticipate Potential Failures**: Design your plans with potential failures in mind and include appropriate error handling mechanisms.\n- **Use Monitors Strategically**: Monitors can be used to detect a wide range of conditions, such as collisions, sensor failures, or changes in the environment.\n- **Implement Recovery Strategies**: Define clear recovery strategies for different types of failures.\n- **Log and Analyze Exceptions**: Use PyCRAM's exception logging to understand the causes of failures and improve your plans.\n\n### Conclusion\n\nError handling and recovery are essential aspects of robust robot control. By leveraging PyCRAM's plan language, monitors, and exception handling mechanisms, you can create resilient robot control programs that can handle unexpected situations and achieve their goals reliably."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to work with objects and attachments in the PyCRAM BulletWorld?"}, {"role": "assistant", "content": "### Working with Objects and Attachments in the PyCRAM BulletWorld\n\nThe PyCRAM BulletWorld provides a simulated environment where you can interact with objects, robots, and their physical properties. This guide will explain how to work with objects and attachments in the BulletWorld.\n\n#### 1. Spawning Objects\n\nObjects in the BulletWorld can be created from various file formats, including URDF (Unified Robot Description Format), OBJ, and STL. To spawn an object, you use the `Object` class, providing its name, type, and the path to the corresponding file.\n\n```python\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType\nfrom pycram.datastructures.pose import Pose\n\n# Spawn a milk carton\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.3, 1, 0.9]))\n\n# Spawn a table\ntable = Object(\"table\", ObjectType.ENVIRONMENT, \"table.urdf\", pose=Pose([1, 0, 0]))\n```\n\n#### 2. Manipulating Object Poses\n\nYou can manipulate the position and orientation of objects using the following methods:\n\n- `set_position(position, base=False)`: Sets the object's position. If `base=True`, the object's base is placed at the given position.\n- `set_orientation(orientation)`: Sets the object's orientation.\n- `set_pose(pose, base=False)`: Sets both the position and orientation of the object.\n\n```python\n# Move the milk carton\nmilk.set_position([1.5, 1, 0.9])\n\n# Rotate the table\ntable.set_orientation([0, 0, 0.707, 0.707])  # Rotate 90 degrees around the z-axis\n```\n\n#### 3. Accessing Links and Joints\n\nObjects spawned from URDF files have links and joints. You can access these using the `links` and `joints` attributes of the `Object` class. These attributes are dictionaries mapping link/joint names to their corresponding IDs.\n\n```python\n# Get the pose of the table's top link\ntable_top_pose = table.get_link_pose(\"table_top\")\n\n# Set the position of the robot's arm joint\nrobot.set_joint_position(\"arm_joint\", 1.57)  # Set the joint to 90 degrees\n```\n\n#### 4. Creating Attachments\n\nAttachments in PyCRAM represent rigid connections between objects. You can attach objects using the `attach` method, specifying the parent and child objects, and optionally the parent and child links to be connected.\n\n```python\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType\nfrom pycram.datastructures.pose import Pose\n\n# Spawn a box\nbox = Object(\"box\", ObjectType.GENERIC_OBJECT, \"box.stl\", pose=Pose([1.2, 1.2, 1]))\n\n# Spawn a robot\nrobot = Object(\"robot\", ObjectType.ROBOT, \"robot.urdf\")\n\n# Attach the box to the robot's gripper\nrobot.attach(box, parent_link=\"gripper_link\")\n```\n\n#### 5. Detaching Objects\n\nTo detach objects, use the `detach` method, specifying the child object to be detached.\n\n```python\n# Detach the box from the robot\nrobot.detach(box)\n```\n\n#### 6. Bidirectional and Loose Attachments\n\nAttachments can be bidirectional or loose. Bidirectional attachments mean that both objects move when one is moved. Loose attachments mean that only the child object moves when the parent is moved.\n\n```python\n# Create a loose attachment (only the box moves when the robot moves)\nrobot.attach(box, parent_link=\"gripper_link\", bidirectional=False)\n```\n\n#### 7. Best Practices and Considerations\n\n- **Collision Checking**: Use the `contact_points` or `contact_points_simulated` methods to check for collisions between objects.\n- **Attachment Management**: Keep track of attachments and detach objects when necessary to avoid unexpected behavior.\n- **Visualization**: Use the BulletWorld's visualization capabilities to inspect object poses and attachments.\n\n### Conclusion\n\nWorking with objects and attachments in the PyCRAM BulletWorld is essential for simulating robot manipulation tasks. By understanding how to spawn objects, manipulate their poses, create attachments, and check for collisions, you can effectively develop and test robot control programs in a virtual environment."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "What is the purpose of the Object Relational Mapping (ORM) in PyCRAM and how does it work?"}, {"role": "assistant", "content": "### Object Relational Mapping (ORM) in PyCRAM: Purpose and Functionality\n\nObject Relational Mapping (ORM) in PyCRAM provides a powerful mechanism for serializing and storing plan data in a database, enabling persistent storage, retrieval, and analysis of plan execution information. This guide will delve into the purpose and functionality of ORM in PyCRAM.\n\n#### 1. Purpose of ORM in PyCRAM\n\nThe primary purpose of ORM in PyCRAM is to facilitate the logging and analysis of robot plan execution data. This data includes:\n\n- **Designator Parameters**: The specific values used for each designator in the plan, such as target poses, object names, and grasp configurations.\n- **Robot States**: The robot's configuration at various points during plan execution, including joint positions, end-effector poses, and sensor readings.\n- **Task Tree Structures**: The hierarchical structure of the plan, capturing the execution order and dependencies between actions.\n\nBy storing this data in a structured and persistent manner, ORM enables:\n\n- **Debugging and Analysis**: Developers can inspect the logged data to understand the plan's execution flow, identify potential issues, and analyze the reasons for plan failures.\n- **Plan Optimization**: The logged data can be used to evaluate plan performance, identify bottlenecks, and optimize the plan for efficiency and robustness.\n- **Learning and Adaptation**: The stored data can serve as training data for machine learning algorithms, enabling the robot to learn from past experiences and adapt its behavior accordingly.\n\n#### 2. How ORM Works in PyCRAM\n\nPyCRAM's ORM implementation leverages the SQLAlchemy library, a powerful and flexible Python toolkit for working with relational databases. SQLAlchemy provides an abstraction layer over the database, allowing you to interact with the database using Python objects and methods instead of writing raw SQL queries.\n\nHere's a simplified overview of how ORM works in PyCRAM:\n\n1. **Defining ORM Classes**: PyCRAM defines ORM classes that correspond to the different entities involved in plan execution, such as actions, motions, objects, and robot states. These classes specify the attributes and relationships between entities.\n2. **Creating a Database Session**: A database session is created using SQLAlchemy, providing a connection to the database.\n3. **Inserting Data**: During plan execution, PyCRAM automatically creates instances of the ORM classes and populates them with the relevant data. These instances are then added to the database session.\n4. **Committing Changes**: Once all the data has been added to the session, the changes are committed to the database, making the data persistent.\n5. **Querying Data**: You can use SQLAlchemy's query language to retrieve specific data from the database based on various criteria.\n\n#### 3. Example: Logging a NavigateAction\n\n```python\nfrom pycram.designators.action_designator import NavigateAction\nfrom pycram.datastructures.pose import Pose\nfrom pycram.process_module import simulated_robot\nimport sqlalchemy\nimport pycram.orm.base\n\n# Create a database engine and session\nengine = sqlalchemy.create_engine(\"sqlite:///my_database.db\")\npycram.orm.base.Base.metadata.create_all(engine)\nsession = sqlalchemy.orm.sessionmaker(bind=engine)()\n\n# Define a target pose\ntarget_pose = Pose([1, 0, 0], [0, 0, 0, 1])\n\n# Create a NavigateAction designator\nnavigate_designator = NavigateAction(target_locations=[target_pose]).resolve()\n\n# Execute the designator in a simulated environment\nwith simulated_robot:\n    navigate_designator.perform()\n\n# Insert the designator data into the database\nsession.add(navigate_designator)\nsession.commit()\n```\n\nThis code snippet demonstrates how to log a `NavigateAction` designator's data into a SQLite database. The `navigate_designator` object, after being performed, is added to the database session and committed, making the data persistent.\n\n#### 4. Benefits of ORM\n\n- **Structured Data Storage**: ORM provides a structured and organized way to store plan execution data, making it easier to query and analyze.\n- **Data Persistence**: The data is stored in a database, ensuring its persistence even after the PyCRAM program terminates.\n- **Abstraction from SQL**: SQLAlchemy's ORM layer abstracts away the complexities of writing raw SQL queries, allowing you to interact with the database using Python objects and methods.\n\n### Conclusion\n\nObject Relational Mapping (ORM) in PyCRAM is a valuable tool for logging, analyzing, and learning from robot plan execution data. By leveraging SQLAlchemy's capabilities, PyCRAM provides a seamless and efficient way to manage plan data, enabling developers to create more robust, adaptable, and intelligent robot control programs."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "What are the best practices for designing and implementing robust and efficient PyCRAM plans?"}, {"role": "assistant", "content": "### Best Practices for Designing and Implementing Robust and Efficient PyCRAM Plans\n\nCreating effective PyCRAM plans involves careful consideration of various factors, from design choices to implementation details. This guide outlines best practices to help you develop robust and efficient robot control programs using PyCRAM.\n\n#### 1. Plan Design\n\n- **Modularity**: Break down complex tasks into smaller, modular actions. This promotes code reusability and simplifies debugging.\n- **Abstraction**: Use designators to represent actions, motions, objects, and locations abstractly. This allows for flexibility and adaptability in planning.\n- **Hierarchy**: Structure your plan using the plan language, creating a clear hierarchy of actions and their dependencies.\n- **Error Handling**: Anticipate potential failures and include error handling mechanisms using the plan language or custom strategies.\n\n#### 2. Designator Selection\n\n- **Choose the Right Designator**: Select designators that are appropriate for the task and the robot's capabilities. Consider factors like visibility, reachability, and collision avoidance.\n- **Parameterization**: Use lists of possible parameters in designator descriptions to allow for flexibility in planning and execution.\n- **Generators**: Leverage the generator capabilities of location and object designators to explore multiple candidate positions or objects.\n\n#### 3. Process Module Implementation\n\n- **Robot-Specific Control**: Implement process modules that interface with your robot's specific control interfaces (e.g., ROS topics, services, or action servers).\n- **Efficiency**: Optimize process module code for efficiency, especially when dealing with real-time control.\n- **Error Handling**: Include error handling mechanisms in process modules to handle communication failures, sensor errors, or other unexpected events.\n\n#### 4. Simulation and Testing\n\n- **Thorough Simulation**: Test your plans extensively in the BulletWorld before deploying them on a real robot. This allows you to identify and resolve issues in a safe and controlled environment.\n- **Realistic Scenarios**: Create simulation scenarios that closely resemble the real-world environment and tasks.\n- **Performance Evaluation**: Analyze the plan's performance in simulation, considering factors like execution time, success rate, and resource usage.\n\n#### 5. Real Robot Deployment\n\n- **Calibration**: Ensure that your robot's sensors and actuators are properly calibrated.\n- **Fine-Tuning**: Adjust parameters in your process modules or designators to account for real-world factors.\n- **Safety First**: Prioritize safety by implementing emergency stops, collision avoidance, and limits on robot movements.\n\n#### 6. Code Style and Documentation\n\n- **Clear and Concise Code**: Write clean, well-structured code that is easy to understand and maintain.\n- **Comprehensive Documentation**: Document your code thoroughly, including design decisions, parameter descriptions, and usage examples.\n\n### Conclusion\n\nDesigning and implementing robust and efficient PyCRAM plans requires a combination of careful planning, effective design choices, and meticulous implementation. By following these best practices, you can create sophisticated robot control programs that achieve high levels of autonomy and reliability in both simulated and real-world environments."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "Explain the concept of 'grasps' in PyCRAM and how they are used in robot manipulation tasks."}, {"role": "assistant", "content": "### Grasps in PyCRAM: Defining Robot Hand Orientations for Manipulation\n\nGrasps in PyCRAM define the orientations of the robot's hand or end-effector for interacting with objects during manipulation tasks. They provide a way to specify how the robot should approach and grasp an object, ensuring a stable and successful grasp.\n\n#### 1. Defining Grasps\n\nGrasps are typically defined within the robot description, which provides semantic information about the robot's structure and capabilities. You can use the `add_grasp_orientation` or `add_grasp_orientations` methods of the `RobotDescription` class to define grasps. Each grasp is associated with a `Grasp` enum value and a quaternion representing the desired hand orientation.\n\nThe `Grasp` enum defines standard grasp types, such as:\n\n- `Grasp.FRONT`: Grasping the object from the front.\n- `Grasp.LEFT`: Grasping the object from the left side.\n- `Grasp.RIGHT`: Grasping the object from the right side.\n- `Grasp.TOP`: Grasping the object from the top.\n\nThe quaternion represents the rotation of the hand relative to the robot's base frame. For example, a quaternion of `[0, 0, 0, 1]` represents no rotation, while a quaternion of `[0, 1, 0, 0]` represents a 180-degree rotation around the Y-axis.\n\nHere's an example of defining grasp orientations for a PR2 robot:\n\n```python\nfrom pycram.datastructures.enums import Grasp\n\n# Add grasp orientations to the robot description\npr2_description.add_grasp_orientations({\n    Grasp.FRONT: [0, 0, 0, 1],\n    Grasp.LEFT: [0, 0, -1, 1],\n    Grasp.RIGHT: [0, 0, 1, 1],\n    Grasp.TOP: [0, 1, 0, 1]\n})\n```\n\n#### 2. Using Grasps in Manipulation Tasks\n\nGrasps are used in action designators like `PickUpAction` to specify the desired hand orientation when grasping an object. The `PickUpAction` designator takes a `grasps` parameter, which is a list of possible grasp types. When the action is resolved, it selects a suitable grasp from the list based on factors like object geometry, robot reachability, and collision avoidance.\n\n```python\nfrom pycram.designators.action_designator import PickUpAction\nfrom pycram.datastructures.enums import Arms, Grasp\n\n# Create a PickUpAction designator with multiple grasp options\npickup_action = PickUpAction(\n    object_designator_description=object_desig,  # Object to be picked up\n    arms=[Arms.RIGHT],  # Arm to use\n    grasps=[Grasp.FRONT, Grasp.TOP]  # Possible grasp types\n)\n\n# Resolve and perform the pickup action\npickup_action.resolve().perform()\n```\n\n#### 3. Considerations for Grasp Selection\n\n- **Object Geometry**: The shape and size of the object influence the choice of grasp. For example, a cylindrical object might be best grasped from the side, while a box-shaped object might be grasped from the top.\n- **Robot Reachability**: The robot's kinematic structure and joint limits determine which grasps are reachable.\n- **Collision Avoidance**: The grasp should be chosen to avoid collisions with the environment or other objects.\n- **Grasp Stability**: The grasp should be stable enough to securely hold the object during manipulation.\n\n#### 4. Custom Grasps\n\nYou can define custom grasps beyond the standard types provided by the `Grasp` enum. This allows you to specify more complex hand orientations or grasp configurations tailored to specific objects or tasks.\n\n### Conclusion\n\nGrasps in PyCRAM play a crucial role in robot manipulation tasks by defining the robot's hand orientations for interacting with objects. By carefully considering object geometry, robot reachability, collision avoidance, and grasp stability, you can choose appropriate grasps that ensure successful and reliable object manipulation."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the methods available under the 'World' category in PyCRAM?"}, {"role": "assistant", "content": "Sure! The 'World' category in PyCRAM includes various methods for interacting with and managing the simulation environment. Would you like an overview of all these methods first?"}, {"role": "user", "content": "Yes, please list all the methods under the 'World' category."}, {"role": "assistant", "content": "Here are the methods available under the 'World' category:\n1. `load_object_and_get_id`\n2. `remove_object`\n3. `get_object_by_name`\n4. `get_object_by_type`\n5. `get_object_by_id`\n6. `simulate`\n7. `reset_world`\n8. `add_fixed_constraint`\n9. `remove_constraint`\n10. `get_joint_position`\n11. `reset_joint_position`\n12. `get_link_pose`\n13. `set_link_color`\n14. `get_link_color`\n15. `get_object_axis_aligned_bounding_box`\n16. `get_link_axis_aligned_bounding_box`\n17. `set_realtime`\n18. `set_gravity`\n19. `ray_test`\n20. `ray_test_batch`\n21. `get_images_for_target`\n22. `add_text`\n23. `remove_text`\nWhich method would you like to know more about first?"}, {"role": "user", "content": "Tell me about 'load_object_and_get_id'."}, {"role": "assistant", "content": "'load_object_and_get_id' is a method that loads an object into the simulation world from a specified path and returns a unique ID for that object. The parameters include:\n- `path` (str): The path to the object file (URDF, OBJ, or STL).\n- `pose` (Pose, optional): The pose at which the object should be spawned.\nThe method returns an `int`, which is the unique ID of the loaded object."}, {"role": "user", "content": "And what about 'remove_object'?"}, {"role": "assistant", "content": "'remove_object' is a method used to remove an object from the world. It takes the following parameter:\n- `obj` (Object): The object that you want to remove from the world.\nThe method returns `None`."}, {"role": "user", "content": "How does 'get_object_by_name' work?"}, {"role": "assistant", "content": "'get_object_by_name' returns the object in the world with the specified name. The parameter it takes is:\n- `name` (str): The name of the object.\nIt returns the `Object` with the given name or `None` if the object is not found."}, {"role": "user", "content": "What is 'get_object_by_type'?"}, {"role": "assistant", "content": "'get_object_by_type' returns a list of objects in the world that match the specified type. It takes the following parameter:\n- `obj_type` (ObjectType): The type of objects you want to retrieve.\nThe method returns a `List[Object]` containing all objects of the given type."}, {"role": "user", "content": "Explain 'get_object_by_id'."}, {"role": "assistant", "content": "'get_object_by_id' retrieves the object with the specified ID. The parameter is:\n- `obj_id` (int): The ID of the object.\nIt returns the `Object` with that ID."}, {"role": "user", "content": "How does 'simulate' work?"}, {"role": "assistant", "content": "'simulate' runs the world simulation for a specified amount of time. The parameters include:\n- `seconds` (float): Duration of the simulation in seconds.\n- `real_time` (bool, optional): Whether to simulate in real-time.\nThe method returns `None`."}, {"role": "user", "content": "What does 'reset_world' do?"}, {"role": "assistant", "content": "'reset_world' resets the world to its initial state. It takes no parameters and returns `None`."}, {"role": "user", "content": "Tell me about 'add_fixed_constraint'."}, {"role": "assistant", "content": "'add_fixed_constraint' adds a fixed constraint between two links in the world. The parameters are:\n- `parent_link` (Link): The parent link of the constraint.\n- `child_link` (Link): The child link of the constraint.\n- `child_to_parent_transform` (Transform): The transform from the child link to the parent link.\nThe method returns an `int`, which is the unique ID of the created constraint."}, {"role": "user", "content": "What about 'remove_constraint'?"}, {"role": "assistant", "content": "'remove_constraint' removes a constraint by its ID. The parameter is:\n- `constraint_id` (int): The ID of the constraint to be removed.\nThe method returns `None`."}, {"role": "user", "content": "Explain 'get_joint_position'."}, {"role": "assistant", "content": "'get_joint_position' returns the position of a specific joint in the world. The parameter is:\n- `joint` (Joint): The joint object whose position you want to retrieve.\nThe method returns a `float`, which is the position of the joint."}, {"role": "user", "content": "What is 'reset_joint_position'?"}, {"role": "assistant", "content": "'reset_joint_position' resets the position of a specified joint. The parameters are:\n- `joint` (Joint): The joint object to reset.\n- `joint_position` (float): The new position for the joint.\nThe method returns `None`."}, {"role": "user", "content": "How does 'get_link_pose' work?"}, {"role": "assistant", "content": "'get_link_pose' returns the pose of a specific link in the world. The parameter is:\n- `link` (Link): The link object whose pose you want to retrieve.\nThe method returns a `Pose`, which is the pose of the link."}, {"role": "user", "content": "What about 'set_link_color'?"}, {"role": "assistant", "content": "'set_link_color' sets the color of a specified link in the world. The parameters are:\n- `link` (Link): The link object whose color you want to set.\n- `rgba_color` (Color): The new color for the link in RGBA format.\nThe method returns `None`."}, {"role": "user", "content": "Explain 'get_link_color'."}, {"role": "assistant", "content": "'get_link_color' returns the current color of a specified link in the world. The parameter is:\n- `link` (Link): The link object whose color you want to retrieve.\nThe method returns a `Color`, which is the current color of the link."}, {"role": "user", "content": "Tell me about 'get_object_axis_aligned_bounding_box'."}, {"role": "assistant", "content": "'get_object_axis_aligned_bounding_box' returns the axis-aligned bounding box (AABB) of a specified object in the world. The parameter is:\n- `obj` (Object): The object whose AABB you want to retrieve.\nThe method returns an `AxisAlignedBoundingBox`, which represents the AABB of the object."}, {"role": "user", "content": "What about 'get_link_axis_aligned_bounding_box'?"}, {"role": "assistant", "content": "'get_link_axis_aligned_bounding_box' returns the axis-aligned bounding box (AABB) of a specified link in the world. The parameter is:\n- `link` (Link): The link object whose AABB you want to retrieve.\nThe method returns an `AxisAlignedBoundingBox`, which represents the AABB of the link."}, {"role": "user", "content": "How does 'set_realtime' work?"}, {"role": "assistant", "content": "'set_realtime' enables or disables real-time simulation in the world. The parameter is:\n- `real_time` (bool): Whether to enable (`True`) or disable (`False`) real-time simulation.\nThe method returns `None`."}, {"role": "user", "content": "Explain 'set_gravity'."}, {"role": "assistant", "content": "'set_gravity' sets the gravity vector for the world. The parameter is:\n- `gravity_vector` (List[float]): The gravity vector as a list of `[x, y, z]` values.\nThe method returns `None`."}, {"role": "user", "content": "Tell me about 'ray_test'."}, {"role": "assistant", "content": "'ray_test' performs a ray test in the world and returns the ID of the first object hit by the ray. The parameters are:\n- `from_position` (List[float]): The starting position of the ray.\n- `to_position` (List[float]): The ending position of the ray.\nThe method returns an `int`, which is the ID of the first object hit by the ray, or `-1` if no object was hit."}, {"role": "user", "content": "What is 'ray_test_batch'?"}, {"role": "assistant", "content": "'ray_test_batch' performs a batch of ray tests and returns a list of object IDs hit by the rays. The parameters are:\n- `from_positions` (List[List[float]]): A list of starting positions for the rays.\n- `to_positions` (List[List[float]]): A list of ending positions for the rays.\n- `num_threads` (int, optional): The number of threads to use for the ray tests.\nThe method returns a `List[int]`, which contains the IDs of objects hit by the rays."}, {"role": "user", "content": "How does 'get_images_for_target' work?"}, {"role": "assistant", "content": "'get_images_for_target' renders images (RGB, depth, segmentation mask) for a given target pose and camera pose in the world. The parameters are:\n- `target_pose` (Pose): The pose of the target to look at.\n- `cam_pose` (Pose): The pose of the camera.\n- `size` (int, optional): The size of the rendered images.\nThe method returns a `List[np.ndarray]`, which contains the rendered images in the following order: `[RGB, depth, segmentation mask]`."}, {"role": "user", "content": "Tell me about 'add_text'."}, {"role": "assistant", "content": "'add_text' adds text to the world at a specified position and orientation. The parameters are:\n- `text` (str): The text to be added.\n- `position` (List[float]): The position of the text in the world.\n- `orientation` (List[float], optional): The orientation of the text in the world.\n- `size` (float, optional): The size of the text.\n- `color` (Color, optional): The color of the text.\n- `life_time` (float, optional): The lifetime of the text in seconds.\n- `parent_object_id` (int, optional): The ID of the parent object.\n- `parent_link_id` (int, optional): The ID of the parent link.\nThe method returns an `int`, which is the ID of the added text."}, {"role": "user", "content": "What about 'remove_text'?"}, {"role": "assistant", "content": "'remove_text' removes text from the world by its ID. The parameter is:\n- `text_id` (int, optional): The ID of the text to remove.\nThe method returns `None`."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the methods available under the 'Object' category in PyCRAM?"}, {"role": "assistant", "content": "Sure! The 'Object' category in PyCRAM includes various methods for interacting with and managing objects within the simulation. Would you like an overview of all these methods first?"}, {"role": "user", "content": "Yes, please list all the methods under the 'Object' category."}, {"role": "assistant", "content": "Here are the methods available under the 'Object' category:\n1. `set_pose`\n2. `get_pose`\n3. `set_position`\n4. `get_position`\n5. `set_orientation`\n6. `get_orientation`\n7. `attach`\n8. `detach`\n9. `get_link_pose`\n10. `get_joint_position`\n11. `set_joint_position`\n12. `set_joint_positions`\n13. `get_axis_aligned_bounding_box`\n14. `get_link_geometry`\n15. `get_link_transform`\n16. `get_link_origin`\n17. `get_link_origin_transform`\n18. `get_joint_id`\n19. `get_root_link_description`\n20. `get_root_link_id`\n21. `get_link_id`\n22. `get_link_by_id`\n23. `reset_all_joints_positions`\n24. `get_joint_damping`\n25. `get_joint_upper_limit`\n26. `get_joint_lower_limit`\n27. `get_joint_axis`\n28. `get_joint_type`\n29. `get_joint_limits`\n30. `get_joint_child_link`\n31. `get_joint_parent_link`\n32. `find_joint_above_link`\n33. `get_positions_of_all_joints`\n34. `update_link_transforms`\n35. `contact_points`\n36. `contact_points_simulated`\n37. `set_color`\n38. `get_color`\n39. `get_base_origin`\n40. `get_joint_by_id`\n41. `copy_to_prospection`\n42. `get_link_for_attached_objects`\nWhich method would you like to know more about first?"}, {"role": "user", "content": "Tell me about 'set_pose'."}, {"role": "assistant", "content": "'set_pose' is a method that sets the pose of an object in the simulation. The parameters include:\n- `pose` (Pose): The new pose of the object.\n- `set_attachments` (bool, optional): Whether to update the poses of attached objects.\nThe method returns `None`."}, {"role": "user", "content": "And what about 'get_pose'?"}, {"role": "assistant", "content": "'get_pose' returns the current pose of the object. It takes no parameters and returns a `Pose`, which represents the current pose of the object."}, {"role": "user", "content": "How does 'set_position' work?"}, {"role": "assistant", "content": "'set_position' sets the position of the object in the simulation. The parameters include:\n- `position` (Union[Pose, Point, List[float]]): The new position of the object.\n- `base` (bool, optional): Whether to place the object base at the given position.\nThe method returns `None`."}, {"role": "user", "content": "What is 'get_position'?"}, {"role": "assistant", "content": "'get_position' returns the current position of the object. It takes no parameters and returns a `Point`, which represents the current position of the object."}, {"role": "user", "content": "Tell me about 'set_orientation'."}, {"role": "assistant", "content": "'set_orientation' sets the orientation of the object in the simulation. The parameter is:\n- `orientation` (Union[Pose, Quaternion, List[float]]): The new orientation of the object.\nThe method returns `None`."}, {"role": "user", "content": "How does 'get_orientation' work?"}, {"role": "assistant", "content": "'get_orientation' returns the current orientation of the object. It takes no parameters and returns a `Quaternion`, which represents the current orientation of the object."}, {"role": "user", "content": "Explain 'attach'."}, {"role": "assistant", "content": "'attach' is a method used to attach another object to the current object in the simulation. The parameters include:\n- `child_object` (Object): The object to be attached.\n- `parent_link` (str, optional): The name of the parent link.\n- `child_link` (str, optional): The name of the child link.\n- `bidirectional` (bool, optional): Whether the attachment should be bidirectional.\nThe method returns `None`."}, {"role": "user", "content": "And what about 'detach'?"}, {"role": "assistant", "content": "'detach' is a method used to detach an attached object from the current object. The parameter is:\n- `child_object` (Object): The object to be detached.\nThe method returns `None`."}, {"role": "user", "content": "How does 'get_link_pose' work?"}, {"role": "assistant", "content": "'get_link_pose' returns the pose of a specified link in the object. The parameter is:\n- `link_name` (str): The name of the link.\nThe method returns a `Pose`, which represents the pose of the link."}, {"role": "user", "content": "What is 'get_joint_position'?"}, {"role": "assistant", "content": "'get_joint_position' returns the position of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns a `float`, which represents the position of the joint."}, {"role": "user", "content": "Tell me about 'set_joint_position'."}, {"role": "assistant", "content": "'set_joint_position' sets the position of a specified joint in the object. The parameters are:\n- `joint_name` (str): The name of the joint.\n- `joint_position` (float): The new position for the joint.\nThe method returns `None`."}, {"role": "user", "content": "What about 'set_joint_positions'?"}, {"role": "assistant", "content": "'set_joint_positions' sets the positions of multiple joints in the object. The parameter is:\n- `joint_poses` (Dict[str, float]): A dictionary mapping joint names to their target positions.\nThe method returns `None`."}, {"role": "user", "content": "Explain 'get_axis_aligned_bounding_box'."}, {"role": "assistant", "content": "'get_axis_aligned_bounding_box' returns the axis-aligned bounding box (AABB) of the object. It takes no parameters and returns an `AxisAlignedBoundingBox`, which represents the AABB of the object."}, {"role": "user", "content": "How does 'get_link_geometry' work?"}, {"role": "assistant", "content": "'get_link_geometry' returns the geometry of a specified link in the object. The parameter is:\n- `link_name` (str): The name of the link.\nThe method returns `Union[VisualShape, None]`, which represents the geometry of the link."}, {"role": "user", "content": "What is 'get_link_transform'?"}, {"role": "assistant", "content": "'get_link_transform' returns the transform of a specified link in the object. The parameter is:\n- `link_name` (str): The name of the link.\nThe method returns a `Transform`, which represents the transform of the link."}, {"role": "user", "content": "Explain 'get_link_origin'."}, {"role": "assistant", "content": "'get_link_origin' returns the origin of a specified link in the object. The parameter is:\n- `link_name` (str): The name of the link.\nThe method returns a `Pose`, which represents the origin of the link."}, {"role": "user", "content": "How does 'get_link_origin_transform' work?"}, {"role": "assistant", "content": "'get_link_origin_transform' returns the origin transform of a specified link in the object. The parameter is:\n- `link_name` (str): The name of the link.\nThe method returns a `Transform`, which represents the origin transform of the link."}, {"role": "user", "content": "What is 'get_joint_id'?"}, {"role": "assistant", "content": "'get_joint_id' returns the unique ID for a specified joint name in the object. The parameter is:\n- `name` (str): The name of the joint.\nThe method returns an `int`, which is the unique ID of the joint."}, {"role": "user", "content": "Tell me about 'get_root_link_description'."}, {"role": "assistant", "content": "'get_root_link_description' returns the root link of the URDF of the object. It takes no parameters and returns a `LinkDescription`, which represents the root link as defined in the URDF."}, {"role": "user", "content": "And what about 'get_root_link_id'?"}, {"role": "assistant", "content": "'get_root_link_id' returns the unique ID of the root link of the object. It takes no parameters and returns an `int`, which is the unique ID of the root link."}, {"role": "user", "content": "How does 'get_link_id' work?"}, {"role": "assistant", "content": "'get_link_id' returns the unique ID for a specified link name in the object. The parameter is:\n- `link_name` (str): The name of the link.\nThe method returns an `int`, which is the unique ID of the link."}, {"role": "user", "content": "What is 'get_link_by_id'?"}, {"role": "assistant", "content": "'get_link_by_id' returns the link associated with a given unique link ID in the object. The parameter is:\n- `link_id` (int): The unique ID of the link.\nThe method returns an `ObjectDescription.Link`, which represents the link object."}, {"role": "user", "content": "Tell me about 'reset_all_joints_positions'."}, {"role": "assistant", "content": "'reset_all_joints_positions' resets the current positions of all joints in the object to 0. It takes no parameters and returns `None`."}, {"role": "user", "content": "How does 'get_joint_damping' work?"}, {"role": "assistant", "content": "'get_joint_damping' returns the damping of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns a `float`, which represents the damping of the joint."}, {"role": "user", "content": "What about 'get_joint_upper_limit'?"}, {"role": "assistant", "content": "'get_joint_upper_limit' returns the upper limit of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns a `float`, which represents the upper limit of the joint."}, {"role": "user", "content": "Explain 'get_joint_lower_limit'."}, {"role": "assistant", "content": "'get_joint_lower_limit' returns the lower limit of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns a `float`, which represents the lower limit of the joint."}, {"role": "user", "content": "How does 'get_joint_axis' work?"}, {"role": "assistant", "content": "'get_joint_axis' returns the axis of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns a `Point`, which represents the axis of the joint."}, {"role": "user", "content": "What is 'get_joint_type'?"}, {"role": "assistant", "content": "'get_joint_type' returns the type of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns a `JointType`, which represents the type of the joint."}, {"role": "user", "content": "Explain 'get_joint_limits'."}, {"role": "assistant", "content": "'get_joint_limits' returns the lower and upper limits of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns a `Tuple[float, float]`, which represents the lower and upper limits of the joint."}, {"role": "user", "content": "How does 'get_joint_child_link' work?"}, {"role": "assistant", "content": "'get_joint_child_link' returns the child link of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns an `ObjectDescription.Link`, which represents the child link of the joint."}, {"role": "user", "content": "What is 'get_joint_parent_link'?"}, {"role": "assistant", "content": "'get_joint_parent_link' returns the parent link of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns an `ObjectDescription.Link`, which represents the parent link of the joint."}, {"role": "user", "content": "Tell me about 'find_joint_above_link'."}, {"role": "assistant", "content": "'find_joint_above_link' traverses the chain from a specified link to the URDF origin and returns the first joint that matches the specified joint type. The parameters are:\n- `link_name` (str): The name of the link above which the joint should be found.\n- `joint_type` (JointType): The type of joint to search for.\nThe method returns a `str`, which is the name of the first joint that matches the given type."}, {"role": "user", "content": "How does 'get_positions_of_all_joints' work?"}, {"role": "assistant", "content": "'get_positions_of_all_joints' returns the positions of all joints in the object as a dictionary of joint names and their respective positions. It takes no parameters and returns a `Dict[str, float]`, which contains the positions of all joints."}, {"role": "user", "content": "Explain 'update_link_transforms'."}, {"role": "assistant", "content": "'update_link_transforms' updates the transforms of all links in the object using a specified time or the current ROS time. The parameter is:\n- `transform_time` (rospy.Time, optional): The time at which the transformation should be updated.\nThe method returns `None`."}, {"role": "user", "content": "What is 'contact_points'?"}, {"role": "assistant", "content": "'contact_points' returns a list of contact points between the object and other objects in the simulation. It takes no parameters and returns a `List`, which contains all contact points with other objects."}, {"role": "user", "content": "How does 'contact_points_simulated' work?"}, {"role": "assistant", "content": "'contact_points_simulated' returns a list of all contact points between the object and other objects after stepping the simulation once. It takes no parameters and returns a `List`, which contains the contact points between the object and other objects."}, {"role": "user", "content": "Tell me about 'set_color'."}, {"role": "assistant", "content": "'set_color' changes the color of the object. The color must be provided as a list of RGBA values. The parameter is:\n- `rgba_color` (Color): The new color of the object as a `Color` object with RGBA values between 0 and 1.\nThe method returns `None`."}, {"role": "user", "content": "What about 'get_color'?"}, {"role": "assistant", "content": "'get_color' returns the color of the object. Depending on the object, the return value is either:\n1. A `Color` object with RGBA values if the object has one link.\n2. A dictionary with link names as keys and colors as values for objects with multiple links.\nThe method returns `Union[Color, Dict[str, Color]]`, representing the color(s) of the object."}, {"role": "user", "content": "Explain 'get_base_origin'."}, {"role": "assistant", "content": "'get_base_origin' returns the origin of the base or bottom of the object. It takes no parameters and returns a `Pose`, which represents the origin of the base."}, {"role": "user", "content": "How does 'get_joint_by_id' work?"}, {"role": "assistant", "content": "'get_joint_by_id' returns the joint object associated with a given unique joint ID. The parameter is:\n- `joint_id` (int): The unique ID of the joint.\nThe method returns a `Joint`, which represents the joint object."}, {"role": "user", "content": "What is 'copy_to_prospection'?"}, {"role": "assistant", "content": "'copy_to_prospection' copies the object to the prospection world. It takes no parameters and returns the copied `Object` in the prospection world."}, {"role": "user", "content": "How does 'get_link_for_attached_objects' work?"}, {"role": "assistant", "content": "'get_link_for_attached_objects' returns a dictionary that maps attached objects to the link of the current object to which they are attached. It takes no parameters and returns a `Dict[Object, ObjectDescription.Link]`, which represents the mapping of attached objects to their corresponding links."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the methods available under the 'Designators' category in PyCRAM?"}, {"role": "assistant", "content": "Sure! The 'Designators' category in PyCRAM includes various methods for working with designators, which are symbolic descriptions used to resolve and execute specific actions or tasks. Would you like an overview of all these methods first?"}, {"role": "user", "content": "Yes, please list all the methods under the 'Designators' category."}, {"role": "assistant", "content": "Here are the methods available under the 'Designators' category:\n1. `resolve`\n2. `perform`\n3. `make_effective`\n4. `newest_effective`\n5. `prop_value`\n6. `check_constraints`\n7. `make_dictionary`\n8. `rename_prop`\nWhich method would you like to know more about first?"}, {"role": "user", "content": "Tell me about 'resolve'."}, {"role": "assistant", "content": "'resolve' is a method that resolves the designator description to a specific designator instance. It takes no parameters and returns a `Designator`, which is the resolved designator instance."}, {"role": "user", "content": "And what about 'perform'?"}, {"role": "assistant", "content": "'perform' is a method that executes the resolved designator. It takes no parameters and returns `Any`, which is the result of the designator execution."}, {"role": "user", "content": "How does 'make_effective' work?"}, {"role": "assistant", "content": "'make_effective' creates a new effective designator of the same type as the current one. If no properties are specified, the current ones are used. The parameters include:\n- `new_properties` (List, optional): A list of properties.\n- `data` (Any, optional): The low-level data structure the new designator describes.\n- `timestamp` (float, optional): The timestamp of creation.\nThe method returns a `Designator`, which is the newly created effective designator."}, {"role": "user", "content": "What is 'newest_effective'?"}, {"role": "assistant", "content": "'newest_effective' returns the newest effective designator. It takes no parameters and returns a `Designator`, which is the newest effective designator."}, {"role": "user", "content": "Explain 'prop_value'."}, {"role": "assistant", "content": "'prop_value' returns the first value matching the specified property key. The parameter is:\n- `key` (str): The key to return the value of.\nThe method returns `Any`, which is the value of the specified key."}, {"role": "user", "content": "How does 'check_constraints' work?"}, {"role": "assistant", "content": "'check_constraints' returns `True` if all the given properties match, and `False` otherwise. The parameter is:\n- `properties` (List): The properties which have to match. A property can be a tuple where the first value is the key of a property that must equal the second value. Otherwise, it's simply the key of a property that must not be `None`.\nThe method returns a `bool`, which is `True` if all properties match, and `False` otherwise."}, {"role": "user", "content": "What about 'make_dictionary'?"}, {"role": "assistant", "content": "'make_dictionary' (deprecated) converts the given properties to a dictionary. The parameter is:\n- `properties` (List): The properties to create a dictionary from. A property can be a tuple where the first value is the dictionary key and the second value is the dictionary value. Otherwise, it's simply the dictionary key and the key of a property that is the dictionary value.\nThe method returns a `Dict`, which is the dictionary with the given properties."}, {"role": "user", "content": "Tell me about 'rename_prop'."}, {"role": "assistant", "content": "'rename_prop' renames a property of the designator. The parameters include:\n- `old` (str): The name of the old property.\n- `new` (str): The name of the new property.\nThe method returns a `Designator`, which is the designator with the renamed property."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the components and methods available in the 'pycram.costmaps' module?"}, {"role": "assistant", "content": "Sure! The 'pycram.costmaps' module in PyCRAM includes several classes and functions related to costmaps, which are used for planning and navigation in robotics. Would you like an overview of all the classes and functions first?"}, {"role": "user", "content": "Yes, please list all the components in the 'pycram.costmaps' module."}, {"role": "assistant", "content": "The 'pycram.costmaps' module includes the following components:\n\n**Attributes:**\n- `cmap`\n\n**Classes:**\n1. `Rectangle`\n2. `Costmap`\n3. `OccupancyCostmap`\n4. `VisibilityCostmap`\n5. `GaussianCostmap`\n6. `SemanticCostmap`\n\n**Functions:**\n1. `plot_grid(data: numpy.ndarray) → None`\n\nWhich class, function, or attribute would you like to know more about first?"}, {"role": "user", "content": "Tell me about the 'Rectangle' class."}, {"role": "assistant", "content": "The `Rectangle` class describes a rectangle by its lower and upper x and y values.\n\n**Attributes:**\n- `x_lower`: float\n- `x_upper`: float\n- `y_lower`: float\n- `y_upper`: float\n\n**Methods:**\n- `translate(x: float, y: float)`: Translates the rectangle by x and y.\n- `scale(x_factor: float, y_factor: float)`: Scales the rectangle by x_factor and y_factor."}, {"role": "user", "content": "And what about the 'Costmap' class?"}, {"role": "assistant", "content": "The `Costmap` class is the base class for all costmaps in PyCRAM, implementing visualization of costmaps in the World.\n\n**Attributes:**\n- `world`\n- `resolution`: float\n- `size`: int\n- `height`: int\n- `width`: int\n- `local_transformer`\n- `origin`: `pycram.datastructures.pose.Pose`\n- `map`: `numpy.ndarray`\n- `vis_ids`: `typing_extensions.List[int]`\n\n**Methods:**\n- `visualize() → None`: Visualizes a costmap in the BulletWorld.\n- `_chunks(lst: typing_extensions.List, n: int) → typing_extensions.List`: Yields n-sized chunks from lst.\n- `close_visualization() → None`: Removes the visualization from the World.\n- `_find_consecutive_line(start: typing_extensions.Tuple[int, int], map: numpy.ndarray) → int`: Finds the number of consecutive entries greater than zero.\n- `_find_max_box_height(start: typing_extensions.Tuple[int, int], length: int, map: numpy.ndarray) → int`: Finds the maximum height for a rectangle with a given width.\n- `merge(other_cm: Costmap) → Costmap`: Merges two costmaps into a new costmap.\n- `__add__(other: Costmap) → Costmap`: Overloads the '+' operator for merging Costmaps.\n- `partitioning_rectangles() → typing_extensions.List[Rectangle]`: Partitions the map into rectangles."}, {"role": "user", "content": "How does the 'OccupancyCostmap' class work?"}, {"role": "assistant", "content": "The `OccupancyCostmap` class represents a map of the environment where obstacles or inaccessible positions have a value of -1.\n\n**Attributes:**\n- `world`\n\n**Methods:**\n- `_calculate_diff_origin(height: int, width: int) → pycram.datastructures.pose.Pose`: Calculates the difference between the origin of the costmap and its center.\n- `_get_map() → numpy.ndarray`: Retrieves the map array from the map server and converts it into a numpy array.\n- `_get_map_metadata() → nav_msgs.msg.MapMetaData`: Retrieves metadata about the costmap from the map server.\n- `_convert_map(map: numpy.ndarray) → numpy.ndarray`: Converts the occupancy map from ROS to be consistent with PyCRAM.\n- `create_sub_map(sub_origin: pycram.datastructures.pose.Pose, size: int) → Costmap`: Creates a smaller map centered around a specific point.\n- `_create_from_world(size: int, resolution: float) → numpy.ndarray`: Creates an Occupancy Costmap for the World, marking valid positions."}, {"role": "user", "content": "What is the 'VisibilityCostmap' class?"}, {"role": "assistant", "content": "The `VisibilityCostmap` class represents the visibility of a specific point from every position around it.\n\n**Attributes:**\n- `world`\n- `map`\n- `size`\n- `resolution`\n- `max_height`: float\n- `min_height`: float\n- `origin`: `pycram.datastructures.pose.Pose`\n\n**Methods:**\n- `_create_images() → typing_extensions.List[numpy.ndarray]`: Creates four depth images around the point of interest.\n- `_depth_buffer_to_meter(buffer: numpy.ndarray) → numpy.ndarray`: Converts depth images to represent positions in meters.\n- `_generate_map()`: Generates the density map using an algorithm."}, {"role": "user", "content": "Explain the 'GaussianCostmap' class."}, {"role": "assistant", "content": "The `GaussianCostmap` class represents 2D Gaussian distributions around the origin with a given mean and sigma.\n\n**Attributes:**\n- `gau`: `numpy.ndarray`\n- `map`: `numpy.ndarray`\n- `size`: float\n- `origin`: `pycram.datastructures.pose.Pose`\n\n**Methods:**\n- `_gaussian_window(mean: int, std: float) → numpy.ndarray`: Creates a window of Gaussian distribution values."}, {"role": "user", "content": "What about the 'SemanticCostmap' class?"}, {"role": "assistant", "content": "The `SemanticCostmap` class represents a 2D distribution over a link of an object, such as a table surface.\n\n**Attributes:**\n- `world`: `pycram.datastructures.world.World`\n- `object`: `pycram.world_concepts.world_object.Object`\n- `link`: `pycram.description.Link`\n- `resolution`: float\n- `origin`: `pycram.datastructures.pose.Pose`\n- `height`: int = 0\n- `width`: int = 0\n- `map`: `numpy.ndarray` = []\n\n**Methods:**\n- `generate_map() → None`: Generates the semantic costmap based on the link's axis-aligned bounding box (AABB).\n- `get_aabb_for_link() → pycram.datastructures.dataclasses.AxisAlignedBoundingBox`: Returns the AABB of the link."}, {"role": "user", "content": "Tell me about the 'plot_grid' function."}, {"role": "assistant", "content": "The `plot_grid` function is an auxiliary method used for debugging. It plots a 2D numpy array using Matplotlib.\n\n**Parameters:**\n- `data`: A 2D numpy array representing the data to be plotted.\n\n**Returns:** None"}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the components and methods available in the 'pycram.datastructures.pose' module?"}, {"role": "assistant", "content": "Sure! The 'pycram.datastructures.pose' module in PyCRAM provides classes and functions related to pose and transformation representations, which are compatible with ROS services and messages. Would you like an overview of all the classes and functions first?"}, {"role": "user", "content": "Yes, please list all the components in the 'pycram.datastructures.pose' module."}, {"role": "assistant", "content": "The 'pycram.datastructures.pose' module includes the following components:\n\n**Classes:**\n1. `Pose`\n2. `Transform`\n\n**Functions:**\n1. `get_normalized_quaternion(quaternion: numpy.ndarray) → geometry_msgs.msg.Quaternion`\n\nWhich class or function would you like to know more about first?"}, {"role": "user", "content": "Tell me about the 'Pose' class."}, {"role": "assistant", "content": "The `Pose` class represents a pose in PyCRAM, extending the PoseStamped ROS message from geometry_msgs, making it compatible with ROS services and messages.\n\n**Properties:**\n- `frame`: str — The TF frame of this Pose.\n- `position`: geometry_msgs.msg.Point — The position of this pose.\n- `orientation`: geometry_msgs.msg.Quaternion — The orientation of this pose.\n\n**Methods:**\n- `from_pose_stamped(pose_stamped: geometry_msgs.msg.PoseStamped) → Pose`: Converts a PoseStamped message to a Pose object.\n- `to_list() → typing_extensions.List[typing_extensions.List[float]]`: Returns the position and orientation as lists.\n- `to_transform(child_frame: str) → Transform`: Converts this pose to a Transform.\n- `copy() → Pose`: Creates a deep copy of this pose.\n- `position_as_list() → typing_extensions.List[float]`: Returns the position as a list of xyz.\n- `orientation_as_list() → typing_extensions.List[float]`: Returns the orientation as a quaternion.\n- `dist(other_pose: Pose) → float`: Calculates the Euclidean distance between this pose and another.\n- `__eq__(other: Pose) → bool`: Checks for equality between two poses.\n- `set_position(new_position: typing_extensions.List[float]) → None`: Sets the position of this pose.\n- `set_orientation(new_orientation: typing_extensions.List[float]) → None`: Sets the orientation of this pose.\n- `to_sql() → pycram.orm.base.Pose`\n- `insert(session: sqlalchemy.orm.Session) → pycram.orm.base.Pose`\n- `multiply_quaternions(quaternion: typing_extensions.List) → None`: Multiplies the orientation quaternion by another quaternion.\n- `set_orientation_from_euler(axis: typing_extensions.List, euler_angles: typing_extensions.List[float]) → None`: Converts axis-angle to quaternion."}, {"role": "user", "content": "And what about the 'Transform' class?"}, {"role": "assistant", "content": "The `Transform` class represents a transformation from one TF frame to another in PyCRAM, extending the TransformStamped ROS message from geometry_msgs, making it compatible with ROS services and messages.\n\n**Properties:**\n- `frame`: str — The TF frame of this Transform.\n- `translation`: None — The translation of this Transform.\n- `rotation`: None — The rotation of this Transform.\n\n**Methods:**\n- `from_pose_and_child_frame(pose: Pose, child_frame_name: str) → Transform`: Creates a Transform from a Pose and a child frame name.\n- `from_transform_stamped(transform_stamped: geometry_msgs.msg.TransformStamped) → Transform`: Creates a Transform from a TransformStamped message.\n- `copy() → Transform`: Creates a deep copy of this Transform.\n- `translation_as_list() → typing_extensions.List[float]`: Returns the translation as a list of xyz.\n- `rotation_as_list() → typing_extensions.List[float]`: Returns the rotation as a quaternion.\n- `to_pose() → Pose`: Converts this Transform to a Pose, losing the child frame.\n- `invert() → Transform`: Inverts this Transform, reversing the direction.\n- `__mul__(other: Transform) → typing_extensions.Union[Transform, None]`: Multiplies this Transform with another one.\n- `inverse_times(other_transform: Transform) → Transform`: Subtracts another Transform from this one.\n- `__eq__(other: Transform) → bool`: Checks for equality between two Transforms.\n- `set_translation(new_translation: typing_extensions.List[float]) → None`: Sets the translation of this Transform.\n- `set_rotation(new_rotation: typing_extensions.List[float]) → None`: Sets the rotation of this Transform."}, {"role": "user", "content": "Tell me about the 'get_normalized_quaternion' function."}, {"role": "assistant", "content": "The `get_normalized_quaternion` function normalizes a given quaternion so that it has a magnitude of 1.\n\n**Parameters:**\n- `quaternion`: numpy.ndarray — The quaternion to be normalized.\n\n**Returns:**\n- `geometry_msgs.msg.Quaternion` — The normalized quaternion."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the components and methods available in the 'pycram.designators.object_designator' module?"}, {"role": "assistant", "content": "Sure! The 'pycram.designators.object_designator' module in PyCRAM provides classes for describing and working with objects within the system, particularly focusing on their believed, located, or real-world representations. Would you like an overview of all the classes in this module first?"}, {"role": "user", "content": "Yes, please list all the classes in the 'pycram.designators.object_designator' module."}, {"role": "assistant", "content": "The 'pycram.designators.object_designator' module includes the following classes:\n1. `BelieveObject`\n2. `ObjectPart`\n3. `LocatedObject`\n4. `RealObject`\n\nWhich class would you like to know more about first?"}, {"role": "user", "content": "Tell me about the 'BelieveObject' class."}, {"role": "assistant", "content": "The `BelieveObject` class describes objects that are only believed to exist, typically without physical verification.\n\n**Methods:**\n- `to_sql() → pycram.orm.object_designator.BelieveObject`: Creates an ORM object corresponding to this description.\n- `insert(session: sqlalchemy.orm.session.Session) → pycram.orm.object_designator.BelieveObject`: Adds and commits this and all related objects to the session."}, {"role": "user", "content": "And what about the 'ObjectPart' class?"}, {"role": "assistant", "content": "The `ObjectPart` class describes objects that are part of another object.\n\n**Attributes:**\n- `part_pose`: `pycram.external_interfaces.robokudo.Pose` — The pose of the part in relation to the whole object.\n\n**Methods:**\n- `to_sql() → pycram.orm.object_designator.ObjectPart`: Creates an ORM object corresponding to this description.\n- `insert(session: sqlalchemy.orm.session.Session) → pycram.orm.object_designator.ObjectPart`: Adds and commits this and all related objects to the session.\n- `ground() → Object`: Returns the first result of the iterator of this instance.\n- `__iter__()`: Iterates through every possible solution for the given input parameter."}, {"role": "user", "content": "Tell me about the 'LocatedObject' class."}, {"role": "assistant", "content": "The `LocatedObject` class provides a description for objects located via KnowRob. It currently has no specialized designators.\n\n**Attributes:**\n- `reference_frame`: `str` — The reference frame in which the position is given.\n- `timestamp`: `float` — The timestamp at which the position was valid.\n- **Additional Attributes:**\n  - `reference_frames`: `pycram.external_interfaces.robokudo.List[str]`\n  - `timestamps`: `pycram.external_interfaces.robokudo.List[float]`"}, {"role": "user", "content": "How does the 'RealObject' class work?"}, {"role": "assistant", "content": "The `RealObject` class represents an object in the real world. When resolving this object designator description, RoboKudo is queried to perceive an object fitting the given criteria. The specialized designator then tries to match the found object to an object in the world.\n\n**Attributes:**\n- `pose`: `pycram.external_interfaces.robokudo.Pose` — The pose of the perceived object.\n- `types`: `pycram.external_interfaces.robokudo.Optional[pycram.external_interfaces.robokudo.List[str]]`\n- `names`: `pycram.external_interfaces.robokudo.Optional[pycram.external_interfaces.robokudo.List[str]]`\n- `world_object`: `pycram.world_concepts.world_object.Object`\n\n**Methods:**\n- `__iter__()`: Queries RoboKudo for objects that fit the description and then iterates over all World objects of the same type to match a World object to the real object."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the components and methods available in the 'pycram.datastructures.dataclasses' module?"}, {"role": "assistant", "content": "Sure! The 'pycram.datastructures.dataclasses' module in PyCRAM provides several classes and functions that represent various data structures, such as colors, bounding boxes, visual shapes, and states. Would you like an overview of all the classes and functions in this module first?"}, {"role": "user", "content": "Yes, please list all the classes in the 'pycram.datastructures.dataclasses' module."}, {"role": "assistant", "content": "The 'pycram.datastructures.dataclasses' module includes the following classes:\n1. `Color`\n2. `AxisAlignedBoundingBox`\n3. `CollisionCallbacks`\n4. `MultiBody`\n5. `VisualShape`\n6. `BoxVisualShape`\n7. `SphereVisualShape`\n8. `CapsuleVisualShape`\n9. `CylinderVisualShape`\n10. `MeshVisualShape`\n11. `PlaneVisualShape`\n12. `State`\n13. `LinkState`\n14. `JointState`\n15. `ObjectState`\n16. `WorldState`\n\nWhich class would you like to know more about first?"}, {"role": "user", "content": "Tell me about the 'Color' class."}, {"role": "assistant", "content": "The `Color` class is a dataclass for storing RGBA color values as floats between 0 and 1. The default color is white, and 'A' stands for opacity.\n\n**Attributes:**\n- `R`: `float = 1`\n- `G`: `float = 1`\n- `B`: `float = 1`\n- `A`: `float = 1`\n\n**Methods:**\n- `from_list(color: typing_extensions.List[float])`: Sets the RGBA color from a list of values.\n- `from_rgb(rgb: typing_extensions.List[float])`: Sets the color from a list of RGB values.\n- `from_rgba(rgba: typing_extensions.List[float])`: Sets the color from a list of RGBA values.\n- `get_rgba() -> typing_extensions.List[float]`: Returns the color as a list of RGBA values.\n- `get_rgb() -> typing_extensions.List[float]`: Returns the color as a list of RGB values."}, {"role": "user", "content": "And what about the 'AxisAlignedBoundingBox' class?"}, {"role": "assistant", "content": "The `AxisAlignedBoundingBox` class is a dataclass for storing the minimum and maximum points of an axis-aligned bounding box.\n\n**Attributes:**\n- `min_x`: `float`\n- `min_y`: `float`\n- `min_z`: `float`\n- `max_x`: `float`\n- `max_y`: `float`\n- `max_z`: `float`\n\n**Methods:**\n- `from_min_max(min_point: typing_extensions.List[float], max_point: typing_extensions.List[float])`: Sets the bounding box from minimum and maximum points.\n- `get_min_max_points() -> typing_extensions.Tuple[pycram.datastructures.pose.Point, pycram.datastructures.pose.Point]`: Returns the bounding box as a tuple of minimum and maximum points.\n- `get_min_point() -> pycram.datastructures.pose.Point`: Returns the minimum point of the bounding box.\n- `get_max_point() -> pycram.datastructures.pose.Point`: Returns the maximum point of the bounding box.\n- `get_min_max() -> typing_extensions.Tuple[typing_extensions.List[float], typing_extensions.List[float]]`: Returns the bounding box as a tuple of minimum and maximum points.\n- `get_min() -> typing_extensions.List[float]`: Returns the minimum point as a list.\n- `get_max() -> typing_extensions.List[float]`: Returns the maximum point as a list."}, {"role": "user", "content": "Tell me about the 'CollisionCallbacks' class."}, {"role": "assistant", "content": "The `CollisionCallbacks` class handles collision callbacks in the system.\n\n**Attributes:**\n- `on_collision_cb`: `typing_extensions.Callable` — A callback function for when a collision occurs.\n- `no_collision_cb`: `typing_extensions.Optional[typing_extensions.Callable] = None` — An optional callback function for when no collision occurs."}, {"role": "user", "content": "What is the 'MultiBody' class?"}, {"role": "assistant", "content": "The `MultiBody` class represents a multi-body system in the simulation.\n\n**Attributes:**\n- `base_visual_shape_index`: `int` — Index of the base visual shape.\n- `base_pose`: `pycram.datastructures.pose.Pose` — Pose of the base.\n- `link_visual_shape_indices`: `typing_extensions.List[int]` — Indices of the visual shapes for the links.\n- `link_poses`: `typing_extensions.List[pycram.datastructures.pose.Pose]` — Poses of the links.\n- `link_masses`: `typing_extensions.List[float]` — Masses of the links.\n- `link_inertial_frame_poses`: `typing_extensions.List[pycram.datastructures.pose.Pose]` — Poses of the inertial frames of the links.\n- `link_parent_indices`: `typing_extensions.List[int]` — Indices of the parent links.\n- `link_joint_types`: `typing_extensions.List[pycram.datastructures.enums.JointType]` — Types of the joints.\n- `link_joint_axis`: `typing_extensions.List[pycram.datastructures.pose.Point]` — Axes of the joints.\n- `link_collision_shape_indices`: `typing_extensions.List[int]` — Indices of the collision shapes for the links."}, {"role": "user", "content": "How does the 'VisualShape' class work?"}, {"role": "assistant", "content": "The `VisualShape` class is a helper class that provides a standard way to create an abstract base class (ABC) using inheritance.\n\n**Attributes:**\n- `rgba_color`: `Color` — The RGBA color of the visual shape.\n- `visual_frame_position`: `typing_extensions.List[float]` — The position of the visual frame.\n\n**Methods:**\n- `shape_data() -> typing_extensions.Dict[str, typing_extensions.Any]`: An abstract method to return the shape data of the visual shape.\n\n**Properties:**\n- `visual_geometry_type`: `pycram.datastructures.enums.Shape` — An abstract property to return the visual geometry type of the visual shape (e.g., box, sphere)."}, {"role": "user", "content": "Tell me about the 'BoxVisualShape' class."}, {"role": "assistant", "content": "The `BoxVisualShape` class is a helper class that inherits from `VisualShape` to represent a box visual shape.\n\n**Attributes:**\n- `half_extents`: `typing_extensions.List[float]` — The half extents of the box.\n\n**Methods:**\n- `shape_data() -> typing_extensions.Dict[str, typing_extensions.List[float]]`: Returns the shape data of the box, such as its half extents.\n\n**Properties:**\n- `visual_geometry_type`: `pycram.datastructures.enums.Shape` — Returns the visual geometry type of the box.\n- `size`: `typing_extensions.List[float]` — Returns the size of the box."}, {"role": "user", "content": "How does the 'SphereVisualShape' class work?"}, {"role": "assistant", "content": "The `SphereVisualShape` class is a helper class that inherits from `VisualShape` to represent a sphere visual shape.\n\n**Attributes:**\n- `radius`: `float` — The radius of the sphere.\n\n**Methods:**\n- `shape_data() -> typing_extensions.Dict[str, float]`: Returns the shape data of the sphere, such as its radius.\n\n**Properties:**\n- `visual_geometry_type`: `pycram.datastructures.enums.Shape` — Returns the visual geometry type of the sphere."}, {"role": "user", "content": "And what about the 'CapsuleVisualShape' class?"}, {"role": "assistant", "content": "The `CapsuleVisualShape` class is a helper class that inherits from `VisualShape` to represent a capsule visual shape.\n\n**Attributes:**\n- `radius`: `float` — The radius of the capsule.\n- `length`: `float` — The length of the capsule.\n\n**Methods:**\n- `shape_data() -> typing_extensions.Dict[str, float]`: Returns the shape data of the capsule, such as its radius and length.\n\n**Properties:**\n- `visual_geometry_type`: `pycram.datastructures.enums.Shape` — Returns the visual geometry type of the capsule."}, {"role": "user", "content": "Tell me about the 'CylinderVisualShape' class."}, {"role": "assistant", "content": "The `CylinderVisualShape` class is a helper class that inherits from `CapsuleVisualShape` to represent a cylinder visual shape.\n\n**Properties:**\n- `visual_geometry_type`: `pycram.datastructures.enums.Shape` — Returns the visual geometry type of the cylinder."}, {"role": "user", "content": "What is the 'MeshVisualShape' class?"}, {"role": "assistant", "content": "The `MeshVisualShape` class is a helper class that inherits from `VisualShape` to represent a mesh visual shape.\n\n**Attributes:**\n- `scale`: `typing_extensions.List[float]` — The scale of the mesh.\n- `file_name`: `str` — The file name of the mesh.\n\n**Methods:**\n- `shape_data() -> typing_extensions.Dict[str, typing_extensions.Union[typing_extensions.List[float], str]]`: Returns the shape data of the mesh, including its scale and file name.\n\n**Properties:**\n- `visual_geometry_type`: `pycram.datastructures.enums.Shape` — Returns the visual geometry type of the mesh."}, {"role": "user", "content": "How does the 'PlaneVisualShape' class work?"}, {"role": "assistant", "content": "The `PlaneVisualShape` class is a helper class that inherits from `VisualShape` to represent a plane visual shape.\n\n**Attributes:**\n- `normal`: `typing_extensions.List[float]` — The normal vector of the plane.\n\n**Methods:**\n- `shape_data() -> typing_extensions.Dict[str, typing_extensions.List[float]]`: Returns the shape data of the plane, such as its normal vector.\n\n**Properties:**\n- `visual_geometry_type`: `pycram.datastructures.enums.Shape` — Returns the visual geometry type of the plane."}, {"role": "user", "content": "Tell me about the 'State' class."}, {"role": "assistant", "content": "The `State` class is a helper class that provides a standard way to create an abstract base class (ABC) using inheritance. It serves as the foundation for various state classes in PyCRAM."}, {"role": "user", "content": "What does the 'LinkState' class do?"}, {"role": "assistant", "content": "The `LinkState` class is a helper class that inherits from `State` and provides a way to represent the state of a link in PyCRAM.\n\n**Attributes:**\n- `constraint_ids`: `typing_extensions.Dict[pycram.description.Link, int]` — A dictionary mapping links to their constraint IDs."}, {"role": "user", "content": "Tell me about the 'JointState' class."}, {"role": "assistant", "content": "The `JointState` class is a helper class that inherits from `State` and represents the state of a joint in PyCRAM.\n\n**Attributes:**\n- `position`: `float` — The position of the joint."}, {"role": "user", "content": "What about the 'ObjectState' class?"}, {"role": "assistant", "content": "The `ObjectState` class is a helper class that inherits from `State` and represents the state of an object in PyCRAM.\n\n**Attributes:**\n- `pose`: `pycram.datastructures.pose.Pose` — The pose of the object.\n- `attachments`: `typing_extensions.Dict[pycram.world_concepts.world_object.Object, pycram.world_concepts.constraints.Attachment]` — A dictionary mapping objects to their attachments.\n- `link_states`: `typing_extensions.Dict[int, LinkState]` — A dictionary mapping link IDs to their states.\n- `joint_states`: `typing_extensions.Dict[int, JointState]` — A dictionary mapping joint IDs to their states."}, {"role": "user", "content": "And finally, what is the 'WorldState' class?"}, {"role": "assistant", "content": "The `WorldState` class is a helper class that inherits from `State` and represents the overall state of the world in PyCRAM.\n\n**Attributes:**\n- `simulator_state_id`: `int` — The ID of the simulator state.\n- `object_states`: `typing_extensions.Dict[str, ObjectState]` — A dictionary mapping object names to their states."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the concept of Designators in PyCRAM and the different types available?"}, {"role": "assistant", "content": "Designators in PyCRAM represent actions, motions, objects, and locations. They consist of a description and a specified element, where the description defines a set of possible designators, and the designator is a specific instance within that set. During runtime, a designator description is resolved to a specific designator, which can then be executed to perform the desired behavior.\n\nFor example, a NavigateAction description might list possible poses that the robot could move to in order to grasp an object. This description is resolved to a specific designator with parameters suitable for execution.\n\nThere are four main types of designators in PyCRAM:\n1. **Action Designators** - Describe complex, executable actions for an agent, including failure handling and parametrization.\n2. **Object Designators** - Represent objects in the simulated world, matching objects by name or type.\n3. **Motion Designators** - Describe atomic, executable actions for an agent, with strict typing and no failure handling.\n4. **Location Designators** - Define a set of locations based on specific constraints like reachability or visibility."}, {"role": "user", "content": "Tell me more about Object Designators."}, {"role": "assistant", "content": "Object Designators in PyCRAM represent objects in the (simulated) world. They can be described using names or types that the object should match. The `ground` method returns an object that matches the description, while the `__iter__` method iterates over all objects that fit the description.\n\nTo create a new Object Designator, you should inherit from the general `ObjectDesignatorDescription` class. If the object they ground to differs from the base object, a dataclass should be created inside the new description. To enable ORM logging for the new objects, you must implement the `to_sql()` and `insert()` methods."}, {"role": "user", "content": "What about Action Designators?"}, {"role": "assistant", "content": "Action Designators describe complex actions that an agent can execute. They act as higher-level plans that include failure handling and parameterization. An Action Designator description takes a list of possible parameters, and when resolved, it picks one parameter from the list to create a specific designator.\n\nThe resolved designator can then be executed to perform the action. Action Designators are useful for defining more sophisticated behaviors where multiple factors must be considered during execution."}, {"role": "user", "content": "Explain Motion Designators."}, {"role": "assistant", "content": "Motion Designators describe atomic actions that an agent can execute, such as moving a robotic arm or opening a gripper. Unlike Action Designators, Motion Designators do not include failure handling and are more straightforward. They take a single, strictly-typed parameter instead of a list of possible parameters.\n\nThe `perform` method of a Motion Designator passes the resolved designator to the respective Process Module for execution on the robot. This makes Motion Designators ideal for defining precise, low-level actions."}, {"role": "user", "content": "Tell me about Location Designators."}, {"role": "assistant", "content": "Location Designators define a set of possible locations based on specific constraints, such as reachability or visibility. They return a single pose from the set that meets the given constraints.\n\nLike Object Designators, Location Designators also have an `__iter__` method that can iterate over all possible solutions for the description. This allows you to explore multiple potential locations that satisfy the specified criteria."}, {"role": "user", "content": "How can I create my own Designator?"}, {"role": "assistant", "content": "Creating your own Designator in PyCRAM involves extending the base class of the respective description type:\n\n- For actions, extend `ActionDesignatorDescription`.\n- For objects, extend `ObjectDesignatorDescription`.\n- For locations, extend `LocationDesignatorDescription`.\n- For motions, extend `BaseMotion`.\n\nYou need to implement a `ground` method, which acts as the default resolver for the designator. For Object and Location Designators, you should also implement an `__iter__` method to iterate over possible solutions. The sub-class you create can include parameters specific to your designator type, and for Action and Motion Designators, you should define a `perform` method that dictates the behavior of the designator when executed."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the different types of Action Designators available in PyCRAM and how they are used?"}, {"role": "assistant", "content": "Action Designators in PyCRAM are high-level descriptions of actions that a robot should execute. These designators are created from an Action Designator Description, which describes the type of action and the parameters for the action, often provided as a list of possible values. When resolved, the description returns a specific, performable Action Designator. Would you like to start with an example of a simple Navigate Action?"}, {"role": "user", "content": "Yes, please show me an example of a Navigate Action."}, {"role": "assistant", "content": "To start with a Navigate Action, you'll first need to create a BulletWorld with a robot. Here’s how you can do it:\n\n```python\nfrom pycram.worlds.bullet_world import BulletWorld\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType, WorldMode\n\nworld = BulletWorld(WorldMode.GUI)\npr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\n```\n\nNext, you can create a description for navigation by specifying a list of possible poses and then resolve it to get a performable designator:\n\n```python\nfrom pycram.designators.action_designator import NavigateAction\nfrom pycram.datastructures.pose import Pose\n\npose = Pose([1, 0, 0], [0, 0, 0, 1])\n\nnavigate_description = NavigateAction(target_locations=[pose])\nnavigate_designator = navigate_description.resolve()\n```\n\nThis will create an Action Designator that can be performed. The designator will move the robot to the pose selected from the list:\n\n```python\nfrom pycram.process_module import simulated_robot\n\nwith simulated_robot:\n    navigate_designator.perform()\n```\n\nYou can perform this designator within a simulation environment like `simulated_robot` or on a real robot using `real_robot`. Would you like to see another example, such as moving the robot’s torso or setting the gripper state?"}, {"role": "user", "content": "Yes, show me how to move the robot's torso."}, {"role": "assistant", "content": "To move the robot’s torso, you’ll use the `MoveTorsoAction` designator. Here’s how you can create a description and resolve it to a performable designator:\n\n```python\nfrom pycram.designators.action_designator import MoveTorsoAction\nfrom pycram.process_module import simulated_robot\n\ntorso_pose = 0.2\ntorso_desig = MoveTorsoAction([torso_pose]).resolve()\n\nwith simulated_robot:\n    torso_desig.perform()\n```\n\nThis example sets the torso joint to the specified value (`0.2`). You perform the designator within the `simulated_robot` environment to see the effect in the simulation. Would you like to explore how to control the robot’s gripper or perform other actions?"}, {"role": "user", "content": "Yes, show me how to control the gripper."}, {"role": "assistant", "content": "To control the robot’s gripper, you can use the `SetGripperAction` designator. Here’s how you can open or close the gripper:\n\n```python\nfrom pycram.designators.action_designator import SetGripperAction\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.enums import GripperState, Arms\n\ngripper = Arms.RIGHT\nmotion = GripperState.OPEN\n\nwith simulated_robot:\n    SetGripperAction(grippers=[gripper], motions=[motion]).resolve().perform()\n```\n\nThis code snippet will open the right gripper of the robot. Similarly, you can close the gripper by setting `GripperState.CLOSE`. Would you like to learn about other actions, such as parking the robot’s arms or performing a pick-and-place operation?"}, {"role": "user", "content": "Show me how to park the robot's arms."}, {"role": "assistant", "content": "To park the robot's arms, you can use the `ParkArmsAction` designator. Here's how you can move one or both arms into the default parking position:\n\n```python\nfrom pycram.designators.action_designator import ParkArmsAction\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.enums import Arms\n\nwith simulated_robot:\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n```\n\nThis example parks both arms of the robot. You can also specify a single arm, such as `Arms.LEFT` or `Arms.RIGHT`, if you want to park only one arm. Would you like to see how to perform more complex tasks like picking up and placing objects?"}, {"role": "user", "content": "Yes, show me how to pick up and place an object."}, {"role": "assistant", "content": "To pick up and place an object, you'll use the `PickUpAction` and `PlaceAction` designators. These actions typically involve object designators to specify the object you want to interact with. Here's how you can set up an environment and perform these actions:\n\nFirst, create a kitchen environment and an object (e.g., a milk carton) to interact with:\n\n```python\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.3, 1, 0.9]))\n\nworld.reset_world()\n```\n\nNext, you can use the following code to pick up and place the milk carton:\n\n```python\nfrom pycram.designators.action_designator import PickUpAction, PlaceAction, ParkArmsAction, MoveTorsoAction, NavigateAction\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.enums import Arms, Grasp\nfrom pycram.datastructures.pose import Pose\n\nmilk_desig = BelieveObject(names=[\"milk\"])\narm = Arms.RIGHT\n\nwith simulated_robot:\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n    MoveTorsoAction([0.3]).resolve().perform()\n    NavigateAction([Pose([0.78, 1, 0.0], [0.0, 0.0, 0.014701099828940344, 0.9998919329926708])]).resolve().perform()\n    PickUpAction(object_designator_description=milk_desig, arms=[arm], grasps=[Grasp.RIGHT]).resolve().perform()\n    NavigateAction([Pose([-1.90, 0.78, 0.0], [0.0, 0.0, 0.16439898301071468, 0.9863939245479175])]).resolve().perform()\n    PlaceAction(object_designator_description=milk_desig, target_locations=[Pose([-1.20, 1.0192, 0.9624], [0, 0, 0, 1])], arms=[arm]).resolve().perform()\n```\n\nThis sequence parks the robot's arms, moves the torso, navigates to the milk carton, picks it up, navigates to the target location, and then places the milk carton down. Would you like to explore more actions, such as looking at objects or detecting objects in the environment?"}, {"role": "user", "content": "Yes, show me how to make the robot look at an object."}, {"role": "assistant", "content": "To make the robot look at a specific object or point, you can use the `LookAtAction` designator. Here’s an example of how to do it:\n\n```python\nfrom pycram.designators.action_designator import LookAtAction\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.pose import Pose\n\ntarget_location = Pose([1, 0, 0.5], [0, 0, 0, 1])\n\nwith simulated_robot:\n    LookAtAction(targets=[target_location]).resolve().perform()\n```\n\nIn this example, the robot will look at the point specified by `target_location`. This is useful for tasks like object detection, where the robot needs to focus on a specific area. Would you like to proceed with an example of detecting objects in the robot’s field of vision?"}, {"role": "user", "content": "Yes, show me how to detect objects."}, {"role": "assistant", "content": "To detect objects within the robot’s field of vision (FOV), you can use the `DetectAction` designator. Here’s how you can do it, continuing from the previous examples where we had a milk carton in the environment:\n\n```python\nfrom pycram.designators.action_designator import DetectAction, LookAtAction, ParkArmsAction, NavigateAction\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.pose import Pose\n\nmilk_desig = BelieveObject(names=[\"milk\"])\n\nwith simulated_robot:\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n    NavigateAction([Pose([0, 1, 0], [0, 0, 0, 1])]).resolve().perform()\n    LookAtAction(targets=[milk_desig.resolve().pose]).resolve().perform()\n    obj_desig = DetectAction(milk_desig).resolve().perform()\n\n    print(obj_desig)\n```\n\nThis code makes the robot park its arms, navigate to a location, look at the milk carton, and then detect it. The `DetectAction` designator returns a resolved instance of an `ObjectDesignatorDescription`, which can be used in further tasks. Would you like to explore more complex actions, such as transporting objects or opening and closing drawers?"}, {"role": "user", "content": "Show me how to transport an object."}, {"role": "assistant", "content": "Transporting an object involves moving it from its current position to another target position. This is similar to the pick-and-place operation but as a continuous action. Here’s how you can transport an object, assuming you’ve already spawned a milk carton:\n\n```python\nfrom pycram.designators.action_designator import TransportAction, MoveTorsoAction\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.pose import Pose\nfrom pycram.datastructures.enums import Arms\n\nmilk_desig = BelieveObject(names=[\"milk\"])\n\ndescription = TransportAction(milk_desig, [Arms.LEFT], [Pose([-1.35, 0.78, 0.95], [0.0, 0.0, 0.16439898301071468, 0.9863939245479175])])\n\nwith simulated_robot:\n    MoveTorsoAction([0.2]).resolve().perform()\n    description.resolve().perform()\n```\n\nThis example makes the robot pick up the milk carton and transport it to the specified target location. The `TransportAction` designator combines navigation and object manipulation into a single action. Would you like to see examples of more specialized actions like opening or closing drawers?"}, {"role": "user", "content": "Yes, show me how to open a drawer."}, {"role": "assistant", "content": "To open a drawer, you can use the `OpenAction` designator along with an `ObjectPart` designator to specify the handle of the drawer. Here’s how you can do it:\n\nFirst, make sure you’re working in the apartment environment since this action is specific to it. If you’re not already in the apartment environment, remove the kitchen and load the apartment:\n\n```python\nkitchen.remove()\napartment = Object(\"apartment\", ObjectType.ENVIRONMENT, \"apartment.urdf\")\n```\n\nThen, use the following code to open the drawer:\n\n```python\nfrom pycram.designators.action_designator import OpenAction, ParkArmsAction, NavigateAction, MoveTorsoAction\nfrom pycram.designators.object_designator import BelieveObject, ObjectPart\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.pose import Pose\n\napartment_desig = BelieveObject(names=[\"apartment\"]).resolve()\nhandle_desig = ObjectPart(names=[\"handle_cab10_t\"], part_of=apartment_desig)\n\nwith simulated_robot:\n    MoveTorsoAction([0.25]).resolve().perform()\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n    NavigateAction([Pose([1.7474915981292725, 2.6873629093170166, 0.0], [-0.0, 0.0, 0.5253598267689507, -0.850880163370435])]).resolve().perform()\n    OpenAction(handle_desig, [Arms.RIGHT]).resolve().perform()\n```\n\nThis sequence parks the robot’s arms, moves the torso, navigates to the drawer, and then opens it using the specified handle. Would you like to see how to close the drawer or perform other actions in the apartment environment?"}, {"role": "user", "content": "Show me how to close a drawer."}, {"role": "assistant", "content": "To close a drawer, you can use the `CloseAction` designator, similar to how you opened it. Here’s how you can do it, assuming the drawer is already open:\n\nIf you haven't already, load the apartment environment and open the drawer:\n\n```python\nkitchen.remove()\napartment = Object(\"apartment\", ObjectType.ENVIRONMENT, \"apartment.urdf\")\napartment.set_joint_state(\"cabinet10_drawer_top_joint\", 0.4)\n```\n\nThen, use the following code to close the drawer:\n\n```python\nfrom pycram.designators.action_designator import CloseAction, ParkArmsAction, NavigateAction, MoveTorsoAction\nfrom pycram.designators.object_designator import BelieveObject, ObjectPart\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.pose import Pose\n\napartment_desig = BelieveObject(names=[\"apartment\"]).resolve()\nhandle_desig = ObjectPart(names=[\"handle_cab10_t\"], part_of=apartment_desig)\n\nwith simulated_robot:\n    MoveTorsoAction([0.25]).resolve().perform()\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n    NavigateAction([Pose([1.7474915981292725, 2.8073629093170166, 0.0], [-0.0, 0.0, 0.5253598267689507, -0.850880163370435])]).resolve().perform()\n    CloseAction(handle_desig, [Arms.RIGHT]).resolve().perform()\n```\n\nThis sequence will navigate the robot to the drawer, grasp the handle, and close the drawer. Let me know if you’d like to explore more actions or have any other questions!"}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain how to use Location Designators in PyCRAM?"}, {"role": "assistant", "content": "Location Designators in PyCRAM are used to semantically describe locations in the world. They can describe locations for visibility, reachability, occupancy, and URDF links, such as a table. Location designators create Costmaps, which are 2D distributions that identify locations fitting specified criteria. Would you like to start with an example of creating a simple location designator that ensures the robot is placed without colliding with the environment?"}, {"role": "user", "content": "Yes, please show me how to create a simple location designator."}, {"role": "assistant", "content": "To create a simple location designator, you first need a BulletWorld, as costmaps are generated based on the current state of the BulletWorld. Here’s how you can set it up:\n\n```python\nfrom pycram.worlds.bullet_world import BulletWorld\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType, WorldMode\nfrom pycram.datastructures.pose import Pose\n\nworld = BulletWorld()\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\n```\n\nNext, create a location designator description using `CostmapLocation`. This will describe the location based on a target, which in this case is simply the kitchen's pose:\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\n\ntarget = kitchen.get_pose()\nlocation_description = CostmapLocation(target)\n\npose = location_description.resolve()\n\nprint(pose)\n```\n\nThis will resolve to a 6D pose where the robot can be placed without colliding with the environment. Would you like to see an example of finding a location from where the robot can reach a specific object?"}, {"role": "user", "content": "Yes, show me how to find a location where the robot can reach an object."}, {"role": "assistant", "content": "To find a location from where the robot can reach an object, you can use the `CostmapLocation` designator, similar to the previous example. This time, you’ll also need to provide the robot as an additional argument. Here's how you can do it:\n\nFirst, let's set up the PR2 robot and an object, such as a milk carton, that the robot should reach:\n\n```python\npr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\npr2.set_joint_state(\"torso_lift_joint\", 0.2)\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.3, 1, 0.9]))\n```\n\nNext, create the location designator:\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\n\ntarget = BelieveObject(names=[\"milk\"]).resolve()\nrobot_desig = BelieveObject(names=[\"pr2\"]).resolve()\n\nlocation_description = CostmapLocation(target=target, reachable_for=robot_desig)\n\nprint(location_description.resolve())\n```\n\nThis code will return a pose near the countertop where the robot can be placed without colliding with the environment, and it will also specify which arms of the robot can reach the given object. Would you like to see how to find a location from where the robot can see a specific object?"}, {"role": "user", "content": "Yes, show me how to find a visible location."}, {"role": "assistant", "content": "To find a location from where the robot can see a specific object, you can use the `CostmapLocation` designator with the `visible_for` parameter. Here's how you can do it, continuing with the PR2 robot and the milk carton as the target object:\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\n\ntarget = BelieveObject(names=[\"milk\"]).resolve()\nrobot_desig = BelieveObject(names=[\"pr2\"]).resolve()\n\nlocation_description = CostmapLocation(target=target, visible_for=robot_desig)\n\nprint(location_description.resolve())\n```\n\nThis will find and return a pose from which the robot can see the specified object. Would you like to explore how to create a semantic location designator for a specific area, like a table surface?"}, {"role": "user", "content": "Yes, show me how to create a semantic location designator."}, {"role": "assistant", "content": "A semantic location designator allows you to find poses on specific parts of an object, like a table surface. To do this, you need to provide the object and the URDF link representing the entity. Here’s how you can create a semantic location designator for placing an object on a kitchen island:\n\nIf you haven't already, set up the kitchen and milk objects:\n\n```python\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\")\n```\n\nNow, create the semantic location designator:\n\n```python\nfrom pycram.designators.location_designator import SemanticCostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\n\nkitchen_desig = BelieveObject(names=[\"kitchen\"]).resolve()\nmilk_desig = BelieveObject(names=[\"milk\"]).resolve()\n\nlocation_description = SemanticCostmapLocation(urdf_link_name=\"kitchen_island_surface\", part_of=kitchen_desig, for_object=milk_desig)\n\nprint(location_description.resolve())\n```\n\nThis will find and return a valid pose on the kitchen island where the milk can be placed. Would you like to learn how to use location designators as generators or how to access specific locations for actions like opening a drawer?"}, {"role": "user", "content": "Yes, show me how to use location designators as generators."}, {"role": "assistant", "content": "Location designators can be used as generators to iterate over all possible valid poses for a given description. This can be useful if the first pose doesn't work for some reason. Here's how you can use a location designator for visibility as a generator:\n\nFirst, if you haven't already, spawn the milk object:\n\n```python\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\")\n```\n\nThen, use the location designator to generate possible poses:\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\n\ntarget = BelieveObject(names=[\"milk\"]).resolve()\nrobot_desig = BelieveObject(names=[\"pr2\"]).resolve()\n\nlocation_description = CostmapLocation(target=target, visible_for=robot_desig)\n\nfor pose in location_description:\n    print(pose.pose)\n```\n\nThis will print out all possible valid poses from which the robot can see the milk. Would you like to learn how to access specific locations for actions like opening a drawer, or how to use a Giskard-based location designator for full-body IK?"}, {"role": "user", "content": "Show me how to access locations for actions like opening a drawer."}, {"role": "assistant", "content": "To access specific locations for actions like opening a drawer, you can use a specialized location designator. This designator will describe a location from which the robot can open the drawer, identified by an `ObjectPart` designator. Here's how you can set it up:\n\nFirst, if you haven’t already, remove the kitchen environment and load the apartment environment since this location designator works in the apartment environment:\n\n```python\nkitchen.remove()\n```\n\n```python\napartment = Object(\"apartment\", ObjectType.ENVIRONMENT, \"apartment.urdf\")\n```\n\nNext, spawn the PR2 robot if it isn't already spawned, and then create the location designator:\n\n```python\npr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\npr2.set_joint_state(\"torso_lift_joint\", 0.25)\n```\n\n```python\nfrom pycram.designators.object_designator import BelieveObject, ObjectPart\nfrom pycram.designators.location_designator import AccessingLocation\n\napartment_desig = BelieveObject(names=[\"apartment\"])\nhandle_desig = ObjectPart(names=[\"handle_cab10_t\"], part_of=apartment_desig.resolve())\nrobot_desig = BelieveObject(names=[\"pr2\"])\n\naccess_location = AccessingLocation(handle_desig.resolve(), robot_desig.resolve()).resolve()\nprint(access_location.pose)\n```\n\nThis will find and return the best location for the robot to stand in order to open the drawer. Would you like to explore using Giskard for full-body IK with location designators?"}, {"role": "user", "content": "Yes, show me how to use Giskard for full-body IK with location designators."}, {"role": "assistant", "content": "Giskard is used for full-body inverse kinematics (IK) with certain robots like the HSR or Stretch2. The `GiskardLocation` designator helps find a pose for the robot to reach a target position using Giskard's IK solver. Here's how you can use it:\n\nFirst, make sure Giskard is running, as this designator relies on it.\n\n```python\nfrom pycram.designators.specialized_designators.location.giskard_location import GiskardLocation\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.datastructures.pose import Pose\n\nrobot_desig = BelieveObject(names=[\"pr2\"]).resolve()\n\nloc = GiskardLocation(target=Pose([1, 1, 1]), reachable_for=robot_desig).resolve()\nprint(loc.pose)\n```\n\nThis will find a pose for the robot that allows it to reach the specified target position using full-body IK. Once you're finished, you can close the world with the following command:\n\n```python\nworld.exit()\n```\n\nWould you like to explore anything else related to location designators or any other PyCRAM concepts?"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know everything about the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain what components are available in the 'pycram.datastructures.enums' module?"}, {"role": "assistant", "content": "The 'pycram.datastructures.enums' module contains several enums that are used throughout PyCRAM. These enums are: ExecutionType, Arms, TaskStatus, JointType, Grasp, ObjectType, State, Shape, WorldMode, AxisIdentifier, GripperState, GripperType, PerceptionTechniques, and ImageEnum. Would you like to know more about a specific enum?"}, {"role": "user", "content": "What is the 'ExecutionType' enum?"}, {"role": "assistant", "content": "The 'ExecutionType' enum in PyCRAM is used to define different types of execution processes in the process module. It has the following attributes: REAL, SIMULATED, and SEMI_REAL."}, {"role": "user", "content": "What about the 'Arms' enum?"}, {"role": "assistant", "content": "The 'Arms' enum is used to specify which arm or arms of the robot are being referred to. It includes the following attributes: LEFT, RIGHT, and BOTH."}, {"role": "user", "content": "Can you explain the 'TaskStatus' enum?"}, {"role": "assistant", "content": "The 'TaskStatus' enum provides readable descriptions of a task's status. Its attributes are: CREATED (0), RUNNING (1), SUCCEEDED (2), and FAILED (3)."}, {"role": "user", "content": "What is the purpose of the 'JointType' enum?"}, {"role": "assistant", "content": "The 'JointType' enum defines different types of joints in a robot. The attributes include: REVOLUTE (0), PRISMATIC (1), SPHERICAL (2), PLANAR (3), FIXED (4), UNKNOWN (5), CONTINUOUS (6), and FLOATING (7)."}, {"role": "user", "content": "Tell me about the 'Grasp' enum."}, {"role": "assistant", "content": "The 'Grasp' enum is used to define different grasp orientations. It has the following attributes: FRONT (0), LEFT (1), RIGHT (2), and TOP (3)."}, {"role": "user", "content": "What does the 'ObjectType' enum define?"}, {"role": "assistant", "content": "The 'ObjectType' enum helps in identifying different types of objects in PyCRAM. Its attributes include: METALMUG, PRINGLES, MILK, SPOON, BOWL, BREAKFAST_CEREAL, JEROEN_CUP, ROBOT, ENVIRONMENT, GENERIC_OBJECT, and HUMAN."}, {"role": "user", "content": "What is the 'State' enum?"}, {"role": "assistant", "content": "The 'State' enum describes the result of a language expression or task. The attributes are: SUCCEEDED (1), FAILED (0), RUNNING (2), and INTERRUPTED (3)."}, {"role": "user", "content": "What can you tell me about the 'Shape' enum?"}, {"role": "assistant", "content": "The 'Shape' enum defines the visual shapes of objects in PyCRAM. Its attributes are: SPHERE (2), BOX (3), CYLINDER (4), MESH (5), PLANE (6), and CAPSULE (7)."}, {"role": "user", "content": "What is the 'WorldMode' enum used for?"}, {"role": "assistant", "content": "The 'WorldMode' enum specifies the different modes in which the world can operate in PyCRAM. The available modes are: GUI ('GUI') and DIRECT ('DIRECT')."}, {"role": "user", "content": "Explain the 'AxisIdentifier' enum."}, {"role": "assistant", "content": "The 'AxisIdentifier' enum is used to translate axis names into vectors. The attributes are: X = (1, 0, 0), Y = (0, 1, 0), and Z = (0, 0, 1)."}, {"role": "user", "content": "What about the 'GripperState' enum?"}, {"role": "assistant", "content": "The 'GripperState' enum defines the different motions that a gripper can perform. The attributes are: OPEN and CLOSE."}, {"role": "user", "content": "Can you explain the 'GripperType' enum?"}, {"role": "assistant", "content": "The 'GripperType' enum categorizes the different types of grippers used in robotics. Its attributes include: PARALLEL, SUCTION, FINGER, HYDRAULIC, PNEUMATIC, and CUSTOM."}, {"role": "user", "content": "Tell me about the 'PerceptionTechniques' enum."}, {"role": "assistant", "content": "The 'PerceptionTechniques' enum lists the techniques that can be used in perception tasks. The attributes are: ALL, HUMAN, and TYPES."}, {"role": "user", "content": "Finally, what is the 'ImageEnum'?"}, {"role": "assistant", "content": "The 'ImageEnum' is used to switch views on the HSRB display. The available attributes include: HI (0), TALK (1), DISH (2), DONE (3), DROP (4), HANDOVER (5), ORDER (6), PICKING (7), PLACING (8), REPEAT (9), SEARCH (10), WAVING (11), FOLLOWING (12), DRIVINGBACK (13), PUSHBUTTONS (14), FOLLOWSTOP (15), JREPEAT (16), SOFA (17), INSPECT (18), CHAIR (37)."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know everything about the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain what components are available in the 'pycram.process_modules' package?"}, {"role": "assistant", "content": "The 'pycram.process_modules' package contains several submodules and classes that manage process modules for different robots in PyCRAM. The submodules include boxy_process_modules, default_process_modules, donbot_process_modules, hsrb_process_modules, pr2_process_modules, and stretch_process_modules. The key classes are Pr2Manager, BoxyManager, DonbotManager, HSRBManager, DefaultManager, and StretchManager. Would you like to know more about a specific class or submodule?"}, {"role": "user", "content": "Tell me about the 'Pr2Manager' class."}, {"role": "assistant", "content": "The 'Pr2Manager' class is a base class for managing process modules for the PR2 robot in PyCRAM. It inherits from 'pycram.process_module.ProcessModuleManager' and includes various locks and methods for controlling different actions, such as navigating, looking, detecting, moving the TCP (Tool Center Point), moving arm joints, detecting world state, moving joints, moving the gripper, opening and closing drawers."}, {"role": "user", "content": "What about the 'BoxyManager' class?"}, {"role": "assistant", "content": "The 'BoxyManager' class, similar to 'Pr2Manager', is a base class for managing process modules for the Boxy robot. It also inherits from 'pycram.process_module.ProcessModuleManager' and provides methods for navigating, looking, detecting, moving the TCP, moving arm joints, detecting world state, moving the gripper, opening, and closing drawers."}, {"role": "user", "content": "Can you explain the 'DonbotManager' class?"}, {"role": "assistant", "content": "The 'DonbotManager' class is designed for managing process modules specific to the Donbot robot. In addition to the standard methods like navigating, looking, and detecting, it includes specialized methods for placing objects, picking up objects, and other robot-specific actions."}, {"role": "user", "content": "What does the 'HSRBManager' class do?"}, {"role": "assistant", "content": "The 'HSRBManager' class manages process modules for the HSRB robot. It includes standard methods for navigating, looking, detecting, moving TCP, moving arm joints, moving joints, and gripper actions. Additionally, it has a 'talk' method for enabling the robot to communicate or express actions."}, {"role": "user", "content": "Tell me about the 'DefaultManager' class."}, {"role": "assistant", "content": "The 'DefaultManager' class is a general-purpose manager for process modules. It includes all the basic methods required for controlling a robot, such as navigating, looking, detecting, moving TCP, moving arm joints, detecting world state, moving joints, moving the gripper, opening, and closing drawers."}, {"role": "user", "content": "Finally, what is the 'StretchManager' class?"}, {"role": "assistant", "content": "The 'StretchManager' class is responsible for managing process modules for the Stretch robot. Like the other managers, it includes methods for navigating, looking, detecting, moving TCP, moving arm joints, detecting world state, moving joints, and gripper operations, as well as opening and closing actions."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know everything about the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the 'pycram.worlds.bullet_world' module and its components?"}, {"role": "assistant", "content": "The 'pycram.worlds.bullet_world' module provides the main interface to the Bullet Physics Engine for PyCRAM. It includes classes and methods for simulating and manipulating a BulletWorld. Key components include 'Link', 'RootLink', 'Joint' (attributes), and 'BulletWorld', 'Gui' (classes). Would you like to know more about any specific component?"}, {"role": "user", "content": "Tell me more about the 'BulletWorld' class."}, {"role": "assistant", "content": "The 'BulletWorld' class represents a simulation environment using the Bullet Physics Engine. It allows you to spawn objects, simulate physics, and manipulate the world. Key methods include 'load_object_and_get_id', 'remove_object_from_simulator', 'add_constraint', 'get_joint_position', 'get_link_pose', 'perform_collision_detection', 'reset_joint_position', 'step', 'set_gravity', and many others. These methods provide comprehensive control over the physics simulation. The class also has attributes like 'extension' and 'vis_axis'. Would you like to explore any specific method in detail?"}, {"role": "user", "content": "Can you explain the 'load_object_and_get_id' method?"}, {"role": "assistant", "content": "The 'load_object_and_get_id' method loads a description file, such as a URDF, at a specified pose in the simulation and returns the ID of the loaded object. This is useful for adding objects to your simulation environment dynamically. You can specify the path to the description file and the desired pose for the object."}, {"role": "user", "content": "What does the 'perform_collision_detection' method do?"}, {"role": "assistant", "content": "The 'perform_collision_detection' method checks for collisions between all objects in the BulletWorld and updates the contact points accordingly. It's essential for ensuring that objects in the simulation interact physically as expected."}, {"role": "user", "content": "Tell me about the 'Gui' class."}, {"role": "assistant", "content": "The 'Gui' class in 'pycram.worlds.bullet_world' is designed for internal use. It creates a new thread for the physics simulation, which remains active until closed by the 'World.exit' method. It also handles camera controls within the simulation environment, checking for mouse and keyboard inputs. The 'Gui' class runs in an endless loop, with brief suspensions to manage simulation updates."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code"}, {"role": "user", "content": "Can you explain how you can let the robot pick something up?"}, {"role": "assistant", "content": "You can use the PickUpAction Action Designator. 'name': 'PickUpAction', 'description': 'Action designator for picking up an object.', 'props': ('object_designator_description','arms','grasps'),'example': 'PickUpAction(object_designator_description=milk_desig, arms=[Arms.RIGHT], grasps=[Grasp.FRONT]).resolve().perform()'"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do you let the robot navigate to a specific location using PyCRAM?"}, {"role": "assistant", "content": "You can use the `NavigateAction` action designator. Example:\n```python\nnavigate_description = NavigateAction(target_locations=[Pose([1, 0, 0], [0, 0, 0, 1])])\nnavigate_designator = navigate_description.resolve()\nnavigate_designator.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What is the purpose of a `MoveTorsoAction` in PyCRAM?"}, {"role": "assistant", "content": "The `MoveTorsoAction` is used to move the robot's torso up or down. Example:\n```python\ntorso_desig = MoveTorsoAction([0.2]).resolve()\ntorso_desig.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can you open or close the gripper using PyCRAM?"}, {"role": "assistant", "content": "Use the `SetGripperAction` action designator to control the gripper's state. Example:\n```python\nSetGripperAction(grippers=[Arms.RIGHT], motions=[GripperState.OPEN]).resolve().perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do you park the robot's arms in the default position?"}, {"role": "assistant", "content": "Use the `ParkArmsAction` action designator. Example:\n```python\nParkArmsAction([Arms.BOTH]).resolve().perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can the robot pick up an object in PyCRAM?"}, {"role": "assistant", "content": "Use the `PickUpAction` action designator along with an object designator. Example:\n```python\nPickUpAction(object_designator_description=milk_desig, arms=[Arms.RIGHT], grasps=[Grasp.RIGHT]).resolve().perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do you use a location designator to find a pose for the robot?"}, {"role": "assistant", "content": "Use the `CostmapLocation` designator to describe and resolve a location. Example:\n```python\nlocation_description = CostmapLocation(target=target)\npose = location_description.resolve()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What is a `SemanticCostmapLocation` in PyCRAM?"}, {"role": "assistant", "content": "It is used to find poses on semantic entities like a table. Example:\n```python\nlocation_description = SemanticCostmapLocation(urdf_link_name=\"kitchen_island_surface\", part_of=kitchen_desig, for_object=milk_desig)\npose = location_description.resolve()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can you detect an object using PyCRAM?"}, {"role": "assistant", "content": "Use the `DetectAction` action designator after looking at the object. Example:\n```python\nLookAtAction(targets=[milk_desig.resolve().pose]).resolve().perform()\nobj_desig = DetectAction(milk_desig).resolve().perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do you create an object designator for an object in the BulletWorld?"}, {"role": "assistant", "content": "Use the `BelieveObject` designator to describe objects in the BulletWorld. Example:\n```python\nobject_description = BelieveObject(names=[\"milk\"])\nresolved_object = object_description.resolve()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I merge two costmaps in PyCRAM?"}, {"role": "assistant", "content": "You can merge two costmaps using the `merge` method on a `Costmap` object. Example:\n```python\nmerged_costmap = costmap1.merge(costmap2)\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What is the purpose of the `VisualShape` class in PyCRAM?"}, {"role": "assistant", "content": "The `VisualShape` class is a base class for creating visual representations of objects. It provides methods for setting color and shape data."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I create a deep copy of a Pose object in PyCRAM?"}, {"role": "assistant", "content": "You can create a deep copy of a `Pose` object using its `copy` method. Example:\n```python\npose_copy = original_pose.copy()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I normalize a quaternion in PyCRAM?"}, {"role": "assistant", "content": "You can normalize a quaternion using the `get_normalized_quaternion` function. Example:\n```python\nnormalized_quat = get_normalized_quaternion(quaternion)\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What is the `AxisAlignedBoundingBox` class used for in PyCRAM?"}, {"role": "assistant", "content": "The `AxisAlignedBoundingBox` class is used to represent the minimum and maximum bounds of an object in 3D space. It provides methods to get and set these bounds."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I perform a ray test in PyCRAM?"}, {"role": "assistant", "content": "You can perform a ray test using the `ray_test` method. Example:\n```python\nobject_id = world.ray_test(from_position=[0, 0, 1], to_position=[1, 1, 1])\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I attach one object to another in PyCRAM?"}, {"role": "assistant", "content": "You can attach one object to another using the `attach` method. Example:\n```python\nparent_object.attach(child_object)\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I create a fixed constraint between two links in PyCRAM?"}, {"role": "assistant", "content": "You can create a fixed constraint between two links using the `add_fixed_constraint` method. Example:\n```python\nconstraint_id = world.add_fixed_constraint(parent_link, child_link, transform)\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What is the `LookAtAction` designator used for in PyCRAM?"}, {"role": "assistant", "content": "The `LookAtAction` designator is used to make the robot look at a specific point in the environment. Example:\n```python\nLookAtAction(targets=[Pose([1, 0, 0.5], [0, 0, 0, 1])]).resolve().perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I set the color of an object in PyCRAM?"}, {"role": "assistant", "content": "You can set the color of an object using the `set_color` method. Example:\n```python\nobject.set_color(Color([1, 0, 0, 1]))  # Set to red\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I write a plan to move a robot to a specific location?"}, {"role": "assistant", "content": "To move a robot to a specific location, you can use the `NavigateAction` designator. Example:\n```python\npose = Pose([1, 0, 0], [0, 0, 0, 1])\nnavigate_action = NavigateAction(target_locations=[pose]).resolve()\nnavigate_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I create a plan to pick up an object and place it at a different location?"}, {"role": "assistant", "content": "You can create a plan using `PickUpAction` and `PlaceAction` designators. Example:\n```python\npick_action = PickUpAction(object_designator_description=milk_desig, arms=[Arms.RIGHT]).resolve()\nplace_action = PlaceAction(object_designator_description=milk_desig, target_locations=[target_pose], arms=[Arms.RIGHT]).resolve()\n\nwith simulated_robot:\n    pick_action.perform()\n    place_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I make the robot perform a sequence of actions in PyCRAM?"}, {"role": "assistant", "content": "You can sequence actions by resolving and performing designators in order. Example:\n```python\nmove_to_pose = NavigateAction(target_locations=[pose]).resolve()\nset_gripper = SetGripperAction(grippers=[Arms.RIGHT], motions=[GripperState.OPEN]).resolve()\nmove_to_pose.perform()\nset_gripper.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I create a plan to open a drawer?"}, {"role": "assistant", "content": "To open a drawer, use the `OpenAction` designator. Example:\n```python\ndrawer_handle = ObjectPart(names=['drawer_handle'], part_of=drawer_object).resolve()\nopen_action = OpenAction(handle_designator=drawer_handle, arms=[Arms.RIGHT]).resolve()\nopen_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What steps do I need to code a plan to detect an object in the environment?"}, {"role": "assistant", "content": "To detect an object, use the `DetectAction` designator along with `LookAtAction`. Example:\n```python\nlook_action = LookAtAction(targets=[object_pose]).resolve()\ndetect_action = DetectAction(object_designator=object_desig).resolve()\nwith simulated_robot:\n    look_action.perform()\n    detected_object = detect_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I create a plan to move the robot's torso?"}, {"role": "assistant", "content": "To move the robot's torso, use the `MoveTorsoAction` designator. Example:\n```python\ntorso_action = MoveTorsoAction([0.3]).resolve()\ntorso_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I plan a motion for the robot's arm?"}, {"role": "assistant", "content": "To plan a motion for the robot's arm, use the `MoveArmAction` designator. Example:\n```python\nmove_arm = MoveArmAction(arm=Arms.RIGHT, target_pose=pose).resolve()\nmove_arm.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I make the robot close its gripper?"}, {"role": "assistant", "content": "You can close the robot's gripper using the `SetGripperAction` designator. Example:\n```python\nclose_gripper = SetGripperAction(grippers=[Arms.RIGHT], motions=[GripperState.CLOSED]).resolve()\nclose_gripper.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I create a plan to park the robot's arms?"}, {"role": "assistant", "content": "To park the robot's arms, use the `ParkArmsAction` designator. Example:\n```python\npark_arms = ParkArmsAction(arms=[Arms.BOTH]).resolve()\npark_arms.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I write a plan to transport an object from one location to another?"}, {"role": "assistant", "content": "To transport an object, use the `TransportAction` designator. Example:\n```python\ntransport_action = TransportAction(object_desig, [Arms.LEFT], [target_pose]).resolve()\ntransport_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I write a plan to let the robot look at an object?"}, {"role": "assistant", "content": "You can use the `LookAtAction` designator to let the robot look at an object. Example:\n```python\nlook_at_action = LookAtAction(targets=[object_pose]).resolve()\nlook_at_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I create a plan to reset the robot's world state?"}, {"role": "assistant", "content": "To reset the robot's world state, you can use the `reset_world` method from the BulletWorld class. Example:\n```python\nworld.reset_world()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I write a plan for the robot to open a gripper, pick up an object, and then close the gripper?"}, {"role": "assistant", "content": "You can chain multiple actions together using the `SetGripperAction` and `PickUpAction` designators. Example:\n```python\nopen_gripper = SetGripperAction(grippers=[Arms.RIGHT], motions=[GripperState.OPEN]).resolve()\npick_up = PickUpAction(object_designator_description=milk_desig, arms=[Arms.RIGHT]).resolve()\nclose_gripper = SetGripperAction(grippers=[Arms.RIGHT], motions=[GripperState.CLOSED]).resolve()\nopen_gripper.perform()\npick_up.perform()\nclose_gripper.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I code a plan to make the robot navigate to a location and then look at an object?"}, {"role": "assistant", "content": "You can combine `NavigateAction` and `LookAtAction` to create this plan. Example:\n```python\nnavigate_action = NavigateAction(target_locations=[target_pose]).resolve()\nlook_at_action = LookAtAction(targets=[object_pose]).resolve()\nnavigate_action.perform()\nlook_at_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I make the robot open and close a drawer in sequence?"}, {"role": "assistant", "content": "You can use the `OpenAction` and `CloseAction` designators. Example:\n```python\ndrawer_handle = ObjectPart(names=['drawer_handle'], part_of=drawer_object).resolve()\nopen_action = OpenAction(handle_designator=drawer_handle, arms=[Arms.RIGHT]).resolve()\nclose_action = CloseAction(handle_designator=drawer_handle, arms=[Arms.RIGHT]).resolve()\nopen_action.perform()\nclose_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I create a plan to make the robot place an object at a specified location?"}, {"role": "assistant", "content": "To place an object at a specified location, use the `PlaceAction` designator. Example:\n```python\nplace_action = PlaceAction(object_designator_description=milk_desig, target_locations=[target_pose], arms=[Arms.RIGHT]).resolve()\nplace_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I code a plan for the robot to detect multiple objects in its environment?"}, {"role": "assistant", "content": "You can iterate over a list of objects using the `DetectAction` designator for each. Example:\n```python\nfor obj in objects_to_detect:\n    detect_action = DetectAction(object_designator=obj).resolve()\n    detected_object = detect_action.perform()\n    print(detected_object)\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I create a plan for the robot to pick up an object, navigate to a location, and place it there?"}, {"role": "assistant", "content": "You can combine `PickUpAction`, `NavigateAction`, and `PlaceAction` designators. Example:\n```python\npick_up = PickUpAction(object_designator_description=milk_desig, arms=[Arms.RIGHT]).resolve()\nnavigate_action = NavigateAction(target_locations=[target_pose]).resolve()\nplace_action = PlaceAction(object_designator_description=milk_desig, target_locations=[target_pose], arms=[Arms.RIGHT]).resolve()\npick_up.perform()\nnavigate_action.perform()\nplace_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I write a plan to navigate through multiple waypoints?"}, {"role": "assistant", "content": "You can loop through a list of waypoints using the `NavigateAction` designator for each. Example:\n```python\nfor waypoint in waypoints:\n    navigate_action = NavigateAction(target_locations=[waypoint]).resolve()\n    navigate_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I code a plan to make the robot transport an object from one room to another?"}, {"role": "assistant", "content": "You can use the `TransportAction` designator to code this plan. Example:\n```python\ntransport_action = TransportAction(object_designator=milk_desig, arms=[Arms.RIGHT], target_location=target_pose).resolve()\ntransport_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code. You will get a Task and world knowledge. Then write a PyCRAM Plan code for it. Respond just with the code."}, {"role": "user", "content": "Can you set the table for breakfast? I want to eat a bowl of cereals with milk. \nWorld Knowledge: robot = Object('pr2', ObjectType.ROBOT, 'pr2.urdf', pose=Pose([1, 2, 0])), apartment = Object('apartment', ObjectType.ENVIRONMENT, 'apartment.urdf'), milk = Object('milk', ObjectType.MILK, 'milk.stl', pose=Pose([2.5, 2, 1.02]), color=[1, 0, 0, 1]), cereal = Object('cereal', ObjectType.BREAKFAST_CEREAL, 'breakfast_cereal.stl', pose=Pose([2.5, 2.3, 1.05]), color=[0, 1, 0, 1]), spoon = Object('spoon', ObjectType.SPOON, 'spoon.stl', pose=Pose([2.4, 2.2, 0.85]), color=[0, 0, 1, 1]), bowl = Object('bowl', ObjectType.BOWL, 'bowl.stl', pose=Pose([2.5, 2.2, 1.02]), color=[1, 1, 0, 1]), apartment.attach(spoon, 'cabinet10_drawer_top')"}, {"role": "assistant", "content": "from pycram.designators.action_designator import *; from pycram.designators.location_designator import *; from pycram.designators.object_designator import *; from pycram.pose import Pose; from pycram.bullet_world import BulletWorld, Object; from pycram.process_module import simulated_robot, with_simulated_robot; from pycram.enums import ObjectType; world = BulletWorld(); robot = Object('pr2', ObjectType.ROBOT, 'pr2.urdf', pose=Pose([1, 2, 0])); apartment = Object('apartment', ObjectType.ENVIRONMENT, 'apartment.urdf'); milk = Object('milk', ObjectType.MILK, 'milk.stl', pose=Pose([2.5, 2, 1.02]), color=[1, 0, 0, 1]); cereal = Object('cereal', ObjectType.BREAKFAST_CEREAL, 'breakfast_cereal.stl', pose=Pose([2.5, 2.3, 1.05]), color=[0, 1, 0, 1]); spoon = Object('spoon', ObjectType.SPOON, 'spoon.stl', pose=Pose([2.4, 2.2, 0.85]), color=[0, 0, 1, 1]); bowl = Object('bowl', ObjectType.BOWL, 'bowl.stl', pose=Pose([2.5, 2.2, 1.02]), color=[1, 1, 0, 1]); apartment.attach(spoon, 'cabinet10_drawer_top'); pick_pose = Pose([2.7, 2.15, 1]); robot_desig = BelieveObject(names=['pr2']); apartment_desig = BelieveObject(names=['apartment']); @with_simulated_robot def move_and_detect(obj_type): NavigateAction(target_locations=[Pose([1.7, 2, 0])]).resolve().perform(); LookAtAction(targets=[pick_pose]).resolve().perform(); object_desig = DetectAction(BelieveObject(types=[obj_type])).resolve().perform(); return object_desig; with simulated_robot: ParkArmsAction([Arms.BOTH]).resolve().perform(); MoveTorsoAction([0.25]).resolve().perform(); milk_desig = move_and_detect(ObjectType.MILK); TransportAction(milk_desig, ['left'], [Pose([4.8, 3.55, 0.8])]).resolve().perform(); cereal_desig = move_and_detect(ObjectType.BREAKFAST_CEREAL); TransportAction(cereal_desig, ['right'], [Pose([5.2, 3.4, 0.8], [0, 0, 1, 1])]).resolve().perform(); bowl_desig = move_and_detect(ObjectType.BOWL); TransportAction(bowl_desig, ['left'], [Pose([5, 3.3, 0.8], [0, 0, 1, 1])]).resolve().perform(); handle_desig = ObjectPart(names=['handle_cab10_t'], part_of=apartment_desig.resolve()); drawer_open_loc = AccessingLocation(handle_desig=handle_desig.resolve(), robot_desig=robot_desig.resolve()).resolve(); NavigateAction([drawer_open_loc.pose]).resolve().perform(); OpenAction(object_designator_description=handle_desig, arms=[drawer_open_loc.arms[0]]).resolve().perform(); spoon.detach(apartment); LookAtAction([apartment.get_link_pose('handle_cab10_t')]).resolve().perform(); spoon_desig = DetectAction(BelieveObject(types=[ObjectType.SPOON])).resolve().perform(); pickup_arm = 'left' if drawer_open_loc.arms[0] == 'right' else 'right'; PickUpAction(spoon_desig, [pickup_arm], ['top']).resolve().perform(); ParkArmsAction([Arms.BOTH]).resolve().perform(); close_loc = drawer_open_loc.pose; close_loc.position.y += 0.1; NavigateAction([close_loc]).resolve().perform(); CloseAction(object_designator_description=handle_desig, arms=[drawer_open_loc.arms[0]]).resolve().perform(); ParkArmsAction([Arms.BOTH]).resolve().perform(); MoveTorsoAction([0.15]).resolve().perform(); spoon_target_pose = Pose([4.85, 3.3, 0.8], [0, 0, 1, 1]); placing_loc = CostmapLocation(target=spoon_target_pose, reachable_for=robot_desig.resolve()).resolve(); NavigateAction([placing_loc.pose]).resolve().perform(); PlaceAction(spoon_desig, [spoon_target_pose], [pickup_arm]).resolve().perform(); ParkArmsAction([Arms.BOTH]).resolve().perform(); world.exit()"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code. You will get a Task and world knowledge. Then write a PyCRAM Plan code for it. Respond just with the code."}, {"role": "user", "content": "Can you place the cereal on the kitchen island?\nWorld knowledge: [kitchen = Object('kitchen', ObjectType.ENVIRONMENT, 'kitchen.urdf'), robot = Object('pr2', ObjectType.ROBOT, 'pr2.urdf'), cereal = Object('cereal', ObjectType.BREAKFAST_CEREAL, 'breakfast_cereal.stl', pose=Pose([1.4, 1, 0.95]))]"}, {"role": "assistant", "content": "#Imports\nfrom pycram.bullet_world import BulletWorld, Object\nfrom pycram.process_module import simulated_robot\nfrom pycram.designators.motion_designator import *\nfrom pycram.designators.location_designator import *\nfrom pycram.designators.action_designator import *\nfrom pycram.designators.object_designator import *\nfrom pycram.enums import ObjectType\n\n#Bulletword Definition\nworld = BulletWorld()\n\n#Objects\nkitchen = Object('kitchen', ObjectType.ENVIRONMENT, 'kitchen.urdf')\nrobot = Object('pr2', ObjectType.ROBOT, 'pr2.urdf')\ncereal = Object('cereal', ObjectType.BREAKFAST_CEREAL, 'breakfast_cereal.stl', pose=Pose([1.4, 1, 0.95]))\n\n#Object Designators\ncereal_desig = ObjectDesignatorDescription(names=['cereal'])\nkitchen_desig = ObjectDesignatorDescription(names=['kitchen'])\nrobot_desig = ObjectDesignatorDescription(names=['pr2']).resolve()\n\n#The 'with simulated_robot'-Block\nwith simulated_robot:\n    #AktionDesignators\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n\n    MoveTorsoAction([0.25]).resolve().perform()\n    \n    #SemanticCostmapLocation\n    pickup_pose = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot_desig).resolve()\n    pickup_arm = pickup_pose.reachable_arms[0]\n\n    #AktionDesignators\n    NavigateAction(target_locations=[pickup_pose.pose]).resolve().perform()\n\n    PickUpAction(object_designator_description=cereal_desig, arms=[pickup_arm], grasps=['front']).resolve().perform()\n\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n        \n    #SemanticCostmapLocation\n    place_island = SemanticCostmapLocation('kitchen_island_surface', kitchen_desig.resolve(), cereal_desig.resolve()).resolve()\n\n    place_stand = CostmapLocation(place_island.pose, reachable_for=robot_desig, reachable_arm=pickup_arm).resolve()\n    \n    #AktionDesignators\n    NavigateAction(target_locations=[place_stand.pose]).resolve().perform()\n\n    PlaceAction(cereal_desig, target_locations=[place_island.pose], arms=[pickup_arm]).resolve().perform()\n\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n\n#BulletWorld Close\nworld.exit()"}]}
{"messages": [{"role": "system", "content": "You are an experienced technical writer and coding educator, specializing in creating comprehensive guides for implementing specific tasks and workflows using the PyCram framework. Your task is to thoroughly explain how to accomplish the given task within PyCram"}, {"role": "user", "content": "How to use Costmaps for robot positioning in PyCRAM?"}, {"role": "assistant", "content": "### Using Costmaps for Robot Positioning in PyCRAM\n\nCostmaps in PyCRAM are essential tools for determining optimal positions for robot actions based on various criteria like visibility, occupancy, and more. This guide will explore how to create and utilize costmaps for robot positioning.\n\n#### 1. Introduction to Costmaps\n\nCostmaps provide a way to evaluate positions in the simulation based on different criteria. PyCRAM supports several types of costmaps, including:\n\n- `OccupancyCostmap`: Determines where the robot can be placed without colliding with objects.\n- `VisibilityCostmap`: Determines positions from which a target is visible.\n- `SemanticCostmap`: Maps positions based on semantic labels, like identifying specific surfaces.\n- `GaussianCostmap`: Generates a costmap with a Gaussian distribution.\n\n#### 2. Creating a Visibility Costmap\n\nVisibility costmaps are used to find positions where a target object is visible. Here’s how to create and visualize a visibility costmap:\n\n```python\nimport pycram.costmaps as cm\nfrom pycram.datastructures.pose import Pose\n\n# Create a visibility costmap\nv = cm.VisibilityCostmap(1.27, 1.60, size=300, resolution=0.02, origin=Pose([0, 0, 0.1], [0, 0, 0, 1]))\n\n# Visualize the costmap\nv.visualize()\n```\n\nTo close the visualization:\n\n```python\nv.close_visualization()\n```\n\n#### 3. Creating an Occupancy Costmap\n\nOccupancy costmaps ensure that the robot is positioned without collisions.\n\n```python\n# Create an occupancy costmap\no = cm.OccupancyCostmap(0.2, from_ros=False, size=300, resolution=0.02, origin=Pose([0, 0, 0.1], [0, 0, 0, 1]))\n\n# Visualize the costmap\no.visualize()\n```\n\n#### 4. Combining Costmaps\n\nYou can combine multiple costmaps to consider different criteria simultaneously:\n\n```python\n# Combine visibility and occupancy costmaps\nov = o + v\nov.visualize()\n```\n\n#### 5. Using Costmaps in Robot Positioning\n\nCostmaps can be used to determine the robot's position when performing tasks. For example, when picking up an object, you might want to find a position that is both reachable and has good visibility:\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.datastructures.enums import ObjectType\n\n# Define the robot and target objects\nrobot_desig = BelieveObject(types=[ObjectType.ROBOT]).resolve()\ntarget_desig = BelieveObject(names=[\"Milk\"]).resolve()\n\n# Create a location designator based on the combined costmap\nlocation_desig = CostmapLocation(target=target_desig, visible_for=robot_desig)\n\n# Resolve the best position for the robot\nbest_position = location_desig.resolve()\nprint(f\"Best Position: {best_position}\")\n```\n\n#### 6. Best Practices and Considerations\n\n- **Resolution and Size**: Choose the resolution and size of costmaps based on the specific needs of the task. Higher resolutions provide more detail but require more computation.\n- **Combination of Costmaps**: When combining costmaps, ensure that the criteria do not conflict, as this might lead to suboptimal positioning.\n- **Visualization**: Always visualize your costmaps to verify that they correctly represent the environment and meet your task’s requirements.\n\n### Conclusion\n\nCostmaps are powerful tools in PyCRAM for determining optimal robot positions based on various criteria. By using and combining different types of costmaps, you can ensure that your robot operates effectively within its environment."}]}
{"messages": [{"role": "system", "content": "You are an experienced technical writer and coding educator, specializing in creating comprehensive guides for implementing specific tasks and workflows using the PyCram framework. Your task is to thoroughly explain how to accomplish the given task within PyCram"}, {"role": "user", "content": "How to create and manage a BulletWorld?"}, {"role": "assistant", "content": "### Creating and Managing a BulletWorld in PyCRAM\n\nThe `BulletWorld` is the core simulation environment in PyCRAM where different objects and robots are spawned, and actions are simulated. This guide will walk you through creating and managing a `BulletWorld`, interacting with objects, and rendering images from the simulation.\n\n#### 1. Setting Up the BulletWorld\n\nTo begin, you need to import the necessary modules from PyCRAM and create an instance of `BulletWorld`.\n\n```python\nfrom pycram.worlds.bullet_world import BulletWorld\n\n# Create an instance of BulletWorld\nworld = BulletWorld()\n```\n\nThis code initializes a new BulletWorld, which serves as the environment where all simulations take place.\n\n#### 2. Spawning Objects in BulletWorld\n\nObjects in the BulletWorld can be spawned using URDF, OBJ, or STL files. Here's how to create an object in the simulation:\n\n```python\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType\n\n# Spawn a milk object in the BulletWorld\nmilk = Object(\"Milk\", ObjectType.MILK, \"milk.stl\")\n```\n\nObjects can be manipulated with methods like `set_position()` and `remove()`.\n\n#### 3. Rendering Images from BulletWorld\n\nYou can render images from different camera perspectives using the `get_images_for_target` method.\n\n```python\nfrom pycram.datastructures.pose import Pose\n\n# Render images from a specific camera position\nworld.get_images_for_target(Pose([1, 0, 1], [0, 0, 0, 1]), Pose([0.3, 0, 1], [0, 0, 0, 1]))\n```\n\nThis function returns an RGB image, a depth image, and a segmentation mask.\n\n#### 4. Managing Objects and Environment\n\nObjects in the BulletWorld can be moved, rotated, or removed. Here's an example of how to manipulate an object:\n\n```python\n# Set the position of the milk object\nmilk.set_position(Pose([1, 0, 0]))\n\n# Remove the milk object from the BulletWorld\nmilk.remove()\n```\n\nYou can also spawn complex environments like a kitchen in the same way:\n\n```python\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\n```\n\n#### 5. Closing the BulletWorld\n\nWhen you're done with the simulation, you can close the BulletWorld using the `exit` method:\n\n```python\nworld.exit()\n```\n\n### Conclusion\n\nManaging a BulletWorld in PyCRAM involves initializing the world, spawning and interacting with objects, rendering images, and finally closing the world. This workflow is essential for setting up simulations that allow for advanced reasoning and testing within the PyCRAM framework."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to use Costmaps for robot positioning in PyCRAM?"}, {"role": "assistant", "content": "### Using Costmaps for Robot Positioning in PyCRAM\n\nCostmaps in PyCRAM are essential tools for determining optimal positions for robot actions based on various criteria like visibility, occupancy, and more. This guide will explore how to create and utilize costmaps for robot positioning.\n\n#### 1. Introduction to Costmaps\n\nCostmaps provide a way to evaluate positions in the simulation based on different criteria. PyCRAM supports several types of costmaps, including:\n\n- `OccupancyCostmap`: Determines where the robot can be placed without colliding with objects.\n- `VisibilityCostmap`: Determines positions from which a target is visible.\n- `SemanticCostmap`: Maps positions based on semantic labels, like identifying specific surfaces.\n- `GaussianCostmap`: Generates a costmap with a Gaussian distribution.\n\n#### 2. Creating a Visibility Costmap\n\nVisibility costmaps are used to find positions where a target object is visible. Here’s how to create and visualize a visibility costmap:\n\n```python\nimport pycram.costmaps as cm\nfrom pycram.datastructures.pose import Pose\n\n# Create a visibility costmap\nv = cm.VisibilityCostmap(1.27, 1.60, size=300, resolution=0.02, origin=Pose([0, 0, 0.1], [0, 0, 0, 1]))\n\n# Visualize the costmap\nv.visualize()\n```\n\nTo close the visualization:\n\n```python\nv.close_visualization()\n```\n\n#### 3. Creating an Occupancy Costmap\n\nOccupancy costmaps ensure that the robot is positioned without collisions.\n\n```python\n# Create an occupancy costmap\no = cm.OccupancyCostmap(0.2, from_ros=False, size=300, resolution=0.02, origin=Pose([0, 0, 0.1], [0, 0, 0, 1]))\n\n# Visualize the costmap\no.visualize()\n```\n\n#### 4. Combining Costmaps\n\nYou can combine multiple costmaps to consider different criteria simultaneously:\n\n```python\n# Combine visibility and occupancy costmaps\nov = o + v\nov.visualize()\n```\n\n#### 5. Using Costmaps in Robot Positioning\n\nCostmaps can be used to determine the robot's position when performing tasks. For example, when picking up an object, you might want to find a position that is both reachable and has good visibility:\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.datastructures.enums import ObjectType\n\n# Define the robot and target objects\nrobot_desig = BelieveObject(types=[ObjectType.ROBOT]).resolve()\ntarget_desig = BelieveObject(names=[\"Milk\"]).resolve()\n\n# Create a location designator based on the combined costmap\nlocation_desig = CostmapLocation(target=target_desig, visible_for=robot_desig)\n\n# Resolve the best position for the robot\nbest_position = location_desig.resolve()\nprint(f\"Best Position: {best_position}\")\n```\n\n#### 6. Best Practices and Considerations\n\n- **Resolution and Size**: Choose the resolution and size of costmaps based on the specific needs of the task. Higher resolutions provide more detail but require more computation.\n- **Combination of Costmaps**: When combining costmaps, ensure that the criteria do not conflict, as this might lead to suboptimal positioning.\n- **Visualization**: Always visualize your costmaps to verify that they correctly represent the environment and meet your task’s requirements.\n\n### Conclusion\n\nCostmaps are powerful tools in PyCRAM for determining optimal robot positions based on various criteria. By using and combining different types of costmaps, you can ensure that your robot operates effectively within its environment."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to use action designators in PyCRAM?"}, {"role": "assistant", "content": "### Using Action Designators in PyCRAM\n\nAction designators in PyCRAM represent high-level actions that a robot can perform. They encapsulate complex behaviors, often composed of multiple motion designators and other logic, to achieve specific goals. This guide will walk you through the process of using action designators in PyCRAM.\n\n#### 1. Introduction to Action Designators\n\nAction designators are symbolic representations of complex robot actions. They provide a high-level interface for defining robot tasks, abstracting away the low-level details of motion planning and execution. Some common action designators in PyCRAM include:\n\n- `NavigateAction`: Navigates the robot to a specific location.\n- `PickUpAction`: Picks up an object.\n- `PlaceAction`: Places an object at a specific location.\n- `OpenAction`: Opens a container-like object.\n- `CloseAction`: Closes a container-like object.\n\n#### 2. Creating and Resolving Action Designators\n\nAction designators are created from action designator descriptions, which specify the type of action and its parameters. These parameters are typically provided as lists of possible values, allowing for flexibility in planning. For example, a `NavigateAction` description might include a list of possible target locations. When resolved, the action designator description selects a specific parameter from the list and returns a performable action designator.\n\nHere's an example of creating and resolving a `NavigateAction` designator:\n\n```python\nfrom pycram.designators.action_designator import NavigateAction\nfrom pycram.datastructures.pose import Pose\n\n# Create a list of possible target locations\ntarget_locations = [Pose([1, 0, 0], [0, 0, 0, 1]), Pose([2, 1, 0], [0, 0, 0, 1])]\n\n# Create a NavigateAction description\nnavigate_description = NavigateAction(target_locations=target_locations)\n\n# Resolve the description to a performable action designator\nnavigate_designator = navigate_description.resolve()\n\n# Print the resolved designator (will show the chosen target location)\nprint(navigate_designator)\n```\n\n#### 3. Performing Action Designators\n\nOnce you have a resolved action designator, you can perform it to execute the action. Performing an action designator typically involves the following steps:\n\n- Verifying the parameters of the designator.\n- Selecting the appropriate process module based on whether the robot is simulated or real.\n- Executing the action using the selected process module.\n\nHere's an example of performing the `NavigateAction` designator created in the previous step:\n\n```python\nfrom pycram.process_module import simulated_robot\n\n# Perform the NavigateAction designator in a simulated environment\nwith simulated_robot:\n    navigate_designator.perform()\n```\n\n#### 4. Combining Action Designators\n\nYou can combine multiple action designators using PyCRAM's plan language to create more complex robot behaviors. The plan language provides operators for sequential execution (`+`), parallel execution (`|`), and more. For example, you could create a plan that navigates the robot to a table, picks up an object, and then places it at another location.\n\n#### 5. Best Practices and Considerations\n\n- **Parameterization**: Use lists of possible parameters in action designator descriptions to allow for flexibility in planning.\n- **Process Modules**: Ensure that the correct process module is selected based on the robot's environment (simulated or real).\n- **Error Handling**: Handle potential errors during action execution using PyCRAM's plan language or custom error handling mechanisms.\n\n### Conclusion\n\nAction designators are a powerful tool in PyCRAM for defining and executing complex robot behaviors. By understanding how to create, resolve, and perform action designators, you can build sophisticated robot control programs that achieve high levels of autonomy."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to create and use object designators in PyCRAM?"}, {"role": "assistant", "content": "### Creating and Using Object Designators in PyCRAM\n\nObject designators in PyCRAM are symbolic representations of objects in the robot's world. They allow you to refer to objects without needing to know their exact physical properties or locations. This guide will explain how to create and use object designators in PyCRAM.\n\n#### 1. Introduction to Object Designators\n\nObject designators provide a way to abstractly represent objects in the robot's environment. They are defined by descriptions that specify criteria for identifying objects, such as their names, types, or other attributes. When resolved, an object designator description returns a specific object instance that matches the criteria.\n\n#### 2. Types of Object Designators\n\nPyCRAM supports different types of object designators, including:\n\n- `BelieveObject`: Represents objects that are part of the robot's internal belief state, typically objects spawned in the simulation.\n- `ObjectPart`: Represents specific parts or components of other objects, like the handle of a drawer.\n- `RealObject`: Represents objects perceived in the real world using sensors.\n\n#### 3. Creating a BelieveObject Designator\n\n`BelieveObject` designators are used to refer to objects that exist in the simulation. Here's an example of creating a `BelieveObject` designator for an object named \"Milk\":\n\n```python\nfrom pycram.designators.object_designator import BelieveObject\n\n# Create a BelieveObject designator for an object named \"Milk\"\nmilk_desig = BelieveObject(names=[\"Milk\"])\n\n# Resolve the designator to get the actual object instance\nmilk_object = milk_desig.resolve()\n\n# Print the object instance\nprint(milk_object)\n```\n\n#### 4. Creating an ObjectPart Designator\n\n`ObjectPart` designators are used to refer to specific parts of other objects. For example, to refer to the handle of a drawer named \"drawer1\", you would create an `ObjectPart` designator like this:\n\n```python\nfrom pycram.designators.object_designator import ObjectPart, BelieveObject\n\n# Assuming 'drawer1' is a BelieveObject designator for the drawer\ndrawer1_desig = BelieveObject(names=[\"drawer1\"]).resolve()\n\n# Create an ObjectPart designator for the handle of 'drawer1'\nhandle_desig = ObjectPart(names=[\"handle\"], part_of=drawer1_desig)\n\n# Resolve the designator to get the handle object\nhandle_object = handle_desig.resolve()\n\n# Print the handle object\nprint(handle_object)\n```\n\n#### 5. Using Object Designators in Actions\n\nObject designators are often used as parameters for action designators. For example, the `PickUpAction` designator requires an object designator to specify the object to be picked up.\n\n```python\nfrom pycram.designators.action_designator import PickUpAction\nfrom pycram.datastructures.enums import Arms\n\n# Assuming 'milk_desig' is a BelieveObject designator for the milk carton\n\n# Create a PickUpAction designator\npickup_action = PickUpAction(object_designator_description=milk_desig, arms=[Arms.RIGHT], grasps=[\"front\"])\n\n# Resolve and perform the pickup action\npickup_action.resolve().perform()\n```\n\n#### 6. Object Designators as Generators\n\nObject designator descriptions can also be used as generators to iterate through all objects that match the description. This is useful when you need to consider multiple candidate objects.\n\n```python\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.datastructures.enums import ObjectType\n\n# Create a BelieveObject designator for all objects of type 'ObjectType.MILK'\nmilk_desig = BelieveObject(types=[ObjectType.MILK])\n\n# Iterate through all milk objects\nfor milk_object in milk_desig:\n    print(milk_object)\n```\n\n### Conclusion\n\nObject designators are a crucial part of PyCRAM, providing a flexible and abstract way to represent and manipulate objects in the robot's world. By understanding how to create and use different types of object designators, you can effectively define and execute complex robot tasks involving object manipulation."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to define and use the plan language in PyCRAM?"}, {"role": "assistant", "content": "### Defining and Using the Plan Language in PyCRAM\n\nPyCRAM's plan language provides a structured and expressive way to define complex robot behaviors by combining individual actions and motions. It allows you to specify the order of execution, handle potential failures, and even execute actions in parallel. This guide will introduce you to the core concepts and syntax of PyCRAM's plan language.\n\n#### 1. Introduction to the Plan Language\n\nThe plan language uses a set of operators to combine designators, representing actions, motions, objects, and locations, into a coherent plan. It allows you to create plans that are more than just a linear sequence of actions, enabling branching, looping, and parallel execution.\n\n#### 2. Language Expressions\n\nPyCRAM's plan language supports the following expressions:\n\n| Expression | Name             | Description                                                                                                                                                                                                                                                                                |\n|------------|------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `+`          | **Sequential**   | Executes designators one after another. If one designator raises an exception, the execution is aborted, and the state `FAILED` is returned.                                                                                                                                  |\n| `-`          | **Try In Order** | Executes designators sequentially. If a designator raises an exception, the exception is caught and saved, but the execution continues with the next designator. Returns `SUCCEEDED` if at least one designator executes without an exception.                                      |\n| `*`          | **Repeat**       | Repeats the preceding language expression a specified number of times. Must be used with a language expression and an integer.                                                                                                                                                                        |\n| `|`         | **Parallel**     | Executes all designators in parallel, each in a separate thread. If any designator raises an exception, the returned state is `FAILED`. However, all designators are executed regardless of exceptions.                                                                              |\n| `^`          | **Try All**      | Executes all designators in parallel. Returns `SUCCEEDED` if at least one designator executes without an exception.                                                                                                                                                                            |\n| `>>`         | **Monitor**      | Monitors the execution of the attached language expression and interrupts it when a given condition is met. The condition can be a callable returning a boolean value or a Fluent.                                                                                                    |\n\n#### 3. Example: Sequential Execution\n\n```python\nfrom pycram.designators.action_designator import NavigateAction, ParkArmsAction\nfrom pycram.datastructures.pose import Pose\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\n\n# Create designators\nnavigate_designator = NavigateAction(target_locations=[Pose([1, 0, 0], [0, 0, 0, 1])]).resolve()\npark_designator = ParkArmsAction([Arms.BOTH]).resolve()\n\n# Define a sequential plan\nplan = navigate_designator + park_designator\n\n# Execute the plan in a simulated environment\nwith simulated_robot:\n    plan.perform()\n```\n\nThis plan will first navigate the robot to the specified pose and then park its arms. If either action fails, the plan will return `FAILED`.\n\n#### 4. Example: Parallel Execution\n\n```python\nfrom pycram.designators.action_designator import NavigateAction, MoveTorsoAction\nfrom pycram.datastructures.pose import Pose\nfrom pycram.process_module import simulated_robot\n\n# Create designators\nnavigate_designator = NavigateAction(target_locations=[Pose([1, 0, 0], [0, 0, 0, 1])]).resolve()\nmove_torso_designator = MoveTorsoAction([0.3]).resolve()\n\n# Define a parallel plan\nplan = navigate_designator | move_torso_designator\n\n# Execute the plan in a simulated environment\nwith simulated_robot:\n    plan.perform()\n```\n\nThis plan will execute both actions simultaneously. The robot will navigate to the target location while also moving its torso to the specified height.\n\n#### 5. Error Handling\n\nThe plan language automatically catches and stores exceptions of type `PlanFailure` that occur during designator execution. These exceptions can be accessed through the `exceptions` attribute of the plan object. This allows you to analyze the reasons for plan failures and implement appropriate recovery strategies.\n\n#### 6. Best Practices and Considerations\n\n- **Choose the Right Expression**: Select the language expression that best suits the desired behavior and error handling requirements.\n- **Avoid Conflicts**: When using parallel execution, ensure that the actions do not interfere with each other.\n- **Handle Exceptions**: Analyze the `exceptions` attribute to understand and address plan failures.\n\n### Conclusion\n\nPyCRAM's plan language provides a powerful and flexible way to define complex robot behaviors. By understanding its expressions and error handling mechanisms, you can create robust and adaptable robot control programs."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to create and use motion designators in PyCRAM?"}, {"role": "assistant", "content": "### Creating and Using Motion Designators in PyCRAM\n\nMotion designators in PyCRAM represent atomic, low-level motions that a robot can perform. They are the building blocks for more complex actions and provide a direct interface to the robot's control mechanisms. This guide will explain how to create and use motion designators in PyCRAM.\n\n#### 1. Introduction to Motion Designators\n\nMotion designators encapsulate specific robot movements, such as moving the base, controlling the gripper, or adjusting joint angles. They are typically executed by process modules, which translate the high-level motion commands into low-level control signals for the robot.\n\n#### 2. Types of Motion Designators\n\nPyCRAM provides a variety of motion designators, including:\n\n- `MoveMotion`: Moves the robot base to a specific pose.\n- `MoveTCPMotion`: Moves the robot's tool center point (TCP) to a specific pose.\n- `LookingMotion`: Orients the robot's head or camera to look at a specific point.\n- `MoveGripperMotion`: Opens or closes the robot's gripper.\n- `MoveArmJointsMotion`: Moves the robot's arm joints to specific positions.\n- `MoveJointsMotion`: Moves any joint of the robot to a specific position.\n- `OpeningMotion`: Opens a container-like object (typically requires grasping the handle first).\n- `ClosingMotion`: Closes a container-like object.\n\n#### 3. Creating and Performing Motion Designators\n\nMotion designators are created by instantiating the corresponding motion designator class with the desired parameters. For example, to create a `MoveTCPMotion` designator that moves the right arm's TCP to a specific pose, you would use the following code:\n\n```python\nfrom pycram.designators.motion_designator import MoveTCPMotion\nfrom pycram.datastructures.pose import Pose\nfrom pycram.datastructures.enums import Arms\n\n# Create a MoveTCPMotion designator\nmove_tcp_designator = MoveTCPMotion(target=Pose([0.5, 0.6, 0.7], [0, 0, 0, 1]), arm=Arms.RIGHT)\n```\n\nTo perform the motion designator, you need to use it within a context that specifies whether the robot is simulated or real. This is done using the `simulated_robot` or `real_robot` context managers, or the corresponding decorators `with_simulated_robot` and `with_real_robot`.\n\n```python\nfrom pycram.process_module import simulated_robot\n\n# Perform the MoveTCPMotion designator in a simulated environment\nwith simulated_robot:\n    move_tcp_designator.perform()\n```\n\n#### 4. Example: Combining Motion Designators\n\nYou can combine motion designators with action designators and other language expressions to create complex robot behaviors. For example, you could create a plan that navigates the robot to a table, opens a drawer, picks up an object, and then closes the drawer.\n\n#### 5. Best Practices and Considerations\n\n- **Parameter Verification**: Ensure that the parameters provided to motion designators are valid and within the robot's capabilities.\n- **Process Module Selection**: Choose the appropriate process module based on the robot's environment (simulated or real).\n- **Error Handling**: Handle potential errors during motion execution, such as collisions or unreachable poses.\n\n### Conclusion\n\nMotion designators are the fundamental building blocks for robot control in PyCRAM. By understanding how to create and use them, you can build complex and sophisticated robot behaviors that achieve specific tasks and goals."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to set up and configure a robot description in PyCRAM?"}, {"role": "assistant", "content": "### Setting Up and Configuring a Robot Description in PyCRAM\n\nRobot descriptions in PyCRAM provide essential information about the robot's structure, capabilities, and kinematic properties that are not directly available from the URDF (Unified Robot Description Format). This guide will walk you through the process of setting up and configuring a robot description in PyCRAM.\n\n#### 1. Introduction to Robot Descriptions\n\nRobot descriptions in PyCRAM encapsulate semantic information about the robot, such as its kinematic chains, end-effectors, cameras, and grasp configurations. This information is crucial for planning and executing robot actions effectively. The robot description is typically defined in a separate Python file and loaded into PyCRAM at startup.\n\n#### 2. Creating a Robot Description\n\nTo create a robot description, you need to instantiate the `RobotDescription` class and provide the following parameters:\n\n- `name`: The name of the robot.\n- `base_link`: The name of the robot's base link.\n- `torso_link`: The name of the robot's torso link (if it has one).\n- `torso_joint`: The name of the robot's torso joint (if it has one).\n- `urdf_path`: The path to the robot's URDF file.\n\nHere's an example of creating a robot description for a PR2 robot:\n\n```python\nfrom pycram.robot_description import RobotDescription\nimport rospkg\n\n# Get the path to the PR2 URDF file\nrospack = rospkg.RosPack()\nfilename = rospack.get_path('pycram') + '/resources/robots/' + \"pr2\" + '.urdf'\n\n# Create a RobotDescription instance\npr2_description = RobotDescription(\"pr2\", \"base_link\", \"torso_lift_link\", \"torso_lift_joint\", filename)\n```\n\n#### 3. Defining Kinematic Chains\n\nKinematic chains represent interconnected links and joints that form a functional unit, such as an arm or a leg. To define a kinematic chain, you need to create a `KinematicChainDescription` instance and specify the following:\n\n- `name`: The name of the kinematic chain.\n- `start_link`: The name of the first link in the chain.\n- `end_link`: The name of the last link in the chain.\n- `urdf_object`: The URDF object of the robot.\n- `arm_type`: The type of arm (e.g., `Arms.LEFT`, `Arms.RIGHT`) if the chain represents an arm.\n\n```python\nfrom pycram.robot_description import KinematicChainDescription\nfrom pycram.datastructures.enums import Arms\n\n# Create a KinematicChainDescription for the right arm\nright_arm = KinematicChainDescription(\"right\", \"torso_lift_link\", \"r_wrist_roll_link\", pr2_description.urdf_object, arm_type=Arms.RIGHT)\n\n# Add the kinematic chain to the robot description\npr2_description.add_kinematic_chain_description(right_arm)\n```\n\n#### 4. Defining End-Effectors\n\nEnd-effectors are devices attached to the end of a kinematic chain, such as grippers or tools. To define an end-effector, you need to create an `EndEffectorDescription` instance and provide the following:\n\n- `name`: The name of the end-effector.\n- `start_link`: The name of the root link of the end-effector.\n- `tool_frame`: The name of the tool frame link in the URDF.\n- `urdf_object`: The URDF object of the robot.\n\n```python\nfrom pycram.robot_description import EndEffectorDescription\n\n# Create an EndEffectorDescription for the right gripper\nright_gripper = EndEffectorDescription(\"right_gripper\", \"r_gripper_palm_link\", \"r_gripper_tool_frame\", pr2_description.urdf_object)\n\n# Add the end-effector to the kinematic chain\nright_arm.end_effector = right_gripper\n```\n\n#### 5. Defining Cameras\n\nCameras are sensors that provide visual information about the environment. To define a camera, you need to create a `CameraDescription` instance and specify the following:\n\n- `name`: The name of the camera.\n- `camera_link`: The name of the camera link in the URDF.\n- `minimal_height`: The minimum height of the camera.\n- `maximal_height`: The maximum height of the camera.\n\n```python\nfrom pycram.robot_description import CameraDescription\n\n# Create a CameraDescription for the head camera\ncamera = CameraDescription(\"head_camera\", \"wide_stereo_optical_frame\", 1.27, 1.60)\n\n# Add the camera to the robot description\npr2_description.add_camera_description(camera)\n```\n\n#### 6. Defining Grasps\n\nGrasps define the robot's hand orientations for interacting with objects. To define grasps, you can use the `add_grasp_orientation` or `add_grasp_orientations` methods of the `RobotDescription` class. Each grasp is associated with a `Grasp` enum value (e.g., `Grasp.FRONT`, `Grasp.LEFT`) and a quaternion representing the hand orientation.\n\n```python\nfrom pycram.datastructures.enums import Grasp\n\n# Add grasp orientations to the robot description\npr2_description.add_grasp_orientations({\n    Grasp.FRONT: [0, 0, 0, 1],\n    Grasp.LEFT: [0, 0, -1, 1],\n    Grasp.RIGHT: [0, 0, 1, 1],\n    Grasp.TOP: [0, 1, 0, 1]\n})\n```\n\n#### 7. Registering the Robot Description\n\nFinally, you need to register the robot description with the `RobotDescriptionManager` to make it available to PyCRAM.\n\n```python\nfrom pycram.robot_description import RobotDescriptionManager\n\n# Register the robot description\nrdm = RobotDescriptionManager()\nrdm.register_description(pr2_description)\n```\n\n### Conclusion\n\nSetting up a robot description in PyCRAM is essential for providing the framework with the necessary information to plan and execute robot actions effectively. By defining kinematic chains, end-effectors, cameras, and grasps, you enable PyCRAM to reason about the robot's capabilities and interact with its environment in a meaningful way."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "What are the different types of costmaps in PyCRAM and how do they work?"}, {"role": "assistant", "content": "### Types of Costmaps in PyCRAM and Their Functionality\n\nCostmaps in PyCRAM are two-dimensional representations of the robot's environment, encoding information about obstacles, free space, and other relevant features. They are used by location designators to find suitable positions for the robot to perform tasks. PyCRAM supports several types of costmaps, each tailored to specific planning criteria. Let's explore these costmap types and their functionality:\n\n#### 1. Occupancy Costmap (`OccupancyCostmap`)\n\n- **Purpose**: Represents the occupancy state of the environment, indicating areas that are occupied by obstacles and areas that are free.\n- **Functionality**: Each cell in the costmap represents a small area in the environment. The cell value indicates the probability of that area being occupied. Values range from 0 (free) to 1 (occupied), with intermediate values representing uncertainty.\n- **Usage**: Used for basic collision avoidance and finding positions where the robot can be placed without colliding with obstacles.\n\n#### 2. Visibility Costmap (`VisibilityCostmap`)\n\n- **Purpose**: Represents the visibility of a target point from different positions in the environment.\n- **Functionality**: Calculates the visibility of a target point by simulating rays cast from the camera at different positions. Cells in the costmap represent the visibility score, with higher values indicating better visibility.\n- **Usage**: Used for finding positions where the robot has a clear line of sight to a target object or location.\n\n#### 3. Semantic Costmap (`SemanticCostmap`)\n\n- **Purpose**: Maps positions based on semantic labels, such as identifying specific surfaces (e.g., table, countertop, floor).\n- **Functionality**: Assigns semantic labels to cells in the costmap based on the object or surface they represent. This allows the robot to reason about the environment in terms of objects and their properties.\n- **Usage**: Used for tasks that require knowledge of object types or surfaces, such as placing an object on a table or navigating to a specific room.\n\n#### 4. Gaussian Costmap (`GaussianCostmap`)\n\n- **Purpose**: Generates a costmap with a Gaussian distribution centered around a specific point.\n- **Functionality**: Creates a costmap where the cost decreases as the distance from the center point increases, following a Gaussian distribution. This can be used to represent areas of preference or importance.\n- **Usage**: Used for tasks where the robot needs to be close to a specific point but with some flexibility in positioning, such as approaching a table or a person.\n\n#### 5. Combining Costmaps\n\nPyCRAM allows you to combine multiple costmaps to consider different criteria simultaneously. For example, you can combine a visibility costmap and an occupancy costmap to find positions that are both visible and collision-free. The combination is typically done by adding the cost values of the individual costmaps, resulting in a new costmap that reflects the combined criteria.\n\n#### 6. Visualizing Costmaps\n\nPyCRAM provides methods for visualizing costmaps in the BulletWorld, allowing you to inspect and verify their correctness. This visualization helps in understanding how the costmaps represent the environment and how they influence robot positioning.\n\n### Conclusion\n\nCostmaps are a fundamental tool in PyCRAM for robot positioning and planning. By understanding the different types of costmaps and their functionality, you can effectively use them to guide your robot's actions and achieve complex tasks in a variety of environments."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to implement error handling and recovery in PyCRAM plans?"}, {"role": "assistant", "content": "### Implementing Error Handling and Recovery in PyCRAM Plans\n\nRobust error handling and recovery are crucial for creating reliable and adaptable robot control programs. PyCRAM provides mechanisms for handling exceptions, monitoring plan execution, and implementing recovery strategies. This guide will explore how to implement error handling and recovery in PyCRAM plans.\n\n#### 1. Exception Handling with the Plan Language\n\nPyCRAM's plan language automatically catches and stores exceptions of type `PlanFailure` that occur during designator execution. These exceptions can be accessed through the `exceptions` attribute of the plan object. This allows you to analyze the reasons for plan failures and implement appropriate recovery strategies.\n\nHere's an example of how to access exceptions caught by the plan language:\n\n```python\nfrom pycram.designators.action_designator import NavigateAction\nfrom pycram.datastructures.pose import Pose\nfrom pycram.process_module import simulated_robot\n\n# Create a NavigateAction designator with an unreachable target\nnavigate_designator = NavigateAction(target_locations=[Pose([100, 100, 100], [0, 0, 0, 1])]).resolve()\n\n# Define a simple plan\nplan = navigate_designator\n\n# Execute the plan in a simulated environment\nwith simulated_robot:\n    plan.perform()\n\n# Print the caught exceptions\nprint(plan.exceptions)\n```\n\n#### 2. Using Monitors for Plan Monitoring\n\nMonitors in PyCRAM allow you to continuously check for specific conditions during plan execution and interrupt the plan if necessary. This is useful for detecting and responding to unexpected events or situations.\n\nHere's an example of using a `Monitor` to interrupt a plan if the robot's battery level falls below a threshold:\n\n```python\nfrom pycram.language import Monitor\nfrom pycram.process_module import simulated_robot\n\n# Define a function that checks the battery level\ndef check_battery():\n    # Replace this with actual battery level retrieval\n    battery_level = 0.2\n    if battery_level < 0.3:\n        return True\n    return False\n\n# Create a Monitor that checks the battery level every 0.1 seconds\nbattery_monitor = Monitor(condition=check_battery)\n\n# Define a plan that will be monitored\nplan = # Your plan here\n\n# Attach the monitor to the plan\nplan = plan >> battery_monitor\n\n# Execute the monitored plan in a simulated environment\nwith simulated_robot:\n    plan.perform()\n```\n\n#### 3. Implementing Recovery Strategies\n\nOnce you have identified a plan failure, you can implement recovery strategies to handle the situation. Recovery strategies can involve retrying the failed action, choosing an alternative action, or requesting human intervention.\n\nHere's an example of a simple recovery strategy that retries a failed navigation action:\n\n```python\nfrom pycram.designators.action_designator import NavigateAction\nfrom pycram.datastructures.pose import Pose\nfrom pycram.process_module import simulated_robot\nfrom pycram.plan_failures import NavigationGoalNotReached\n\n# Define a function that attempts navigation and retries if necessary\ndef navigate_with_retry(target_pose, max_retries=3):\n    for i in range(max_retries):\n        try:\n            NavigateAction(target_locations=[target_pose]).resolve().perform()\n            return True\n        except NavigationGoalNotReached:\n            print(f\"Navigation failed, retrying ({i+1}/{max_retries})\")\n    return False\n\n# Define a target pose\ntarget_pose = Pose([1, 0, 0], [0, 0, 0, 1])\n\n# Execute the navigation with retry strategy in a simulated environment\nwith simulated_robot:\n    success = navigate_with_retry(target_pose)\n    if success:\n        print(\"Navigation successful\")\n    else:\n        print(\"Navigation failed after retries\")\n```\n\n#### 4. Best Practices and Considerations\n\n- **Anticipate Potential Failures**: Design your plans with potential failures in mind and include appropriate error handling mechanisms.\n- **Use Monitors Strategically**: Monitors can be used to detect a wide range of conditions, such as collisions, sensor failures, or changes in the environment.\n- **Implement Recovery Strategies**: Define clear recovery strategies for different types of failures.\n- **Log and Analyze Exceptions**: Use PyCRAM's exception logging to understand the causes of failures and improve your plans.\n\n### Conclusion\n\nError handling and recovery are essential aspects of robust robot control. By leveraging PyCRAM's plan language, monitors, and exception handling mechanisms, you can create resilient robot control programs that can handle unexpected situations and achieve their goals reliably."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "How to work with objects and attachments in the PyCRAM BulletWorld?"}, {"role": "assistant", "content": "### Working with Objects and Attachments in the PyCRAM BulletWorld\n\nThe PyCRAM BulletWorld provides a simulated environment where you can interact with objects, robots, and their physical properties. This guide will explain how to work with objects and attachments in the BulletWorld.\n\n#### 1. Spawning Objects\n\nObjects in the BulletWorld can be created from various file formats, including URDF (Unified Robot Description Format), OBJ, and STL. To spawn an object, you use the `Object` class, providing its name, type, and the path to the corresponding file.\n\n```python\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType\nfrom pycram.datastructures.pose import Pose\n\n# Spawn a milk carton\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.3, 1, 0.9]))\n\n# Spawn a table\ntable = Object(\"table\", ObjectType.ENVIRONMENT, \"table.urdf\", pose=Pose([1, 0, 0]))\n```\n\n#### 2. Manipulating Object Poses\n\nYou can manipulate the position and orientation of objects using the following methods:\n\n- `set_position(position, base=False)`: Sets the object's position. If `base=True`, the object's base is placed at the given position.\n- `set_orientation(orientation)`: Sets the object's orientation.\n- `set_pose(pose, base=False)`: Sets both the position and orientation of the object.\n\n```python\n# Move the milk carton\nmilk.set_position([1.5, 1, 0.9])\n\n# Rotate the table\ntable.set_orientation([0, 0, 0.707, 0.707])  # Rotate 90 degrees around the z-axis\n```\n\n#### 3. Accessing Links and Joints\n\nObjects spawned from URDF files have links and joints. You can access these using the `links` and `joints` attributes of the `Object` class. These attributes are dictionaries mapping link/joint names to their corresponding IDs.\n\n```python\n# Get the pose of the table's top link\ntable_top_pose = table.get_link_pose(\"table_top\")\n\n# Set the position of the robot's arm joint\nrobot.set_joint_position(\"arm_joint\", 1.57)  # Set the joint to 90 degrees\n```\n\n#### 4. Creating Attachments\n\nAttachments in PyCRAM represent rigid connections between objects. You can attach objects using the `attach` method, specifying the parent and child objects, and optionally the parent and child links to be connected.\n\n```python\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType\nfrom pycram.datastructures.pose import Pose\n\n# Spawn a box\nbox = Object(\"box\", ObjectType.GENERIC_OBJECT, \"box.stl\", pose=Pose([1.2, 1.2, 1]))\n\n# Spawn a robot\nrobot = Object(\"robot\", ObjectType.ROBOT, \"robot.urdf\")\n\n# Attach the box to the robot's gripper\nrobot.attach(box, parent_link=\"gripper_link\")\n```\n\n#### 5. Detaching Objects\n\nTo detach objects, use the `detach` method, specifying the child object to be detached.\n\n```python\n# Detach the box from the robot\nrobot.detach(box)\n```\n\n#### 6. Bidirectional and Loose Attachments\n\nAttachments can be bidirectional or loose. Bidirectional attachments mean that both objects move when one is moved. Loose attachments mean that only the child object moves when the parent is moved.\n\n```python\n# Create a loose attachment (only the box moves when the robot moves)\nrobot.attach(box, parent_link=\"gripper_link\", bidirectional=False)\n```\n\n#### 7. Best Practices and Considerations\n\n- **Collision Checking**: Use the `contact_points` or `contact_points_simulated` methods to check for collisions between objects.\n- **Attachment Management**: Keep track of attachments and detach objects when necessary to avoid unexpected behavior.\n- **Visualization**: Use the BulletWorld's visualization capabilities to inspect object poses and attachments.\n\n### Conclusion\n\nWorking with objects and attachments in the PyCRAM BulletWorld is essential for simulating robot manipulation tasks. By understanding how to spawn objects, manipulate their poses, create attachments, and check for collisions, you can effectively develop and test robot control programs in a virtual environment."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "What is the purpose of the Object Relational Mapping (ORM) in PyCRAM and how does it work?"}, {"role": "assistant", "content": "### Object Relational Mapping (ORM) in PyCRAM: Purpose and Functionality\n\nObject Relational Mapping (ORM) in PyCRAM provides a powerful mechanism for serializing and storing plan data in a database, enabling persistent storage, retrieval, and analysis of plan execution information. This guide will delve into the purpose and functionality of ORM in PyCRAM.\n\n#### 1. Purpose of ORM in PyCRAM\n\nThe primary purpose of ORM in PyCRAM is to facilitate the logging and analysis of robot plan execution data. This data includes:\n\n- **Designator Parameters**: The specific values used for each designator in the plan, such as target poses, object names, and grasp configurations.\n- **Robot States**: The robot's configuration at various points during plan execution, including joint positions, end-effector poses, and sensor readings.\n- **Task Tree Structures**: The hierarchical structure of the plan, capturing the execution order and dependencies between actions.\n\nBy storing this data in a structured and persistent manner, ORM enables:\n\n- **Debugging and Analysis**: Developers can inspect the logged data to understand the plan's execution flow, identify potential issues, and analyze the reasons for plan failures.\n- **Plan Optimization**: The logged data can be used to evaluate plan performance, identify bottlenecks, and optimize the plan for efficiency and robustness.\n- **Learning and Adaptation**: The stored data can serve as training data for machine learning algorithms, enabling the robot to learn from past experiences and adapt its behavior accordingly.\n\n#### 2. How ORM Works in PyCRAM\n\nPyCRAM's ORM implementation leverages the SQLAlchemy library, a powerful and flexible Python toolkit for working with relational databases. SQLAlchemy provides an abstraction layer over the database, allowing you to interact with the database using Python objects and methods instead of writing raw SQL queries.\n\nHere's a simplified overview of how ORM works in PyCRAM:\n\n1. **Defining ORM Classes**: PyCRAM defines ORM classes that correspond to the different entities involved in plan execution, such as actions, motions, objects, and robot states. These classes specify the attributes and relationships between entities.\n2. **Creating a Database Session**: A database session is created using SQLAlchemy, providing a connection to the database.\n3. **Inserting Data**: During plan execution, PyCRAM automatically creates instances of the ORM classes and populates them with the relevant data. These instances are then added to the database session.\n4. **Committing Changes**: Once all the data has been added to the session, the changes are committed to the database, making the data persistent.\n5. **Querying Data**: You can use SQLAlchemy's query language to retrieve specific data from the database based on various criteria.\n\n#### 3. Example: Logging a NavigateAction\n\n```python\nfrom pycram.designators.action_designator import NavigateAction\nfrom pycram.datastructures.pose import Pose\nfrom pycram.process_module import simulated_robot\nimport sqlalchemy\nimport pycram.orm.base\n\n# Create a database engine and session\nengine = sqlalchemy.create_engine(\"sqlite:///my_database.db\")\npycram.orm.base.Base.metadata.create_all(engine)\nsession = sqlalchemy.orm.sessionmaker(bind=engine)()\n\n# Define a target pose\ntarget_pose = Pose([1, 0, 0], [0, 0, 0, 1])\n\n# Create a NavigateAction designator\nnavigate_designator = NavigateAction(target_locations=[target_pose]).resolve()\n\n# Execute the designator in a simulated environment\nwith simulated_robot:\n    navigate_designator.perform()\n\n# Insert the designator data into the database\nsession.add(navigate_designator)\nsession.commit()\n```\n\nThis code snippet demonstrates how to log a `NavigateAction` designator's data into a SQLite database. The `navigate_designator` object, after being performed, is added to the database session and committed, making the data persistent.\n\n#### 4. Benefits of ORM\n\n- **Structured Data Storage**: ORM provides a structured and organized way to store plan execution data, making it easier to query and analyze.\n- **Data Persistence**: The data is stored in a database, ensuring its persistence even after the PyCRAM program terminates.\n- **Abstraction from SQL**: SQLAlchemy's ORM layer abstracts away the complexities of writing raw SQL queries, allowing you to interact with the database using Python objects and methods.\n\n### Conclusion\n\nObject Relational Mapping (ORM) in PyCRAM is a valuable tool for logging, analyzing, and learning from robot plan execution data. By leveraging SQLAlchemy's capabilities, PyCRAM provides a seamless and efficient way to manage plan data, enabling developers to create more robust, adaptable, and intelligent robot control programs."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "What are the best practices for designing and implementing robust and efficient PyCRAM plans?"}, {"role": "assistant", "content": "### Best Practices for Designing and Implementing Robust and Efficient PyCRAM Plans\n\nCreating effective PyCRAM plans involves careful consideration of various factors, from design choices to implementation details. This guide outlines best practices to help you develop robust and efficient robot control programs using PyCRAM.\n\n#### 1. Plan Design\n\n- **Modularity**: Break down complex tasks into smaller, modular actions. This promotes code reusability and simplifies debugging.\n- **Abstraction**: Use designators to represent actions, motions, objects, and locations abstractly. This allows for flexibility and adaptability in planning.\n- **Hierarchy**: Structure your plan using the plan language, creating a clear hierarchy of actions and their dependencies.\n- **Error Handling**: Anticipate potential failures and include error handling mechanisms using the plan language or custom strategies.\n\n#### 2. Designator Selection\n\n- **Choose the Right Designator**: Select designators that are appropriate for the task and the robot's capabilities. Consider factors like visibility, reachability, and collision avoidance.\n- **Parameterization**: Use lists of possible parameters in designator descriptions to allow for flexibility in planning and execution.\n- **Generators**: Leverage the generator capabilities of location and object designators to explore multiple candidate positions or objects.\n\n#### 3. Process Module Implementation\n\n- **Robot-Specific Control**: Implement process modules that interface with your robot's specific control interfaces (e.g., ROS topics, services, or action servers).\n- **Efficiency**: Optimize process module code for efficiency, especially when dealing with real-time control.\n- **Error Handling**: Include error handling mechanisms in process modules to handle communication failures, sensor errors, or other unexpected events.\n\n#### 4. Simulation and Testing\n\n- **Thorough Simulation**: Test your plans extensively in the BulletWorld before deploying them on a real robot. This allows you to identify and resolve issues in a safe and controlled environment.\n- **Realistic Scenarios**: Create simulation scenarios that closely resemble the real-world environment and tasks.\n- **Performance Evaluation**: Analyze the plan's performance in simulation, considering factors like execution time, success rate, and resource usage.\n\n#### 5. Real Robot Deployment\n\n- **Calibration**: Ensure that your robot's sensors and actuators are properly calibrated.\n- **Fine-Tuning**: Adjust parameters in your process modules or designators to account for real-world factors.\n- **Safety First**: Prioritize safety by implementing emergency stops, collision avoidance, and limits on robot movements.\n\n#### 6. Code Style and Documentation\n\n- **Clear and Concise Code**: Write clean, well-structured code that is easy to understand and maintain.\n- **Comprehensive Documentation**: Document your code thoroughly, including design decisions, parameter descriptions, and usage examples.\n\n### Conclusion\n\nDesigning and implementing robust and efficient PyCRAM plans requires a combination of careful planning, effective design choices, and meticulous implementation. By following these best practices, you can create sophisticated robot control programs that achieve high levels of autonomy and reliability in both simulated and real-world environments."}]}
{"messages": [{"role": "system", "content": "You an expert in coding."}, {"role": "user", "content": "Explain the concept of 'grasps' in PyCRAM and how they are used in robot manipulation tasks."}, {"role": "assistant", "content": "### Grasps in PyCRAM: Defining Robot Hand Orientations for Manipulation\n\nGrasps in PyCRAM define the orientations of the robot's hand or end-effector for interacting with objects during manipulation tasks. They provide a way to specify how the robot should approach and grasp an object, ensuring a stable and successful grasp.\n\n#### 1. Defining Grasps\n\nGrasps are typically defined within the robot description, which provides semantic information about the robot's structure and capabilities. You can use the `add_grasp_orientation` or `add_grasp_orientations` methods of the `RobotDescription` class to define grasps. Each grasp is associated with a `Grasp` enum value and a quaternion representing the desired hand orientation.\n\nThe `Grasp` enum defines standard grasp types, such as:\n\n- `Grasp.FRONT`: Grasping the object from the front.\n- `Grasp.LEFT`: Grasping the object from the left side.\n- `Grasp.RIGHT`: Grasping the object from the right side.\n- `Grasp.TOP`: Grasping the object from the top.\n\nThe quaternion represents the rotation of the hand relative to the robot's base frame. For example, a quaternion of `[0, 0, 0, 1]` represents no rotation, while a quaternion of `[0, 1, 0, 0]` represents a 180-degree rotation around the Y-axis.\n\nHere's an example of defining grasp orientations for a PR2 robot:\n\n```python\nfrom pycram.datastructures.enums import Grasp\n\n# Add grasp orientations to the robot description\npr2_description.add_grasp_orientations({\n    Grasp.FRONT: [0, 0, 0, 1],\n    Grasp.LEFT: [0, 0, -1, 1],\n    Grasp.RIGHT: [0, 0, 1, 1],\n    Grasp.TOP: [0, 1, 0, 1]\n})\n```\n\n#### 2. Using Grasps in Manipulation Tasks\n\nGrasps are used in action designators like `PickUpAction` to specify the desired hand orientation when grasping an object. The `PickUpAction` designator takes a `grasps` parameter, which is a list of possible grasp types. When the action is resolved, it selects a suitable grasp from the list based on factors like object geometry, robot reachability, and collision avoidance.\n\n```python\nfrom pycram.designators.action_designator import PickUpAction\nfrom pycram.datastructures.enums import Arms, Grasp\n\n# Create a PickUpAction designator with multiple grasp options\npickup_action = PickUpAction(\n    object_designator_description=object_desig,  # Object to be picked up\n    arms=[Arms.RIGHT],  # Arm to use\n    grasps=[Grasp.FRONT, Grasp.TOP]  # Possible grasp types\n)\n\n# Resolve and perform the pickup action\npickup_action.resolve().perform()\n```\n\n#### 3. Considerations for Grasp Selection\n\n- **Object Geometry**: The shape and size of the object influence the choice of grasp. For example, a cylindrical object might be best grasped from the side, while a box-shaped object might be grasped from the top.\n- **Robot Reachability**: The robot's kinematic structure and joint limits determine which grasps are reachable.\n- **Collision Avoidance**: The grasp should be chosen to avoid collisions with the environment or other objects.\n- **Grasp Stability**: The grasp should be stable enough to securely hold the object during manipulation.\n\n#### 4. Custom Grasps\n\nYou can define custom grasps beyond the standard types provided by the `Grasp` enum. This allows you to specify more complex hand orientations or grasp configurations tailored to specific objects or tasks.\n\n### Conclusion\n\nGrasps in PyCRAM play a crucial role in robot manipulation tasks by defining the robot's hand orientations for interacting with objects. By carefully considering object geometry, robot reachability, collision avoidance, and grasp stability, you can choose appropriate grasps that ensure successful and reliable object manipulation."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the methods available under the 'World' category in PyCRAM?"}, {"role": "assistant", "content": "Sure! The 'World' category in PyCRAM includes various methods for interacting with and managing the simulation environment. Would you like an overview of all these methods first?"}, {"role": "user", "content": "Yes, please list all the methods under the 'World' category."}, {"role": "assistant", "content": "Here are the methods available under the 'World' category:\n1. `load_object_and_get_id`\n2. `remove_object`\n3. `get_object_by_name`\n4. `get_object_by_type`\n5. `get_object_by_id`\n6. `simulate`\n7. `reset_world`\n8. `add_fixed_constraint`\n9. `remove_constraint`\n10. `get_joint_position`\n11. `reset_joint_position`\n12. `get_link_pose`\n13. `set_link_color`\n14. `get_link_color`\n15. `get_object_axis_aligned_bounding_box`\n16. `get_link_axis_aligned_bounding_box`\n17. `set_realtime`\n18. `set_gravity`\n19. `ray_test`\n20. `ray_test_batch`\n21. `get_images_for_target`\n22. `add_text`\n23. `remove_text`\nWhich method would you like to know more about first?"}, {"role": "user", "content": "Tell me about 'load_object_and_get_id'."}, {"role": "assistant", "content": "'load_object_and_get_id' is a method that loads an object into the simulation world from a specified path and returns a unique ID for that object. The parameters include:\n- `path` (str): The path to the object file (URDF, OBJ, or STL).\n- `pose` (Pose, optional): The pose at which the object should be spawned.\nThe method returns an `int`, which is the unique ID of the loaded object."}, {"role": "user", "content": "And what about 'remove_object'?"}, {"role": "assistant", "content": "'remove_object' is a method used to remove an object from the world. It takes the following parameter:\n- `obj` (Object): The object that you want to remove from the world.\nThe method returns `None`."}, {"role": "user", "content": "How does 'get_object_by_name' work?"}, {"role": "assistant", "content": "'get_object_by_name' returns the object in the world with the specified name. The parameter it takes is:\n- `name` (str): The name of the object.\nIt returns the `Object` with the given name or `None` if the object is not found."}, {"role": "user", "content": "What is 'get_object_by_type'?"}, {"role": "assistant", "content": "'get_object_by_type' returns a list of objects in the world that match the specified type. It takes the following parameter:\n- `obj_type` (ObjectType): The type of objects you want to retrieve.\nThe method returns a `List[Object]` containing all objects of the given type."}, {"role": "user", "content": "Explain 'get_object_by_id'."}, {"role": "assistant", "content": "'get_object_by_id' retrieves the object with the specified ID. The parameter is:\n- `obj_id` (int): The ID of the object.\nIt returns the `Object` with that ID."}, {"role": "user", "content": "How does 'simulate' work?"}, {"role": "assistant", "content": "'simulate' runs the world simulation for a specified amount of time. The parameters include:\n- `seconds` (float): Duration of the simulation in seconds.\n- `real_time` (bool, optional): Whether to simulate in real-time.\nThe method returns `None`."}, {"role": "user", "content": "What does 'reset_world' do?"}, {"role": "assistant", "content": "'reset_world' resets the world to its initial state. It takes no parameters and returns `None`."}, {"role": "user", "content": "Tell me about 'add_fixed_constraint'."}, {"role": "assistant", "content": "'add_fixed_constraint' adds a fixed constraint between two links in the world. The parameters are:\n- `parent_link` (Link): The parent link of the constraint.\n- `child_link` (Link): The child link of the constraint.\n- `child_to_parent_transform` (Transform): The transform from the child link to the parent link.\nThe method returns an `int`, which is the unique ID of the created constraint."}, {"role": "user", "content": "What about 'remove_constraint'?"}, {"role": "assistant", "content": "'remove_constraint' removes a constraint by its ID. The parameter is:\n- `constraint_id` (int): The ID of the constraint to be removed.\nThe method returns `None`."}, {"role": "user", "content": "Explain 'get_joint_position'."}, {"role": "assistant", "content": "'get_joint_position' returns the position of a specific joint in the world. The parameter is:\n- `joint` (Joint): The joint object whose position you want to retrieve.\nThe method returns a `float`, which is the position of the joint."}, {"role": "user", "content": "What is 'reset_joint_position'?"}, {"role": "assistant", "content": "'reset_joint_position' resets the position of a specified joint. The parameters are:\n- `joint` (Joint): The joint object to reset.\n- `joint_position` (float): The new position for the joint.\nThe method returns `None`."}, {"role": "user", "content": "How does 'get_link_pose' work?"}, {"role": "assistant", "content": "'get_link_pose' returns the pose of a specific link in the world. The parameter is:\n- `link` (Link): The link object whose pose you want to retrieve.\nThe method returns a `Pose`, which is the pose of the link."}, {"role": "user", "content": "What about 'set_link_color'?"}, {"role": "assistant", "content": "'set_link_color' sets the color of a specified link in the world. The parameters are:\n- `link` (Link): The link object whose color you want to set.\n- `rgba_color` (Color): The new color for the link in RGBA format.\nThe method returns `None`."}, {"role": "user", "content": "Explain 'get_link_color'."}, {"role": "assistant", "content": "'get_link_color' returns the current color of a specified link in the world. The parameter is:\n- `link` (Link): The link object whose color you want to retrieve.\nThe method returns a `Color`, which is the current color of the link."}, {"role": "user", "content": "Tell me about 'get_object_axis_aligned_bounding_box'."}, {"role": "assistant", "content": "'get_object_axis_aligned_bounding_box' returns the axis-aligned bounding box (AABB) of a specified object in the world. The parameter is:\n- `obj` (Object): The object whose AABB you want to retrieve.\nThe method returns an `AxisAlignedBoundingBox`, which represents the AABB of the object."}, {"role": "user", "content": "What about 'get_link_axis_aligned_bounding_box'?"}, {"role": "assistant", "content": "'get_link_axis_aligned_bounding_box' returns the axis-aligned bounding box (AABB) of a specified link in the world. The parameter is:\n- `link` (Link): The link object whose AABB you want to retrieve.\nThe method returns an `AxisAlignedBoundingBox`, which represents the AABB of the link."}, {"role": "user", "content": "How does 'set_realtime' work?"}, {"role": "assistant", "content": "'set_realtime' enables or disables real-time simulation in the world. The parameter is:\n- `real_time` (bool): Whether to enable (`True`) or disable (`False`) real-time simulation.\nThe method returns `None`."}, {"role": "user", "content": "Explain 'set_gravity'."}, {"role": "assistant", "content": "'set_gravity' sets the gravity vector for the world. The parameter is:\n- `gravity_vector` (List[float]): The gravity vector as a list of `[x, y, z]` values.\nThe method returns `None`."}, {"role": "user", "content": "Tell me about 'ray_test'."}, {"role": "assistant", "content": "'ray_test' performs a ray test in the world and returns the ID of the first object hit by the ray. The parameters are:\n- `from_position` (List[float]): The starting position of the ray.\n- `to_position` (List[float]): The ending position of the ray.\nThe method returns an `int`, which is the ID of the first object hit by the ray, or `-1` if no object was hit."}, {"role": "user", "content": "What is 'ray_test_batch'?"}, {"role": "assistant", "content": "'ray_test_batch' performs a batch of ray tests and returns a list of object IDs hit by the rays. The parameters are:\n- `from_positions` (List[List[float]]): A list of starting positions for the rays.\n- `to_positions` (List[List[float]]): A list of ending positions for the rays.\n- `num_threads` (int, optional): The number of threads to use for the ray tests.\nThe method returns a `List[int]`, which contains the IDs of objects hit by the rays."}, {"role": "user", "content": "How does 'get_images_for_target' work?"}, {"role": "assistant", "content": "'get_images_for_target' renders images (RGB, depth, segmentation mask) for a given target pose and camera pose in the world. The parameters are:\n- `target_pose` (Pose): The pose of the target to look at.\n- `cam_pose` (Pose): The pose of the camera.\n- `size` (int, optional): The size of the rendered images.\nThe method returns a `List[np.ndarray]`, which contains the rendered images in the following order: `[RGB, depth, segmentation mask]`."}, {"role": "user", "content": "Tell me about 'add_text'."}, {"role": "assistant", "content": "'add_text' adds text to the world at a specified position and orientation. The parameters are:\n- `text` (str): The text to be added.\n- `position` (List[float]): The position of the text in the world.\n- `orientation` (List[float], optional): The orientation of the text in the world.\n- `size` (float, optional): The size of the text.\n- `color` (Color, optional): The color of the text.\n- `life_time` (float, optional): The lifetime of the text in seconds.\n- `parent_object_id` (int, optional): The ID of the parent object.\n- `parent_link_id` (int, optional): The ID of the parent link.\nThe method returns an `int`, which is the ID of the added text."}, {"role": "user", "content": "What about 'remove_text'?"}, {"role": "assistant", "content": "'remove_text' removes text from the world by its ID. The parameter is:\n- `text_id` (int, optional): The ID of the text to remove.\nThe method returns `None`."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the methods available under the 'Object' category in PyCRAM?"}, {"role": "assistant", "content": "Sure! The 'Object' category in PyCRAM includes various methods for interacting with and managing objects within the simulation. Would you like an overview of all these methods first?"}, {"role": "user", "content": "Yes, please list all the methods under the 'Object' category."}, {"role": "assistant", "content": "Here are the methods available under the 'Object' category:\n1. `set_pose`\n2. `get_pose`\n3. `set_position`\n4. `get_position`\n5. `set_orientation`\n6. `get_orientation`\n7. `attach`\n8. `detach`\n9. `get_link_pose`\n10. `get_joint_position`\n11. `set_joint_position`\n12. `set_joint_positions`\n13. `get_axis_aligned_bounding_box`\n14. `get_link_geometry`\n15. `get_link_transform`\n16. `get_link_origin`\n17. `get_link_origin_transform`\n18. `get_joint_id`\n19. `get_root_link_description`\n20. `get_root_link_id`\n21. `get_link_id`\n22. `get_link_by_id`\n23. `reset_all_joints_positions`\n24. `get_joint_damping`\n25. `get_joint_upper_limit`\n26. `get_joint_lower_limit`\n27. `get_joint_axis`\n28. `get_joint_type`\n29. `get_joint_limits`\n30. `get_joint_child_link`\n31. `get_joint_parent_link`\n32. `find_joint_above_link`\n33. `get_positions_of_all_joints`\n34. `update_link_transforms`\n35. `contact_points`\n36. `contact_points_simulated`\n37. `set_color`\n38. `get_color`\n39. `get_base_origin`\n40. `get_joint_by_id`\n41. `copy_to_prospection`\n42. `get_link_for_attached_objects`\nWhich method would you like to know more about first?"}, {"role": "user", "content": "Tell me about 'set_pose'."}, {"role": "assistant", "content": "'set_pose' is a method that sets the pose of an object in the simulation. The parameters include:\n- `pose` (Pose): The new pose of the object.\n- `set_attachments` (bool, optional): Whether to update the poses of attached objects.\nThe method returns `None`."}, {"role": "user", "content": "And what about 'get_pose'?"}, {"role": "assistant", "content": "'get_pose' returns the current pose of the object. It takes no parameters and returns a `Pose`, which represents the current pose of the object."}, {"role": "user", "content": "How does 'set_position' work?"}, {"role": "assistant", "content": "'set_position' sets the position of the object in the simulation. The parameters include:\n- `position` (Union[Pose, Point, List[float]]): The new position of the object.\n- `base` (bool, optional): Whether to place the object base at the given position.\nThe method returns `None`."}, {"role": "user", "content": "What is 'get_position'?"}, {"role": "assistant", "content": "'get_position' returns the current position of the object. It takes no parameters and returns a `Point`, which represents the current position of the object."}, {"role": "user", "content": "Tell me about 'set_orientation'."}, {"role": "assistant", "content": "'set_orientation' sets the orientation of the object in the simulation. The parameter is:\n- `orientation` (Union[Pose, Quaternion, List[float]]): The new orientation of the object.\nThe method returns `None`."}, {"role": "user", "content": "How does 'get_orientation' work?"}, {"role": "assistant", "content": "'get_orientation' returns the current orientation of the object. It takes no parameters and returns a `Quaternion`, which represents the current orientation of the object."}, {"role": "user", "content": "Explain 'attach'."}, {"role": "assistant", "content": "'attach' is a method used to attach another object to the current object in the simulation. The parameters include:\n- `child_object` (Object): The object to be attached.\n- `parent_link` (str, optional): The name of the parent link.\n- `child_link` (str, optional): The name of the child link.\n- `bidirectional` (bool, optional): Whether the attachment should be bidirectional.\nThe method returns `None`."}, {"role": "user", "content": "And what about 'detach'?"}, {"role": "assistant", "content": "'detach' is a method used to detach an attached object from the current object. The parameter is:\n- `child_object` (Object): The object to be detached.\nThe method returns `None`."}, {"role": "user", "content": "How does 'get_link_pose' work?"}, {"role": "assistant", "content": "'get_link_pose' returns the pose of a specified link in the object. The parameter is:\n- `link_name` (str): The name of the link.\nThe method returns a `Pose`, which represents the pose of the link."}, {"role": "user", "content": "What is 'get_joint_position'?"}, {"role": "assistant", "content": "'get_joint_position' returns the position of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns a `float`, which represents the position of the joint."}, {"role": "user", "content": "Tell me about 'set_joint_position'."}, {"role": "assistant", "content": "'set_joint_position' sets the position of a specified joint in the object. The parameters are:\n- `joint_name` (str): The name of the joint.\n- `joint_position` (float): The new position for the joint.\nThe method returns `None`."}, {"role": "user", "content": "What about 'set_joint_positions'?"}, {"role": "assistant", "content": "'set_joint_positions' sets the positions of multiple joints in the object. The parameter is:\n- `joint_poses` (Dict[str, float]): A dictionary mapping joint names to their target positions.\nThe method returns `None`."}, {"role": "user", "content": "Explain 'get_axis_aligned_bounding_box'."}, {"role": "assistant", "content": "'get_axis_aligned_bounding_box' returns the axis-aligned bounding box (AABB) of the object. It takes no parameters and returns an `AxisAlignedBoundingBox`, which represents the AABB of the object."}, {"role": "user", "content": "How does 'get_link_geometry' work?"}, {"role": "assistant", "content": "'get_link_geometry' returns the geometry of a specified link in the object. The parameter is:\n- `link_name` (str): The name of the link.\nThe method returns `Union[VisualShape, None]`, which represents the geometry of the link."}, {"role": "user", "content": "What is 'get_link_transform'?"}, {"role": "assistant", "content": "'get_link_transform' returns the transform of a specified link in the object. The parameter is:\n- `link_name` (str): The name of the link.\nThe method returns a `Transform`, which represents the transform of the link."}, {"role": "user", "content": "Explain 'get_link_origin'."}, {"role": "assistant", "content": "'get_link_origin' returns the origin of a specified link in the object. The parameter is:\n- `link_name` (str): The name of the link.\nThe method returns a `Pose`, which represents the origin of the link."}, {"role": "user", "content": "How does 'get_link_origin_transform' work?"}, {"role": "assistant", "content": "'get_link_origin_transform' returns the origin transform of a specified link in the object. The parameter is:\n- `link_name` (str): The name of the link.\nThe method returns a `Transform`, which represents the origin transform of the link."}, {"role": "user", "content": "What is 'get_joint_id'?"}, {"role": "assistant", "content": "'get_joint_id' returns the unique ID for a specified joint name in the object. The parameter is:\n- `name` (str): The name of the joint.\nThe method returns an `int`, which is the unique ID of the joint."}, {"role": "user", "content": "Tell me about 'get_root_link_description'."}, {"role": "assistant", "content": "'get_root_link_description' returns the root link of the URDF of the object. It takes no parameters and returns a `LinkDescription`, which represents the root link as defined in the URDF."}, {"role": "user", "content": "And what about 'get_root_link_id'?"}, {"role": "assistant", "content": "'get_root_link_id' returns the unique ID of the root link of the object. It takes no parameters and returns an `int`, which is the unique ID of the root link."}, {"role": "user", "content": "How does 'get_link_id' work?"}, {"role": "assistant", "content": "'get_link_id' returns the unique ID for a specified link name in the object. The parameter is:\n- `link_name` (str): The name of the link.\nThe method returns an `int`, which is the unique ID of the link."}, {"role": "user", "content": "What is 'get_link_by_id'?"}, {"role": "assistant", "content": "'get_link_by_id' returns the link associated with a given unique link ID in the object. The parameter is:\n- `link_id` (int): The unique ID of the link.\nThe method returns an `ObjectDescription.Link`, which represents the link object."}, {"role": "user", "content": "Tell me about 'reset_all_joints_positions'."}, {"role": "assistant", "content": "'reset_all_joints_positions' resets the current positions of all joints in the object to 0. It takes no parameters and returns `None`."}, {"role": "user", "content": "How does 'get_joint_damping' work?"}, {"role": "assistant", "content": "'get_joint_damping' returns the damping of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns a `float`, which represents the damping of the joint."}, {"role": "user", "content": "What about 'get_joint_upper_limit'?"}, {"role": "assistant", "content": "'get_joint_upper_limit' returns the upper limit of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns a `float`, which represents the upper limit of the joint."}, {"role": "user", "content": "Explain 'get_joint_lower_limit'."}, {"role": "assistant", "content": "'get_joint_lower_limit' returns the lower limit of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns a `float`, which represents the lower limit of the joint."}, {"role": "user", "content": "How does 'get_joint_axis' work?"}, {"role": "assistant", "content": "'get_joint_axis' returns the axis of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns a `Point`, which represents the axis of the joint."}, {"role": "user", "content": "What is 'get_joint_type'?"}, {"role": "assistant", "content": "'get_joint_type' returns the type of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns a `JointType`, which represents the type of the joint."}, {"role": "user", "content": "Explain 'get_joint_limits'."}, {"role": "assistant", "content": "'get_joint_limits' returns the lower and upper limits of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns a `Tuple[float, float]`, which represents the lower and upper limits of the joint."}, {"role": "user", "content": "How does 'get_joint_child_link' work?"}, {"role": "assistant", "content": "'get_joint_child_link' returns the child link of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns an `ObjectDescription.Link`, which represents the child link of the joint."}, {"role": "user", "content": "What is 'get_joint_parent_link'?"}, {"role": "assistant", "content": "'get_joint_parent_link' returns the parent link of a specified joint in the object. The parameter is:\n- `joint_name` (str): The name of the joint.\nThe method returns an `ObjectDescription.Link`, which represents the parent link of the joint."}, {"role": "user", "content": "Tell me about 'find_joint_above_link'."}, {"role": "assistant", "content": "'find_joint_above_link' traverses the chain from a specified link to the URDF origin and returns the first joint that matches the specified joint type. The parameters are:\n- `link_name` (str): The name of the link above which the joint should be found.\n- `joint_type` (JointType): The type of joint to search for.\nThe method returns a `str`, which is the name of the first joint that matches the given type."}, {"role": "user", "content": "How does 'get_positions_of_all_joints' work?"}, {"role": "assistant", "content": "'get_positions_of_all_joints' returns the positions of all joints in the object as a dictionary of joint names and their respective positions. It takes no parameters and returns a `Dict[str, float]`, which contains the positions of all joints."}, {"role": "user", "content": "Explain 'update_link_transforms'."}, {"role": "assistant", "content": "'update_link_transforms' updates the transforms of all links in the object using a specified time or the current ROS time. The parameter is:\n- `transform_time` (rospy.Time, optional): The time at which the transformation should be updated.\nThe method returns `None`."}, {"role": "user", "content": "What is 'contact_points'?"}, {"role": "assistant", "content": "'contact_points' returns a list of contact points between the object and other objects in the simulation. It takes no parameters and returns a `List`, which contains all contact points with other objects."}, {"role": "user", "content": "How does 'contact_points_simulated' work?"}, {"role": "assistant", "content": "'contact_points_simulated' returns a list of all contact points between the object and other objects after stepping the simulation once. It takes no parameters and returns a `List`, which contains the contact points between the object and other objects."}, {"role": "user", "content": "Tell me about 'set_color'."}, {"role": "assistant", "content": "'set_color' changes the color of the object. The color must be provided as a list of RGBA values. The parameter is:\n- `rgba_color` (Color): The new color of the object as a `Color` object with RGBA values between 0 and 1.\nThe method returns `None`."}, {"role": "user", "content": "What about 'get_color'?"}, {"role": "assistant", "content": "'get_color' returns the color of the object. Depending on the object, the return value is either:\n1. A `Color` object with RGBA values if the object has one link.\n2. A dictionary with link names as keys and colors as values for objects with multiple links.\nThe method returns `Union[Color, Dict[str, Color]]`, representing the color(s) of the object."}, {"role": "user", "content": "Explain 'get_base_origin'."}, {"role": "assistant", "content": "'get_base_origin' returns the origin of the base or bottom of the object. It takes no parameters and returns a `Pose`, which represents the origin of the base."}, {"role": "user", "content": "How does 'get_joint_by_id' work?"}, {"role": "assistant", "content": "'get_joint_by_id' returns the joint object associated with a given unique joint ID. The parameter is:\n- `joint_id` (int): The unique ID of the joint.\nThe method returns a `Joint`, which represents the joint object."}, {"role": "user", "content": "What is 'copy_to_prospection'?"}, {"role": "assistant", "content": "'copy_to_prospection' copies the object to the prospection world. It takes no parameters and returns the copied `Object` in the prospection world."}, {"role": "user", "content": "How does 'get_link_for_attached_objects' work?"}, {"role": "assistant", "content": "'get_link_for_attached_objects' returns a dictionary that maps attached objects to the link of the current object to which they are attached. It takes no parameters and returns a `Dict[Object, ObjectDescription.Link]`, which represents the mapping of attached objects to their corresponding links."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the methods available under the 'Designators' category in PyCRAM?"}, {"role": "assistant", "content": "Sure! The 'Designators' category in PyCRAM includes various methods for working with designators, which are symbolic descriptions used to resolve and execute specific actions or tasks. Would you like an overview of all these methods first?"}, {"role": "user", "content": "Yes, please list all the methods under the 'Designators' category."}, {"role": "assistant", "content": "Here are the methods available under the 'Designators' category:\n1. `resolve`\n2. `perform`\n3. `make_effective`\n4. `newest_effective`\n5. `prop_value`\n6. `check_constraints`\n7. `make_dictionary`\n8. `rename_prop`\nWhich method would you like to know more about first?"}, {"role": "user", "content": "Tell me about 'resolve'."}, {"role": "assistant", "content": "'resolve' is a method that resolves the designator description to a specific designator instance. It takes no parameters and returns a `Designator`, which is the resolved designator instance."}, {"role": "user", "content": "And what about 'perform'?"}, {"role": "assistant", "content": "'perform' is a method that executes the resolved designator. It takes no parameters and returns `Any`, which is the result of the designator execution."}, {"role": "user", "content": "How does 'make_effective' work?"}, {"role": "assistant", "content": "'make_effective' creates a new effective designator of the same type as the current one. If no properties are specified, the current ones are used. The parameters include:\n- `new_properties` (List, optional): A list of properties.\n- `data` (Any, optional): The low-level data structure the new designator describes.\n- `timestamp` (float, optional): The timestamp of creation.\nThe method returns a `Designator`, which is the newly created effective designator."}, {"role": "user", "content": "What is 'newest_effective'?"}, {"role": "assistant", "content": "'newest_effective' returns the newest effective designator. It takes no parameters and returns a `Designator`, which is the newest effective designator."}, {"role": "user", "content": "Explain 'prop_value'."}, {"role": "assistant", "content": "'prop_value' returns the first value matching the specified property key. The parameter is:\n- `key` (str): The key to return the value of.\nThe method returns `Any`, which is the value of the specified key."}, {"role": "user", "content": "How does 'check_constraints' work?"}, {"role": "assistant", "content": "'check_constraints' returns `True` if all the given properties match, and `False` otherwise. The parameter is:\n- `properties` (List): The properties which have to match. A property can be a tuple where the first value is the key of a property that must equal the second value. Otherwise, it's simply the key of a property that must not be `None`.\nThe method returns a `bool`, which is `True` if all properties match, and `False` otherwise."}, {"role": "user", "content": "What about 'make_dictionary'?"}, {"role": "assistant", "content": "'make_dictionary' (deprecated) converts the given properties to a dictionary. The parameter is:\n- `properties` (List): The properties to create a dictionary from. A property can be a tuple where the first value is the dictionary key and the second value is the dictionary value. Otherwise, it's simply the dictionary key and the key of a property that is the dictionary value.\nThe method returns a `Dict`, which is the dictionary with the given properties."}, {"role": "user", "content": "Tell me about 'rename_prop'."}, {"role": "assistant", "content": "'rename_prop' renames a property of the designator. The parameters include:\n- `old` (str): The name of the old property.\n- `new` (str): The name of the new property.\nThe method returns a `Designator`, which is the designator with the renamed property."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the components and methods available in the 'pycram.costmaps' module?"}, {"role": "assistant", "content": "Sure! The 'pycram.costmaps' module in PyCRAM includes several classes and functions related to costmaps, which are used for planning and navigation in robotics. Would you like an overview of all the classes and functions first?"}, {"role": "user", "content": "Yes, please list all the components in the 'pycram.costmaps' module."}, {"role": "assistant", "content": "The 'pycram.costmaps' module includes the following components:\n\n**Attributes:**\n- `cmap`\n\n**Classes:**\n1. `Rectangle`\n2. `Costmap`\n3. `OccupancyCostmap`\n4. `VisibilityCostmap`\n5. `GaussianCostmap`\n6. `SemanticCostmap`\n\n**Functions:**\n1. `plot_grid(data: numpy.ndarray) → None`\n\nWhich class, function, or attribute would you like to know more about first?"}, {"role": "user", "content": "Tell me about the 'Rectangle' class."}, {"role": "assistant", "content": "The `Rectangle` class describes a rectangle by its lower and upper x and y values.\n\n**Attributes:**\n- `x_lower`: float\n- `x_upper`: float\n- `y_lower`: float\n- `y_upper`: float\n\n**Methods:**\n- `translate(x: float, y: float)`: Translates the rectangle by x and y.\n- `scale(x_factor: float, y_factor: float)`: Scales the rectangle by x_factor and y_factor."}, {"role": "user", "content": "And what about the 'Costmap' class?"}, {"role": "assistant", "content": "The `Costmap` class is the base class for all costmaps in PyCRAM, implementing visualization of costmaps in the World.\n\n**Attributes:**\n- `world`\n- `resolution`: float\n- `size`: int\n- `height`: int\n- `width`: int\n- `local_transformer`\n- `origin`: `pycram.datastructures.pose.Pose`\n- `map`: `numpy.ndarray`\n- `vis_ids`: `typing_extensions.List[int]`\n\n**Methods:**\n- `visualize() → None`: Visualizes a costmap in the BulletWorld.\n- `_chunks(lst: typing_extensions.List, n: int) → typing_extensions.List`: Yields n-sized chunks from lst.\n- `close_visualization() → None`: Removes the visualization from the World.\n- `_find_consecutive_line(start: typing_extensions.Tuple[int, int], map: numpy.ndarray) → int`: Finds the number of consecutive entries greater than zero.\n- `_find_max_box_height(start: typing_extensions.Tuple[int, int], length: int, map: numpy.ndarray) → int`: Finds the maximum height for a rectangle with a given width.\n- `merge(other_cm: Costmap) → Costmap`: Merges two costmaps into a new costmap.\n- `__add__(other: Costmap) → Costmap`: Overloads the '+' operator for merging Costmaps.\n- `partitioning_rectangles() → typing_extensions.List[Rectangle]`: Partitions the map into rectangles."}, {"role": "user", "content": "How does the 'OccupancyCostmap' class work?"}, {"role": "assistant", "content": "The `OccupancyCostmap` class represents a map of the environment where obstacles or inaccessible positions have a value of -1.\n\n**Attributes:**\n- `world`\n\n**Methods:**\n- `_calculate_diff_origin(height: int, width: int) → pycram.datastructures.pose.Pose`: Calculates the difference between the origin of the costmap and its center.\n- `_get_map() → numpy.ndarray`: Retrieves the map array from the map server and converts it into a numpy array.\n- `_get_map_metadata() → nav_msgs.msg.MapMetaData`: Retrieves metadata about the costmap from the map server.\n- `_convert_map(map: numpy.ndarray) → numpy.ndarray`: Converts the occupancy map from ROS to be consistent with PyCRAM.\n- `create_sub_map(sub_origin: pycram.datastructures.pose.Pose, size: int) → Costmap`: Creates a smaller map centered around a specific point.\n- `_create_from_world(size: int, resolution: float) → numpy.ndarray`: Creates an Occupancy Costmap for the World, marking valid positions."}, {"role": "user", "content": "What is the 'VisibilityCostmap' class?"}, {"role": "assistant", "content": "The `VisibilityCostmap` class represents the visibility of a specific point from every position around it.\n\n**Attributes:**\n- `world`\n- `map`\n- `size`\n- `resolution`\n- `max_height`: float\n- `min_height`: float\n- `origin`: `pycram.datastructures.pose.Pose`\n\n**Methods:**\n- `_create_images() → typing_extensions.List[numpy.ndarray]`: Creates four depth images around the point of interest.\n- `_depth_buffer_to_meter(buffer: numpy.ndarray) → numpy.ndarray`: Converts depth images to represent positions in meters.\n- `_generate_map()`: Generates the density map using an algorithm."}, {"role": "user", "content": "Explain the 'GaussianCostmap' class."}, {"role": "assistant", "content": "The `GaussianCostmap` class represents 2D Gaussian distributions around the origin with a given mean and sigma.\n\n**Attributes:**\n- `gau`: `numpy.ndarray`\n- `map`: `numpy.ndarray`\n- `size`: float\n- `origin`: `pycram.datastructures.pose.Pose`\n\n**Methods:**\n- `_gaussian_window(mean: int, std: float) → numpy.ndarray`: Creates a window of Gaussian distribution values."}, {"role": "user", "content": "What about the 'SemanticCostmap' class?"}, {"role": "assistant", "content": "The `SemanticCostmap` class represents a 2D distribution over a link of an object, such as a table surface.\n\n**Attributes:**\n- `world`: `pycram.datastructures.world.World`\n- `object`: `pycram.world_concepts.world_object.Object`\n- `link`: `pycram.description.Link`\n- `resolution`: float\n- `origin`: `pycram.datastructures.pose.Pose`\n- `height`: int = 0\n- `width`: int = 0\n- `map`: `numpy.ndarray` = []\n\n**Methods:**\n- `generate_map() → None`: Generates the semantic costmap based on the link's axis-aligned bounding box (AABB).\n- `get_aabb_for_link() → pycram.datastructures.dataclasses.AxisAlignedBoundingBox`: Returns the AABB of the link."}, {"role": "user", "content": "Tell me about the 'plot_grid' function."}, {"role": "assistant", "content": "The `plot_grid` function is an auxiliary method used for debugging. It plots a 2D numpy array using Matplotlib.\n\n**Parameters:**\n- `data`: A 2D numpy array representing the data to be plotted.\n\n**Returns:** None"}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the components and methods available in the 'pycram.datastructures.pose' module?"}, {"role": "assistant", "content": "Sure! The 'pycram.datastructures.pose' module in PyCRAM provides classes and functions related to pose and transformation representations, which are compatible with ROS services and messages. Would you like an overview of all the classes and functions first?"}, {"role": "user", "content": "Yes, please list all the components in the 'pycram.datastructures.pose' module."}, {"role": "assistant", "content": "The 'pycram.datastructures.pose' module includes the following components:\n\n**Classes:**\n1. `Pose`\n2. `Transform`\n\n**Functions:**\n1. `get_normalized_quaternion(quaternion: numpy.ndarray) → geometry_msgs.msg.Quaternion`\n\nWhich class or function would you like to know more about first?"}, {"role": "user", "content": "Tell me about the 'Pose' class."}, {"role": "assistant", "content": "The `Pose` class represents a pose in PyCRAM, extending the PoseStamped ROS message from geometry_msgs, making it compatible with ROS services and messages.\n\n**Properties:**\n- `frame`: str — The TF frame of this Pose.\n- `position`: geometry_msgs.msg.Point — The position of this pose.\n- `orientation`: geometry_msgs.msg.Quaternion — The orientation of this pose.\n\n**Methods:**\n- `from_pose_stamped(pose_stamped: geometry_msgs.msg.PoseStamped) → Pose`: Converts a PoseStamped message to a Pose object.\n- `to_list() → typing_extensions.List[typing_extensions.List[float]]`: Returns the position and orientation as lists.\n- `to_transform(child_frame: str) → Transform`: Converts this pose to a Transform.\n- `copy() → Pose`: Creates a deep copy of this pose.\n- `position_as_list() → typing_extensions.List[float]`: Returns the position as a list of xyz.\n- `orientation_as_list() → typing_extensions.List[float]`: Returns the orientation as a quaternion.\n- `dist(other_pose: Pose) → float`: Calculates the Euclidean distance between this pose and another.\n- `__eq__(other: Pose) → bool`: Checks for equality between two poses.\n- `set_position(new_position: typing_extensions.List[float]) → None`: Sets the position of this pose.\n- `set_orientation(new_orientation: typing_extensions.List[float]) → None`: Sets the orientation of this pose.\n- `to_sql() → pycram.orm.base.Pose`\n- `insert(session: sqlalchemy.orm.Session) → pycram.orm.base.Pose`\n- `multiply_quaternions(quaternion: typing_extensions.List) → None`: Multiplies the orientation quaternion by another quaternion.\n- `set_orientation_from_euler(axis: typing_extensions.List, euler_angles: typing_extensions.List[float]) → None`: Converts axis-angle to quaternion."}, {"role": "user", "content": "And what about the 'Transform' class?"}, {"role": "assistant", "content": "The `Transform` class represents a transformation from one TF frame to another in PyCRAM, extending the TransformStamped ROS message from geometry_msgs, making it compatible with ROS services and messages.\n\n**Properties:**\n- `frame`: str — The TF frame of this Transform.\n- `translation`: None — The translation of this Transform.\n- `rotation`: None — The rotation of this Transform.\n\n**Methods:**\n- `from_pose_and_child_frame(pose: Pose, child_frame_name: str) → Transform`: Creates a Transform from a Pose and a child frame name.\n- `from_transform_stamped(transform_stamped: geometry_msgs.msg.TransformStamped) → Transform`: Creates a Transform from a TransformStamped message.\n- `copy() → Transform`: Creates a deep copy of this Transform.\n- `translation_as_list() → typing_extensions.List[float]`: Returns the translation as a list of xyz.\n- `rotation_as_list() → typing_extensions.List[float]`: Returns the rotation as a quaternion.\n- `to_pose() → Pose`: Converts this Transform to a Pose, losing the child frame.\n- `invert() → Transform`: Inverts this Transform, reversing the direction.\n- `__mul__(other: Transform) → typing_extensions.Union[Transform, None]`: Multiplies this Transform with another one.\n- `inverse_times(other_transform: Transform) → Transform`: Subtracts another Transform from this one.\n- `__eq__(other: Transform) → bool`: Checks for equality between two Transforms.\n- `set_translation(new_translation: typing_extensions.List[float]) → None`: Sets the translation of this Transform.\n- `set_rotation(new_rotation: typing_extensions.List[float]) → None`: Sets the rotation of this Transform."}, {"role": "user", "content": "Tell me about the 'get_normalized_quaternion' function."}, {"role": "assistant", "content": "The `get_normalized_quaternion` function normalizes a given quaternion so that it has a magnitude of 1.\n\n**Parameters:**\n- `quaternion`: numpy.ndarray — The quaternion to be normalized.\n\n**Returns:**\n- `geometry_msgs.msg.Quaternion` — The normalized quaternion."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the components and methods available in the 'pycram.designators.object_designator' module?"}, {"role": "assistant", "content": "Sure! The 'pycram.designators.object_designator' module in PyCRAM provides classes for describing and working with objects within the system, particularly focusing on their believed, located, or real-world representations. Would you like an overview of all the classes in this module first?"}, {"role": "user", "content": "Yes, please list all the classes in the 'pycram.designators.object_designator' module."}, {"role": "assistant", "content": "The 'pycram.designators.object_designator' module includes the following classes:\n1. `BelieveObject`\n2. `ObjectPart`\n3. `LocatedObject`\n4. `RealObject`\n\nWhich class would you like to know more about first?"}, {"role": "user", "content": "Tell me about the 'BelieveObject' class."}, {"role": "assistant", "content": "The `BelieveObject` class describes objects that are only believed to exist, typically without physical verification.\n\n**Methods:**\n- `to_sql() → pycram.orm.object_designator.BelieveObject`: Creates an ORM object corresponding to this description.\n- `insert(session: sqlalchemy.orm.session.Session) → pycram.orm.object_designator.BelieveObject`: Adds and commits this and all related objects to the session."}, {"role": "user", "content": "And what about the 'ObjectPart' class?"}, {"role": "assistant", "content": "The `ObjectPart` class describes objects that are part of another object.\n\n**Attributes:**\n- `part_pose`: `pycram.external_interfaces.robokudo.Pose` — The pose of the part in relation to the whole object.\n\n**Methods:**\n- `to_sql() → pycram.orm.object_designator.ObjectPart`: Creates an ORM object corresponding to this description.\n- `insert(session: sqlalchemy.orm.session.Session) → pycram.orm.object_designator.ObjectPart`: Adds and commits this and all related objects to the session.\n- `ground() → Object`: Returns the first result of the iterator of this instance.\n- `__iter__()`: Iterates through every possible solution for the given input parameter."}, {"role": "user", "content": "Tell me about the 'LocatedObject' class."}, {"role": "assistant", "content": "The `LocatedObject` class provides a description for objects located via KnowRob. It currently has no specialized designators.\n\n**Attributes:**\n- `reference_frame`: `str` — The reference frame in which the position is given.\n- `timestamp`: `float` — The timestamp at which the position was valid.\n- **Additional Attributes:**\n  - `reference_frames`: `pycram.external_interfaces.robokudo.List[str]`\n  - `timestamps`: `pycram.external_interfaces.robokudo.List[float]`"}, {"role": "user", "content": "How does the 'RealObject' class work?"}, {"role": "assistant", "content": "The `RealObject` class represents an object in the real world. When resolving this object designator description, RoboKudo is queried to perceive an object fitting the given criteria. The specialized designator then tries to match the found object to an object in the world.\n\n**Attributes:**\n- `pose`: `pycram.external_interfaces.robokudo.Pose` — The pose of the perceived object.\n- `types`: `pycram.external_interfaces.robokudo.Optional[pycram.external_interfaces.robokudo.List[str]]`\n- `names`: `pycram.external_interfaces.robokudo.Optional[pycram.external_interfaces.robokudo.List[str]]`\n- `world_object`: `pycram.world_concepts.world_object.Object`\n\n**Methods:**\n- `__iter__()`: Queries RoboKudo for objects that fit the description and then iterates over all World objects of the same type to match a World object to the real object."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the components and methods available in the 'pycram.datastructures.dataclasses' module?"}, {"role": "assistant", "content": "Sure! The 'pycram.datastructures.dataclasses' module in PyCRAM provides several classes and functions that represent various data structures, such as colors, bounding boxes, visual shapes, and states. Would you like an overview of all the classes and functions in this module first?"}, {"role": "user", "content": "Yes, please list all the classes in the 'pycram.datastructures.dataclasses' module."}, {"role": "assistant", "content": "The 'pycram.datastructures.dataclasses' module includes the following classes:\n1. `Color`\n2. `AxisAlignedBoundingBox`\n3. `CollisionCallbacks`\n4. `MultiBody`\n5. `VisualShape`\n6. `BoxVisualShape`\n7. `SphereVisualShape`\n8. `CapsuleVisualShape`\n9. `CylinderVisualShape`\n10. `MeshVisualShape`\n11. `PlaneVisualShape`\n12. `State`\n13. `LinkState`\n14. `JointState`\n15. `ObjectState`\n16. `WorldState`\n\nWhich class would you like to know more about first?"}, {"role": "user", "content": "Tell me about the 'Color' class."}, {"role": "assistant", "content": "The `Color` class is a dataclass for storing RGBA color values as floats between 0 and 1. The default color is white, and 'A' stands for opacity.\n\n**Attributes:**\n- `R`: `float = 1`\n- `G`: `float = 1`\n- `B`: `float = 1`\n- `A`: `float = 1`\n\n**Methods:**\n- `from_list(color: typing_extensions.List[float])`: Sets the RGBA color from a list of values.\n- `from_rgb(rgb: typing_extensions.List[float])`: Sets the color from a list of RGB values.\n- `from_rgba(rgba: typing_extensions.List[float])`: Sets the color from a list of RGBA values.\n- `get_rgba() -> typing_extensions.List[float]`: Returns the color as a list of RGBA values.\n- `get_rgb() -> typing_extensions.List[float]`: Returns the color as a list of RGB values."}, {"role": "user", "content": "And what about the 'AxisAlignedBoundingBox' class?"}, {"role": "assistant", "content": "The `AxisAlignedBoundingBox` class is a dataclass for storing the minimum and maximum points of an axis-aligned bounding box.\n\n**Attributes:**\n- `min_x`: `float`\n- `min_y`: `float`\n- `min_z`: `float`\n- `max_x`: `float`\n- `max_y`: `float`\n- `max_z`: `float`\n\n**Methods:**\n- `from_min_max(min_point: typing_extensions.List[float], max_point: typing_extensions.List[float])`: Sets the bounding box from minimum and maximum points.\n- `get_min_max_points() -> typing_extensions.Tuple[pycram.datastructures.pose.Point, pycram.datastructures.pose.Point]`: Returns the bounding box as a tuple of minimum and maximum points.\n- `get_min_point() -> pycram.datastructures.pose.Point`: Returns the minimum point of the bounding box.\n- `get_max_point() -> pycram.datastructures.pose.Point`: Returns the maximum point of the bounding box.\n- `get_min_max() -> typing_extensions.Tuple[typing_extensions.List[float], typing_extensions.List[float]]`: Returns the bounding box as a tuple of minimum and maximum points.\n- `get_min() -> typing_extensions.List[float]`: Returns the minimum point as a list.\n- `get_max() -> typing_extensions.List[float]`: Returns the maximum point as a list."}, {"role": "user", "content": "Tell me about the 'CollisionCallbacks' class."}, {"role": "assistant", "content": "The `CollisionCallbacks` class handles collision callbacks in the system.\n\n**Attributes:**\n- `on_collision_cb`: `typing_extensions.Callable` — A callback function for when a collision occurs.\n- `no_collision_cb`: `typing_extensions.Optional[typing_extensions.Callable] = None` — An optional callback function for when no collision occurs."}, {"role": "user", "content": "What is the 'MultiBody' class?"}, {"role": "assistant", "content": "The `MultiBody` class represents a multi-body system in the simulation.\n\n**Attributes:**\n- `base_visual_shape_index`: `int` — Index of the base visual shape.\n- `base_pose`: `pycram.datastructures.pose.Pose` — Pose of the base.\n- `link_visual_shape_indices`: `typing_extensions.List[int]` — Indices of the visual shapes for the links.\n- `link_poses`: `typing_extensions.List[pycram.datastructures.pose.Pose]` — Poses of the links.\n- `link_masses`: `typing_extensions.List[float]` — Masses of the links.\n- `link_inertial_frame_poses`: `typing_extensions.List[pycram.datastructures.pose.Pose]` — Poses of the inertial frames of the links.\n- `link_parent_indices`: `typing_extensions.List[int]` — Indices of the parent links.\n- `link_joint_types`: `typing_extensions.List[pycram.datastructures.enums.JointType]` — Types of the joints.\n- `link_joint_axis`: `typing_extensions.List[pycram.datastructures.pose.Point]` — Axes of the joints.\n- `link_collision_shape_indices`: `typing_extensions.List[int]` — Indices of the collision shapes for the links."}, {"role": "user", "content": "How does the 'VisualShape' class work?"}, {"role": "assistant", "content": "The `VisualShape` class is a helper class that provides a standard way to create an abstract base class (ABC) using inheritance.\n\n**Attributes:**\n- `rgba_color`: `Color` — The RGBA color of the visual shape.\n- `visual_frame_position`: `typing_extensions.List[float]` — The position of the visual frame.\n\n**Methods:**\n- `shape_data() -> typing_extensions.Dict[str, typing_extensions.Any]`: An abstract method to return the shape data of the visual shape.\n\n**Properties:**\n- `visual_geometry_type`: `pycram.datastructures.enums.Shape` — An abstract property to return the visual geometry type of the visual shape (e.g., box, sphere)."}, {"role": "user", "content": "Tell me about the 'BoxVisualShape' class."}, {"role": "assistant", "content": "The `BoxVisualShape` class is a helper class that inherits from `VisualShape` to represent a box visual shape.\n\n**Attributes:**\n- `half_extents`: `typing_extensions.List[float]` — The half extents of the box.\n\n**Methods:**\n- `shape_data() -> typing_extensions.Dict[str, typing_extensions.List[float]]`: Returns the shape data of the box, such as its half extents.\n\n**Properties:**\n- `visual_geometry_type`: `pycram.datastructures.enums.Shape` — Returns the visual geometry type of the box.\n- `size`: `typing_extensions.List[float]` — Returns the size of the box."}, {"role": "user", "content": "How does the 'SphereVisualShape' class work?"}, {"role": "assistant", "content": "The `SphereVisualShape` class is a helper class that inherits from `VisualShape` to represent a sphere visual shape.\n\n**Attributes:**\n- `radius`: `float` — The radius of the sphere.\n\n**Methods:**\n- `shape_data() -> typing_extensions.Dict[str, float]`: Returns the shape data of the sphere, such as its radius.\n\n**Properties:**\n- `visual_geometry_type`: `pycram.datastructures.enums.Shape` — Returns the visual geometry type of the sphere."}, {"role": "user", "content": "And what about the 'CapsuleVisualShape' class?"}, {"role": "assistant", "content": "The `CapsuleVisualShape` class is a helper class that inherits from `VisualShape` to represent a capsule visual shape.\n\n**Attributes:**\n- `radius`: `float` — The radius of the capsule.\n- `length`: `float` — The length of the capsule.\n\n**Methods:**\n- `shape_data() -> typing_extensions.Dict[str, float]`: Returns the shape data of the capsule, such as its radius and length.\n\n**Properties:**\n- `visual_geometry_type`: `pycram.datastructures.enums.Shape` — Returns the visual geometry type of the capsule."}, {"role": "user", "content": "Tell me about the 'CylinderVisualShape' class."}, {"role": "assistant", "content": "The `CylinderVisualShape` class is a helper class that inherits from `CapsuleVisualShape` to represent a cylinder visual shape.\n\n**Properties:**\n- `visual_geometry_type`: `pycram.datastructures.enums.Shape` — Returns the visual geometry type of the cylinder."}, {"role": "user", "content": "What is the 'MeshVisualShape' class?"}, {"role": "assistant", "content": "The `MeshVisualShape` class is a helper class that inherits from `VisualShape` to represent a mesh visual shape.\n\n**Attributes:**\n- `scale`: `typing_extensions.List[float]` — The scale of the mesh.\n- `file_name`: `str` — The file name of the mesh.\n\n**Methods:**\n- `shape_data() -> typing_extensions.Dict[str, typing_extensions.Union[typing_extensions.List[float], str]]`: Returns the shape data of the mesh, including its scale and file name.\n\n**Properties:**\n- `visual_geometry_type`: `pycram.datastructures.enums.Shape` — Returns the visual geometry type of the mesh."}, {"role": "user", "content": "How does the 'PlaneVisualShape' class work?"}, {"role": "assistant", "content": "The `PlaneVisualShape` class is a helper class that inherits from `VisualShape` to represent a plane visual shape.\n\n**Attributes:**\n- `normal`: `typing_extensions.List[float]` — The normal vector of the plane.\n\n**Methods:**\n- `shape_data() -> typing_extensions.Dict[str, typing_extensions.List[float]]`: Returns the shape data of the plane, such as its normal vector.\n\n**Properties:**\n- `visual_geometry_type`: `pycram.datastructures.enums.Shape` — Returns the visual geometry type of the plane."}, {"role": "user", "content": "Tell me about the 'State' class."}, {"role": "assistant", "content": "The `State` class is a helper class that provides a standard way to create an abstract base class (ABC) using inheritance. It serves as the foundation for various state classes in PyCRAM."}, {"role": "user", "content": "What does the 'LinkState' class do?"}, {"role": "assistant", "content": "The `LinkState` class is a helper class that inherits from `State` and provides a way to represent the state of a link in PyCRAM.\n\n**Attributes:**\n- `constraint_ids`: `typing_extensions.Dict[pycram.description.Link, int]` — A dictionary mapping links to their constraint IDs."}, {"role": "user", "content": "Tell me about the 'JointState' class."}, {"role": "assistant", "content": "The `JointState` class is a helper class that inherits from `State` and represents the state of a joint in PyCRAM.\n\n**Attributes:**\n- `position`: `float` — The position of the joint."}, {"role": "user", "content": "What about the 'ObjectState' class?"}, {"role": "assistant", "content": "The `ObjectState` class is a helper class that inherits from `State` and represents the state of an object in PyCRAM.\n\n**Attributes:**\n- `pose`: `pycram.datastructures.pose.Pose` — The pose of the object.\n- `attachments`: `typing_extensions.Dict[pycram.world_concepts.world_object.Object, pycram.world_concepts.constraints.Attachment]` — A dictionary mapping objects to their attachments.\n- `link_states`: `typing_extensions.Dict[int, LinkState]` — A dictionary mapping link IDs to their states.\n- `joint_states`: `typing_extensions.Dict[int, JointState]` — A dictionary mapping joint IDs to their states."}, {"role": "user", "content": "And finally, what is the 'WorldState' class?"}, {"role": "assistant", "content": "The `WorldState` class is a helper class that inherits from `State` and represents the overall state of the world in PyCRAM.\n\n**Attributes:**\n- `simulator_state_id`: `int` — The ID of the simulator state.\n- `object_states`: `typing_extensions.Dict[str, ObjectState]` — A dictionary mapping object names to their states."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the concept of Designators in PyCRAM and the different types available?"}, {"role": "assistant", "content": "Designators in PyCRAM represent actions, motions, objects, and locations. They consist of a description and a specified element, where the description defines a set of possible designators, and the designator is a specific instance within that set. During runtime, a designator description is resolved to a specific designator, which can then be executed to perform the desired behavior.\n\nFor example, a NavigateAction description might list possible poses that the robot could move to in order to grasp an object. This description is resolved to a specific designator with parameters suitable for execution.\n\nThere are four main types of designators in PyCRAM:\n1. **Action Designators** - Describe complex, executable actions for an agent, including failure handling and parametrization.\n2. **Object Designators** - Represent objects in the simulated world, matching objects by name or type.\n3. **Motion Designators** - Describe atomic, executable actions for an agent, with strict typing and no failure handling.\n4. **Location Designators** - Define a set of locations based on specific constraints like reachability or visibility."}, {"role": "user", "content": "Tell me more about Object Designators."}, {"role": "assistant", "content": "Object Designators in PyCRAM represent objects in the (simulated) world. They can be described using names or types that the object should match. The `ground` method returns an object that matches the description, while the `__iter__` method iterates over all objects that fit the description.\n\nTo create a new Object Designator, you should inherit from the general `ObjectDesignatorDescription` class. If the object they ground to differs from the base object, a dataclass should be created inside the new description. To enable ORM logging for the new objects, you must implement the `to_sql()` and `insert()` methods."}, {"role": "user", "content": "What about Action Designators?"}, {"role": "assistant", "content": "Action Designators describe complex actions that an agent can execute. They act as higher-level plans that include failure handling and parameterization. An Action Designator description takes a list of possible parameters, and when resolved, it picks one parameter from the list to create a specific designator.\n\nThe resolved designator can then be executed to perform the action. Action Designators are useful for defining more sophisticated behaviors where multiple factors must be considered during execution."}, {"role": "user", "content": "Explain Motion Designators."}, {"role": "assistant", "content": "Motion Designators describe atomic actions that an agent can execute, such as moving a robotic arm or opening a gripper. Unlike Action Designators, Motion Designators do not include failure handling and are more straightforward. They take a single, strictly-typed parameter instead of a list of possible parameters.\n\nThe `perform` method of a Motion Designator passes the resolved designator to the respective Process Module for execution on the robot. This makes Motion Designators ideal for defining precise, low-level actions."}, {"role": "user", "content": "Tell me about Location Designators."}, {"role": "assistant", "content": "Location Designators define a set of possible locations based on specific constraints, such as reachability or visibility. They return a single pose from the set that meets the given constraints.\n\nLike Object Designators, Location Designators also have an `__iter__` method that can iterate over all possible solutions for the description. This allows you to explore multiple potential locations that satisfy the specified criteria."}, {"role": "user", "content": "How can I create my own Designator?"}, {"role": "assistant", "content": "Creating your own Designator in PyCRAM involves extending the base class of the respective description type:\n\n- For actions, extend `ActionDesignatorDescription`.\n- For objects, extend `ObjectDesignatorDescription`.\n- For locations, extend `LocationDesignatorDescription`.\n- For motions, extend `BaseMotion`.\n\nYou need to implement a `ground` method, which acts as the default resolver for the designator. For Object and Location Designators, you should also implement an `__iter__` method to iterate over possible solutions. The sub-class you create can include parameters specific to your designator type, and for Action and Motion Designators, you should define a `perform` method that dictates the behavior of the designator when executed."}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the different types of Action Designators available in PyCRAM and how they are used?"}, {"role": "assistant", "content": "Action Designators in PyCRAM are high-level descriptions of actions that a robot should execute. These designators are created from an Action Designator Description, which describes the type of action and the parameters for the action, often provided as a list of possible values. When resolved, the description returns a specific, performable Action Designator. Would you like to start with an example of a simple Navigate Action?"}, {"role": "user", "content": "Yes, please show me an example of a Navigate Action."}, {"role": "assistant", "content": "To start with a Navigate Action, you'll first need to create a BulletWorld with a robot. Here’s how you can do it:\n\n```python\nfrom pycram.worlds.bullet_world import BulletWorld\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType, WorldMode\n\nworld = BulletWorld(WorldMode.GUI)\npr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\n```\n\nNext, you can create a description for navigation by specifying a list of possible poses and then resolve it to get a performable designator:\n\n```python\nfrom pycram.designators.action_designator import NavigateAction\nfrom pycram.datastructures.pose import Pose\n\npose = Pose([1, 0, 0], [0, 0, 0, 1])\n\nnavigate_description = NavigateAction(target_locations=[pose])\nnavigate_designator = navigate_description.resolve()\n```\n\nThis will create an Action Designator that can be performed. The designator will move the robot to the pose selected from the list:\n\n```python\nfrom pycram.process_module import simulated_robot\n\nwith simulated_robot:\n    navigate_designator.perform()\n```\n\nYou can perform this designator within a simulation environment like `simulated_robot` or on a real robot using `real_robot`. Would you like to see another example, such as moving the robot’s torso or setting the gripper state?"}, {"role": "user", "content": "Yes, show me how to move the robot's torso."}, {"role": "assistant", "content": "To move the robot’s torso, you’ll use the `MoveTorsoAction` designator. Here’s how you can create a description and resolve it to a performable designator:\n\n```python\nfrom pycram.designators.action_designator import MoveTorsoAction\nfrom pycram.process_module import simulated_robot\n\ntorso_pose = 0.2\ntorso_desig = MoveTorsoAction([torso_pose]).resolve()\n\nwith simulated_robot:\n    torso_desig.perform()\n```\n\nThis example sets the torso joint to the specified value (`0.2`). You perform the designator within the `simulated_robot` environment to see the effect in the simulation. Would you like to explore how to control the robot’s gripper or perform other actions?"}, {"role": "user", "content": "Yes, show me how to control the gripper."}, {"role": "assistant", "content": "To control the robot’s gripper, you can use the `SetGripperAction` designator. Here’s how you can open or close the gripper:\n\n```python\nfrom pycram.designators.action_designator import SetGripperAction\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.enums import GripperState, Arms\n\ngripper = Arms.RIGHT\nmotion = GripperState.OPEN\n\nwith simulated_robot:\n    SetGripperAction(grippers=[gripper], motions=[motion]).resolve().perform()\n```\n\nThis code snippet will open the right gripper of the robot. Similarly, you can close the gripper by setting `GripperState.CLOSE`. Would you like to learn about other actions, such as parking the robot’s arms or performing a pick-and-place operation?"}, {"role": "user", "content": "Show me how to park the robot's arms."}, {"role": "assistant", "content": "To park the robot's arms, you can use the `ParkArmsAction` designator. Here's how you can move one or both arms into the default parking position:\n\n```python\nfrom pycram.designators.action_designator import ParkArmsAction\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.enums import Arms\n\nwith simulated_robot:\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n```\n\nThis example parks both arms of the robot. You can also specify a single arm, such as `Arms.LEFT` or `Arms.RIGHT`, if you want to park only one arm. Would you like to see how to perform more complex tasks like picking up and placing objects?"}, {"role": "user", "content": "Yes, show me how to pick up and place an object."}, {"role": "assistant", "content": "To pick up and place an object, you'll use the `PickUpAction` and `PlaceAction` designators. These actions typically involve object designators to specify the object you want to interact with. Here's how you can set up an environment and perform these actions:\n\nFirst, create a kitchen environment and an object (e.g., a milk carton) to interact with:\n\n```python\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.3, 1, 0.9]))\n\nworld.reset_world()\n```\n\nNext, you can use the following code to pick up and place the milk carton:\n\n```python\nfrom pycram.designators.action_designator import PickUpAction, PlaceAction, ParkArmsAction, MoveTorsoAction, NavigateAction\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.enums import Arms, Grasp\nfrom pycram.datastructures.pose import Pose\n\nmilk_desig = BelieveObject(names=[\"milk\"])\narm = Arms.RIGHT\n\nwith simulated_robot:\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n    MoveTorsoAction([0.3]).resolve().perform()\n    NavigateAction([Pose([0.78, 1, 0.0], [0.0, 0.0, 0.014701099828940344, 0.9998919329926708])]).resolve().perform()\n    PickUpAction(object_designator_description=milk_desig, arms=[arm], grasps=[Grasp.RIGHT]).resolve().perform()\n    NavigateAction([Pose([-1.90, 0.78, 0.0], [0.0, 0.0, 0.16439898301071468, 0.9863939245479175])]).resolve().perform()\n    PlaceAction(object_designator_description=milk_desig, target_locations=[Pose([-1.20, 1.0192, 0.9624], [0, 0, 0, 1])], arms=[arm]).resolve().perform()\n```\n\nThis sequence parks the robot's arms, moves the torso, navigates to the milk carton, picks it up, navigates to the target location, and then places the milk carton down. Would you like to explore more actions, such as looking at objects or detecting objects in the environment?"}, {"role": "user", "content": "Yes, show me how to make the robot look at an object."}, {"role": "assistant", "content": "To make the robot look at a specific object or point, you can use the `LookAtAction` designator. Here’s an example of how to do it:\n\n```python\nfrom pycram.designators.action_designator import LookAtAction\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.pose import Pose\n\ntarget_location = Pose([1, 0, 0.5], [0, 0, 0, 1])\n\nwith simulated_robot:\n    LookAtAction(targets=[target_location]).resolve().perform()\n```\n\nIn this example, the robot will look at the point specified by `target_location`. This is useful for tasks like object detection, where the robot needs to focus on a specific area. Would you like to proceed with an example of detecting objects in the robot’s field of vision?"}, {"role": "user", "content": "Yes, show me how to detect objects."}, {"role": "assistant", "content": "To detect objects within the robot’s field of vision (FOV), you can use the `DetectAction` designator. Here’s how you can do it, continuing from the previous examples where we had a milk carton in the environment:\n\n```python\nfrom pycram.designators.action_designator import DetectAction, LookAtAction, ParkArmsAction, NavigateAction\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.pose import Pose\n\nmilk_desig = BelieveObject(names=[\"milk\"])\n\nwith simulated_robot:\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n    NavigateAction([Pose([0, 1, 0], [0, 0, 0, 1])]).resolve().perform()\n    LookAtAction(targets=[milk_desig.resolve().pose]).resolve().perform()\n    obj_desig = DetectAction(milk_desig).resolve().perform()\n\n    print(obj_desig)\n```\n\nThis code makes the robot park its arms, navigate to a location, look at the milk carton, and then detect it. The `DetectAction` designator returns a resolved instance of an `ObjectDesignatorDescription`, which can be used in further tasks. Would you like to explore more complex actions, such as transporting objects or opening and closing drawers?"}, {"role": "user", "content": "Show me how to transport an object."}, {"role": "assistant", "content": "Transporting an object involves moving it from its current position to another target position. This is similar to the pick-and-place operation but as a continuous action. Here’s how you can transport an object, assuming you’ve already spawned a milk carton:\n\n```python\nfrom pycram.designators.action_designator import TransportAction, MoveTorsoAction\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.pose import Pose\nfrom pycram.datastructures.enums import Arms\n\nmilk_desig = BelieveObject(names=[\"milk\"])\n\ndescription = TransportAction(milk_desig, [Arms.LEFT], [Pose([-1.35, 0.78, 0.95], [0.0, 0.0, 0.16439898301071468, 0.9863939245479175])])\n\nwith simulated_robot:\n    MoveTorsoAction([0.2]).resolve().perform()\n    description.resolve().perform()\n```\n\nThis example makes the robot pick up the milk carton and transport it to the specified target location. The `TransportAction` designator combines navigation and object manipulation into a single action. Would you like to see examples of more specialized actions like opening or closing drawers?"}, {"role": "user", "content": "Yes, show me how to open a drawer."}, {"role": "assistant", "content": "To open a drawer, you can use the `OpenAction` designator along with an `ObjectPart` designator to specify the handle of the drawer. Here’s how you can do it:\n\nFirst, make sure you’re working in the apartment environment since this action is specific to it. If you’re not already in the apartment environment, remove the kitchen and load the apartment:\n\n```python\nkitchen.remove()\napartment = Object(\"apartment\", ObjectType.ENVIRONMENT, \"apartment.urdf\")\n```\n\nThen, use the following code to open the drawer:\n\n```python\nfrom pycram.designators.action_designator import OpenAction, ParkArmsAction, NavigateAction, MoveTorsoAction\nfrom pycram.designators.object_designator import BelieveObject, ObjectPart\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.pose import Pose\n\napartment_desig = BelieveObject(names=[\"apartment\"]).resolve()\nhandle_desig = ObjectPart(names=[\"handle_cab10_t\"], part_of=apartment_desig)\n\nwith simulated_robot:\n    MoveTorsoAction([0.25]).resolve().perform()\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n    NavigateAction([Pose([1.7474915981292725, 2.6873629093170166, 0.0], [-0.0, 0.0, 0.5253598267689507, -0.850880163370435])]).resolve().perform()\n    OpenAction(handle_desig, [Arms.RIGHT]).resolve().perform()\n```\n\nThis sequence parks the robot’s arms, moves the torso, navigates to the drawer, and then opens it using the specified handle. Would you like to see how to close the drawer or perform other actions in the apartment environment?"}, {"role": "user", "content": "Show me how to close a drawer."}, {"role": "assistant", "content": "To close a drawer, you can use the `CloseAction` designator, similar to how you opened it. Here’s how you can do it, assuming the drawer is already open:\n\nIf you haven't already, load the apartment environment and open the drawer:\n\n```python\nkitchen.remove()\napartment = Object(\"apartment\", ObjectType.ENVIRONMENT, \"apartment.urdf\")\napartment.set_joint_state(\"cabinet10_drawer_top_joint\", 0.4)\n```\n\nThen, use the following code to close the drawer:\n\n```python\nfrom pycram.designators.action_designator import CloseAction, ParkArmsAction, NavigateAction, MoveTorsoAction\nfrom pycram.designators.object_designator import BelieveObject, ObjectPart\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.pose import Pose\n\napartment_desig = BelieveObject(names=[\"apartment\"]).resolve()\nhandle_desig = ObjectPart(names=[\"handle_cab10_t\"], part_of=apartment_desig)\n\nwith simulated_robot:\n    MoveTorsoAction([0.25]).resolve().perform()\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n    NavigateAction([Pose([1.7474915981292725, 2.8073629093170166, 0.0], [-0.0, 0.0, 0.5253598267689507, -0.850880163370435])]).resolve().perform()\n    CloseAction(handle_desig, [Arms.RIGHT]).resolve().perform()\n```\n\nThis sequence will navigate the robot to the drawer, grasp the handle, and close the drawer. Let me know if you’d like to explore more actions or have any other questions!"}]}
{"messages": [{"role": "system", "content": "You are an expert in coding and specialized on the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain how to use Location Designators in PyCRAM?"}, {"role": "assistant", "content": "Location Designators in PyCRAM are used to semantically describe locations in the world. They can describe locations for visibility, reachability, occupancy, and URDF links, such as a table. Location designators create Costmaps, which are 2D distributions that identify locations fitting specified criteria. Would you like to start with an example of creating a simple location designator that ensures the robot is placed without colliding with the environment?"}, {"role": "user", "content": "Yes, please show me how to create a simple location designator."}, {"role": "assistant", "content": "To create a simple location designator, you first need a BulletWorld, as costmaps are generated based on the current state of the BulletWorld. Here’s how you can set it up:\n\n```python\nfrom pycram.worlds.bullet_world import BulletWorld\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType, WorldMode\nfrom pycram.datastructures.pose import Pose\n\nworld = BulletWorld()\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\n```\n\nNext, create a location designator description using `CostmapLocation`. This will describe the location based on a target, which in this case is simply the kitchen's pose:\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\n\ntarget = kitchen.get_pose()\nlocation_description = CostmapLocation(target)\n\npose = location_description.resolve()\n\nprint(pose)\n```\n\nThis will resolve to a 6D pose where the robot can be placed without colliding with the environment. Would you like to see an example of finding a location from where the robot can reach a specific object?"}, {"role": "user", "content": "Yes, show me how to find a location where the robot can reach an object."}, {"role": "assistant", "content": "To find a location from where the robot can reach an object, you can use the `CostmapLocation` designator, similar to the previous example. This time, you’ll also need to provide the robot as an additional argument. Here's how you can do it:\n\nFirst, let's set up the PR2 robot and an object, such as a milk carton, that the robot should reach:\n\n```python\npr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\npr2.set_joint_state(\"torso_lift_joint\", 0.2)\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.3, 1, 0.9]))\n```\n\nNext, create the location designator:\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\n\ntarget = BelieveObject(names=[\"milk\"]).resolve()\nrobot_desig = BelieveObject(names=[\"pr2\"]).resolve()\n\nlocation_description = CostmapLocation(target=target, reachable_for=robot_desig)\n\nprint(location_description.resolve())\n```\n\nThis code will return a pose near the countertop where the robot can be placed without colliding with the environment, and it will also specify which arms of the robot can reach the given object. Would you like to see how to find a location from where the robot can see a specific object?"}, {"role": "user", "content": "Yes, show me how to find a visible location."}, {"role": "assistant", "content": "To find a location from where the robot can see a specific object, you can use the `CostmapLocation` designator with the `visible_for` parameter. Here's how you can do it, continuing with the PR2 robot and the milk carton as the target object:\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\n\ntarget = BelieveObject(names=[\"milk\"]).resolve()\nrobot_desig = BelieveObject(names=[\"pr2\"]).resolve()\n\nlocation_description = CostmapLocation(target=target, visible_for=robot_desig)\n\nprint(location_description.resolve())\n```\n\nThis will find and return a pose from which the robot can see the specified object. Would you like to explore how to create a semantic location designator for a specific area, like a table surface?"}, {"role": "user", "content": "Yes, show me how to create a semantic location designator."}, {"role": "assistant", "content": "A semantic location designator allows you to find poses on specific parts of an object, like a table surface. To do this, you need to provide the object and the URDF link representing the entity. Here’s how you can create a semantic location designator for placing an object on a kitchen island:\n\nIf you haven't already, set up the kitchen and milk objects:\n\n```python\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\")\n```\n\nNow, create the semantic location designator:\n\n```python\nfrom pycram.designators.location_designator import SemanticCostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\n\nkitchen_desig = BelieveObject(names=[\"kitchen\"]).resolve()\nmilk_desig = BelieveObject(names=[\"milk\"]).resolve()\n\nlocation_description = SemanticCostmapLocation(urdf_link_name=\"kitchen_island_surface\", part_of=kitchen_desig, for_object=milk_desig)\n\nprint(location_description.resolve())\n```\n\nThis will find and return a valid pose on the kitchen island where the milk can be placed. Would you like to learn how to use location designators as generators or how to access specific locations for actions like opening a drawer?"}, {"role": "user", "content": "Yes, show me how to use location designators as generators."}, {"role": "assistant", "content": "Location designators can be used as generators to iterate over all possible valid poses for a given description. This can be useful if the first pose doesn't work for some reason. Here's how you can use a location designator for visibility as a generator:\n\nFirst, if you haven't already, spawn the milk object:\n\n```python\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\")\n```\n\nThen, use the location designator to generate possible poses:\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\n\ntarget = BelieveObject(names=[\"milk\"]).resolve()\nrobot_desig = BelieveObject(names=[\"pr2\"]).resolve()\n\nlocation_description = CostmapLocation(target=target, visible_for=robot_desig)\n\nfor pose in location_description:\n    print(pose.pose)\n```\n\nThis will print out all possible valid poses from which the robot can see the milk. Would you like to learn how to access specific locations for actions like opening a drawer, or how to use a Giskard-based location designator for full-body IK?"}, {"role": "user", "content": "Show me how to access locations for actions like opening a drawer."}, {"role": "assistant", "content": "To access specific locations for actions like opening a drawer, you can use a specialized location designator. This designator will describe a location from which the robot can open the drawer, identified by an `ObjectPart` designator. Here's how you can set it up:\n\nFirst, if you haven’t already, remove the kitchen environment and load the apartment environment since this location designator works in the apartment environment:\n\n```python\nkitchen.remove()\n```\n\n```python\napartment = Object(\"apartment\", ObjectType.ENVIRONMENT, \"apartment.urdf\")\n```\n\nNext, spawn the PR2 robot if it isn't already spawned, and then create the location designator:\n\n```python\npr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\npr2.set_joint_state(\"torso_lift_joint\", 0.25)\n```\n\n```python\nfrom pycram.designators.object_designator import BelieveObject, ObjectPart\nfrom pycram.designators.location_designator import AccessingLocation\n\napartment_desig = BelieveObject(names=[\"apartment\"])\nhandle_desig = ObjectPart(names=[\"handle_cab10_t\"], part_of=apartment_desig.resolve())\nrobot_desig = BelieveObject(names=[\"pr2\"])\n\naccess_location = AccessingLocation(handle_desig.resolve(), robot_desig.resolve()).resolve()\nprint(access_location.pose)\n```\n\nThis will find and return the best location for the robot to stand in order to open the drawer. Would you like to explore using Giskard for full-body IK with location designators?"}, {"role": "user", "content": "Yes, show me how to use Giskard for full-body IK with location designators."}, {"role": "assistant", "content": "Giskard is used for full-body inverse kinematics (IK) with certain robots like the HSR or Stretch2. The `GiskardLocation` designator helps find a pose for the robot to reach a target position using Giskard's IK solver. Here's how you can use it:\n\nFirst, make sure Giskard is running, as this designator relies on it.\n\n```python\nfrom pycram.designators.specialized_designators.location.giskard_location import GiskardLocation\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.datastructures.pose import Pose\n\nrobot_desig = BelieveObject(names=[\"pr2\"]).resolve()\n\nloc = GiskardLocation(target=Pose([1, 1, 1]), reachable_for=robot_desig).resolve()\nprint(loc.pose)\n```\n\nThis will find a pose for the robot that allows it to reach the specified target position using full-body IK. Once you're finished, you can close the world with the following command:\n\n```python\nworld.exit()\n```\n\nWould you like to explore anything else related to location designators or any other PyCRAM concepts?"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know everything about the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain what components are available in the 'pycram.datastructures.enums' module?"}, {"role": "assistant", "content": "The 'pycram.datastructures.enums' module contains several enums that are used throughout PyCRAM. These enums are: ExecutionType, Arms, TaskStatus, JointType, Grasp, ObjectType, State, Shape, WorldMode, AxisIdentifier, GripperState, GripperType, PerceptionTechniques, and ImageEnum. Would you like to know more about a specific enum?"}, {"role": "user", "content": "What is the 'ExecutionType' enum?"}, {"role": "assistant", "content": "The 'ExecutionType' enum in PyCRAM is used to define different types of execution processes in the process module. It has the following attributes: REAL, SIMULATED, and SEMI_REAL."}, {"role": "user", "content": "What about the 'Arms' enum?"}, {"role": "assistant", "content": "The 'Arms' enum is used to specify which arm or arms of the robot are being referred to. It includes the following attributes: LEFT, RIGHT, and BOTH."}, {"role": "user", "content": "Can you explain the 'TaskStatus' enum?"}, {"role": "assistant", "content": "The 'TaskStatus' enum provides readable descriptions of a task's status. Its attributes are: CREATED (0), RUNNING (1), SUCCEEDED (2), and FAILED (3)."}, {"role": "user", "content": "What is the purpose of the 'JointType' enum?"}, {"role": "assistant", "content": "The 'JointType' enum defines different types of joints in a robot. The attributes include: REVOLUTE (0), PRISMATIC (1), SPHERICAL (2), PLANAR (3), FIXED (4), UNKNOWN (5), CONTINUOUS (6), and FLOATING (7)."}, {"role": "user", "content": "Tell me about the 'Grasp' enum."}, {"role": "assistant", "content": "The 'Grasp' enum is used to define different grasp orientations. It has the following attributes: FRONT (0), LEFT (1), RIGHT (2), and TOP (3)."}, {"role": "user", "content": "What does the 'ObjectType' enum define?"}, {"role": "assistant", "content": "The 'ObjectType' enum helps in identifying different types of objects in PyCRAM. Its attributes include: METALMUG, PRINGLES, MILK, SPOON, BOWL, BREAKFAST_CEREAL, JEROEN_CUP, ROBOT, ENVIRONMENT, GENERIC_OBJECT, and HUMAN."}, {"role": "user", "content": "What is the 'State' enum?"}, {"role": "assistant", "content": "The 'State' enum describes the result of a language expression or task. The attributes are: SUCCEEDED (1), FAILED (0), RUNNING (2), and INTERRUPTED (3)."}, {"role": "user", "content": "What can you tell me about the 'Shape' enum?"}, {"role": "assistant", "content": "The 'Shape' enum defines the visual shapes of objects in PyCRAM. Its attributes are: SPHERE (2), BOX (3), CYLINDER (4), MESH (5), PLANE (6), and CAPSULE (7)."}, {"role": "user", "content": "What is the 'WorldMode' enum used for?"}, {"role": "assistant", "content": "The 'WorldMode' enum specifies the different modes in which the world can operate in PyCRAM. The available modes are: GUI ('GUI') and DIRECT ('DIRECT')."}, {"role": "user", "content": "Explain the 'AxisIdentifier' enum."}, {"role": "assistant", "content": "The 'AxisIdentifier' enum is used to translate axis names into vectors. The attributes are: X = (1, 0, 0), Y = (0, 1, 0), and Z = (0, 0, 1)."}, {"role": "user", "content": "What about the 'GripperState' enum?"}, {"role": "assistant", "content": "The 'GripperState' enum defines the different motions that a gripper can perform. The attributes are: OPEN and CLOSE."}, {"role": "user", "content": "Can you explain the 'GripperType' enum?"}, {"role": "assistant", "content": "The 'GripperType' enum categorizes the different types of grippers used in robotics. Its attributes include: PARALLEL, SUCTION, FINGER, HYDRAULIC, PNEUMATIC, and CUSTOM."}, {"role": "user", "content": "Tell me about the 'PerceptionTechniques' enum."}, {"role": "assistant", "content": "The 'PerceptionTechniques' enum lists the techniques that can be used in perception tasks. The attributes are: ALL, HUMAN, and TYPES."}, {"role": "user", "content": "Finally, what is the 'ImageEnum'?"}, {"role": "assistant", "content": "The 'ImageEnum' is used to switch views on the HSRB display. The available attributes include: HI (0), TALK (1), DISH (2), DONE (3), DROP (4), HANDOVER (5), ORDER (6), PICKING (7), PLACING (8), REPEAT (9), SEARCH (10), WAVING (11), FOLLOWING (12), DRIVINGBACK (13), PUSHBUTTONS (14), FOLLOWSTOP (15), JREPEAT (16), SOFA (17), INSPECT (18), CHAIR (37)."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know everything about the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain what components are available in the 'pycram.process_modules' package?"}, {"role": "assistant", "content": "The 'pycram.process_modules' package contains several submodules and classes that manage process modules for different robots in PyCRAM. The submodules include boxy_process_modules, default_process_modules, donbot_process_modules, hsrb_process_modules, pr2_process_modules, and stretch_process_modules. The key classes are Pr2Manager, BoxyManager, DonbotManager, HSRBManager, DefaultManager, and StretchManager. Would you like to know more about a specific class or submodule?"}, {"role": "user", "content": "Tell me about the 'Pr2Manager' class."}, {"role": "assistant", "content": "The 'Pr2Manager' class is a base class for managing process modules for the PR2 robot in PyCRAM. It inherits from 'pycram.process_module.ProcessModuleManager' and includes various locks and methods for controlling different actions, such as navigating, looking, detecting, moving the TCP (Tool Center Point), moving arm joints, detecting world state, moving joints, moving the gripper, opening and closing drawers."}, {"role": "user", "content": "What about the 'BoxyManager' class?"}, {"role": "assistant", "content": "The 'BoxyManager' class, similar to 'Pr2Manager', is a base class for managing process modules for the Boxy robot. It also inherits from 'pycram.process_module.ProcessModuleManager' and provides methods for navigating, looking, detecting, moving the TCP, moving arm joints, detecting world state, moving the gripper, opening, and closing drawers."}, {"role": "user", "content": "Can you explain the 'DonbotManager' class?"}, {"role": "assistant", "content": "The 'DonbotManager' class is designed for managing process modules specific to the Donbot robot. In addition to the standard methods like navigating, looking, and detecting, it includes specialized methods for placing objects, picking up objects, and other robot-specific actions."}, {"role": "user", "content": "What does the 'HSRBManager' class do?"}, {"role": "assistant", "content": "The 'HSRBManager' class manages process modules for the HSRB robot. It includes standard methods for navigating, looking, detecting, moving TCP, moving arm joints, moving joints, and gripper actions. Additionally, it has a 'talk' method for enabling the robot to communicate or express actions."}, {"role": "user", "content": "Tell me about the 'DefaultManager' class."}, {"role": "assistant", "content": "The 'DefaultManager' class is a general-purpose manager for process modules. It includes all the basic methods required for controlling a robot, such as navigating, looking, detecting, moving TCP, moving arm joints, detecting world state, moving joints, moving the gripper, opening, and closing drawers."}, {"role": "user", "content": "Finally, what is the 'StretchManager' class?"}, {"role": "assistant", "content": "The 'StretchManager' class is responsible for managing process modules for the Stretch robot. Like the other managers, it includes methods for navigating, looking, detecting, moving TCP, moving arm joints, detecting world state, moving joints, and gripper operations, as well as opening and closing actions."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know everything about the PyCRAM framework. You explain aspects of the code in a short from in a dialog with the user."}, {"role": "user", "content": "Can you explain the 'pycram.worlds.bullet_world' module and its components?"}, {"role": "assistant", "content": "The 'pycram.worlds.bullet_world' module provides the main interface to the Bullet Physics Engine for PyCRAM. It includes classes and methods for simulating and manipulating a BulletWorld. Key components include 'Link', 'RootLink', 'Joint' (attributes), and 'BulletWorld', 'Gui' (classes). Would you like to know more about any specific component?"}, {"role": "user", "content": "Tell me more about the 'BulletWorld' class."}, {"role": "assistant", "content": "The 'BulletWorld' class represents a simulation environment using the Bullet Physics Engine. It allows you to spawn objects, simulate physics, and manipulate the world. Key methods include 'load_object_and_get_id', 'remove_object_from_simulator', 'add_constraint', 'get_joint_position', 'get_link_pose', 'perform_collision_detection', 'reset_joint_position', 'step', 'set_gravity', and many others. These methods provide comprehensive control over the physics simulation. The class also has attributes like 'extension' and 'vis_axis'. Would you like to explore any specific method in detail?"}, {"role": "user", "content": "Can you explain the 'load_object_and_get_id' method?"}, {"role": "assistant", "content": "The 'load_object_and_get_id' method loads a description file, such as a URDF, at a specified pose in the simulation and returns the ID of the loaded object. This is useful for adding objects to your simulation environment dynamically. You can specify the path to the description file and the desired pose for the object."}, {"role": "user", "content": "What does the 'perform_collision_detection' method do?"}, {"role": "assistant", "content": "The 'perform_collision_detection' method checks for collisions between all objects in the BulletWorld and updates the contact points accordingly. It's essential for ensuring that objects in the simulation interact physically as expected."}, {"role": "user", "content": "Tell me about the 'Gui' class."}, {"role": "assistant", "content": "The 'Gui' class in 'pycram.worlds.bullet_world' is designed for internal use. It creates a new thread for the physics simulation, which remains active until closed by the 'World.exit' method. It also handles camera controls within the simulation environment, checking for mouse and keyboard inputs. The 'Gui' class runs in an endless loop, with brief suspensions to manage simulation updates."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code"}, {"role": "user", "content": "Can you explain how you can let the robot pick something up?"}, {"role": "assistant", "content": "You can use the PickUpAction Action Designator. 'name': 'PickUpAction', 'description': 'Action designator for picking up an object.', 'props': ('object_designator_description','arms','grasps'),'example': 'PickUpAction(object_designator_description=milk_desig, arms=[Arms.RIGHT], grasps=[Grasp.FRONT]).resolve().perform()'"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do you let the robot navigate to a specific location using PyCRAM?"}, {"role": "assistant", "content": "You can use the `NavigateAction` action designator. Example:\n```python\nnavigate_description = NavigateAction(target_locations=[Pose([1, 0, 0], [0, 0, 0, 1])])\nnavigate_designator = navigate_description.resolve()\nnavigate_designator.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What is the purpose of a `MoveTorsoAction` in PyCRAM?"}, {"role": "assistant", "content": "The `MoveTorsoAction` is used to move the robot's torso up or down. Example:\n```python\ntorso_desig = MoveTorsoAction([0.2]).resolve()\ntorso_desig.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can you open or close the gripper using PyCRAM?"}, {"role": "assistant", "content": "Use the `SetGripperAction` action designator to control the gripper's state. Example:\n```python\nSetGripperAction(grippers=[Arms.RIGHT], motions=[GripperState.OPEN]).resolve().perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do you park the robot's arms in the default position?"}, {"role": "assistant", "content": "Use the `ParkArmsAction` action designator. Example:\n```python\nParkArmsAction([Arms.BOTH]).resolve().perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can the robot pick up an object in PyCRAM?"}, {"role": "assistant", "content": "Use the `PickUpAction` action designator along with an object designator. Example:\n```python\nPickUpAction(object_designator_description=milk_desig, arms=[Arms.RIGHT], grasps=[Grasp.RIGHT]).resolve().perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do you use a location designator to find a pose for the robot?"}, {"role": "assistant", "content": "Use the `CostmapLocation` designator to describe and resolve a location. Example:\n```python\nlocation_description = CostmapLocation(target=target)\npose = location_description.resolve()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What is a `SemanticCostmapLocation` in PyCRAM?"}, {"role": "assistant", "content": "It is used to find poses on semantic entities like a table. Example:\n```python\nlocation_description = SemanticCostmapLocation(urdf_link_name=\"kitchen_island_surface\", part_of=kitchen_desig, for_object=milk_desig)\npose = location_description.resolve()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can you detect an object using PyCRAM?"}, {"role": "assistant", "content": "Use the `DetectAction` action designator after looking at the object. Example:\n```python\nLookAtAction(targets=[milk_desig.resolve().pose]).resolve().perform()\nobj_desig = DetectAction(milk_desig).resolve().perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do you create an object designator for an object in the BulletWorld?"}, {"role": "assistant", "content": "Use the `BelieveObject` designator to describe objects in the BulletWorld. Example:\n```python\nobject_description = BelieveObject(names=[\"milk\"])\nresolved_object = object_description.resolve()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I merge two costmaps in PyCRAM?"}, {"role": "assistant", "content": "You can merge two costmaps using the `merge` method on a `Costmap` object. Example:\n```python\nmerged_costmap = costmap1.merge(costmap2)\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What is the purpose of the `VisualShape` class in PyCRAM?"}, {"role": "assistant", "content": "The `VisualShape` class is a base class for creating visual representations of objects. It provides methods for setting color and shape data."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I create a deep copy of a Pose object in PyCRAM?"}, {"role": "assistant", "content": "You can create a deep copy of a `Pose` object using its `copy` method. Example:\n```python\npose_copy = original_pose.copy()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I normalize a quaternion in PyCRAM?"}, {"role": "assistant", "content": "You can normalize a quaternion using the `get_normalized_quaternion` function. Example:\n```python\nnormalized_quat = get_normalized_quaternion(quaternion)\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What is the `AxisAlignedBoundingBox` class used for in PyCRAM?"}, {"role": "assistant", "content": "The `AxisAlignedBoundingBox` class is used to represent the minimum and maximum bounds of an object in 3D space. It provides methods to get and set these bounds."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I perform a ray test in PyCRAM?"}, {"role": "assistant", "content": "You can perform a ray test using the `ray_test` method. Example:\n```python\nobject_id = world.ray_test(from_position=[0, 0, 1], to_position=[1, 1, 1])\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I attach one object to another in PyCRAM?"}, {"role": "assistant", "content": "You can attach one object to another using the `attach` method. Example:\n```python\nparent_object.attach(child_object)\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I create a fixed constraint between two links in PyCRAM?"}, {"role": "assistant", "content": "You can create a fixed constraint between two links using the `add_fixed_constraint` method. Example:\n```python\nconstraint_id = world.add_fixed_constraint(parent_link, child_link, transform)\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What is the `LookAtAction` designator used for in PyCRAM?"}, {"role": "assistant", "content": "The `LookAtAction` designator is used to make the robot look at a specific point in the environment. Example:\n```python\nLookAtAction(targets=[Pose([1, 0, 0.5], [0, 0, 0, 1])]).resolve().perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I set the color of an object in PyCRAM?"}, {"role": "assistant", "content": "You can set the color of an object using the `set_color` method. Example:\n```python\nobject.set_color(Color([1, 0, 0, 1]))  # Set to red\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I write a plan to move a robot to a specific location?"}, {"role": "assistant", "content": "To move a robot to a specific location, you can use the `NavigateAction` designator. Example:\n```python\npose = Pose([1, 0, 0], [0, 0, 0, 1])\nnavigate_action = NavigateAction(target_locations=[pose]).resolve()\nnavigate_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I create a plan to pick up an object and place it at a different location?"}, {"role": "assistant", "content": "You can create a plan using `PickUpAction` and `PlaceAction` designators. Example:\n```python\npick_action = PickUpAction(object_designator_description=milk_desig, arms=[Arms.RIGHT]).resolve()\nplace_action = PlaceAction(object_designator_description=milk_desig, target_locations=[target_pose], arms=[Arms.RIGHT]).resolve()\n\nwith simulated_robot:\n    pick_action.perform()\n    place_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I make the robot perform a sequence of actions in PyCRAM?"}, {"role": "assistant", "content": "You can sequence actions by resolving and performing designators in order. Example:\n```python\nmove_to_pose = NavigateAction(target_locations=[pose]).resolve()\nset_gripper = SetGripperAction(grippers=[Arms.RIGHT], motions=[GripperState.OPEN]).resolve()\nmove_to_pose.perform()\nset_gripper.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I create a plan to open a drawer?"}, {"role": "assistant", "content": "To open a drawer, use the `OpenAction` designator. Example:\n```python\ndrawer_handle = ObjectPart(names=['drawer_handle'], part_of=drawer_object).resolve()\nopen_action = OpenAction(handle_designator=drawer_handle, arms=[Arms.RIGHT]).resolve()\nopen_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What steps do I need to code a plan to detect an object in the environment?"}, {"role": "assistant", "content": "To detect an object, use the `DetectAction` designator along with `LookAtAction`. Example:\n```python\nlook_action = LookAtAction(targets=[object_pose]).resolve()\ndetect_action = DetectAction(object_designator=object_desig).resolve()\nwith simulated_robot:\n    look_action.perform()\n    detected_object = detect_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I create a plan to move the robot's torso?"}, {"role": "assistant", "content": "To move the robot's torso, use the `MoveTorsoAction` designator. Example:\n```python\ntorso_action = MoveTorsoAction([0.3]).resolve()\ntorso_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I plan a motion for the robot's arm?"}, {"role": "assistant", "content": "To plan a motion for the robot's arm, use the `MoveArmAction` designator. Example:\n```python\nmove_arm = MoveArmAction(arm=Arms.RIGHT, target_pose=pose).resolve()\nmove_arm.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I make the robot close its gripper?"}, {"role": "assistant", "content": "You can close the robot's gripper using the `SetGripperAction` designator. Example:\n```python\nclose_gripper = SetGripperAction(grippers=[Arms.RIGHT], motions=[GripperState.CLOSED]).resolve()\nclose_gripper.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I create a plan to park the robot's arms?"}, {"role": "assistant", "content": "To park the robot's arms, use the `ParkArmsAction` designator. Example:\n```python\npark_arms = ParkArmsAction(arms=[Arms.BOTH]).resolve()\npark_arms.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I write a plan to transport an object from one location to another?"}, {"role": "assistant", "content": "To transport an object, use the `TransportAction` designator. Example:\n```python\ntransport_action = TransportAction(object_desig, [Arms.LEFT], [target_pose]).resolve()\ntransport_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I write a plan to let the robot look at an object?"}, {"role": "assistant", "content": "You can use the `LookAtAction` designator to let the robot look at an object. Example:\n```python\nlook_at_action = LookAtAction(targets=[object_pose]).resolve()\nlook_at_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I create a plan to reset the robot's world state?"}, {"role": "assistant", "content": "To reset the robot's world state, you can use the `reset_world` method from the BulletWorld class. Example:\n```python\nworld.reset_world()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I write a plan for the robot to open a gripper, pick up an object, and then close the gripper?"}, {"role": "assistant", "content": "You can chain multiple actions together using the `SetGripperAction` and `PickUpAction` designators. Example:\n```python\nopen_gripper = SetGripperAction(grippers=[Arms.RIGHT], motions=[GripperState.OPEN]).resolve()\npick_up = PickUpAction(object_designator_description=milk_desig, arms=[Arms.RIGHT]).resolve()\nclose_gripper = SetGripperAction(grippers=[Arms.RIGHT], motions=[GripperState.CLOSED]).resolve()\nopen_gripper.perform()\npick_up.perform()\nclose_gripper.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I code a plan to make the robot navigate to a location and then look at an object?"}, {"role": "assistant", "content": "You can combine `NavigateAction` and `LookAtAction` to create this plan. Example:\n```python\nnavigate_action = NavigateAction(target_locations=[target_pose]).resolve()\nlook_at_action = LookAtAction(targets=[object_pose]).resolve()\nnavigate_action.perform()\nlook_at_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I make the robot open and close a drawer in sequence?"}, {"role": "assistant", "content": "You can use the `OpenAction` and `CloseAction` designators. Example:\n```python\ndrawer_handle = ObjectPart(names=['drawer_handle'], part_of=drawer_object).resolve()\nopen_action = OpenAction(handle_designator=drawer_handle, arms=[Arms.RIGHT]).resolve()\nclose_action = CloseAction(handle_designator=drawer_handle, arms=[Arms.RIGHT]).resolve()\nopen_action.perform()\nclose_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I create a plan to make the robot place an object at a specified location?"}, {"role": "assistant", "content": "To place an object at a specified location, use the `PlaceAction` designator. Example:\n```python\nplace_action = PlaceAction(object_designator_description=milk_desig, target_locations=[target_pose], arms=[Arms.RIGHT]).resolve()\nplace_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I code a plan for the robot to detect multiple objects in its environment?"}, {"role": "assistant", "content": "You can iterate over a list of objects using the `DetectAction` designator for each. Example:\n```python\nfor obj in objects_to_detect:\n    detect_action = DetectAction(object_designator=obj).resolve()\n    detected_object = detect_action.perform()\n    print(detected_object)\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I create a plan for the robot to pick up an object, navigate to a location, and place it there?"}, {"role": "assistant", "content": "You can combine `PickUpAction`, `NavigateAction`, and `PlaceAction` designators. Example:\n```python\npick_up = PickUpAction(object_designator_description=milk_desig, arms=[Arms.RIGHT]).resolve()\nnavigate_action = NavigateAction(target_locations=[target_pose]).resolve()\nplace_action = PlaceAction(object_designator_description=milk_desig, target_locations=[target_pose], arms=[Arms.RIGHT]).resolve()\npick_up.perform()\nnavigate_action.perform()\nplace_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How do I write a plan to navigate through multiple waypoints?"}, {"role": "assistant", "content": "You can loop through a list of waypoints using the `NavigateAction` designator for each. Example:\n```python\nfor waypoint in waypoints:\n    navigate_action = NavigateAction(target_locations=[waypoint]).resolve()\n    navigate_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "How can I code a plan to make the robot transport an object from one room to another?"}, {"role": "assistant", "content": "You can use the `TransportAction` designator to code this plan. Example:\n```python\ntransport_action = TransportAction(object_designator=milk_desig, arms=[Arms.RIGHT], target_location=target_pose).resolve()\ntransport_action.perform()\n```"}]}
{"messages": [{"role": "system", "content": "You are an experienced technical writer and coding educator, specializing in creating comprehensive guides for implementing specific tasks and workflows using the PyCram framework. Your task is to thoroughly explain how to accomplish the given task within PyCram"}, {"role": "user", "content": "How to use Costmaps for robot positioning in PyCRAM?"}, {"role": "assistant", "content": "### Using Costmaps for Robot Positioning in PyCRAM\n\nCostmaps in PyCRAM are essential tools for determining optimal positions for robot actions based on various criteria like visibility, occupancy, and more. This guide will explore how to create and utilize costmaps for robot positioning.\n\n#### 1. Introduction to Costmaps\n\nCostmaps provide a way to evaluate positions in the simulation based on different criteria. PyCRAM supports several types of costmaps, including:\n\n- `OccupancyCostmap`: Determines where the robot can be placed without colliding with objects.\n- `VisibilityCostmap`: Determines positions from which a target is visible.\n- `SemanticCostmap`: Maps positions based on semantic labels, like identifying specific surfaces.\n- `GaussianCostmap`: Generates a costmap with a Gaussian distribution.\n\n#### 2. Creating a Visibility Costmap\n\nVisibility costmaps are used to find positions where a target object is visible. Here’s how to create and visualize a visibility costmap:\n\n```python\nimport pycram.costmaps as cm\nfrom pycram.datastructures.pose import Pose\n\n# Create a visibility costmap\nv = cm.VisibilityCostmap(1.27, 1.60, size=300, resolution=0.02, origin=Pose([0, 0, 0.1], [0, 0, 0, 1]))\n\n# Visualize the costmap\nv.visualize()\n```\n\nTo close the visualization:\n\n```python\nv.close_visualization()\n```\n\n#### 3. Creating an Occupancy Costmap\n\nOccupancy costmaps ensure that the robot is positioned without collisions.\n\n```python\n# Create an occupancy costmap\no = cm.OccupancyCostmap(0.2, from_ros=False, size=300, resolution=0.02, origin=Pose([0, 0, 0.1], [0, 0, 0, 1]))\n\n# Visualize the costmap\no.visualize()\n```\n\n#### 4. Combining Costmaps\n\nYou can combine multiple costmaps to consider different criteria simultaneously:\n\n```python\n# Combine visibility and occupancy costmaps\nov = o + v\nov.visualize()\n```\n\n#### 5. Using Costmaps in Robot Positioning\n\nCostmaps can be used to determine the robot's position when performing tasks. For example, when picking up an object, you might want to find a position that is both reachable and has good visibility:\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.datastructures.enums import ObjectType\n\n# Define the robot and target objects\nrobot_desig = BelieveObject(types=[ObjectType.ROBOT]).resolve()\ntarget_desig = BelieveObject(names=[\"Milk\"]).resolve()\n\n# Create a location designator based on the combined costmap\nlocation_desig = CostmapLocation(target=target_desig, visible_for=robot_desig)\n\n# Resolve the best position for the robot\nbest_position = location_desig.resolve()\nprint(f\"Best Position: {best_position}\")\n```\n\n#### 6. Best Practices and Considerations\n\n- **Resolution and Size**: Choose the resolution and size of costmaps based on the specific needs of the task. Higher resolutions provide more detail but require more computation.\n- **Combination of Costmaps**: When combining costmaps, ensure that the criteria do not conflict, as this might lead to suboptimal positioning.\n- **Visualization**: Always visualize your costmaps to verify that they correctly represent the environment and meet your task’s requirements.\n\n### Conclusion\n\nCostmaps are powerful tools in PyCRAM for determining optimal robot positions based on various criteria. By using and combining different types of costmaps, you can ensure that your robot operates effectively within its environment."}]}
{"messages": [{"role": "system", "content": "You are an experienced technical writer and coding educator, specializing in creating comprehensive guides for implementing specific tasks and workflows using the PyCram framework. Your task is to thoroughly explain how to accomplish the given task within PyCram"}, {"role": "user", "content": "How to create and manage a BulletWorld?"}, {"role": "assistant", "content": "### Creating and Managing a BulletWorld in PyCRAM\n\nThe `BulletWorld` is the core simulation environment in PyCRAM where different objects and robots are spawned, and actions are simulated. This guide will walk you through creating and managing a `BulletWorld`, interacting with objects, and rendering images from the simulation.\n\n#### 1. Setting Up the BulletWorld\n\nTo begin, you need to import the necessary modules from PyCRAM and create an instance of `BulletWorld`.\n\n```python\nfrom pycram.worlds.bullet_world import BulletWorld\n\n# Create an instance of BulletWorld\nworld = BulletWorld()\n```\n\nThis code initializes a new BulletWorld, which serves as the environment where all simulations take place.\n\n#### 2. Spawning Objects in BulletWorld\n\nObjects in the BulletWorld can be spawned using URDF, OBJ, or STL files. Here's how to create an object in the simulation:\n\n```python\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType\n\n# Spawn a milk object in the BulletWorld\nmilk = Object(\"Milk\", ObjectType.MILK, \"milk.stl\")\n```\n\nObjects can be manipulated with methods like `set_position()` and `remove()`.\n\n#### 3. Rendering Images from BulletWorld\n\nYou can render images from different camera perspectives using the `get_images_for_target` method.\n\n```python\nfrom pycram.datastructures.pose import Pose\n\n# Render images from a specific camera position\nworld.get_images_for_target(Pose([1, 0, 1], [0, 0, 0, 1]), Pose([0.3, 0, 1], [0, 0, 0, 1]))\n```\n\nThis function returns an RGB image, a depth image, and a segmentation mask.\n\n#### 4. Managing Objects and Environment\n\nObjects in the BulletWorld can be moved, rotated, or removed. Here's an example of how to manipulate an object:\n\n```python\n# Set the position of the milk object\nmilk.set_position(Pose([1, 0, 0]))\n\n# Remove the milk object from the BulletWorld\nmilk.remove()\n```\n\nYou can also spawn complex environments like a kitchen in the same way:\n\n```python\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\n```\n\n#### 5. Closing the BulletWorld\n\nWhen you're done with the simulation, you can close the BulletWorld using the `exit` method:\n\n```python\nworld.exit()\n```\n\n### Conclusion\n\nManaging a BulletWorld in PyCRAM involves initializing the world, spawning and interacting with objects, rendering images, and finally closing the world. This workflow is essential for setting up simulations that allow for advanced reasoning and testing within the PyCRAM framework."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the key concepts covered in the Designators section of the PyCRAM documentation?"}, {"role": "assistant", "content": "Designators\n\n\nDesignators are CRAMs and PyCRAMs way of representing actions, motions, objects and locations.\n\nIn general, PyCRAM-Designators consist of a description and a specified element.\nDescriptions describe sets of designators and designators are one thing in the described set.\nFor example, such a description could describe an action where the robot moves to a location\nfrom where it can grasp an object. The specific location in this case is not relevant as long\nas the robot can reach the object.\n\nThe designator description will be resolved during runtime which results in a designator with\nspecific parameter, the resulting designator can also be performed to let the robot perform the\ndesired behaviour.\n\nTo stay on the example of an action designator which should move the robot to a location from\nwhere it can grasp an object, we will create a NavigateAction description with a list of possible\nposes.\n\n.. code-block:: python\n\n    poses = [Pose([1, 0, 0], [0, 0, 0, 1]), Pose([1.2, 0.2, 0], [0, 0, 1, 0])]\n    NavigateAction(target_locations=poses)\n\nThis is a description of an action which moves the robot to a pose in the environment.\nIn this case the description describes a set of action designators which have a pose of the ``poses``\nlist as target location.\n\nBy resolving the description it will return a single designator with specific parameter.\nThis can look like this:\n\n.. code-block:: python\n\n    designator = NavigateAction(target_locations=poses).resolve()\n\nThe resolver will check the available parameter and return a designator with appropriate parameter\nwhich can then be performed. The designator returned by the resolver will always be a sub-class\nof the description, in this way the designator can be assigned the type of action it performs.\nThe resolved designator can also contain new parameter which might be relevant for performing the\ndesignator and will be inferred while resolving. A resolved action designator for a navigate\naction looks like this:\n\n.. code-block:: python\n\n    NavigateActionPerformable(robot_position=(Pose([0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 1.0]), target_location=Pose([1, 0, 0], [0, 0, 0, 1]))\n\n\nA visual representation of the whole idea of designator and designator descriptions can be\nseen in the following image.\n\n.. image:: ../images/designators.png\n   :alt: Schematic representation of Designators.\n\n\n\nThere are four types of designators in PyCRAM:\n\n - :mod:`pycram.designators.action_designator`\n - :mod:`pycram.designators.object_designator`\n - :mod:`pycram.designators.location_designator`\n - :mod:`pycram.designators.motion_designator`\n\nObject Designator\n=================\n\nObject designators represent objects in (simulated) world.\nThe description of object designators can take names and types that the object should match.\nThe :meth:`~pycram.designator.ObjectDesignatorDescription.ground` method returns an object with all\nits data attached that matches the description.\nThe :meth:`~pycram.designator.ObjectDesignatorDescription.__iter__` method iterates over all objects\nthat match the description.\n\nContributing Object Designators\n\nObject Designators should always be part of an object designator description.\nThe general class structure is seen in :mod:`~pycram.designator.ObjectDesignatorDescription`.\nNew object description need to inherit from the general object description. If the object they ground to differs from\nthe base object, a `dataclass <https://docs.python.org/3/library/dataclasses.html>`_. should be created inside the new\ndescription. The dataclass is one element that matches the description.\nIf ORM logging of the new objects is wanted a ``to_sql()`` and ``insert()`` method has to be implemented\n(see :ref:`orm` for more details).\n\n\nAction Designator\n=================\nAction designators describe complex actions that are executable for an agent. Action designators can be seen as higher\nlevel plans that include failure handling and parametrization.\nAn action designator description always takes the parameter as a list of possible parameter, when\nresolving the description to a single designator one parameter out of the given list will be picked.\n\nMotion Designator\n=================\nMotion designators describe atomic actions that are executable for an agent. In contrast to action\ndesignators there is no failure handling or other action designators. Furthermore, the :meth:`~pycram.designator.MotionDesignatorDescription.Motion.perform`\nmethod passes the resolved motion designator to the respective Process Module for execution on the robot.\n\nAnother difference to action designator is that motion designators only take a single parameter instead of a\nlist, this parameter is also strictly typed.\n\nLocation Designator\n===================\nLocation designator describe a set of locations in regards to specific constrains. These constrains can be things\nlike ``reachable`` or ``visible``. The pose returned by a location designator is a single pose of the set defined\nby the constrains given to the location designator description.\n\nSimilar to object designator poses location designator also a :meth:`~pycram.designators.location_designator.CostmapLocation.__iter__`\nmethod which can iterate over all possible solutions for this description.\n\nCreating your own Designator\n============================\nCreating your own designator is fairly easy, you only need to extend the base class of the respective description.\n\n - :mod:`~pycram.designator.ActionDesignatorDescription`\n - :mod:`~pycram.designator.ObjectDesignatorDescription`\n - :mod:`~pycram.designator.LocationDesignatorDescription`\n - :mod:`~pycram.designator.BaseMotion`\n\nAfterwards you need to implement your own ``ground`` method which is the default resolver and for location and object\ndesignator it makes sense to also implement a ``__iter__`` method. The ``ground`` and ``__iter__`` methods should return\nthe designator sub-class so you also need to implement these with the parameter your designator needs.\n\nThe sub-class can already contain some parameters, this is usually the case if the parameter is the same for every designator\nof this type. For example, :class:`~pycram.designator.LocationDesignatorDescription.Location`\ncontains a ``pose`` parameter since every location designator contains a resolved pose.\n\nFor action and motion designator the sub-class is also the place where the ``perform`` method is written which contains\nthe behaviour of the designator."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What common issues are addressed in the Troubleshooting section of the PyCRAM documentation?"}, {"role": "assistant", "content": "Troubleshooting\n\nThis page contains the most common errors that could happen when using PyCRAM and how to resolve them.\n\n\nRos Init Exception\n\n.. code-block:: Python\n\n    ROSInitException: time is not initialized. Have you called init_node()\n\nThis exception usually occurs when trying to load an Object into the BulletWorld or when creating a Pose. The reason for\nthis exception is that the ROS node of PyCRAM could not be initialized, this is usually the case when the PyCRAM launch\nfile was not launched.\n\nTo solve this problem you just have to launch the ``ik_and_description`` file of PyCRAM. This can be done via the\nfollowing command.\n\n.. code-block:: shell\n\n    roslaunch pycram ik_and_description\n\n\nRobot Description not Loaded\n\nIn PyCRAM a lot of things are base on the robot description that is currently loaded and in turn the robot description\nthat will be loaded depends on the robot description that is on the ROS parameter server at the time PyCRAM is started.\n\nIf you get an error that looks similar to the following exception the most likely case is that the robot description was\nnot loaded.\n\n.. code-block:: python\n   :emphasize-lines: 3\n\n        763 with open(self.path) as f:\n        764     self.urdf_object = URDF.from_xml_string(f.read())\n    --> 765     if self.urdf_object.name == robot_description.name and not BulletWorld.robot:\n        766         BulletWorld.robot = self\n        768 self.links[self.urdf_object.get_root()] = -1\n\n    AttributeError: 'NoneType' object has no attribute 'name'\n\n\nThere could be a few reasons for this behaviour:\n   * The name of the URDF on the parameter server and the name in the PyCRAM robot description are different\n      * The PyCRAM robot description is matched by the name of the robot in the URDF\n      * You can check the assignment of the PyCRAM robot description in this function :func:`~pycram.robot_descriptions.update_robot_description` (there is a link to the source code)\n   * You only started a roscore\n   * You did not start the ``ik_and_description`` launch file\n\n\nStop Iteration\n\nStop iterations usually happen when you try to resolve a designator for which there is no solution or if you iterate over a\ndesignator and reached the end of all possible solutions.\n\nWhen you try to resolve a designator which has no solution the error will look something like this.\n\n.. code-block:: python\n   :emphasize-lines: 7\n\n       753 def ground(self) -> Union[Object, bool]:\n       754     \"\"\"\n       755     Return the first object from the bullet world that fits the description.\n       756\n       757     :return: A resolved object designator\n       758     \"\"\"\n   --> 759     return next(iter(self))\n\n   StopIteration:\n\nIf you encounter such an error the most likely reason is that you put the wrong arguments into your DesignatorDescription.\nThe best solution is to double check the input arguments of the DesignatorDescription.\n\n\n\nBulletWorld crashes after loading an URDF\n\nIt can happen that the BulletWorld crashes when loading a URDF. This happens when loading a URDF with more than 127 links.\nThis is a limitation of PyBullet which can not deal with objects with more links.\n\nOnly real solution here is to either delete links such that you have at max 127 links or split up the URDF and load the\nsplit parts individually.\n\n\nError when performing Actions or Motions\n\n.. code-block:: python\n\n        30 def perform(self):\n        31     pm_manager = ProcessModuleManager.get_manager()\n   ---> 32     return pm_manager.navigate().execute(self)\n\n   AttributeError: 'NoneType' object has no attribute 'navigate'\n\nIf you get an error like this when trying to perform an action or motion designator, then you did not specify how the\ndesignator should be executed. You can specify how the designator should be performed by using the simulated_robot or\nreal_robot environments. This is also explained in the `Action Designator Example <https://pycram.readthedocs.io/en/latest/notebooks/action_designator.html#Navigate-Action>`_.\n\n.. code-block:: python\n\n   with simulated_robot:\n      NavigateAction([Pose()]).resolve().perform()\n\nMissing pr2_arm_kinematics\n==========================\n\nAptitudes autoremove likes to also remove the arm kinematics. The error message looks similar to this. Important is the\nmissing library libmoveit_kinematics_base.so. This can be fixed by reinstalling the missing libraries.\n\n.. code-block:: shell\n\n   process[pr2_left_arm_kinematics-3]: started with pid [26862]\n   pr2_arm_kinematics_node: error while loading shared libraries: libmoveit_kinematics_base.so.1.1.12: cannot open shared object file: No such file or directory\n   process[pr2_right_arm_kinematics-4]: started with pid [26863]\n   [pr2_left_arm_kinematics-3] process has died [pid 26862, exit code 127, cmd ~/pycram/devel/lib/pr2_arm_kinematics/pr2_arm_kinematics_node __name:=pr2_left_arm_kinematics __log:=~/.ros/log/ba5e95de-384f-11ee-ab53-97c8787037e5/pr2_left_arm_kinematics-3.log].\n   log file: ~/.ros/log/ba5e95de-384f-11ee-ab53-97c8787037e5/pr2_left_arm_kinematics-3*.log\n   pr2_arm_kinematics_node: error while loading shared libraries: libmoveit_kinematics_base.so.1.1.12: cannot open shared object file: No such file or directory\n   [pr2_right_arm_kinematics-4] process has died [pid 26863, exit code 127, cmd ~/pycram/devel/lib/pr2_arm_kinematics/pr2_arm_kinematics_node __name:=pr2_right_arm_kinematics __log:=~/.ros/log/ba5e95de-384f-11ee-ab53-97c8787037e5/pr2_right_arm_kinematics-4.log].\n   log file: ~/.ros/log/ba5e95de-384f-11ee-ab53-97c8787037e5/pr2_right_arm_kinematics-4*.log\n   IK server ready.\n\n\nReinstall the missing libraries with\n\n.. code-block:: shell\n\n    sudo apt-get install ros-noetic-moveit\n\nThen rebuild your workspace."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the key features of PyCRAM mentioned in the introduction of the documentation?"}, {"role": "assistant", "content": "PyCRAM Introduction\n\n```python\nimport pycram\n```\n\n# Bullet World\n\nThe BulletWorld is the internal simulation of PyCRAM. You can simulate different actions and reason about the outcome of\ndifferent actions.\n\nIt is possible to spawn objects and robots into the BulletWorld, these objects can come from URDF, OBJ or STL files.\n\nA BulletWorld can be created by simply creating an object of the BulletWorld class.\n\n```python\nfrom pycram.worlds.bullet_world import BulletWorld\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType\nfrom pycram.datastructures.pose import Pose\n\nworld = BulletWorld()\n```\n\nThe BulletWorld allows to render images from arbitrary positions. In the following example we render images with the\ncamera at the position [0.3, 0, 1] and pointing towards [1, 0, 1], so we are looking upwards along the x-axis.\n\nThe renderer returns 3 different kinds of images which are also shown on the left side of the BulletWorld window. (If\nthese winodws are missing, click the BulletWorld window to focus it, and press \"g\") These images are:\n\n* An RGB image which shows everything like it is rendered in the BulletWorld window, just from another perspective.\n* A depth image which consists of distance values from the camera towards the objects in the field of view.\n* A segmentation mask image which segments the image into the different objects displayed. The segmentation is done by\n  assigning every pixel the unique id of the object that is displayed there.\n\n```python\nworld.get_images_for_target(Pose([1, 0, 1], [0, 0, 0, 1]), Pose([0.3, 0, 1], [0, 0, 0, 1]))\n```\n\n## Objects\n\nEverything that is located inside the BulletWorld is an Object.\nObjects can be created from URDF, OBJ or STL files. Since everything is of type Object a robot might share the same\nmethods as a milk (with some limitations).\n\nSignature:\nObject:\n\n* Name\n* Type\n* Filename or Filepath\n\nOptional:\n\n* Position\n* Orientation\n* World\n* Color\n* Ignore Cached Files\n\nIf there is only a filename and no path, PyCRAM will check in the resource directory if there is a matching file.\n\n```python\nmilk = Object(\"Milk\", ObjectType.MILK, \"milk.stl\")\n```\n\nObjects provide methods to change the position and rotation, change the color, attach other objects, set the state of\njoints if the objects has any or get the position and orientation of a link.\n\nThese methods are the same for every Object, however since some Objects may not have joints or more than one link\nmethods related to these will not work.\n\n```python\nmilk.set_position(Pose([1, 0, 0]))\n```\n\nTo remove an Object from the BulletWorld just call the 'remove' method on the Object.\n\n```python\nmilk.remove()\n```\n\nSince everything inside the BulletWorld is an Object, even a complex environment Object like the kitchen can be spawned\nin the same way as the milk.\n\n```python\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\n```\n\n## Costmaps\n\nCostmaps are a way to get positions with respect to certain criterias.\nThe currently available costmaps are:\n\n* {class}`~pycram.costmaps.OccupancyCostmap`\n* {class}`~pycram.costmaps.VisibilityCostmap`\n* {class}`~pycram.costmaps.SemanticCostmap`\n* {class}`~pycram.costmaps.GaussianCostmap`\n\nIt is also possible to merge multiple costmaps to combine different criteria.\n\n### Visibility Costmaps\n\nVisibility costmaps determine every position, around a target position, from which the target is visible. Visibility\nCostmaps are able to work with cameras that are movable in height for example, if the robot has a movable torso.\n\n```python\nimport pycram.costmaps as cm\n\nv = cm.VisibilityCostmap(1.27, 1.60, size=300, resolution=0.02, origin=Pose([0, 0, 0.1], [0, 0, 0, 1]))\n```\n\n```python\nv.visualize()\n```\n\n```python\nv.close_visualization()\n```\n\n### Occupancy Costmap\n\nIs valid for every position where the robot can be placed without colliding with an object.\n\n```python\no = cm.OccupancyCostmap(0.2, from_ros=False, size=300, resolution=0.02, origin=Pose([0, 0, 0.1], [0, 0, 0, 1]))\n```\n\n```python\ns = cm.SemanticCostmap(kitchen, \"kitchen_island_surface\", size=100, resolution=0.02)\n\ng = cm.GaussianCostmap(200, 15, resolution=0.02)\n```\n\nYou can visualize the costmap in the BulletWorld to get an impression what information is actually contained in the\ncostmap. With this you could also check if the costmap was created correctly.\nVisualization can be done via the 'visualize' method of each costmap.\n\n```python\no.visualize()\n```\n\n```python\no.close_visualization()\n```\n\nIt is also possible to combine two costmap, this will result in a new costmap with the same size which contains the\ninformation of both previous costmaps. Combination is done by checking for each position in the two costmaps if they are\nzero, in this case to same position in the new costmap will also be zero in any other case the new position will be the\nnormalized product of the two combined costmaps.\n\n```python\nov = o + v\n```\n\n```python\nov.visualize()\n```\n\n```python\nov.close_visualization()\n```\n\n## Bullet World Reasoning\n\nAllows for geometric reasoning in the BulletWorld. At the moment the following types of reasoning are supported:\n\n* {meth}`~pycram.world_reasoning.stable`\n* {meth}`~pycram.world_reasoning.contact`\n* {meth}`~pycram.world_reasoning.visible`\n* {meth}`~pycram.world_reasoning.occluding`\n* {meth}`~pycram.world_reasoning.reachable`\n* {meth}`~pycram.world_reasoning.blocking`\n* {meth}`~pycram.world_reasoning.supporting`\n\nTo show the geometric reasoning we first spawn a robot as well as the milk Object again.\n\n```python\nimport pycram.world_reasoning as btr\n\nmilk = Object(\"Milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1, 0, 1]))\npr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\n```\n\nWe start with testing for visibility\n\n```python\nmilk.set_position(Pose([1, 0, 1]))\nvisible = btr.visible(milk, pr2.get_link_pose(\"wide_stereo_optical_frame\"))\nprint(f\"Milk visible: {visible}\")\n```\n\n```python\nmilk.set_position(Pose([1, 0, 0.05]))\n\nplane = BulletWorld.current_bullet_world.objects[0]\ncontact = btr.contact(milk, plane)\nprint(f\"Milk is in contact with the floor: {contact}\")\n```\n\n```python\nmilk.set_position(Pose([0.6, -0.5, 0.7]))\n\nreachable = btr.reachable(milk, pr2, \"r_gripper_tool_frame\")\nprint(f\"Milk is reachable for the PR2: {reachable}\")\n```\n\n# Designators\n\nDesignators are symbolic descriptions of Actions, Motions, Objects or Locations. In PyCRAM the different types of\ndesignators are represented by a class which takes a description, the description then tells the designator what to do.\n\nFor example, let's look at a Motion Designator to move the robot to a specific location.\n\n## Motion Designators\n\nWhen using a Motion Designator you need to specify which Process Module needs to be used, either the Process Module for\nthe real or the simulated robot. A Process Module is the interface between a real or simulated robot, and PyCRAM\ndesignators. By exchanging the Process Module, one can quickly change the robot the plan is executed on, allowing PyCRAM\nplans to be re-used across multiple robot platforms. This can be done either with a decorator which can be added to a\nfunction and then every designator executed within this function, will be executed on the specified robot. The other\npossibility is a \"with\" scope which wraps a code piece.\n\nThese two ways can also be combined, you could write a function which should be executed on the real robot and the\nfunction contains a \"with\" scope which executes something on the simulated robot for reasoning purposes.\n\n```python\nfrom pycram.designators.motion_designator import *\nfrom pycram.process_module import simulated_robot, with_simulated_robot\n\ndescription = MoveMotion(target=Pose([1, 0, 0], [0, 0, 0, 1]))\n\nwith simulated_robot:\n    description.perform()\n\n\n```\n\n```python\nfrom pycram.process_module import with_simulated_robot\n\n\n@with_simulated_robot\ndef move():\n    MoveMotion(target=Pose([0, 0, 0], [0, 0, 0, 1])).perform()\n\n\nmove()\n```\n\nOther implemented Motion Designator descriptions are:\n\n* Accessing\n* Move TCP\n* Looking\n* Move Gripper\n* Detecting\n* Move Arm Joint\n* World State Detecting\n\n## Object Designators\n\nAn Object Designator represents objects. These objects could either be from the BulletWorld or the real world. Object\nDesignators are used, for example, by the PickUpAction to know which object should be picked up.\n\n```python\nfrom pycram.designators.object_designator import *\n\nmilk_desig = BelieveObject(names=[\"Milk\"])\nmilk_desig.resolve()\n```\n\n## Location Designator\n\nLocation Designator can create a position in cartisian space from a symbolic desctiption\n\n```python\nfrom pycram.designators.object_designator import *\n\nmilk_desig = BelieveObject(names=[\"Milk\"])\nmilk_desig.resolve()\n```\n\n## Location Designators\n\nLocation Designators can create a position in cartesian space from a symbolic description.\n\n```python\nfrom pycram.designators.location_designator import *\nfrom pycram.designators.object_designator import *\n\nrobot_desig = BelieveObject(types=[ObjectType.ROBOT]).resolve()\nmilk_desig = BelieveObject(names=[\"Milk\"]).resolve()\nlocation_desig = CostmapLocation(target=milk_desig, visible_for=robot_desig)\n\nprint(f\"Resolved: {location_desig.resolve()}\")\nprint()\n\nfor pose in location_desig:\n    print(pose)\n\n```\n\n# Action Designator\n\nAction Designators are used to describe high-level actions. Action Designators are usually composed of other Designators\nto describe the high-level action in detail.\n\n```python\nfrom pycram.designators.action_designator import *\nfrom pycram.datastructures.enums import Arms\n\nwith simulated_robot:\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n\n```\n\n# Making a simple plan\n\nTo get familiar with the PyCRAM Framework we will write a simple pick and place plan. This plan will let the robot grasp\na cereal box from the kitchen counter and place it on the kitchen island. This is a simple pick and place plan.\n\n```python\nfrom pycram.designators.object_designator import *\n\ncereal = Object(\"cereal\", ObjectType.BREAKFAST_CEREAL, \"breakfast_cereal.stl\", pose=Pose([1.4, 1, 0.95]))\n\n```\n\n```python\ncereal_desig = ObjectDesignatorDescription(names=[\"cereal\"])\nkitchen_desig = ObjectDesignatorDescription(names=[\"kitchen\"])\nrobot_desig = ObjectDesignatorDescription(names=[\"pr2\"]).resolve()\nwith simulated_robot:\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n\n    MoveTorsoAction([0.3]).resolve().perform()\n\n    pickup_pose = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot_desig).resolve()\n    pickup_arm = pickup_pose.reachable_arms[0]\n\n    NavigateAction(target_locations=[pickup_pose.pose]).resolve().perform()\n\n    PickUpAction(object_designator_description=cereal_desig, arms=[pickup_arm], grasps=[\"front\"]).resolve().perform()\n\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n\n    place_island = SemanticCostmapLocation(\"kitchen_island_surface\", kitchen_desig.resolve(),\n                                           cereal_desig.resolve()).resolve()\n\n    place_stand = CostmapLocation(place_island.pose, reachable_for=robot_desig, reachable_arm=pickup_arm).resolve()\n\n    NavigateAction(target_locations=[place_stand.pose]).resolve().perform()\n\n    PlaceAction(cereal_desig, target_locations=[place_island.pose], arms=[pickup_arm]).resolve().perform()\n\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n\n\n\n```\n\n# Task Trees\n\nTask trees are a hierarchical representation of all Actions involved in a plan. The Task tree can later be used to\ninspect and restructure the execution order of Actions in the plan.\n\n```python\nimport pycram.task\nimport anytree\n\ntt = pycram.task.task_tree\nprint(anytree.RenderTree(tt))\n```\n\n```python\nfrom anytree.dotexport import RenderTreeGraph, DotExporter\n\nRenderTreeGraph(tt).to_picture(\"tree.png\")\n```\n\n# ORM\n\n```python\nimport sqlalchemy.orm\nimport pycram.orm.base\nimport pycram.orm.action_designator\n\n# set description of what we are doing\npycram.orm.base.ProcessMetaData().description = \"Tutorial for getting familiar with the ORM.\"\n\nengine = sqlalchemy.create_engine(\"sqlite+pysqlite:///:memory:\", echo=False)\nsession = sqlalchemy.orm.Session(bind=engine)\npycram.orm.base.Base.metadata.create_all(engine)\nsession.commit()\n\ntt.insert(session)\n```\n\n```python\nfrom sqlalchemy import select\n\nnavigations = session.scalars(select(pycram.orm.action_designator.NavigateAction)).all()\nprint(*navigations, sep=\"\\n\")\n```\n\n```python\nnavigations = (session.scalars(\n    select(pycram.orm.action_designator.NavigateAction, pycram.orm.base.Position, pycram.orm.base.Quaternion).\n    join(pycram.orm.action_designator.NavigateAction.pose).\n    join(pycram.orm.base.Pose.position).\n    join(pycram.orm.base.Pose.orientation)).all())\nprint(*navigations, sep=\"\\n\")\n```\n\nThe world can also be closed with the 'exit' method\n\n```python\nworld.exit()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the key features of the Bullet World in the PyCRAM documentation?"}, {"role": "assistant", "content": "Bullet World\n\nThis Notebook will show you the basics of working with the PyCRAM BulletWorld.\n\nFirst we need to import and create a BulletWorld.\n\n```python\nfrom pycram.worlds.bullet_world import BulletWorld\nfrom pycram.datastructures.pose import Pose\nfrom pycram.datastructures.enums import ObjectType, WorldMode\n\nworld = BulletWorld(mode=WorldMode.GUI)\n```\n\nThis new window is the BulletWorld, PyCRAMs internal physics simulation. You can use the mouse to move the camera\naround:\n\n* Press the left mouse button to rotate the camera\n* Press the right mouse button to move the camera\n* Press the middle mouse button (scroll wheel) and move the mouse up or down to zoom\n\nAt the moment the BulletWorld only contains a floor, this is spawned by default when creating the BulletWorld.\nFurthermore, the gravity is set to 9.8 $m^2$, which is the same gravitation as the one on earth.\n\nTo spawn new things in the BulletWorld we need to import the Object class and create and instance of it.\n\n```python\nfrom pycram.world_concepts.world_object import Object\n\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([0, 0, 1]))\n```\n\n<!-- #region -->\nAs you can see this spawns a milk floating in the air. What we did here was create a new Object which has the name \"\nmilk\" as well as the type {attr}`~pycram.datastructures.enums.ObjectType.MILK`, is spawned from the file \"milk.stl\" and is at the position [0, 0, 1].\n\nThe type of an Object can either be from the enum ObjectType or a string. However, it is recommended to use the enum\nsince this would make for a more consistent naming of types which makes it easier to work with types. But since the\ntypes of the enum might not fit your case you can also use strings.\n\nThe first three of these parameters are required while the position is optional. As you can see it was sufficient to\nonly specify the filename for PyCRAM to spawn the milk mesh. When only providing a filename, PyCRAM will search in its\nresource directory for a matching file and use it.\n\nFor a complete list of all parameters that can be used to crate an Object please check the documentation.\n\nSince the Object is spawned, we can now interact with it. First we want to move it around and change its orientation\n<!-- #endregion -->\n\n```python\nmilk.set_position(Pose([1, 1, 1]))\n```\n\n```python\nmilk.set_orientation(Pose(orientation=[1, 0, 0, 1]))\n```\n\n```python\nmilk.set_pose(Pose([0, 0, 1], [0, 0, 0, 1]))\n```\n\nIn the same sense as setting the position or orientation, you can also get the position and orientation.\n\n```python\nprint(f\"Position: \\n{milk.get_position()}\")\n\nprint(f\"Orientation: \\n{milk.get_orientation()}\")\n\nprint(f\"Pose: \\n{milk.get_pose()}\")\n```\n\n## Attachments\n\nYou can attach Objects to each other simply by calling the attach method on one of them and providing the other as\nparameter. Since attachments are bi-directional it doesn't matter on which Object you call the method.\n\nFirst we need another Object\n\n```python\ncereal = Object(\"cereal\", ObjectType.BREAKFAST_CEREAL, \"breakfast_cereal.stl\", pose=Pose([1, 0, 1]))\n```\n\n```python\nmilk.attach(cereal)\n```\n\nNow since they are attached to each other, if we move one of them the other will move in conjunction.\n\n```python\nmilk.set_position(Pose([1, 1, 1]))\n```\n\nIn the same way the Object can also be detached, just call the detach method on one of the two attached Objects.\n\n```python\ncereal.detach(milk)\n```\n\n## Links and Joints\n\nObjects spawned from mesh files do not have links or joints, but if you spawn things from a URDF like a robot they will\nhave a lot of links and joints. Every Object has two dictionaries as attributes, namely ```links``` and ```joints```\nwhich contain every link or joint as key and a unique id, used by PyBullet, as value.\n\nWe will see this at the example of the PR2:\n\n```python\npr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\nprint(pr2.links)\n```\n\nFor links there are similar methods available as for the pose. However, you can only **get** the position and\norientation of a link.\n\n```python\nprint(f\"Position: \\n{pr2.get_link_position('torso_lift_link')}\")\n\nprint(f\"Orientation: \\n{pr2.get_link_orientation('torso_lift_link')}\")\n\nprint(f\"Pose: \\n{pr2.get_link_pose('torso_lift_link')}\")\n```\n\nMethods available for joints are:\n\n* {meth}`~pycram.world_concepts.world_object.Object.get_joint_position`\n* {meth}`~pycram.world_concepts.world_object.Object.set_joint_position`\n* {meth}`~pycram.world_concepts.world_object.Object.get_joint_limits`\n\nWe will see how these methods work at the example of the torso_lift_joint:\n\n```python\nprint(f\"Joint limits: {pr2.get_joint_limits('torso_lift_joint')}\")\n\nprint(f\"Current Joint state: {pr2.get_joint_position('torso_lift_joint')}\")\n\npr2.set_joint_position(\"torso_lift_joint\", 0.2)\n\nprint(f\"New Joint state: {pr2.get_joint_position('torso_lift_joint')}\")\n```\n\n## Misc Methods\n\nThere are a few methods that don't fit any category but could be helpful anyway. The first two are {meth}`~pycram.description.Link.get_color`\nand {meth}`~pycram.description.Link.set_color`, as the name implies they can be used to get or set the color for specific links or the whole\nObject.\n\n```python\nprint(f\"Pr2 forearm color: {pr2.get_link_color('r_forearm_link')}\")\n```\n\n```python\npr2.set_link_color(\"r_forearm_link\", [1, 0, 0])\n```\n\nLastly, there is {meth}`~pycram.description.Link.get_axis_aligned_bounding_box`, AABB stands for *A*xis *A*ligned *B*ounding *B*ox. This method returns two points in\nworld coordinates which span a rectangle representing the AABB.\n\n```python\npr2.get_axis_aligned_bounding_box()\n```\n\nTo close the BulletWorld again please use the {meth}`~pycram.datastructures.world.World.exit` method since it will also terminate threads running in the\nbackground\n\n```python\nworld.exit()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the key features of the Plan Language in the PyCRAM documentation?"}, {"role": "assistant", "content": "Plan Language\n\nThe PyCRAM plan language is a way to structure the execution of your plan. In generally the plan language allows to\nexecute designators either sequential or in parallel. Furthermore, exceptions that occur during execution of a plan with\nthe plan language do not interrupt the execution instead they are caught and saved to a dictionary for later analysis.\nAll language expressions return a State, this can either be SUCCEDED or FAILED.\n\nThere are 4 language expressions:\n\n| Expression | Name             | Description                                                                                                                                                                                                                                                                                | \n|------------|------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| +          | **Sequential**   | Executes the designators one after another, if one of the designators raises an exception the execution is aborted and the state FAILED will be returned.                                                                                                                                  |\n| -          | **Try In Order** | Executes the designators one after another, if one designator raises an exception the exception is caught and saved but the execution is not interrupted and the other designators are executed. Returns the state SUCCEDED if at least one designator can be executed without exception. |\n| *          | **Repeat**       | Repeat the previous language expression a number of time. Has to be used with a language expression and an integer.                                                                                                                                                                        | \n| \\|         | **Parallel**     | Executes all designators in parallel. For each designator there will be a new thread created and the designator is executed in this thread. If one of the designators raises an exception the returned state will be FAILED.                                                               |\n| ^          | **Try All**      | Executes all designators in parallel with a designated thread for each designator. Returns the state SUCCEDED if at least one designator can be executed without an exception                                                                                                              |\n| >>         | **Monitor**      | Monitors the execution of the attached langauge expression, will interrupt the execution as soon as a given condition is fulfilled.                                                                                                                                                        | \n\nThe Sequential expression is the only one which aborts the execution once an error is raised.\n\nWhen using the plan language a tree structure of the plan is created where the language expressions are nodes and\ndesignators are leafs. This tree uses AnyTree (like the task tree) and can be rendered with the anytree Renderer.\n\n## Sequential\n\nThis language expression allows to execute designators one after another, if one of the designators raises an exception\nthe execution will be aborted and the state FAILED will be returned.\n\nWe will start with a simple example that uses an action designator for moving the robot and parking its arms.\n\n```python\nimport time\n\nfrom pycram.designators.action_designator import *\nfrom pycram.datastructures.pose import Pose\nfrom pycram.datastructures.enums import Arms\n\nnavigate = NavigateAction([Pose([1, 1, 0])])\npark = ParkArmsAction([Arms.BOTH])\n\nplan = navigate + park\n```\n\nWith this simple plan created we can inspect it and render the created tree structure.\n\n```python\nfrom anytree import RenderTree\n\nprint(RenderTree(plan))\n```\n\nAs you can see there is the root node which is the language expression and then there are the leafs which are the\ndesignators. When executing this plan the Sequential node will try to execute the NavigateAction and if that is finished\nwithout any error the ParkArmsAction will be executed.\n\nThe plan can be executed by wrapping it inside a ```with simulated_robot``` environment and calling perform on the\nplan.\n\nIf you are performing a plan with a simulated robot, you need a BulletWorld.\n\n```python\nfrom pycram.worlds.bullet_world import BulletWorld\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType\n\nworld = BulletWorld()\npr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\n```\n\n```python\nfrom pycram.process_module import simulated_robot\n\nworld.reset_bullet_world()\n\nwith simulated_robot:\n    plan.perform()\n```\n\n## Try In Order\n\nTry in order is similar to Sequential, it also executes all designators one after another but the key difference is that\nan exception in one of the designators does not terminate the whole execution. Furthermore, the state FAILED will only\nbe returned if all designator executions raise an error.\n\nBesides the described difference in behaviour this language expression can be used in the same way as Sequential.\n\n```python\nfrom pycram.designators.action_designator import *\nfrom pycram.datastructures.pose import Pose\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\n\nworld.reset_bullet_world()\n\nnavigate = NavigateAction([Pose([1, 1, 0])])\npark = ParkArmsAction([Arms.BOTH])\n\nplan = navigate - park\n\nwith simulated_robot:\n    plan.perform()\n```\n\n## Parallel\n\nParallel executes all designator at once in dedicated threads. The execution of other designators is not aborted when a\nexception is raised, this is the case since threads can not be killed from the outside and this would also cause\nunforeseen problems. The state returned will be SUCCEDED if all designators could be executed without an exception raised\nin any other case FAILED will be returned.\n\nSince executing designators in parallel can get chaotic especially with complex actions like PickUp or Transport. For\nthis reason not all action designators can be used in parallel and try all expressions. The list of action designator\nthat cannot be used in language expressions can be seen in {attr}`~pycram.language.Language.parallel_blocklist`.\n\nDesignators that cannot be used in parallel and try all:\n\n* PickUpAction\n* PlaceAction\n* OpenAction\n* CloseAction\n* TransportAction\n\nUsing the parallel expressions works like Sequential and TryInOrder.\n\n```python\nfrom pycram.designators.action_designator import *\nfrom pycram.datastructures.pose import Pose\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\n\nworld.reset_world()\n\nnavigate = NavigateAction([Pose([1, 1, 0])])\npark = ParkArmsAction([Arms.BOTH])\n\nplan = navigate | park\n\nwith simulated_robot:\n    plan.perform()\n```\n\n## Try All\n\nTryAll is to Parallel what TryInOrder is to Sequential, meaning TryAll will also execute all designators in parallel but\nwill return SUCCEEDED if at least one designator is executed without raising an exception.\n\nTryAll can be used like any other language expression.\n\n```python\nfrom pycram.designators.action_designator import *\nfrom pycram.datastructures.pose import Pose\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\n\nworld.reset_bullet_world()\n\nnavigate = NavigateAction([Pose([1, 1, 0])])\npark = ParkArmsAction([Arms.BOTH])\n\nplan = navigate ^ park\n\nwith simulated_robot:\n    plan.perform()\n```\n\n## Combination of Expressions\n\nYou can also combine different language expressions to further structure your plans. If you combine sequential and\nparallel expression please keep in mind that sequential expressions bind stringer than parallel ones. For example:\n\n```\nnavigate | park + move_torso\n```\n\nIn this case 'park' and 'move_torso' would form a Sequential expression and 'naviagte' would form a Parallel expression\nwith Sequential. You can try this yourself in the following cell.\n\n```python\nfrom pycram.designators.action_designator import *\nfrom pycram.datastructures.pose import Pose\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\n\nworld.reset_world()\n\nnavigate = NavigateAction([Pose([1, 1, 0])])\npark = ParkArmsAction([Arms.BOTH])\nmove_torso = MoveTorsoAction([0.3])\n\nplan = navigate | park + move_torso\n\nwith simulated_robot:\n    plan.perform()\n```\n\n## Code Objects\n\nYou can not only use designators in the plan language but also python code. For this there is the {class}`~pycram.language.Code`  object\nwhich takes a callable and the arguments for this callable. This allows you to execute arbitrary code in a plan.\n\nThe callable that is used in the {class}`~pycram.language.Code` object can either be a lambda expression or, for more complex code, a\nfunction. If you use a function you can provide parameters as keyword-arguments.\n\n```python\nfrom pycram.designators.action_designator import *\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\nfrom pycram.language import Code\n\n\ndef code_test(param):\n    print(\"-\" * 20)\n    print(param)\n\n\npark = ParkArmsAction([Arms.BOTH])\ncode = Code(lambda: print(\"This is from the code object\"))\ncode_func = Code(code_test, {\"param\": \"Code function\"})\n\nplan = park | code | code_func\n\nwith simulated_robot:\n    plan.perform()\n```\n\n## Exception Handling\n\nIf an exception is raised during the execution of a designator when it is used in a language expression the exception\nwill be caught and saved to a dictionary. In general all designators in a language expression are executed regardless\nof exceptions raised, the only exception from this is the Sequential expression which stops after it encountered an\nexception.\n\nThe language will only catch exceptions that are of type {class}`~pycram.plan_failures.PlanFailure` meaning errors that are defined in\nplan_failures.py in PyCRAM. This also means normal Python errors, such as KeyError, will interrupt the execution of your\ndesignators.\n\nWe will see how exceptions are handled at a simple example.\n\n```python\nfrom pycram.designators.action_designator import *\nfrom pycram.process_module import simulated_robot\nfrom pycram.language import Code\nfrom pycram.plan_failures import PlanFailure\n\n\ndef code_test():\n    raise PlanFailure\n\n\nnavigate = NavigateAction([Pose([1, 1, 0])])\ncode_func = Code(code_test)\n\nplan = navigate | code_func\n\nwith simulated_robot:\n    plan.perform()\n\nprint(plan.exceptions)\n```\n\n## Repeat\n\nRepeat simply repeats a language expression a number of times. As all other language expressions Repeat captures\nexceptions that occur during execution and saves them to the dictionary in the root of the plan.\n\nSince Repeat uses the \\* operator you should keep in mind that it will be evaluated before any other operator, so use\nparentheses to ensure the correct structure of your plan.\n\nYou can see an example of how to use Repeat below.\n\n```python\nfrom pycram.designators.action_designator import *\nfrom pycram.process_module import simulated_robot\n\nmove_torso_up = MoveTorsoAction([0.3])\nmove_torso_down = MoveTorsoAction([0.])\n\nplan = (move_torso_up + move_torso_down) * 5\n\nwith simulated_robot:\n    plan.perform()\n```\n\n## Monitor\n\nMonitor allows to monitor the execution of a language expression and interrupt it as soon as a given condition is\nfulfilled. The condition can either be a Callable which returns a boolean or a Fluent.\nWhen executed the Monitor will create a separate thread which will check if the condition is satisfied with a frequency\nof 10 Hz. If the condition is satisfied the execution of the language expression will be interrupted.\n\nFor the example on how Monitors work we will use the previous example with the robot moving up and down. We will use a\nMonitor to interrupt the execution after 2 seconds instead of executing the whole plan 5 times.\n\n```python\nfrom pycram.designators.action_designator import *\nfrom pycram.process_module import simulated_robot\nfrom pycram.language import Monitor\nimport time\n\nmove_torso_up = MoveTorsoAction([0.3])\nmove_torso_down = MoveTorsoAction([0.])\n\n\ndef monitor_func():\n    time.sleep(2)\n    return True\n\n\nplan = (move_torso_up + move_torso_down) * 5 >> Monitor(monitor_func)\n\nwith simulated_robot:\n    plan.perform()\n```\n\nIf you are finished with this example you can close the world with the cell below.\n\n```python\nworld.exit()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the key concepts covered in the Action Designator section of the PyCRAM documentation?"}, {"role": "assistant", "content": "Action Designator\n\nThis example will show the different kinds of Action Designators that are available. We will see how to create Action\nDesignators and what they do.\n\nAction Designators are high-level descriptions of actions which the robot should execute.\n\nAction Designators are created from an Action Designator Description, which describes the type of action as well as the\nparameter for this action. Parameter are given as a list of possible parameters.\nFor example, if you want to describe the robot moving to a table you would need a\n{meth}`~pycram.designators.action_designator.NavigateAction` and a list of poses that are near the table. The Action\nDesignator Description will then pick one of the poses and return a performable Action Designator which contains the\npicked pose.\n\n\n<!-- #endregion -->\n\n## Navigate Action\n\nWe will start with a simple example of the {meth}`~pycram.designators.action_designator.NavigateAction`.\n\nFirst, we need a BulletWorld with a robot.\n\n```python\nfrom pycram.worlds.bullet_world import BulletWorld\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType, WorldMode\n\nworld = BulletWorld(WorldMode.GUI)\npr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\n```\n\nTo move the robot we need to create a description and resolve it to an actual Designator. The description of navigation\nonly needs a list of possible poses.\n\n```python\nfrom pycram.designators.action_designator import NavigateAction\nfrom pycram.datastructures.pose import Pose\n\npose = Pose([1, 0, 0], [0, 0, 0, 1])\n\n# This is the Designator Description\nnavigate_description = NavigateAction(target_locations=[pose])\n\n# This is the performable Designator\nnavigate_designator = navigate_description.resolve()\n```\n\nWhat we now did was: create the pose where we want to move the robot, create a description describing a navigation with\na list of possible poses (in this case the list contains only one pose) and create an action designator from the\ndescription. The action designator contains the pose picked from the list of possible poses and can be performed.\n\n```python\nfrom pycram.process_module import simulated_robot\n\nwith simulated_robot:\n    navigate_designator.perform()\n```\n\nEvery designator that is performed needs to be in an environment that specifies where to perform the designator either\non the real robot or the simulated one. This environment is called {meth}`~pycram.process_module.simulated_robot`  similar there is also\na {meth}`~pycram.process_module.real_robot` environment.\n\nThere are also decorators which do the same thing but for whole methods, they are called {meth}`~pycram.process_module.with_real_robot` \nand {meth}`~pycram.process_module.with_simulated_robot`.\n\n## Move Torso\n\nThis action designator moves the torso up or down, specifically it sets the torso joint to a given value.\n\nWe start again by creating a description and resolving it to a designator. Afterwards, the designator is performed in\na {meth}`~pycram.process_module.simulated_robot` environment.\n\n```python\nfrom pycram.designators.action_designator import MoveTorsoAction\nfrom pycram.process_module import simulated_robot\n\ntorso_pose = 0.2\n\ntorso_desig = MoveTorsoAction([torso_pose]).resolve()\n\nwith simulated_robot:\n    torso_desig.perform()\n```\n\n## Set Gripper\n\nAs the name implies, this action designator is used to open or close the gripper.\n\nThe procedure is similar to the last time, but this time we will shorten it a bit.\n\n```python\nfrom pycram.designators.action_designator import SetGripperAction\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.enums import GripperState, Arms\n\ngripper = Arms.RIGHT\nmotion = GripperState.OPEN\n\nwith simulated_robot:\n    SetGripperAction(grippers=[gripper], motions=[motion]).resolve().perform()\n```\n\n## Park Arms\n\nPark arms is used to move one or both arms into the default parking position.\n\n```python\nfrom pycram.designators.action_designator import ParkArmsAction\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.enums import Arms\n\nwith simulated_robot:\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n```\n\n## Pick Up and Place\n\nSince these two are dependent on each other, meaning you can only place something when you picked it up beforehand, they\nwill be shown together.\n\nThese action designators use object designators, which will not be further explained in this tutorial so please check\nthe example on object designators for more details.\n\nTo start we need an environment in which we can pick up and place things as well as an object to pick up.\n\n```python\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.3, 1, 0.9]))\n\nworld.reset_world()\n```\n\n```python\nfrom pycram.designators.action_designator import PickUpAction, PlaceAction, ParkArmsAction, MoveTorsoAction,\n\nNavigateAction\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.enums import Arms, Grasp\nfrom pycram.datastructures.pose import Pose\n\nmilk_desig = BelieveObject(names=[\"milk\"])\narm = Arms.RIGHT\n\nwith simulated_robot:\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n\n    MoveTorsoAction([0.3]).resolve().perform()\n\n    NavigateAction([Pose([0.78, 1, 0.0],\n                         [0.0, 0.0, 0.014701099828940344, 0.9998919329926708])]).resolve().perform()\n\n    PickUpAction(object_designator_description=milk_desig,\n                 arms=[arm],\n                 grasps=[Grasp.RIGHT]).resolve().perform()\n\n    NavigateAction([Pose([-1.90, 0.78, 0.0],\n                         [0.0, 0.0, 0.16439898301071468, 0.9863939245479175])]).resolve().perform()\n\n    PlaceAction(object_designator_description=milk_desig,\n                target_locations=[Pose([-1.20, 1.0192, 0.9624],\n                                       # [0.0, 0.0, 0.6339889056055381, 0.7733421413379024])], \n                                       [0, 0, 0, 1])],\n                arms=[arm]).resolve().perform()\n```\n\n```python\nworld.reset_world()\n```\n\n## Look At\n\nLook at lets the robot look at a specific point, for example if it should look at an object for detecting.\n\n```python\nfrom pycram.designators.action_designator import LookAtAction\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.pose import Pose\n\ntarget_location = Pose([1, 0, 0.5], [0, 0, 0, 1])\nwith simulated_robot:\n    LookAtAction(targets=[target_location]).resolve().perform()\n```\n\n## Detect\n\nDetect is used to detect objects in the field of vision (FOV) of the robot. We will use the milk used in the pick\nup/place example, if you didn't execute that example you can spawn the milk with the following cell. The detect\ndesignator will return a resolved instance of an ObjectDesignatorDescription.\n\n```python\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.3, 1, 0.9]))\n```\n\n```python\nfrom pycram.designators.action_designator import DetectAction, LookAtAction, ParkArmsAction, NavigateAction\nfrom pycram.designators.object_designator import BelieveObject\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.pose import Pose\n\nmilk_desig = BelieveObject(names=[\"milk\"])\n\nwith simulated_robot:\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n\n    NavigateAction([Pose([0, 1, 0], [0, 0, 0, 1])]).resolve().perform()\n\n    LookAtAction(targets=[milk_desig.resolve().pose]).resolve().perform()\n\n    obj_desig = DetectAction(milk_desig).resolve().perform()\n\n    print(obj_desig)\n```\n\n## Transporting\n\nTransporting can transport an object from its current position to another target position. It is similar to the Pick and\nPlace plan used in the Pick-up and Place example. Since we need an Object which we can transport we spawn a milk, you\ndon't need to do this if you already have spawned it in a previous example.\n\n```python\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.3, 1, 0.9]))\n```\n\n```python\nfrom pycram.designators.action_designator import *\nfrom pycram.designators.object_designator import *\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.pose import Pose\nfrom pycram.datastructures.enums import Arms\n\nmilk_desig = BelieveObject(names=[\"milk\"])\n\ndescription = TransportAction(milk_desig,\n                              [Arms.LEFT],\n                              [Pose([-1.35, 0.78, 0.95],\n                                    [0.0, 0.0, 0.16439898301071468, 0.9863939245479175])])\nwith simulated_robot:\n    MoveTorsoAction([0.2]).resolve().perform()\n    description.resolve().perform()\n```\n\n## Opening\n\nOpening allows the robot to open a drawer, the drawer is identified by an ObjectPart designator which describes the\nhandle of the drawer that should be grasped.\n\nFor the moment this designator works only in the apartment environment, therefore we remove the kitchen and spawn the\napartment.\n\n```python\nkitchen.remove()\n```\n\n```python\napartment = Object(\"apartment\", ObjectType.ENVIRONMENT, \"apartment.urdf\")\n```\n\n```python\nfrom pycram.designators.action_designator import *\nfrom pycram.designators.object_designator import *\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.pose import Pose\n\napartment_desig = BelieveObject(names=[\"apartment\"]).resolve()\nhandle_deisg = ObjectPart(names=[\"handle_cab10_t\"], part_of=apartment_desig)\n\nwith simulated_robot:\n    MoveTorsoAction([0.25]).resolve().perform()\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n    NavigateAction([Pose([1.7474915981292725, 2.6873629093170166, 0.0],\n                         [-0.0, 0.0, 0.5253598267689507, -0.850880163370435])]).resolve().perform()\n    OpenAction(handle_deisg, [Arms.RIGHT]).resolve().perform()\n```\n\n## Closing\n\nClosing lets the robot close an open drawer, like opening the drawer is identified by an ObjectPart designator\ndescribing the handle to be grasped.\n\nThis action designator only works in the apartment environment for the moment, therefore we remove the kitchen and spawn\nthe apartment. Additionally, we open the drawer such that we can close it with the action designator.\n\n```python\nkitchen.remove()\n```\n\n```python\napartment = Object(\"apartment\", ObjectType.ENVIRONMENT, \"apartment.urdf\")\napartment.set_joint_state(\"cabinet10_drawer_top_joint\", 0.4)\n```\n\n```python\nfrom pycram.designators.action_designator import *\nfrom pycram.designators.object_designator import *\nfrom pycram.datastructures.enums import Arms\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.pose import Pose\n\napartment_desig = BelieveObject(names=[\"apartment\"]).resolve()\nhandle_deisg = ObjectPart(names=[\"handle_cab10_t\"], part_of=apartment_desig)\n\nwith simulated_robot:\n    MoveTorsoAction([0.25]).resolve().perform()\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n    NavigateAction([Pose([1.7474915981292725, 2.8073629093170166, 0.0],\n                         [-0.0, 0.0, 0.5253598267689507, -0.850880163370435])]).resolve().perform()\n    CloseAction(handle_deisg, [Arms.RIGHT]).resolve().perform()\n```\n\n```python\nworld.exit()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the key concepts covered in the Object Designator section of the PyCRAM documentation?"}, {"role": "assistant", "content": "Object Designator\n\nObject designators are used to describe objects located in the BulletWorld or the real environment and then resolve them\nduring runtime to concrete objects.\n\nObject designators are different from the Object class in bullet_world.py in the way that they just describe an object\nand do not create objects or provide methods to manipulate them. Nevertheless, object designators contain a reference to\nthe BulletWorld object.\n\nAn Object designator takes two parameters, of which at least one has to be provided. These parameters are:\n\n* A list of names\n* A list of types\n\nObject Designators work similar to Location designators, they get constrains describing a set of objects and when\nresolved return a specific instance.\n\nFor all following examples we need a BulletWorld, so let's create one.\n\n```python\nfrom pycram.worlds.bullet_world import BulletWorld\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType, WorldMode\nfrom pycram.datastructures.pose import Pose\n\nworld = BulletWorld(WorldMode.GUI)\n```\n\n## Believe Object\n\nThis object designator is used to describe objects that are located in the BulletWorld. So objects that are in the\nbelief state, hence the name. In the future when there is a perception interface, there will be a ```RealObject```\ndescription which will be used to describe objects in the real world.\n\nSince {meth}`~pycram.designators.object_designator.BelieveObject` describes Objects in the BulletWorld we create a few.\n\n```python\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.3, 1, 0.9]))\ncereal = Object(\"froot_loops\", ObjectType.BREAKFAST_CEREAL, \"breakfast_cereal.stl\", pose=Pose([1.3, 0.9, 0.95]))\nspoon = Object(\"spoon\", ObjectType.SPOON, \"spoon.stl\", pose=Pose([1.3, 1.1, 0.87]))\n```\n\nNow that we have objects we can create an object designator to describe them. For the start we want an object designator\nonly describing the milk. Since all objects have unique names we can create an object designator using a list with only\nthe name of the object.\n\n```python\nfrom pycram.designators.object_designator import BelieveObject\n\nobject_description = BelieveObject(names=[\"milk\"])\n\nprint(object_description.resolve())\n```\n\nYou can also use the type to describe objects, so now we want to have an object designator that describes every food in\nthe world.\n\n```python\nfrom pycram.designators.object_designator import BelieveObject\n\nobject_description = BelieveObject(types=[ObjectType.MILK, ObjectType.BREAKFAST_CEREAL])\n\nprint(object_description.resolve())\n```\n\n## Object Part\n\nPart of object designators can be used to describe something as part of another object. For example, you could describe\na specific drawer as part of the kitchen. This is necessary since the drawer is no single BulletWorld Object but rather\na link of the kitchen which is a BulletWorld Object.\n\nFor this example we need just need the kitchen, if you didn't spawn it in the previous example you can spawn it with the\nfollowing cell.\n\n```python\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\n```\n\n```python\nfrom pycram.designators.object_designator import ObjectPart, BelieveObject\n\nkitchen_desig = BelieveObject(names=[\"kitchen\"]).resolve()\n\nobject_description = ObjectPart(names=[\"sink_area_left_upper_drawer_main\"], part_of=kitchen_desig)\n\nprint(object_description.resolve())\n```\n\n## Object Designators as Generators\n\nSimilar to location designators object designators can be used as generators to iterate through every object that they\nare describing. We will see this at the example of an object designator describing every type of food.\n\nFor this we need some objects, so if you didn't already spawn them you can use the next cell for this.\n\n```python\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.3, 1, 0.9]))\ncereal = Object(\"froot_loops\", ObjectType.BREAKFAST_CEREAL, \"breakfast_cereal.stl\", pose=Pose([1.3, 0.9, 0.95]))\nspoon = Object(\"spoon\", ObjectType.SPOON, \"spoon.stl\", pose=Pose([1.3, 1.1, 0.87]))\n```\n\n```python\nfrom pycram.designators.object_designator import BelieveObject\n\nobject_description = BelieveObject(types=[ObjectType.MILK, ObjectType.BREAKFAST_CEREAL])\n\nfor obj in object_description:\n    print(obj, \"\\n\")\n```\n\nTo close the world use the following exit function.\n\n```python\nworld.exit()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What information can I find about Location Designators in the PyCRAM documentation?"}, {"role": "assistant", "content": "Location Designator\n\nThis example will show you what location designators are, how to use them and what they are capable of.\n\nLocation Designators are used to semantically describe locations in the world. You could, for example, create a location\ndesignator that describes every position where a robot can be placed without colliding with the environment. Location\ndesignator can describe locations for:\n\n* Visibility\n* Reachability\n* Occupancy\n* URDF Links (for example a table)\n\nTo find locations that fit the given constrains, location designator create Costmaps. Costmaps are a 2D distribution\nthat have a value greater than 0 for every position that fits the costmap criteria.\n\nLocation designators work similar to other designators, meaning you have to create a location designator description\nwhich describes the location. This description can then be resolved to the actual 6D pose on runtime.\n\n## Occupancy\n\nWe will start with a simple location designator that describes a location where the robot can be placed without\ncolliding with the environment. To do this we need a BulletWorld since the costmaps are mostly created from the current\nstate of the BulletWorld.\n\n```python\nfrom pycram.worlds.bullet_world import BulletWorld\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType, WorldMode\nfrom pycram.datastructures.pose import Pose\n\nworld = BulletWorld()\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\n```\n\nNext up we will create the location designator description, the {meth}`~pycram.designators.location_designator.CostmapLocation` that we will be using needs a\ntarget as a parameter. This target describes what the location designator is for, this could either be a pose or object\nthat the robot should be able to see or reach.\n\nIn this case we only want poses where the robot can be placed, this is the default behaviour of the location designator\nwhich we will be extending later.\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\n\ntarget = kitchen.get_pose()\n\nlocation_description = CostmapLocation(target)\n\npose = location_description.resolve()\n\nprint(pose)\n```\n\n## Reachable\n\nNext we want to locations from where the robot can reach a specific point, like an object the robot should pick up. This\ncan also be done with the {meth}`~pycram.designators.location_designator.CostmapLocation` description, but this time we need to provide an additional argument.\nThe additional argument is the robo which should be able to reach the pose.\n\nSince a robot is needed we will use the PR2 and use a milk as a target point for the robot to reach. The torso of the\nPR2 will be set to 0.2 since otherwise the arms of the robot will be too low to reach on the countertop.\n\n```python\npr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\npr2.set_joint_state(\"torso_lift_joint\", 0.2)\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.3, 1, 0.9]))\n\n```\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\n\ntarget = BelieveObject(names=[\"milk\"]).resolve()\nrobot_desig = BelieveObject(names=[\"pr2\"]).resolve()\n\nlocation_description = CostmapLocation(target=target, reachable_for=robot_desig)\n\nprint(location_description.resolve())\n```\n\nAs you can see we get a pose near the countertop where the robot can be placed without colliding with it. Furthermore,\nwe get a list of arms with which the robot can reach the given object.\n\n## Visibile\n\nThe {meth}`~pycram.designators.location_designator.CostmapLocation` can also find position from which the robot can see a given object or location. This is very\nsimilar to how reachable locations are described, meaning we provide a object designator or a pose and a robot\ndesignator but this time we use the ```visible_for``` parameter.\n\nFor this example we need the milk as well as the PR2, so if you did not spawn them during the previous location\ndesignator you can spawn them with the following cell.\n\n```python\npr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.3, 1, 0.9]))\n```\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\n\ntarget = BelieveObject(names=[\"milk\"]).resolve()\nrobot_desig = BelieveObject(names=[\"pr2\"]).resolve()\n\nlocation_description = CostmapLocation(target=target, visible_for=robot_desig)\n\nprint(location_description.resolve())\n```\n\n## Semantic\n\nSemantic location designator are used to create location descriptions for semantic entities, like a table. An example of\nthis is: You have a robot that picked up an object and should place it on a table. Semantic location designator then\nallows to find poses that are on this table.\n\nSemantic location designator need an object from which the target entity is a part and the URDF link representing the\nentity. In this case we want a position on the kitchen island, so we have to provide the kitchen object designator since\nthe island is a part of the kitchen and the link name of the island surface.\n\nFor this example we need the kitchen as well as the milk. If you spawned them in one of the previous examples you don't\nneed to execute the following cell.\n\n```python\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\")\n```\n\n```python\nfrom pycram.designators.location_designator import SemanticCostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\n\nkitchen_desig = BelieveObject(names=[\"kitchen\"]).resolve()\nmilk_desig = BelieveObject(names=[\"milk\"]).resolve()\n\nlocation_description = SemanticCostmapLocation(urdf_link_name=\"kitchen_island_surface\",\n                                               part_of=kitchen_desig,\n                                               for_object=milk_desig)\n\nprint(location_description.resolve())\n```\n\n## Location Designator as Generator\n\nLocation designator descriptions implement an iter method, so they can be used as generators which generate valid poses\nfor the location described in the description. This can be useful if the first pose does not work for some reason.\n\nWe will see this at the example of a location designator for visibility. For this example we need the milk, if you\nalready have a milk spawned in you world you can ignore the following cell.\n\n```python\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\")\n```\n\n```python\nfrom pycram.designators.location_designator import CostmapLocation\nfrom pycram.designators.object_designator import BelieveObject\n\ntarget = BelieveObject(names=[\"milk\"]).resolve()\nrobot_desig = BelieveObject(names=[\"pr2\"]).resolve()\n\nlocation_description = CostmapLocation(target=target, visible_for=robot_desig)\n\nfor pose in location_description:\n    print(pose.pose)\n```\n\n## Accessing Locations\n\nAccessing describes a location from which the robot can open a drawer. The drawer is specified by a ObjetcPart\ndesignator which describes the handle of the drawer.\n\nAt the moment this location designator only works in the apartment environment, so please remove the kitchen if you\nspawned it in a previous example. Furthermore, we need a robot, so we also spawn the PR2 if it isn't spawned already.\n\n```python\nkitchen.remove()\n```\n\n```python\napartment = Object(\"apartment\", ObjectType.ENVIRONMENT, \"apartment.urdf\")\n```\n\n```python\npr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\npr2.set_joint_state(\"torso_lift_joint\", 0.25)\n```\n\n```python\nfrom pycram.designators.object_designator import *\nfrom pycram.designators.location_designator import *\n\napartment_desig = BelieveObject(names=[\"apartment\"])\nhandle_desig = ObjectPart(names=[\"handle_cab10_t\"], part_of=apartment_desig.resolve())\nrobot_desig = BelieveObject(names=[\"pr2\"])\n\naccess_location = AccessingLocation(handle_desig.resolve(), robot_desig.resolve()).resolve()\nprint(access_location.pose)\n```\n\n## Giskard Location\n\nSome robots like the HSR or the Stretch2 need a full-body ik solver to utilize the whole body. For this case robots\nthe {meth}`~pycram.designators.specialized_designators.location.giskard_location.GiskardLocation` can be used. This location designator uses giskard as an ik solver to find a pose for the\nrobot to reach a target pose.\n\n**Note:** The GiskardLocation relies on Giskard, therefore Giskard needs to run in order for this Location Designator to\nwork.\n\n```python\nfrom pycram.designators.specialized_designators.location.giskard_location import GiskardLocation\n\nrobot_desig = BelieveObject(names=[\"pr2\"]).resolve()\n\nloc = GiskardLocation(target=Pose([1, 1, 1]), reachable_for=robot_desig).resolve()\nprint(loc.pose)\n```\n\nIf you are finished with this example you can close the world with the following cell:\n\n```python\nworld.exit()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the key features of the Motion Designator in the PyCRAM documentation?"}, {"role": "assistant", "content": "Motion Designator\n\nMotion designators are similar to action designators, but unlike action designators, motion designators represent atomic\nlow-level motions. Motion designators only take the parameter that they should execute and not a list of possible\nparameters, like the other designators. Like action designators, motion designators can be performed, performing motion\ndesignator verifies the parameter and passes the designator to the respective process module.\n\nSince motion designators perform a motion on the robot, we need a robot which we can use. Therefore, we will create a\nBulletWorld as well as a PR2 robot.\n\n```python\nfrom pycram.worlds.bullet_world import BulletWorld\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.enums import ObjectType, WorldMode\n\nworld = BulletWorld(WorldMode.GUI)\npr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\n```\n\n## Move\n\nMove is used to let the robot drive to the given target pose. Motion designator are used in the same way as the other\ndesignator, first create a description then resolve it to the actual designator and lastly, perform the resolved\ndesignator.\n\n```python\nfrom pycram.datastructures.pose import Pose\nfrom pycram.designators.motion_designator import MoveMotion\nfrom pycram.process_module import simulated_robot\n\nwith simulated_robot:\n    motion_description = MoveMotion(target=Pose([1, 0, 0], [0, 0, 0, 1]))\n\n    motion_description.perform()\n```\n\n```python\nworld.reset_world()\n```\n\n## MoveTCP\n\nMoveTCP is used to move the tool center point (TCP) of the given arm to the target position specified by the parameter.\nLike any designator we start by creating a description and then resolving and performing it.\n\n```python\nfrom pycram.designators.motion_designator import MoveTCPMotion\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.enums import Arms\n\nwith simulated_robot:\n    motion_description = MoveTCPMotion(target=Pose([0.5, 0.6, 0.6], [0, 0, 0, 1]), arm=Arms.LEFT)\n\n    motion_description.perform()\n```\n\n## Looking\n\nLooking motion designator adjusts the robot state such that the cameras point towards the target pose. Although this\nmotion designator takes the target as position and orientation, in reality only the position is used.\n\n```python\nfrom pycram.designators.motion_designator import LookingMotion\nfrom pycram.process_module import simulated_robot\n\nwith simulated_robot:\n    motion_description = LookingMotion(target=Pose([1, 1, 1], [0, 0, 0, 1]))\n\n    motion_description.perform()\n```\n\n## Move Gripper\n\nMove gripper moves the gripper of an arm to one of two states. The states can be {attr}`~pycram.datastructures.enums.GripperState.OPEN`  and {attr}`~pycram.datastructures.enums.GripperState.CLOSE`, which open\nand close the gripper respectively.\n\n```python\nfrom pycram.designators.motion_designator import MoveGripperMotion\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.enums import Arms, GripperState\n\nwith simulated_robot:\n    motion_description = MoveGripperMotion(motion=GripperState.OPEN, gripper=Arms.LEFT)\n\n    motion_description.perform()\n```\n\n## Detecting\n\nThis is the motion designator implementation of detecting, if an object with the given object type is in the field of\nview (FOV) this motion designator will return an object designator describing the object.\n\nSince we need an object that we can detect, we will spawn a milk for this.\n\n```python\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.5, 0, 1]))\n```\n\n```python\nfrom pycram.designators.motion_designator import DetectingMotion, LookingMotion\nfrom pycram.process_module import simulated_robot\n\nwith simulated_robot:\n    LookingMotion(target=Pose([1.5, 0, 1], [0, 0, 0, 1])).perform()\n\n    motion_description = DetectingMotion(object_type=ObjectType.MILK)\n\n    obj = motion_description.perform()\n\n    print(obj)\n```\n\n## Move Arm Joints\n\nThis motion designator moves one or both arms. Movement targets are a dictionary with joint name as key and target pose\nas value.\n\n```python\nfrom pycram.designators.motion_designator import MoveArmJointsMotion\nfrom pycram.process_module import simulated_robot\n\nwith simulated_robot:\n    motion_description = MoveArmJointsMotion(right_arm_poses={\"r_shoulder_pan_joint\": -0.7})\n\n    motion_description.perform()\n```\n\n## World State Detecting\n\nWorld state detecting is also used to detect objects, however, the object is not required to be in the FOV of the robot.\nAs long as the object is somewhere in the belief state (BulletWorld) a resolved object designator will be returned.\n\nSine we want to detect something we will spawn an object that we can detect. If you already spawned the milk from the\nprevious example, you can skip this step.\n\n```python\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([-1, 0, 1]))\n```\n\n```python\nfrom pycram.designators.motion_designator import WorldStateDetectingMotion\nfrom pycram.process_module import simulated_robot\n\nwith simulated_robot:\n    motion_description = WorldStateDetectingMotion(object_type=ObjectType.MILK)\n\n    obj = motion_description.perform()\n\n    print(obj)\n```\n\n## Move Joints\n\nMove joints can move any number of joints of the robot, the designator takes two lists as parameter. The first list are\nthe names of all joints that should be moved and the second list are the positions to which the joints should be moved.\n\n```python\nfrom pycram.designators.motion_designator import MoveJointsMotion\nfrom pycram.process_module import simulated_robot\n\nwith simulated_robot:\n    motion_description = MoveJointsMotion(names=[\"torso_lift_joint\", \"r_shoulder_pan_joint\"], positions=[0.2, -1.2])\n\n    motion_description.perform()\n```\n\nThe following cell can be used after testing the examples, to close the BulletWorld.\n\n```python\nworld.exit()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the key features of Object Relational Mapping in PyCRAM?"}, {"role": "assistant", "content": "Hands on Object Relational Mapping in PyCram\n\nThis tutorial will walk you through the serialization of a minimal plan in pycram.\nFirst we will import sqlalchemy, create an in memory database and connect a session to it.\n\n```python\nimport sqlalchemy\nimport sqlalchemy.orm\n\nengine = sqlalchemy.create_engine(\"sqlite+pysqlite:///:memory:\", echo=False)\nsession = sqlalchemy.orm.Session(bind=engine)\nsession\n```\n\nNext we create the database schema using the sqlalchemy functionality. For that we need to import the base class of pycram.orm.\n\n```python\nimport pycram.orm.base\nimport pycram.orm.action_designator\npycram.orm.base.Base.metadata.create_all(engine)\nsession.commit()\n```\n\nNext we will write a simple plan where the robot parks his arms and then moves somewhere. We will construct a TaskTree around it such that we can serialize it later. As usual, we first create a world and then define the plan. By doing so, we obtain the task tree.\n\n```python\nfrom pycram.designators.action_designator import *\nfrom pycram.designators.location_designator import *\nfrom pycram.process_module import simulated_robot\nfrom pycram.datastructures.enums import Arms, ObjectType, Grasp, WorldMode\nfrom pycram.tasktree import with_tree\nimport pycram.tasktree\nfrom pycram.worlds.bullet_world import BulletWorld\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.designators.object_designator import *\nfrom pycram.datastructures.pose import Pose\nimport anytree\n\nworld = BulletWorld(WorldMode.GUI)\npr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.3, 1, 0.9]))\ncereal = Object(\"cereal\", ObjectType.BREAKFAST_CEREAL, \"breakfast_cereal.stl\", pose=Pose([1.3, 0.7, 0.95]))\nmilk_desig = ObjectDesignatorDescription(names=[\"milk\"])\ncereal_desig = ObjectDesignatorDescription(names=[\"cereal\"])\nrobot_desig = ObjectDesignatorDescription(names=[\"pr2\"]).resolve()\nkitchen_desig = ObjectDesignatorDescription(names=[\"kitchen\"])\n\n@with_tree\ndef plan():\n    with simulated_robot:\n        ParkArmsActionPerformable(Arms.BOTH).perform()\n        MoveTorsoAction([0.2]).resolve().perform()\n        pickup_pose = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot_desig).resolve()\n        pickup_arm = pickup_pose.reachable_arms[0]\n        NavigateAction(target_locations=[pickup_pose.pose]).resolve().perform()\n        PickUpAction(object_designator_description=cereal_desig, arms=[pickup_arm], grasps=[Grasp.FRONT]).resolve().perform()\n        ParkArmsAction([Arms.BOTH]).resolve().perform()\n\n        place_island = SemanticCostmapLocation(\"kitchen_island_surface\", kitchen_desig.resolve(),\n                                           cereal_desig.resolve()).resolve()\n\n        place_stand = CostmapLocation(place_island.pose, reachable_for=robot_desig, reachable_arm=pickup_arm).resolve()\n\n        NavigateAction(target_locations=[place_stand.pose]).resolve().perform()\n\n        PlaceAction(cereal_desig, target_locations=[place_island.pose], arms=[pickup_arm]).resolve().perform()\n\n        ParkArmsActionPerformable(Arms.BOTH).perform()\n\nplan()\n\n# set description of what we are doing\npycram.orm.base.ProcessMetaData().description = \"Tutorial for getting familiar with the ORM.\"\ntask_tree = pycram.tasktree.task_tree\nprint(anytree.RenderTree(task_tree))\n```\n\nNext we serialize the task tree by recursively inserting from its root.\n\n```python\ntask_tree.root.insert(session)\n```\n\nWe can look at our experiment (Process)MetaData to get some context on the data we just created.\n\n```python\nfrom sqlalchemy import select\n\nprint(*session.scalars(select(pycram.orm.base.ProcessMetaData)).all())\n```\n\nLastly we can look at various table to see how the structures got logged.\nFor example, we can get all the navigate actions that occurred.\n\n```python\nnavigations = session.scalars(select(pycram.orm.action_designator.NavigateAction)).all()\nprint(*navigations, sep=\"\\n\")\n```\n\nDue to the inheritance mapped in the ORM package, we can also obtain all executed actions with just one query. \n\n```python\nactions = session.scalars(select(pycram.orm.action_designator.Action)).all()\nprint(*actions, sep=\"\\n\")\n```\n\nOf course all relational algebra operators, such as filtering and joining also work in pycram.orm queries. Let's say we need all the poses of objects, that were picked up by a robot. Since we defined a relationship between the PickUpAction table and the Object table and between the Object table and the Pose table in the ORM class schema, we can just use the join operator without any further specification:\n\n```python\nobject_actions = (session.scalars(select(pycram.orm.base.Pose)\n                  .join(pycram.orm.action_designator.PickUpAction.object)\n                  .join(pycram.orm.object_designator.Object.pose))\n                  .all())\nprint(*object_actions, sep=\"\\n\")\n\n```\n\nDid you notice, that for the joins we did not join the tables together in a typical sql kind of way, but rather used the relationships defined in the ORM classes and wrote joins like PickUpAction.object or Object.pose? This is because the ORM package automatically creates the joins for us, so we only have to join on the attributes that hold the relationship. This is a huge advantage over writing sql queries by hand, since we do not have to worry about the join conditions. \nThis is a strong tool, but it is crucial to use it properly. Very important to note: The order of the joins matters! For instance, if we joined the Pose table with the Object table first, and placed the join between the PickUpAction table and the Object table second, sqlalchemy would have selected the Pose not from the join between all three tables, but rather from a join between the Pose and the Object table + from a join between the PickUpAction table and the Object table. These mistakes can lead to wrong results or even to errors (the above-mentioned example would actually lead to an error due to the Object table being accessed twice in two separate joins in the same query and therefore the column names of the Object tables would have been ambiguous and could not be used by sqlalchemy to join).\n\nMake sure to check out the other examples of ORM querying.\n\n\nIf we want to filter for all successful tasks we can just add the filter operator:\n\n```python\nfrom pycram.orm.tasktree import TaskTreeNode\n\nsuccessful_tasks = session.scalars(select(TaskTreeNode).where(TaskTreeNode.status == \"SUCCEEDED\"))\nprint(*successful_tasks, sep=\"\\n\")\n```\n\nAs expected all but the root node succeeded, since the root node is still running.\n\nWriting an extension to the ORM package is also done with ease. We need to create a new ActionDesignator class and its ORM equivalent, where we define our new table. Let's say we want to log all the things the robot says. We will create a new ActionDesignator class called Saying and its ORM equivalent called ORMSaying. \n\n```python\nfrom sqlalchemy.orm import Mapped, mapped_column, Session\nfrom pycram.orm.action_designator import Action\nfrom dataclasses import dataclass\n\n\n# define ORM class from pattern in every pycram.orm class\nclass ORMSaying(Action):\n\n    id: Mapped[int] = mapped_column(sqlalchemy.ForeignKey(f'{Action.__tablename__}.id'), primary_key=True, init=False)\n    # since we do not want to add any custom specifications to our column, we don't even need to define mapped_column, sqlalchemy does this internally.\n    text: Mapped[str] \n\n# define brand new action designator\n\n@dataclass \nclass SayingActionPerformable(ActionDesignatorDescription.Action):\n    \n    text: str\n        \n    @with_tree\n    def perform(self) -> None:\n        print(self.text)\n\n    def to_sql(self) -> ORMSaying:\n        return ORMSaying(self.text)\n\n    def insert(self, session: Session, *args, **kwargs) -> ORMSaying:\n        action = super().insert(session)\n        session.add(action)\n        session.commit()\n        return action\n\n```\n\nNow we got our new ActionDesignator called Saying and its ORM version. Since this class got created after all other classes got inserted into the database (in the beginning of the notebook) we have to insert it manually. \n\n```python\nORMSaying.metadata.create_all(bind=engine)\n```\n\nNow we can create and insert a Saying action. Since this is the last part where we interact with the BulletWorld, we can also close it.\n\n```python\n# create a saying action and insert it\nSayingActionPerformable(\"Patchie, Patchie; Where is my Patchie?\").perform()\npycram.tasktree.task_tree.root.insert(session)\nsession.commit()\n\nworld.exit()\n```\n\nIt is notable that committing the object to the session fills its primary key. Hence, there is no worries about assigning unique IDs manually.\nFinally, we can double-check that our object exists in the database.\n\n```python\nsession.scalars(select(ORMSaying)).all()\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What information can I find about Pose in the PyCRAM documentation tutorial?"}, {"role": "assistant", "content": "Pose\n\nPoses in PyCRAM are represented by the Pose class which inherits from the PoseStamped message of ROS. This makes PyCRAMs\nposes compatible with everything in ROS like services, topics or TF.\n\nThis notebook will provide an overview about poses, how to use them and what they can do. We will start by simply\ncreating a pose.\n\nBefore we start a few words about naming convention of Poses in PyCRAM. Naming convention is similar to the PoseStamped\nmessage so if you are familiar with that this should be easy.\n\n* **Position:** A position means the position in cartesian space, so the x, y, and z coordinates.\n* **Orientation:** An orientation is the rotation in all three axes represented as a quaternion with x, y, z, w.\n* **Pose:** A pose is the combination of a position and an orientation. Poses in PyCRAM also contain a frame of\n  reference to which the position and orientation are relative.\n\n```python\nfrom pycram.datastructures.pose import Pose\n\nexample_pose = Pose([1, 2, 3], [0, 0, 0, 1], \"map\")\nprint(example_pose)\n```\n\nAs you can see we created the ```example_pose``` with a position of ```[1, 2, 3]``` and an orientation\nof ```[0, 0, 0, 1]``` in the frame ```map```. But we don't need to provide all these parameters for a Pose, in case\nthere is no parameter the Pose will use default parameter.\n\n```python\nfrom pycram.datastructures.pose import Pose\n\ndefault_pose = Pose()\nprint(default_pose)\n```\n\nIn case no parameter is provided the defualt parameter are:\n\n* position: ```[0, 0, 0]```\n* orientation: ```[o, 0, 0, 1]```\n* frame: ```map```\n\nThe following example will show how to access the data stored in a pose.\n\n```python\nfrom pycram.datastructures.pose import Pose\n\nexample_pose = Pose([1, 2, 3], [0, 0, 0, 1], \"map\")\n\nprint(f\"Access to a component of the position: {example_pose.position.y}\")\n\nprint(f\"Access to a component of the rotation: {example_pose.orientation.x}\")\n\nprint(f\"Get the whole position as geometry_msgs/Pose:\\n{example_pose.position}\")\n\nprint(f\"You can also get position or orientation as a list: {example_pose.position_as_list()}\")\n\nprint(f\"Same with the whole pose: {example_pose.to_list()}\")\n\nprint(f\"Access the reference frame: {example_pose.frame}\")\n```\n\n## Editing a pose\n\nYou can also edit the data saved in a Pose, similar to how you access it.\n\n```python\nfrom pycram.datastructures.pose import Pose\n\nexample_pose = Pose([1, 2, 3], [0, 0, 0, 1], \"map\")\n\n# Edit a single component of the position \nexample_pose.position.x = 3\nprint(f\"Edit only one component:\\n{example_pose.position}\", \"\\n\")\n\n# Edit the whole position\nexample_pose.position = [0, 0, 1]\nprint(f\"Edit the whole position:\\n{example_pose.position}\", \"\\n\")\n\nexample_pose.frame = \"new_frame\"\nprint(f\"Set a new frame:\\n{example_pose.frame}\", \"\\n\")\n\nexample_pose.set_position([3, 2, 1])\nprint(f\"Set the position via method:\\n{example_pose.position}\", \"\\n\")\n```\n\n## Copy Poses\n\nYou can also copy Poses to create a new Pose with the same data. This can be useful if you have a method which would\nneed to alter the Pose, since poses are passed by reference to a method every change done to the Pose in the method\nwould affect the instanced passed to the method.\n\n```python\nfrom pycram.datastructures.pose import Pose\n\nexample_pose = Pose([1, 2, 3], [0, 0, 0, 1], \"map\")\n\ncopy_pose = example_pose.copy()\n\nprint(example_pose, \"\\n\")\nprint(copy_pose)\n```\n\n## Convert to Transform\n\nPyCRAM also has its own transform at which we will take a look in the next section. However, here we will take a look at\nhow to convert a Pose into a Transform.\n\nFor this example we will take a Pose which represents the current pose of a milk object and convert it into a Transform\nwhich represents the transformation from the ```map``` frame to the ```milk``` frame.\n\n```python\nfrom pycram.datastructures.pose import Pose\n\nmilk_pose = Pose([3, 4, 1], [1, 0, 0, 1], \"map\")\n\nmilk_transform = milk_pose.to_transform(\"milk\")\n\nprint(milk_transform)\n```\n\n# Transforms\n\nTransforms are similar to Poses but instead of representing a Pose in a frame of reference they represent a\ntransformation from one frame of reference to another. For this purpose Transforms have an additional parameter\ncalled ```child_frame_id``` which is the frame of reference to which the Transform is pointing.\n\nTransforms in PyCRAM inherit from the TransformStamped message of ROS which makes them, like Poses, compatible to ROS\nservices and topics that expect a TransformStamped message. Therefore, the naming conventions of Transforms are the same\nas of TransformStamped which.\n\n* **Translation:** The vector describing the transformation in cartesian space.\n* **Rotation:** The quaternion describing the transformation of rotation.\n* **Transform:** The combination of translation and rotation\n\n```python\nfrom pycram.datastructures.pose import Transform\n\nexample_transform = Transform([1, 2, 2], [0, 0, 0, 1], \"map\", \"object\")\n\nprint(example_transform)\n```\n\nTransforms have the same methods to get and set values as Poses have, therefore only a short showcase will be given. For\nmore details please look at the Pose example or the API documentation.\n\n```python\nfrom pycram.datastructures.pose import Transform\n\nexample_transform = Transform([2, 5, 1], [0, 0, 1, 1], \"map\", \"object\")\n\nprint(f\"Access the rotation:\\n{example_transform.rotation}\", \"\\n\")\n\nprint(f\"Access the child_frane: {example_transform.child_frame_id}\", \"\\n\")\n\n# changing translation and rotation is exactly like with Poses.\n\nexample_transform.translation = [1, 1, 1]\nprint(f\"New translation:\\n{example_transform.translation}\")\n```\n\n## Convert to Pose and Copy\n\nAnalog to Poses Transforms have a method that converts a Transform to a Pose, in this process the ```child_frame_id```\nwill be lost.\n\nAlso like in Poses Transforms have a ```copy``` method which creates an exact copy of this Transform.\n\n```python\nfrom pycram.datastructures.pose import Transform\n\nmilk_transform = Transform([1, 1, 1], [0, 0, 0, 1], \"map\", \"milk\")\n\nmilk_pose = milk_transform.to_pose()\n\nprint(f\"The converted pose:\\n{milk_pose}\", \"\\n\")\n\nexample_transform = Transform([1, 1, 1], [0, 0, 0, 1], \"map\", \"milk\")\n\ncopy_transform = example_transform.copy()\n\nprint(f\"The copied transform:\\n{copy_transform}\")\n```\n\n## Operations on Transforms\n\nTransforms have, unlike Poses, operations that can be done. These operations are:\n\n* Multiplication\n* Invert\n* InverseTimes\n\n### Multiplication\n\nWe will first take a look at the multiplication of Transforms. We will use an example were we have two Transforms, the\nfirst from ```map``` to a ```hand``` frame and the second from the ```hand``` to a ```milk``` frame. By multiplying\nthese two we get the Transform from ```map``` to ```milk``` frame.\n\n```python\nfrom pycram.datastructures.pose import Transform\n\nmap_to_hand = Transform([1, 1, 1], [0, 0, 0, 1], \"map\", \"hand\")\n\nhand_to_milk = Transform([0.1, 0.05, 0], [0, 0, 0, 1], \"hand\", \"milk\")\n\nmap_to_milk = map_to_hand * hand_to_milk\n\nprint(map_to_milk)\n```\n\n### Invert\n\nThis inverts a Transform, so in we have a transform from ```map``` to ```milk``` then inverting it results in a\nTransform from ```milk``` to ```map``` .\n\n```python\nfrom pycram.datastructures.pose import Transform\n\nmap_to_milk = Transform([1, 1, 0.5], [0, 0, 0, 1], \"map\", \"milk\")\n\nmilk_to_map = map_to_milk.invert()\n\nprint(milk_to_map)\n```\n\n### Inverse Times\n\nInverse times combines the inverting and multiplication of Transforms, this results in a 'minus' for Transforms. We will\nagain use the example of a hand holding a milk, but this time we have the Transforms from ```map``` to ```milk```\nand ```hand``` to ```milk```.\n\n```python\nfrom pycram.datastructures.pose import Transform\n\nmap_to_milk = Transform([1.1, 1.05, 1], [0, 0, 0, 1], \"map\", \"milk\")\n\nhand_to_milk = Transform([0.1, 0.05, 0], [0, 0, 0, 1], \"hand\", \"milk\")\n\nmap_to_milk = map_to_milk.inverse_times(hand_to_milk)\n\nprint(map_to_milk)\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What information can I find on the Robot Description page of the PyCRAM documentation?"}, {"role": "assistant", "content": "Robot Description\n\n(robot_description_header)=\nThe robot description contains semantic information about the robot which can not be extracted from the URDF in a\ngeneral way. This inludes kinematic chains, end-effectors, cameras and their parameter, etc.\n\nIn genral a Robot Description consists a number of different descriptions, these are:\n\n* RobotDescription\n* KinematicChainDescription\n* EndEffectorDescription\n* CameraDescription\n\nIn this example we will create a robot description step-by-step and describe the different components on the way. The\nrobot we will use as an example will be the PR2, the complete PR2 description can also be seen in\n{meth}`pycram.robot_descriptions.pr2_description`.\n\n## Robot Description Class\n\nWe start by creating an instance of the {class}`~pycram.robot_description.RobotDescription` class, this will serve as a\nthe main component to which all other descriptions will be added.\n\nTo initialize a {class}`~pycram.robot_description.RobotDescription` we need a few parameter which are:\n\n* Name\n* base_link\n* torso_link\n* torso_joint\n* Path to a URDF file\n\n```python\nfrom pycram.robot_description import RobotDescription\nimport rospkg\n\nrospack = rospkg.RosPack()\nfilename = rospack.get_path('pycram') + '/resources/robots/' + \"pr2\" + '.urdf'\n\npr2_description = RobotDescription(\"pr2\", \"base_link\", \"torso_lift_link\", \"torso_lift_joint\", filename)\n```\n\n## Kinematic Chain Description\n\nThe kinematic chain description describes a chain of links and joints of the robot which might be interesting when\nworking with the robot. An example of such a chain would be the arm of the robot, when programming for the robot it is\nimportant to know which links and joints exactly make up the arm, however, these can not be extracted from the URDF\nautomatically.\n\nThe kinematic chain is based upon the URDF, meaning when initializing the description one only needs to specify the\nfirst and last link of the chain.\n\nWe will now create the kinematic chain description for the right arm of the PR2. For initializing\nthe {class}`~pycram.robot_description.KinematicChainDescription` the following parameter are needed:\n\n* Name\n* first link\n* last link\n* URDF object\n* Arm type\n\nThe arm type specifies which arm this kinematic chain describes, this is needed when one wants to access only the arms\nof the robot.\n\n```python\nfrom pycram.robot_description import KinematicChainDescription\nfrom pycram.datastructures.enums import Arms\n\nright_arm = KinematicChainDescription(\"right\", \"torso_lift_link\", \"r_wrist_roll_link\",\n                                      pr2_description.urdf_object, arm_type=Arms.RIGHT)\n```\n\nThe created {class}`~pycram.robot_description.KinematicChainDescription` can now be added to the robot description.\n\n```python\npr2_description.add_kinematic_chain_description(right_arm)\n```\n\n## End Effector Description\n\nSince kinematic chains only describe a moveable chain of links and joints like arms these do not represent end-effectors\nwhich can be used to do manipulation tasks.\n\nTo represent end-effectors we will create an {class}`~pycram.robot_description.EndEffectorDescription` which contains the information of the respective\nend-effector. When creating an {class}`~pycram.robot_description.EndEffectorDescription` we need the following parameter:\n\n* Name\n* first link\n* tool_frame\n* URDF object\n\nYou might have noticed that the end-efftor only has a first link but no last link, this is the case since end-effectors\nare at the end of the arms. Therefore, all links and joints below a certain link can be seen as part of the\nend-effector.\n\n```python\nfrom pycram.robot_description import EndEffectorDescription\n\nright_gripper = EndEffectorDescription(\"right_gripper\", \"r_gripper_palm_link\", \"r_gripper_tool_frame\",\n                                       pr2_description.urdf_object)\n```\n\nThe gripper can no be added to the previously created {class}`~pycram.robot_description.KinematicChainDescription`.\n\n```python\nright_arm.end_effector = right_gripper\n```\n\n## Camera Description\n\nThe camera description contains all parameters of a camera, which is mounted on the robot. The parameter for\nthe {class}`~pycram.robot_description.CameraDescription` are:\n\n* Name\n* Link name\n* minimal height\n* maximal height\n* horizontal angle\n* vertical angle\n\n```python\nfrom pycram.robot_description import CameraDescription\nfrom pycram.datastructures.enums import Grasp\n\ncamera = CameraDescription(\"kinect_camera\", \"wide_stereo_optical_frame\", 1.27,\n                           1.60, 0.99483, 0.75049)\n```\n\nThe finished camera description can now be added to the robot description.\n\n```python\npr2_description.add_camera_description(camera)\n```\n\n## Grasps\n\nGrasps define how a robot interacts with objects. The grasps defined in the robot description define for each grasp (\nright, left, top, front) the orientation of the end-effector, relative to the base_frame of the robot, to achieve the\nrespective grasp.\n\n```python\npr2_description.add_grasp_orientations({Grasp.FRONT: [0, 0, 0, 1],\n                                        Grasp.LEFT: [0, 0, -1, 1],\n                                        Grasp.RIGHT: [0, 0, 1, 1],\n                                        Grasp.TOP: [0, 1, 0, 1]})\n```\n\n## Register Robot Description\n\nLastly, you need to register the robot description to the {class}`~pycram.robot_description.RobotDescriptionManager`. As you can see the code to\nregister the robot description has to be executed at the start of PyCRAM, if you put your file with the robot\ndescription in the {class}`pycram.robot_descriptions` directory it will be executed upon the start of PyCRAM.\n\n```python\nfrom pycram.robot_description import RobotDescriptionManager\n\nrdm = RobotDescriptionManager()\nrdm.register_description(pr2_description)\n```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the key features of the action designator in the PyCRAM documentation?"}, {"role": "assistant", "content": "pycram.designators.action_designator\n### **Classes**\n\n#### **MoveTorsoAction**\n- **Description**: Action Designator for Moving the torso of the robot up and down.\n\n#### **SetGripperAction**\n- **Description**: Set the gripper state of the robot.\n\n#### **ReleaseAction**\n- **Description**: Releases an Object from the robot.\n\n#### **GripAction**\n- **Description**: Grip an object with the robot.\n\n#### **ParkArmsAction**\n- **Description**: Park the arms of the robot.\n\n#### **PickUpAction**\n- **Description**: Designator to let the robot pick up an object.\n\n#### **PlaceAction**\n- **Description**: Places an Object at a position using an arm.\n\n#### **NavigateAction**\n- **Description**: Navigates the Robot to a position.\n\n#### **TransportAction**\n- **Description**: Transports an object to a position using an arm.\n\n#### **LookAtAction**\n- **Description**: Lets the robot look at a position.\n\n#### **DetectAction**\n- **Description**: Detects an object that fits the object description and returns an object designator describing the object.\n\n#### **OpenAction**\n- **Description**: Opens a container like object.\n\n#### **CloseAction**\n- **Description**: Closes a container like object.\n\n#### **GraspingAction**\n- **Description**: Grasps an object described by the given Object Designator description.\n\n#### **ActionAbstract**\n- **Description**: Base class for performable actions.\n\n#### **MoveTorsoActionPerformable**\n- **Description**: Move the torso of the robot up and down.\n\n#### **SetGripperActionPerformable**\n- **Description**: Set the gripper state of the robot.\n\n#### **ReleaseActionPerformable**\n- **Description**: Releases an Object from the robot.\n\n#### **GripActionPerformable**\n- **Description**: Grip an object with the robot.\n\n#### **ParkArmsActionPerformable**\n- **Description**: Park the arms of the robot.\n\n#### **PickUpActionPerformable**\n- **Description**: Let the robot pick up an object.\n\n#### **PlaceActionPerformable**\n- **Description**: Places an Object at a position using an arm.\n\n#### **NavigateActionPerformable**\n- **Description**: Navigates the Robot to a position.\n\n#### **TransportActionPerformable**\n- **Description**: Transports an object to a position using an arm.\n\n#### **LookAtActionPerformable**\n- **Description**: Lets the robot look at a position.\n\n#### **DetectActionPerformable**\n- **Description**: Detects an object that fits the object description and returns an object designator describing the object.\n\n#### **OpenActionPerformable**\n- **Description**: Opens a container like object.\n\n#### **CloseActionPerformable**\n- **Description**: Closes a container like object.\n\n#### **GraspingActionPerformable**\n- **Description**: Grasps an object described by the given Object Designator description.\n\n#### **FaceAtPerformable**\n- **Description**: Turn the robot chassis such that it faces the pose and then perform a look at action.\n\n#### **MoveAndPickUpPerformable**\n- **Description**: Navigate to standing position, turn towards the object, and pick it up.\n\n---\n\n### **Module Contents**\n\n#### **pycram.designators.action_designator.MoveTorsoAction**\n- **Inherits**: `pycram.designator.ActionDesignatorDescription`\n- **Description**: Action Designator for Moving the torso of the robot up and down.\n- **Attributes**:\n  - **positions**: `List[float]`\n- **Methods**:\n  - **ground()**: Returns a `MoveTorsoActionPerformable`.\n  - **__iter__()**: Iterates over possible values and returns a `MoveTorsoActionPerformable`.\n\n#### **pycram.designators.action_designator.SetGripperAction**\n- **Inherits**: `pycram.designator.ActionDesignatorDescription`\n- **Description**: Set the gripper state of the robot.\n- **Attributes**:\n  - **grippers**: `List[pycram.datastructures.enums.GripperState]`\n  - **motions**: `List[pycram.datastructures.enums.Arms]`\n- **Methods**:\n  - **ground()**: Returns a `SetGripperActionPerformable`.\n  - **__iter__()**: Iterates over possible combinations and returns a `SetGripperActionPerformable`.\n\n#### **pycram.designators.action_designator.ReleaseAction**\n- **Inherits**: `pycram.designator.ActionDesignatorDescription`\n- **Description**: Releases an Object from the robot.\n- **Attributes**:\n  - **grippers**: `List[pycram.datastructures.enums.Arms]`\n  - **object_designator_description**\n- **Methods**:\n  - **ground()**: Returns a `ReleaseActionPerformable`.\n\n#### **pycram.designators.action_designator.GripAction**\n- **Inherits**: `pycram.designator.ActionDesignatorDescription`\n- **Description**: Grip an object with the robot.\n- **Attributes**:\n  - **grippers**: `List[pycram.datastructures.enums.Arms]`\n  - **object_designator_description**: `pycram.designators.object_designator.ObjectDesignatorDescription`\n  - **efforts**: `List[float]`\n- **Methods**:\n  - **ground()**: Returns a `GripActionPerformable`.\n\n#### **pycram.designators.action_designator.ParkArmsAction**\n- **Inherits**: `pycram.designator.ActionDesignatorDescription`\n- **Description**: Park the arms of the robot.\n- **Attributes**:\n  - **arms**: `List[pycram.datastructures.enums.Arms]`\n- **Methods**:\n  - **ground()**: Returns a `ParkArmsActionPerformable`.\n\n#### **pycram.designators.action_designator.PickUpAction**\n- **Inherits**: `pycram.designator.ActionDesignatorDescription`\n- **Description**: Designator to let the robot pick up an object.\n- **Attributes**:\n  - **object_designator_description**: `Union[pycram.designators.object_designator.ObjectDesignatorDescription, pycram.designators.object_designator.Object]`\n  - **arms**: `List[pycram.datastructures.enums.Arms]`\n  - **grasps**: `List[pycram.datastructures.enums.Grasp]`\n- **Methods**:\n  - **ground()**: Returns a `PickUpActionPerformable`.\n\n#### **pycram.designators.action_designator.PlaceAction**\n- **Inherits**: `pycram.designator.ActionDesignatorDescription`\n- **Description**: Places an Object at a position using an arm.\n- **Attributes**:\n  - **object_designator_description**: `Union[pycram.designators.object_designator.ObjectDesignatorDescription, pycram.designators.object_designator.Object]`\n  - **target_locations**: `List[pycram.datastructures.pose.Pose]`\n  - **arms**: `List[pycram.datastructures.enums.Arms]`\n- **Methods**:\n  - **ground()**: Returns a `PlaceActionPerformable`.\n\n#### **pycram.designators.action_designator.NavigateAction**\n- **Inherits**: `pycram.designator.ActionDesignatorDescription`\n- **Description**: Navigates the Robot to a position.\n- **Attributes**:\n  - **target_locations**: `List[pycram.datastructures.pose.Pose]`\n- **Methods**:\n  - **ground()**: Returns a `NavigateActionPerformable`.\n\n#### **pycram.designators.action_designator.TransportAction**\n- **Inherits**: `pycram.designator.ActionDesignatorDescription`\n- **Description**: Transports an object to a position using an arm.\n- **Attributes**:\n  - **object_designator_description**: `Union[pycram.designators.object_designator.ObjectDesignatorDescription, pycram.designators.object_designator.Object]`\n  - **arms**: `List[pycram.datastructures.enums.Arms]`\n  - **target_locations**: `List[pycram.datastructures.pose.Pose]`\n- **Methods**:\n  - **ground()**: Returns a `TransportActionPerformable`.\n\n#### **pycram.designators.action_designator.LookAtAction**\n- **Inherits**: `pycram.designator.ActionDesignatorDescription`\n- **Description**: Lets the robot look at a position.\n- **Attributes**:\n  - **targets**: `List[pycram.datastructures.pose.Pose]`\n- **Methods**:\n  - **ground()**: Returns a `LookAtActionPerformable`.\n\n#### **pycram.designators.action_designator.DetectAction**\n- **Inherits**: `pycram.designator.ActionDesignatorDescription`\n- **Description**: Detects an object that fits the object description and returns an object designator describing the object.\n- **Attributes**:\n  - **object_designator_description**: `pycram.designators.object_designator.ObjectDesignatorDescription`\n- **Methods**:\n  - **ground()**: Returns a `DetectActionPerformable`.\n\n#### **pycram.designators.action_designator.OpenAction**\n- **Inherits**: `pycram.designator.ActionDesignatorDescription`\n- **Description**: Opens a container like object.\n- **Attributes**:\n  - **object_designator_description**: `pycram.designators.object_designator.ObjectPart`\n  - **\n\narms**: `List[pycram.datastructures.enums.Arms]`\n- **Methods**:\n  - **ground()**: Returns an `OpenActionPerformable`.\n\n#### **pycram.designators.action_designator.CloseAction**\n- **Inherits**: `pycram.designator.ActionDesignatorDescription`\n- **Description**: Closes a container like object.\n- **Attributes**:\n  - **object_designator_description**: `pycram.designators.object_designator.ObjectPart`\n  - **arms**: `List[pycram.datastructures.enums.Arms]`\n- **Methods**:\n  - **ground()**: Returns a `CloseActionPerformable`.\n\n#### **pycram.designators.action_designator.GraspingAction**\n- **Inherits**: `pycram.designator.ActionDesignatorDescription`\n- **Description**: Grasps an object described by the given Object Designator description.\n- **Attributes**:\n  - **arms**: `List[pycram.datastructures.enums.Arms]`\n  - **object_description**: `Union[pycram.designators.object_designator.ObjectDesignatorDescription, pycram.designators.object_designator.ObjectPart]`\n- **Methods**:\n  - **ground()**: Returns a `GraspingActionPerformable`.\n\n#### **pycram.designators.action_designator.ActionAbstract**\n- **Inherits**: `pycram.designator.ActionDesignatorDescription.Action, abc.ABC`\n- **Description**: Base class for performable actions.\n- **Attributes**:\n  - **orm_class**: `Type[pycram.orm.action_designator.Action]`\n- **Methods**:\n  - **abstract perform()**: Must be overwritten by each action.\n  - **to_sql()**: Converts the action to its ORM equivalent.\n  - **insert(session: sqlalchemy.orm.Session, **kwargs)**: Inserts the action into the database.\n\n#### **pycram.designators.action_designator.MoveTorsoActionPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Move the torso of the robot up and down.\n- **Attributes**:\n  - **position**: `float`\n- **Methods**:\n  - **perform()**: Overwritten by each action.\n\n#### **pycram.designators.action_designator.SetGripperActionPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Set the gripper state of the robot.\n- **Attributes**:\n  - **gripper**: `pycram.datastructures.enums.Arms`\n  - **motion**: `pycram.datastructures.enums.GripperState`\n- **Methods**:\n  - **perform()**: Overwritten by each action.\n\n#### **pycram.designators.action_designator.ReleaseActionPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Releases an Object from the robot.\n- **Attributes**:\n  - **gripper**: `pycram.datastructures.enums.Arms`\n  - **object_designator**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`\n- **Methods**:\n  - **perform()**: Overwritten by each action.\n\n#### **pycram.designators.action_designator.GripActionPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Grip an object with the robot.\n- **Attributes**:\n  - **gripper**: `pycram.datastructures.enums.Arms`\n  - **object_designator**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`\n  - **effort**: `float`\n- **Methods**:\n  - **perform()**: Overwritten by each action.\n\n#### **pycram.designators.action_designator.ParkArmsActionPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Park the arms of the robot.\n- **Attributes**:\n  - **arm**: `pycram.datastructures.enums.Arms`\n- **Methods**:\n  - **perform()**: Overwritten by each action.\n\n#### **pycram.designators.action_designator.PickUpActionPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Let the robot pick up an object.\n- **Attributes**:\n  - **object_designator**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`\n  - **arm**: `pycram.datastructures.enums.Arms`\n  - **grasp**: `pycram.datastructures.enums.Grasp`\n  - **object_at_execution**: `Optional[pycram.designators.object_designator.ObjectDesignatorDescription.Object]`\n- **Methods**:\n  - **perform()**: Overwritten by each action.\n\n#### **pycram.designators.action_designator.PlaceActionPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Places an Object at a position using an arm.\n- **Attributes**:\n  - **object_designator**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`\n  - **arm**: `pycram.datastructures.enums.Arms`\n  - **target_location**: `pycram.datastructures.pose.Pose`\n- **Methods**:\n  - **perform()**: Overwritten by each action.\n\n#### **pycram.designators.action_designator.NavigateActionPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Navigates the Robot to a position.\n- **Attributes**:\n  - **target_location**: `pycram.datastructures.pose.Pose`\n- **Methods**:\n  - **perform()**: Overwritten by each action.\n\n#### **pycram.designators.action_designator.TransportActionPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Transports an object to a position using an arm.\n- **Attributes**:\n  - **object_designator**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`\n  - **arm**: `pycram.datastructures.enums.Arms`\n  - **target_location**: `pycram.datastructures.pose.Pose`\n- **Methods**:\n  - **perform()**: Overwritten by each action.\n\n#### **pycram.designators.action_designator.LookAtActionPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Lets the robot look at a position.\n- **Attributes**:\n  - **target**: `pycram.datastructures.pose.Pose`\n- **Methods**:\n  - **perform()**: Overwritten by each action.\n\n#### **pycram.designators.action_designator.DetectActionPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Detects an object that fits the object description and returns an object designator describing the object.\n- **Attributes**:\n  - **object_designator**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`\n- **Methods**:\n  - **perform()**: Overwritten by each action.\n\n#### **pycram.designators.action_designator.OpenActionPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Opens a container like object.\n- **Attributes**:\n  - **object_designator**: `pycram.designators.object_designator.ObjectPart.Object`\n  - **arm**: `pycram.datastructures.enums.Arms`\n- **Methods**:\n  - **perform()**: Overwritten by each action.\n\n#### **pycram.designators.action_designator.CloseActionPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Closes a container like object.\n- **Attributes**:\n  - **object_designator**: `pycram.designators.object_designator.ObjectPart.Object`\n  - **arm**: `pycram.datastructures.enums.Arms`\n- **Methods**:\n  - **perform()**: Overwritten by each action.\n\n#### **pycram.designators.action_designator.GraspingActionPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Grasps an object described by the given Object Designator description.\n- **Attributes**:\n  - **arm**: `pycram.datastructures.enums.Arms`\n  - **object_desig**: `Union[pycram.designators.object_designator.ObjectDesignatorDescription.Object, pycram.designators.object_designator.ObjectPart.Object]`\n- **Methods**:\n  - **perform()**: Overwritten by each action.\n\n#### **pycram.designators.action_designator.FaceAtPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Turn the robot chassis such that it faces the pose and then perform a look at action.\n- **Attributes**:\n  - **pose**: `pycram.datastructures.pose.Pose`\n- **Methods**:\n  - **perform()**: Overwritten by each action.\n\n#### **pycram.designators.action_designator.MoveAndPickUpPerformable**\n- **Inherits**: `ActionAbstract`\n- **Description**: Navigate to standing position, turn towards the object, and pick it up.\n- **Attributes**:\n  - **standing_position**: `pycram.datastructures.pose.Pose`\n  - **object_designator**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`\n  - **arm**: `pycram.datastructures.enums.Arms`\n  - **grasp**: `pycram.datastructures.enums\n\n.Grasp`\n- **Methods**:\n  - **perform()**: Overwritten by each action."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the key features of the pose data structure in the PyCRAM documentation?"}, {"role": "assistant", "content": "pycram.datastructures.pose\n### Classes\n\n**Pose**\n- Pose representation for PyCRAM, this class extends the PoseStamped ROS message from geometry_msgs. Thus making it compatible with every ROS service and message expecting a PoseStamped message.\n\n**Transform**\n- Represents a Transformation from one TF frame to another in PyCRAM. Like with Poses, this class inherits from the ROS message TransformStamped from geometry_msgs, making it compatible with ROS services and messages requiring a TransformStamped message.\n\n### Functions\n\n**get_normalized_quaternion(→ geometry_msgs.msg.Quaternion)**\n- Normalizes a given quaternion such that it has a magnitude of 1.\n\n### Module Contents\n\n**pycram.datastructures.pose.get_normalized_quaternion(quaternion: numpy.ndarray) → geometry_msgs.msg.Quaternion**\n- Normalizes a given quaternion such that it has a magnitude of 1.\n\n  **Parameters:**\n  - quaternion: The quaternion that should be normalized\n\n  **Returns:**\n  - The normalized quaternion\n\n**class pycram.datastructures.pose.Pose(position: typing_extensions.Optional[typing_extensions.List[float]] = None, orientation: typing_extensions.Optional[typing_extensions.List[float]] = None, frame: str = 'map', time: rospy.Time = None)**\n- Bases: geometry_msgs.msg.PoseStamped\n- Pose representation for PyCRAM, this class extends the PoseStamped ROS message from geometry_msgs, making it compatible with every ROS service and message expecting a PoseStamped message.\n\n  **Naming convention for Poses:**\n  - Pose: Instances of this class, representing a cartesian position and a quaternion for orientation\n  - Position: Only the cartesian position in xyz\n  - Orientation: Only the quaternion as xyzw\n\n  **Properties:**\n  - **frame:** str\n    - Property for the frame_id such that it is easier accessible. Instead of Pose.header.frame_id, it is Pose.frame\n    - **Returns:** The TF frame of this Pose\n\n  - **position:** geometry_msgs.msg.Point\n    - Property that points to the position of this pose\n\n  - **orientation:** geometry_msgs.msg.Quaternion\n    - Property that points to the orientation of this pose\n\n  **Methods:**\n  - **static from_pose_stamped(pose_stamped: geometry_msgs.msg.PoseStamped) → Pose**\n    - Converts a geometry_msgs/PoseStamped message to a Pose object. Should be used for compatibility with ROS.\n\n    **Parameters:**\n    - pose_stamped: The pose stamped message which should be converted\n\n    **Returns:**\n    - A Pose object with the same information as the given message\n\n  - **to_list() → typing_extensions.List[typing_extensions.List[float]]**\n    - Returns the position and orientation of this pose as a list containing two lists.\n\n    **Returns:**\n    - The position and orientation as lists\n\n  - **to_transform(child_frame: str) → Transform**\n    - Converts this pose to a Transform from the TF frame of the pose to the given child_frame.\n\n    **Parameters:**\n    - child_frame: Child frame id to which the Transform points\n\n    **Returns:**\n    - A new Transform\n\n  - **copy() → Pose**\n    - Creates a deep copy of this pose.\n\n    **Returns:**\n    - A copy of this pose\n\n  - **position_as_list() → typing_extensions.List[float]**\n    - Returns only the position as a list of xyz.\n\n    **Returns:**\n    - The position as a list\n\n  - **orientation_as_list() → typing_extensions.List[float]**\n    - Returns only the orientation as a list of a quaternion\n\n    **Returns:**\n    - The orientation as a quaternion with xyzw\n\n  - **dist(other_pose: Pose) → float**\n    - Calculates the Euclidean distance between this Pose and the given one. For distance calculation, only the position is used.\n\n    **Parameters:**\n    - other_pose: Pose to which the distance should be calculated\n\n    **Returns:**\n    - The distance between the Poses\n\n  - **__eq__(other: Pose) → bool**\n    - Overloads the ‘==’ operator to check for equality between two Poses. Only compares the position, orientation, and frame. Timestamps of Poses are not taken into account.\n\n    **Parameters:**\n    - other: Other pose which should be compared\n\n    **Returns:**\n    - True if both Poses have the same position, orientation, and frame. False otherwise\n\n  - **set_position(new_position: typing_extensions.List[float]) → None**\n    - Sets the position of this Pose to the given position. Position has to be given as a vector in cartesian space.\n\n    **Parameters:**\n    - new_position: New position as a vector of xyz\n\n  - **set_orientation(new_orientation: typing_extensions.List[float]) → None**\n    - Sets the orientation to the given quaternion. The new orientation has to be given as a quaternion.\n\n    **Parameters:**\n    - new_orientation: New orientation as a quaternion with xyzw\n\n  - **to_sql() → pycram.orm.base.Pose**\n\n  - **insert(session: sqlalchemy.orm.Session) → pycram.orm.base.Pose**\n\n  - **multiply_quaternions(quaternion: typing_extensions.List) → None**\n    - Multiply the quaternion of this Pose with the given quaternion. The result will be the new orientation of this Pose.\n\n    **Parameters:**\n    - quaternion: The quaternion by which the orientation of this Pose should be multiplied\n\n  - **set_orientation_from_euler(axis: typing_extensions.List, euler_angles: typing_extensions.List[float]) → None**\n    - Convert axis-angle to quaternion.\n\n    **Parameters:**\n    - axis: (x, y, z) tuple representing rotation axis.\n    - angle: rotation angle in degree\n\n    **Returns:**\n    - The quaternion representing the axis angle\n\n**class pycram.datastructures.pose.Transform(translation: typing_extensions.Optional[typing_extensions.List[float]] = None, rotation: typing_extensions.Optional[typing_extensions.List[float]] = None, frame: typing_extensions.Optional[str] = 'map', child_frame: typing_extensions.Optional[str] = '', time: rospy.Time = None)**\n- Bases: geometry_msgs.msg.TransformStamped\n- Represents a Transformation from one TF frame to another in PyCRAM. Like with Poses, this class inherits from the ROS message TransformStamped from geometry_msgs, making it compatible with ROS services and messages requiring a TransformStamped message.\n\n  **Naming Convention for Transforms:**\n  - Transform: Instances of this class, representing a translation and rotation from frame_id to child_frame_id\n  - Translation: A vector representing the conversion in cartesian space\n  - Rotation: A quaternion representing the conversion of rotation between both frames\n\n  **Properties:**\n  - **frame:** str\n    - Property for the frame_id such that it is easier accessible. Instead of Pose.header.frame_id, it is Pose.frame\n\n    **Returns:**\n    - The TF frame of this Pose\n\n  - **translation:** None\n    - Property that points to the translation of this Transform\n\n  - **rotation:** None\n    - Property that points to the rotation of this Transform\n\n  **Methods:**\n  - **classmethod from_pose_and_child_frame(pose: Pose, child_frame_name: str) → Transform**\n\n  - **static from_transform_stamped(transform_stamped: geometry_msgs.msg.TransformStamped) → Transform**\n    - Creates a Transform instance from a geometry_msgs/TransformStamped message. Should be used for compatibility with ROS.\n\n    **Parameters:**\n    - transform_stamped: The transform stamped message that should be converted\n\n    **Returns:**\n    - A Transform with the same information as the transform stamped message\n\n  - **copy() → Transform**\n    - Creates a deep copy of this pose.\n\n    **Returns:**\n    - A copy of this pose\n\n  - **translation_as_list() → typing_extensions.List[float]**\n    - Returns the translation of this Transform as a list.\n\n    **Returns:**\n    - The translation as a list of xyz\n\n  - **rotation_as_list() → typing_extensions.List[float]**\n    - Returns the rotation of this Transform as a list representing a quaternion.\n\n    **Returns:**\n    - The rotation of this Transform as a list with xyzw\n\n  - **to_pose() → Pose**\n    - Converts this Transform to a Pose, in this process the child_frame_id is lost.\n\n    **Returns:**\n    - A new pose with the same translation as position and rotation as orientation\n\n  - **invert() → Transform**\n    - Inverts this Transform. The new Transform points from the child_frame_id to the frame_id.\n\n    **Returns:**\n    - A new inverted Transform\n\n  - **__mul__(other: Transform) → typing_extensions.Union[Transform, None]**\n    - Multiplies this Transform with another one. The resulting Transform points from the frame_id of this Transform to the child_frame_id of the other Transform.\n\n    **Parameters:**\n    - other: The Transform which should be multiplied with this one.\n\n    **Returns:**\n    - The resulting Transform from the multiplication\n\n  - **inverse_times(other_transform: Transform) → Transform**\n    - Like a ‘minus’ for Transforms, subtracts the other_transform from this one.\n\n    **Parameters:**\n    - other_transform: Transform which should be subtracted from this one\n\n    **Returns:**\n    - The resulting Transform from the calculation\n\n  - **__eq__(other: Transform) → bool**\n    - Overloads the ‘==’ operator to check for equality between two Transforms. Only compares the translation, rotation, frame, and child frame. Timestamps of Poses are not taken into account.\n\n    **Parameters:**\n    - other: Other pose which should be compared\n\n    **Returns:**\n    - True if both Transforms have the same translation, rotation, frame, and child frame. False otherwise\n\n  - **set_translation(new_translation: typing_extensions.List[float]) → None**\n    - Sets the translation of this Transform to the newly given one. Translation has to be a vector in cartesian space.\n\n    **Parameters:**\n    - new_translation: The new translation as a vector with xyz.\n\n  - **set_rotation(new_rotation: typing_extensions.List[float]) → None**\n    - Sets the rotation of this Transform to the newly given one. Rotation has to be a quaternion.\n\n    **Parameters:**\n    - new_rotation: The new rotation as a quaternion with xyzw"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the key features of the location designator in the PyCRAM documentation?"}, {"role": "assistant", "content": "pycram.designators.location_designator \n===========================================\n\n### **Classes**\n\n- **Location**  \n  Default location designator which only wraps a pose.\n\n- **ObjectRelativeLocation**  \n  Location relative to an object.\n\n- **CostmapLocation**  \n  Uses Costmaps to create locations for complex constraints.\n\n- **AccessingLocation**  \n  Location designator that describes poses used for opening drawers.\n\n- **SemanticCostmapLocation**  \n  Locations over semantic entities, like a table surface.\n\n**Module Contents**  \n### **Location**  \nBases: `pycram.designator.LocationDesignatorDescription`\n\nDefault location designator which only wraps a pose.\n\n- **Class Location**  \n  Bases: `pycram.designator.LocationDesignatorDescription.Location`\n\n  Resolved location that represents a specific point in the world which satisfies the constraints of the location designator description.\n\n  - **Attributes:**\n    - **pose**: `pycram.datastructures.pose.Pose`\n\n  - **Methods:**\n    - **ground() → Location**  \n      Default specialized designator that returns a resolved designator containing the pose given in `__init__`.\n      - **Returns:** A resolved designator.\n\n### **ObjectRelativeLocation**  \nBases: `pycram.designator.LocationDesignatorDescription`\n\nLocation relative to an object.\n\n- **Class Location**  \n  Bases: `pycram.designator.LocationDesignatorDescription.Location`\n\n  Resolved location that represents a specific point in the world which satisfies the constraints of the location designator description.\n\n  - **Attributes:**\n    - **relative_pose**: `pycram.datastructures.pose.Pose`  \n      Pose relative to the object.\n    - **reference_object**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`  \n      Object to which the pose is relative.\n\n  - **Methods:**\n    - **ground() → Location**  \n      Default specialized designator that returns a resolved location based on the description input. The resolved location is the first result from the iteration of this instance.\n      - **Returns:** A resolved location.\n\n    - **__iter__() → typing_extensions.Iterable[Location]**  \n      Iterates over all possible solutions for a resolved location relative to the given object.\n      - **Yields:** An instance of `ObjectRelativeLocation.Location` with the relative pose.\n\n### **CostmapLocation**  \nBases: `pycram.designator.LocationDesignatorDescription`\n\nUses Costmaps to create locations for complex constraints.\n\n- **Class Location**  \n  Bases: `pycram.designator.LocationDesignatorDescription.Location`\n\n  Resolved location that represents a specific point in the world which satisfies the constraints of the location designator description.\n\n  - **Attributes:**\n    - **reachable_arms**: `typing_extensions.List[pycram.datastructures.enums.Arms]`  \n      List of arms with which the pose can be reached, used when the `reachable_for` parameter is applied.\n\n  - **Methods:**\n    - **ground() → Location**  \n      Default specialized designator that returns the first result from the iteration of this instance.\n      - **Returns:** A resolved location.\n\n    - **__iter__()**  \n      Generates positions from a costmap based on given constraints and returns them. The generation is based on a costmap created by merging costmaps, each for a different purpose. The base is always an occupancy costmap, with additional costmaps (e.g., visibility or Gaussian) merged according to the constraints. The generator produces pose candidates from the costmap. Each candidate is validated against the constraints, and valid poses are yielded.\n      - **Yields:** An instance of `CostmapLocation.Location` with a valid position that satisfies the given constraints.\n\n### **AccessingLocation**  \nBases: `pycram.designator.LocationDesignatorDescription`\n\nLocation designator that describes poses used for opening drawers.\n\n- **Class Location**  \n  Bases: `pycram.designator.LocationDesignatorDescription.Location`\n\n  Resolved location that represents a specific point in the world which satisfies the constraints of the location designator description.\n\n  - **Attributes:**\n    - **arms**: `typing_extensions.List[pycram.datastructures.enums.Arms]`  \n      List of arms that can be used for accessing from this pose.\n\n  - **Methods:**\n    - **ground() → Location**  \n      Default specialized designator for this location designator, returning the first element from the iteration.\n      - **Returns:** A location designator for a pose from which the drawer can be opened.\n\n    - **__iter__() → Location**  \n      Creates poses from which the robot can open the drawer specified by the `ObjectPart` designator describing the handle. Poses are validated by checking if the robot can grasp the handle while the drawer is closed and if the handle can be grasped when the drawer is open.\n      - **Yields:** A location designator containing the pose and the arms that can be used.\n\n### **SemanticCostmapLocation**  \nBases: `pycram.designator.LocationDesignatorDescription`\n\nLocations over semantic entities, like a table surface.\n\n- **Class Location**  \n  Bases: `pycram.designator.LocationDesignatorDescription.Location`\n\n  Resolved location that represents a specific point in the world which satisfies the constraints of the location designator description.\n\n  - **Attributes:**\n    - **urdf_link_name**: `str`\n    - **part_of**: `pycram.designators.object_designator.ObjectDesignatorDescription.Object`\n    - **for_object**: `typing_extensions.Optional[pycram.designators.object_designator.ObjectDesignatorDescription.Object]`\n\n  - **Methods:**\n    - **ground() → Location**  \n      Default specialized designator that returns the first element of the iterator of this instance.\n      - **Returns:** A resolved location.\n\n    - **__iter__()**  \n      Creates a costmap on top of a link of an object and generates positions from it. If there is a specific object for which the position should be found, a height offset will be calculated to ensure that the bottom of the object is at the position in the costmap, not the origin of the object, which is usually in the center.\n      - **Yields:** An instance of `SemanticCostmapLocation.Location` with the valid position from the costmap."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the key features of the object designator in the PyCRAM documentation?"}, {"role": "assistant", "content": "pycram.designators.object_designator  \n====================================\n\nClasses  \n\n\n- **BelieveObject**: Description for Objects that are only believed in.\n- **ObjectPart**: Object Designator Descriptions for Objects that are part of some other object.\n- **LocatedObject**: Description for KnowRob located objects.\n- **RealObject**: Object designator representing an object in the real world, when resolving this object designator description ]\n\nModule Contents  \n\n**pycram.designators.object_designator.BelieveObject**  \nBases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription`\n\nDescription for objects that are only believed in.\n\n- **class Object**  \n  Bases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription.Object`\n\n  Concrete object that is believed in.\n\n  - **to_sql() → pycram.orm.object_designator.BelieveObject**  \n    Creates an ORM object that corresponds to this description.\n    - **Returns:** The created ORM object.\n\n  - **insert(session: sqlalchemy.orm.session.Session) → pycram.orm.object_designator.BelieveObject**  \n    Adds and commits this and all related objects to the session. Auto-incrementing primary keys and foreign keys have to be filled by this method.\n    - **Parameters:** \n      - **session:** Session with a database that is used to add and commit the objects\n    - **Returns:** The completely instanced ORM object.\n\n**pycram.designators.object_designator.ObjectPart**  \nBases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription`\n\nObject Designator Description for objects that are part of some other object.\n\n- **class Object**  \n  Bases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription.Object`\n\n  A single element that fits the description.\n\n  - **Attributes:**\n    - **part_pose:** `pycram.external_interfaces.robokudo.Pose`\n\n  - **to_sql() → pycram.orm.object_designator.ObjectPart**  \n    Creates an ORM object that corresponds to this description.\n    - **Returns:** The created ORM object.\n\n  - **insert(session: sqlalchemy.orm.session.Session) → pycram.orm.object_designator.ObjectPart**  \n    Adds and commits this and all related objects to the session. Auto-incrementing primary keys and foreign keys have to be filled by this method.\n    - **Parameters:** \n      - **session:** Session with a database that is used to add and commit the objects\n    - **Returns:** The completely instanced ORM object.\n\n  - **ground() → Object**  \n    Default specialized designator, returns the first result of the iterator of this instance.\n    - **Returns:** A resolved object designator.\n\n  - **__iter__()**  \n    Iterates through every possible solution for the given input parameter.\n    - **Yields:** A resolved object designator.\n\n  - **Additional Attributes:**\n    - **type:** `pycram.external_interfaces.robokudo.Optional[str]`\n    - **names:** `pycram.external_interfaces.robokudo.Optional[pycram.external_interfaces.robokudo.List[str]]`\n    - **part_of**\n\n**pycram.designators.object_designator.LocatedObject**  \nBases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription`\n\nDescription for KnowRob located objects.  \n**Currently has no specialized designators.**\n\n- **class Object**  \n  Bases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription.Object`\n\n  A single element that fits the description.\n\n  - **Attributes:**\n    - **reference_frame:** `str`\n      - Reference frame in which the position is given.\n    - **timestamp:** `float`\n      - Timestamp at which the position was valid.\n    - **Additional Attributes:**\n      - **reference_frames:** `pycram.external_interfaces.robokudo.List[str]`\n      - **timestamps:** `pycram.external_interfaces.robokudo.List[float]`\n\n**pycram.designators.object_designator.RealObject**  \nBases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription`\n\nObject designator representing an object in the real world. When resolving this object designator description, RoboKudo is queried to perceive an object fitting the given criteria. Afterward, the specialized designator tries to match the found object to an object in the world.\n\n- **class Object**  \n  Bases: `pycram.external_interfaces.robokudo.ObjectDesignatorDescription.Object`\n\n  A single element that fits the description.\n\n  - **Attributes:**\n    - **pose:** `pycram.external_interfaces.robokudo.Pose`\n      - Pose of the perceived object.\n    - **types:** `pycram.external_interfaces.robokudo.Optional[pycram.external_interfaces.robokudo.List[str]]`\n    - **names:** `pycram.external_interfaces.robokudo.Optional[pycram.external_interfaces.robokudo.List[str]]`\n    - **world_object:** `pycram.world_concepts.world_object.Object`\n\n  - **__iter__()**  \n    Queries RoboKudo for objects that fit the description and then iterates over all World objects that have the same type to match a World object to the real object.\n    - **Yields:** A resolved object designator with reference to the world object."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the key features of the motion designator in the PyCRAM documentation?"}, {"role": "assistant", "content": "pycram.designators.motion_designator  \n==========================================\n\n### **Classes**\n\n- **MoveMotion**  \n  Moves the robot to a designated location.\n\n- **MoveTCPMotion**  \n  Moves the Tool Center Point (TCP) of the robot.\n\n- **LookingMotion**  \n  Lets the robot look at a point.\n\n- **MoveGripperMotion**  \n  Opens or closes the gripper.\n\n- **DetectingMotion**  \n  Tries to detect an object in the Field of View (FOV) of the robot.\n\n- **MoveArmJointsMotion**  \n  Moves the joints of each arm into the given position.\n\n- **WorldStateDetectingMotion**  \n  Detects an object based on the world state.\n\n- **MoveJointsMotion**  \n  Moves any joint on the robot.\n\n- **OpeningMotion**  \n  Designator for opening a container.\n\n- **ClosingMotion**  \n  Designator for closing a container.\n\n- **TalkingMotion**  \n  Talking Motion, lets the robot say a sentence.\n\n**Module Contents**  \n\n### **Class Details**\n\n#### **MoveMotion**\n   Bases: `pycram.designator.BaseMotion`  \n   Moves the robot to a designated location.\n\n- **Attributes:**\n  - `target`: `pycram.datastructures.pose.Pose`  \n    Location to which the robot should be moved.\n\n- **Methods:**\n  - `perform()`: Passes this designator to the process module for execution.\n  - `to_sql() -> pycram.orm.motion_designator.MoveMotion`: Creates an ORM object corresponding to this description.\n  - `insert(session, *args, **kwargs) -> pycram.orm.motion_designator.MoveMotion`: Adds and commits this and all related objects to the session.\n\n#### **MoveTCPMotion**\n   Bases: `pycram.designator.BaseMotion`  \n   Moves the Tool Center Point (TCP) of the robot.\n\n- **Attributes:**\n  - `target`: `pycram.datastructures.pose.Pose`  \n    Target pose to which the TCP should be moved.\n  - `arm`: `pycram.datastructures.enums.Arms`  \n    Arm with the TCP that should be moved to the target.\n  - `allow_gripper_collision`: `typing_extensions.Optional[bool] = None`  \n    If the gripper can collide with something.\n\n- **Methods:**\n  - `perform()`: Passes this designator to the process module for execution.\n  - `to_sql() -> pycram.orm.motion_designator.MoveTCPMotion`: Creates an ORM object corresponding to this description.\n  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.MoveTCPMotion`: Adds and commits this and all related objects to the session.\n\n#### **LookingMotion**\n   Bases: `pycram.designator.BaseMotion`  \n   Lets the robot look at a point.\n\n- **Attributes:**\n  - `target`: `pycram.datastructures.pose.Pose`  \n\n- **Methods:**\n  - `perform()`: Passes this designator to the process module for execution.\n  - `to_sql() -> pycram.orm.motion_designator.LookingMotion`: Creates an ORM object corresponding to this description.\n  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.LookingMotion`: Adds and commits this and all related objects to the session.\n\n#### **MoveGripperMotion**\n   Bases: `pycram.designator.BaseMotion`  \n   Opens or closes the gripper.\n\n- **Attributes:**\n  - `motion`: `pycram.datastructures.enums.GripperState`  \n    Motion that should be performed, either 'open' or 'close'.\n  - `gripper`: `pycram.datastructures.enums.Arms`  \n    Name of the gripper that should be moved.\n  - `allow_gripper_collision`: `typing_extensions.Optional[bool] = None`  \n    If the gripper is allowed to collide with something.\n\n- **Methods:**\n  - `perform()`: Passes this designator to the process module for execution.\n  - `to_sql() -> pycram.orm.motion_designator.MoveGripperMotion`: Creates an ORM object corresponding to this description.\n  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.MoveGripperMotion`: Adds and commits this and all related objects to the session.\n\n#### **DetectingMotion**\n   Bases: `pycram.designator.BaseMotion`  \n   Tries to detect an object in the FOV of the robot.\n\n- **Attributes:**\n  - `object_type`: `pycram.datastructures.enums.ObjectType`  \n    Type of the object that should be detected.\n\n- **Methods:**\n  - `perform()`: Passes this designator to the process module for execution.\n  - `to_sql() -> pycram.orm.motion_designator.DetectingMotion`: Creates an ORM object corresponding to this description.\n  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.DetectingMotion`: Adds and commits this and all related objects to the session.\n\n#### **MoveArmJointsMotion**\n   Bases: `pycram.designator.BaseMotion`  \n   Moves the joints of each arm into the given position.\n\n- **Attributes:**\n  - `left_arm_poses`: `typing_extensions.Optional[typing_extensions.Dict[str, float]] = None`  \n    Target positions for the left arm joints.\n  - `right_arm_poses`: `typing_extensions.Optional[typing_extensions.Dict[str, float]] = None`  \n    Target positions for the right arm joints.\n\n- **Methods:**\n  - `perform()`: Passes this designator to the process module for execution.\n  - `to_sql() -> pycram.orm.motion_designator.Motion`: Creates an ORM object corresponding to this description.\n  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.Motion`: Adds and commits this and all related objects to the session.\n\n#### **WorldStateDetectingMotion**\n   Bases: `pycram.designator.BaseMotion`  \n   Detects an object based on the world state.\n\n- **Attributes:**\n  - `object_type`: `pycram.datastructures.enums.ObjectType`  \n    Object type that should be detected.\n\n- **Methods:**\n  - `perform()`: Passes this designator to the process module for execution.\n  - `to_sql() -> pycram.orm.motion_designator.Motion`: Creates an ORM object corresponding to this description.\n  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.Motion`: Adds and commits this and all related objects to the session.\n\n#### **MoveJointsMotion**\n   Bases: `pycram.designator.BaseMotion`  \n   Moves any joint on the robot.\n\n- **Attributes:**\n  - `names`: `list`  \n    List of joint names that should be moved.\n  - `positions`: `list`  \n    Target positions of joints, should correspond to the list of names.\n\n- **Methods:**\n  - `perform()`: Passes this designator to the process module for execution.\n  - `to_sql() -> pycram.orm.motion_designator.Motion`: Creates an ORM object corresponding to this description.\n  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.Motion`: Adds and commits this and all related objects to the session.\n\n#### **OpeningMotion**\n   Bases: `pycram.designator.BaseMotion`  \n   Designator for opening a container.\n\n- **Attributes:**\n  - `object_part`: `pycram.designators.object_designator.ObjectPart.Object`  \n    Object designator for the drawer handle.\n  - `arm`: `pycram.datastructures.enums.Arms`  \n    Arm that should be used.\n\n- **Methods:**\n  - `perform()`: Passes this designator to the process module for execution.\n  - `to_sql() -> pycram.orm.motion_designator.OpeningMotion`: Creates an ORM object corresponding to this description.\n  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.OpeningMotion`: Adds and commits this and all related objects to the session.\n\n#### **ClosingMotion**\n   Bases: `pycram.designator.BaseMotion`  \n   Designator for closing a container.\n\n- **Attributes:**\n  - `object_part`: `pycram.designators.object_designator.ObjectPart.Object`  \n    Object designator for the drawer handle.\n  - `arm`: `pycram.datastructures.enums.Arms`  \n    Arm that should be used.\n\n- **Methods:**\n  - `perform()`: Passes this designator to the process module for execution.\n  - `to_sql() -> pycram.orm.motion_designator.ClosingMotion`: Creates an ORM object corresponding to this description.\n  - `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.ClosingMotion`: Adds and commits this and all related objects to the session.\n\n#### **TalkingMotion**\n   Bases: `pycram.designator.BaseMotion`  \n   Talking Motion, lets the robot say a sentence.\n\n- **Attributes:**\n  - `cmd`: `str`  \n    Sentence that the robot should say.\n\n- **Methods:**\n  - `perform()`: Passes this designator to the process module for execution.\n  - `to_sql() -> pycram.orm.motion_designator.Motion`: Creates an ORM object corresponding to this description.\n  -\n\n `insert(session: sqlalchemy.orm.Session, *args, **kwargs) -> pycram.orm.motion_designator.Motion`: Adds and commits this and all related objects to the session."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What functionalities are provided by the costmaps in the PyCRAM documentation?"}, {"role": "assistant", "content": "pycram.costmaps \n====================================\n\n**Attributes**  \n\n- **cmap**\n\n**Classes**  \n\n- **Rectangle**  \n  A rectangle described by lower and upper x and y values.\n\n- **Costmap**  \n  The base class of all Costmaps, implementing the visualization of costmaps.\n\n- **OccupancyCostmap**  \n  Represents a map of the environment where obstacles or inaccessible positions for a robot have a value of -1.\n\n- **VisibilityCostmap**  \n  Represents the visibility of a specific point for every position around it.\n\n- **GaussianCostmap**  \n  Represents 2D Gaussian distributions around the origin with a given mean and sigma.\n\n- **SemanticCostmap**  \n  Represents a 2D distribution over a link of an object, such as a table surface.\n\n**Functions**  \n\n\n- **plot_grid(data: numpy.ndarray) → None**  \n  An auxiliary method only used for debugging. It plots a 2D numpy array using Matplotlib.\n\n**Module Contents** \n\n### **Rectangle**\n\nA rectangle described by lower and upper x and y values.\n\n- **Attributes:**\n  - **x_lower**: float\n  - **x_upper**: float\n  - **y_lower**: float\n  - **y_upper**: float\n\n- **Methods:**\n  - **translate(x: float, y: float)**  \n    Translates the rectangle by x and y.\n\n  - **scale(x_factor: float, y_factor: float)**  \n    Scales the rectangle by x_factor and y_factor.\n\n### **Costmap**  \nBases: Costmap\n\nThe base class of all Costmaps, implementing the visualization of costmaps in the World.\n\n- **Attributes:**\n  - **world**\n  - **resolution**: float\n  - **size**: int\n  - **height**: int\n  - **width**: int\n  - **local_transformer**\n  - **origin**: pycram.datastructures.pose.Pose\n  - **map**: numpy.ndarray\n  - **vis_ids**: typing_extensions.List[int] = []\n\n- **Methods:**\n  - **visualize() → None**  \n    Visualizes a costmap in the BulletWorld by subdividing the costmap into rectangles, which are then visualized as pybullet visual shapes.\n\n  - **_chunks(lst: typing_extensions.List, n: int) → typing_extensions.List**  \n    Yields successive n-sized chunks from lst.\n\n    - **Parameters:**\n      - **lst**: The list from which chunks should be yielded.\n      - **n**: Size of the chunks.\n    - **Returns:** A list of size n from lst.\n\n  - **close_visualization() → None**  \n    Removes the visualization from the World.\n\n  - **_find_consecutive_line(start: typing_extensions.Tuple[int, int], map: numpy.ndarray) → int**  \n    Finds the number of consecutive entries in the costmap that are greater than zero.\n\n    - **Parameters:**\n      - **start**: The indices in the costmap from which the consecutive line should be found.\n      - **map**: The costmap in which the line should be found.\n    - **Returns:** The length of the consecutive line of entries greater than zero.\n\n  - **_find_max_box_height(start: typing_extensions.Tuple[int, int], length: int, map: numpy.ndarray) → int**  \n    Finds the maximum height for a rectangle with a given width in a costmap.\n\n    - **Parameters:**\n      - **start**: The indices in the costmap from which the method should start.\n      - **length**: The given width for the rectangle.\n      - **map**: The costmap in which the search should be conducted.\n    - **Returns:** The height of the rectangle.\n\n  - **merge(other_cm: Costmap) → Costmap**  \n    Merges the values of two costmaps and returns a new costmap with the merged values of both inputs. To merge two costmaps, they must fulfill three constraints:\n    1. Same size.\n    2. Same x and y coordinates in the origin.\n    3. Same resolution.\n\n    - **Parameters:**\n      - **other_cm**: The other costmap to be merged.\n    - **Returns:** A new costmap with merged values.\n\n  - **__add__(other: Costmap) → Costmap**  \n    Overloads the \"+\" operator for merging Costmaps. Ensures that 'other' is a Costmap and raises a ValueError if not. Refer to **merge** for more information.\n\n    - **Parameters:**\n      - **other**: Another Costmap.\n    - **Returns:** A new Costmap with merged values from both Costmaps.\n\n  - **partitioning_rectangles() → typing_extensions.List[Rectangle]**  \n    Partitions the map attached to this costmap into rectangles. The rectangles are axis-aligned, exhaustive, and disjoint.\n\n    - **Returns:** A list containing the partitioning rectangles.\n\n### **OccupancyCostmap**  \nBases: Costmap\n\nRepresents a map of the environment where obstacles or inaccessible positions for a robot have a value of -1.\n\n- **Attributes:**\n  - **world**\n\n- **Methods:**\n  - **_calculate_diff_origin(height: int, width: int) → pycram.datastructures.pose.Pose**  \n    Calculates the difference between the origin of the costmap as stated by the metadata and the actual middle of the costmap used by PyCRAM for visualization.\n\n    - **Parameters:**\n      - **height**: The height of the costmap.\n      - **width**: The width of the costmap.\n    - **Returns:** The difference between the actual origin and center of the costmap.\n\n  - **_get_map() → numpy.ndarray**  \n    Receives the map array from the map server and converts it into a numpy array.\n\n    - **Returns:** The costmap as a numpy array.\n\n  - **_get_map_metadata() → nav_msgs.msg.MapMetaData**  \n    Receives metadata about the costmap from the map server. Metadata includes height, width, origin, and resolution.\n\n    - **Returns:** The metadata for the costmap array.\n\n  - **_convert_map(map: numpy.ndarray) → numpy.ndarray**  \n    Converts the Occupancy Map from ROS to be consistent with PyCRAM's handling of costmaps. Valid cells for a robot are set to one, and others to zero, considering the distance to obstacle parameter.\n\n    - **Parameters:**\n      - **map**: The map to be converted, represented as a 2D numpy array.\n    - **Returns:** The converted map as a 2D numpy array.\n\n  - **create_sub_map(sub_origin: pycram.datastructures.pose.Pose, size: int) → Costmap**  \n    Creates a smaller map centered around a specified point with the size \"size\". The resolution remains the same.\n\n    - **Parameters:**\n      - **sub_origin**: The point in the global coordinate frame around which the sub-costmap should be centered.\n      - **size**: The size the sub-costmap should have.\n    - **Returns:** The sub-costmap as a 2D numpy array.\n\n  - **_create_from_world(size: int, resolution: float) → numpy.ndarray**  \n    Creates an Occupancy Costmap for the specified World. Marks every position as valid that has no object above it, applying the distance to obstacle parameter afterward.\n\n    - **Parameters:**\n      - **size**: The size of the costmap. Specifies the length of one side of the costmap, created as a square.\n      - **resolution**: The resolution of the costmap, determining how much meter a pixel represents.\n\n  - **_chunks(lst: typing_extensions.List, n: int) → typing_extensions.List**  \n    Yields successive n-sized chunks from lst.\n\n    - **Parameters:**\n      - **lst**: The list from which chunks should be yielded.\n      - **n**: Size of the chunks.\n    - **Returns:** A list of size n from lst.\n\n### **VisibilityCostmap**  \nBases: Costmap\n\nRepresents the visibility of a specific point for every position around it. Refer to the PhD Thesis (page 173) for a detailed explanation.\n\n- **Attributes:**\n  - **world**\n  - **map**\n  - **size**\n  - **resolution**\n  - **max_height**: float\n  - **min_height**: float\n  - **origin**: pycram.datastructures.pose.Pose\n\n- **Methods:**\n  - **_create_images() → typing_extensions.List[numpy.ndarray]**  \n    Creates four depth images in every direction around the point for which the costmap should be created. The depth images represent the distance to the next object in meters.\n\n    - **Returns:** A list of four depth images, represented as 2D arrays.\n\n  - **_depth_buffer_to_meter(buffer: numpy.ndarray) → numpy.ndarray**  \n    Converts the depth images generated by the World to represent each position in meters.\n\n    - **Returns:** The depth image in meters.\n\n  - **_generate_map()**  \n    Generates the resulting density map using the algorithm in Lorenz Mösenlechner's PhD Thesis (page 178). The map is then saved to `self.map`.\n\n### **GaussianCostmap**  \nBases: Costmap\n\nGaussian Costmaps are 2D Gaussian distributions around the origin with the given mean and sigma.\n\n- **Attributes:**\n  - **gau**: numpy.ndarray\n  - **map**: numpy.ndarray\n  - **size**: float\n  - **origin**: pycram.datas\n\ntructures.pose.Pose\n\n- **Methods:**\n  - **_gaussian_window(mean: int, std: float) → numpy.ndarray**  \n    Creates a window of values with a Gaussian distribution of size \"mean\" and standard deviation \"std\". Code is based on Scipy.\n\n### **SemanticCostmap**  \nBases: Costmap\n\nSemantic Costmaps represent a 2D distribution over a link of an object, such as a table surface.\n\n- **Attributes:**\n  - **world**: pycram.datastructures.world.World\n  - **object**: pycram.world_concepts.world_object.Object\n  - **link**: pycram.description.Link\n  - **resolution**: float\n  - **origin**: pycram.datastructures.pose.Pose\n  - **height**: int = 0\n  - **width**: int = 0\n  - **map**: numpy.ndarray = []\n\n- **Methods:**\n  - **generate_map() → None**  \n    Generates the semantic costmap according to the provided parameters using the axis-aligned bounding box (AABB) for the link. The height and width of the final Costmap correspond to the x and y sizes of the AABB.\n\n  - **get_aabb_for_link() → pycram.datastructures.dataclasses.AxisAlignedBoundingBox**  \n    Returns the AABB of the link provided when creating the costmap. The object is rotated to align the link in the identity orientation."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What information is available about plan failures in the PyCRAM documentation?"}, {"role": "assistant", "content": "pycram.plan_failures  \n====================================\n\n### **Exceptions**\n\n- **PlanFailure**  \n  Implementation of plan failures.\n\n- **NotALanguageExpression**  \n  Implementation of plan failures.\n\n- **FailureDiagnosis**  \n  Implementation of plan failures.\n\n- **LowLevelFailure**  \n  Failure thrown by low-level modules: robot or projection PMs.\n\n- **ActionlibActionTimeout**  \n  Failure thrown by low-level modules: robot or projection PMs.\n\n- **HighLevelFailure**  \n  Failure thrown by high-level modules, i.e., plans.\n\n- **DeliveringFailed**  \n  Thrown when a delivering plan completely gives up.\n\n- **ManipulationLowLevelFailure**  \n  Thrown when a low-level, i.e., hardware-related, failure is detected in a manipulation action.\n\n- **EnvironmentManipulationGoalNotReached**  \n  Thrown when the door/drawer opening/closing goal is still not reached.\n\n- **EnvironmentManipulationImpossible**  \n  Thrown when environment manipulation cannot be achieved.\n\n- **EnvironmentUnreachable**  \n  Thrown when environment manipulation is in collision or unreachable.\n\n- **FetchingFailed**  \n  Thrown when a fetching plan completely gives up.\n\n- **GripperLowLevelFailure**  \n  Thrown when a failure involving the gripper hardware occurs.\n\n- **GripperClosedCompletely**  \n  Thrown when the gripper closes completely, despite not being expected to do so (e.g., because it should have grasped something).\n\n- **GripperGoalNotReached**  \n  Thrown when the gripper does not reach its goal.\n\n- **LookingHighLevelFailure**  \n  High-level failure produced when looking for an object, i.e., it is not a hardware issue but one relating to the looking task, its parameters, and how they relate to the environment.\n\n- **ManipulationGoalInCollision**  \n  Thrown when executing a manipulation action results in a collision.\n\n- **ManipulationGoalNotReached**  \n  Thrown when, after executing the action, the goal is still not reached.\n\n- **IKError**  \n  Thrown when no inverse kinematics solution could be found.\n\n- **ManipulationPoseUnreachable**  \n  Thrown when no IK solution can be found.\n\n- **NavigationHighLevelFailure**  \n  High-level failure produced while navigating the robot, i.e., it is not a hardware issue but one relating to the navigation task, its parameters, and how they relate to the environment.\n\n- **NavigationGoalInCollision**  \n  Navigation goal cannot be reached because the goal itself is already occupied by some other object.\n\n- **NavigationLowLevelFailure**  \n  Low-level failure produced while navigating the robot, i.e., some kind of hardware issue.\n\n- **NavigationGoalNotReached**  \n  Thrown when the base moved as a result of the navigation action, but the goal was not reached.\n\n- **NavigationPoseUnreachable**  \n  Thrown when the goal pose for navigation is computed to be unreachable.\n\n- **ObjectNowhereToBeFound**  \n  Thrown when the robot cannot find an object of a given description in its surroundings.\n\n- **ObjectUndeliverable**  \n  Thrown when no base positioning can assure a reachable pose to place the object from.\n\n- **ObjectUnfetchable**  \n  Thrown when no base positioning can assure a reachable pose to grasp the object from.\n\n- **ObjectUnreachable**  \n  Thrown when no IK solution is found for a particular base pose.\n\n- **PerceptionLowLevelFailure**  \n  Low-level failure produced while perceiving, i.e., some kind of hardware issue.\n\n- **PerceptionObjectNotFound**  \n  Thrown when an attempt to find an object by perception fails -- and this can still be interpreted as the robot not looking in the right direction, as opposed to the object being absent.\n\n- **PerceptionObjectNotInWorld**  \n  Thrown when an attempt to find an object by perception fails -- and this is because the object can be assumed absent or perhaps is known to be absent due to the setup of a simulation.\n\n- **SearchingFailed**  \n  Thrown when a searching plan completely gives up.\n\n- **TorsoLowLevelFailure**  \n  Low-level failure produced while moving the torso, i.e., some kind of hardware issue.\n\n- **TorsoGoalNotReached**  \n  Thrown when the torso moved as a result of a torso action, but the goal was not reached.\n\n- **TorsoGoalUnreachable**  \n  Thrown when the goal for the torso is computed to be unreachable.\n\n- **Task**  \n  Implementation of plan failures.\n\n- **Grasping**  \n\n- **Looking**  \n\n- **ObjectPoseMisestimation**  \n  Implementation of plan failures.\n\n- **SuccessfulCompletion**  \n  Implementation of plan failures.\n\n- **ObjectNotFound**  \n  Implementation of plan failures.\n\n- **LocomotorFailure**  \n  Implementation of plan failures.\n\n- **ArmFailure**  \n  Implementation of plan failures.\n\n- **ObjectLost**  \n  Implementation of plan failures.\n\n- **SensorFailure**  \n  Implementation of plan failures.\n\n- **IllPosedGoalFailure**  \n  Implementation of plan failures.\n\n- **CapabilityAbsenceFailure**  \n  Implementation of plan failures.\n\n- **ReachabilityFailure**  \n  Implementation of plan failures.\n\n- **TorsoFailure**  \n  Implementation of plan failures.\n\n- **ConfigurationNotReached**  \n  Implementation of plan failures.\n\n- **Timeout**  \n  Implementation of plan failures.\n\n- **EndEffectorFailure**  \n  Implementation of plan failures.\n\n- **ObjectUnavailable**  \n  Implementation of plan failures.\n\n- **SustainedFailure**  \n  Implementation of plan failures.\n\n- **ReasoningError**  \n  Implementation of plan failures.\n\n- **CollisionError**  \n  Implementation of plan failures.\n\n**Module Contents**  \n\n### **py:exception:: PlanFailure(*args, **kwargs)**  \nBases: `Exception`\n\nImplementation of plan failures.\n\n### **py:exception:: NotALanguageExpression(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: FailureDiagnosis(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: LowLevelFailure(*args, **kwargs)**  \nBases: `FailureDiagnosis`\n\nFailure thrown by low-level modules: robot or projection PMs.\n\n### **py:exception:: ActionlibActionTimeout(*args, **kwargs)**  \nBases: `LowLevelFailure`\n\nFailure thrown by low-level modules: robot or projection PMs.\n\n### **py:exception:: HighLevelFailure(*args, **kwargs)**  \nBases: `FailureDiagnosis`\n\nFailure thrown by high-level modules, i.e., plans.\n\n### **py:exception:: DeliveringFailed(*args, **kwargs)**  \nBases: `HighLevelFailure`\n\nThrown when a delivering plan completely gives up.\n\n### **py:exception:: ManipulationLowLevelFailure(*args, **kwargs)**  \nBases: `LowLevelFailure`\n\nThrown when a low-level, i.e., hardware-related, failure is detected in a manipulation action.\n\n### **py:exception:: EnvironmentManipulationGoalNotReached(*args, **kwargs)**  \nBases: `ManipulationLowLevelFailure`\n\nThrown when the door/drawer opening/closing goal is still not reached.\n\n### **py:exception:: EnvironmentManipulationImpossible(*args, **kwargs)**  \nBases: `HighLevelFailure`\n\nThrown when environment manipulation cannot be achieved.\n\n### **py:exception:: EnvironmentUnreachable(*args, **kwargs)**  \nBases: `HighLevelFailure`\n\nThrown when environment manipulation is in collision or unreachable.\n\n### **py:exception:: FetchingFailed(*args, **kwargs)**  \nBases: `HighLevelFailure`\n\nThrown when a fetching plan completely gives up.\n\n### **py:exception:: GripperLowLevelFailure(*args, **kwargs)**  \nBases: `LowLevelFailure`\n\nThrown when a failure involving the gripper hardware occurs.\n\n### **py:exception:: GripperClosedCompletely(*args, **kwargs)**  \nBases: `GripperLowLevelFailure`\n\nThrown when the gripper closes completely, despite not being expected to do so (e.g., because it should have grasped something).\n\n### **py:exception:: GripperGoalNotReached(*args, **kwargs)**  \nBases: `GripperLowLevelFailure`\n\nThrown when the gripper does not reach its goal.\n\n### **py:exception:: LookingHighLevelFailure(*args, **kwargs)**  \nBases: `HighLevelFailure`\n\nHigh-level failure produced when looking for an object, i.e., it is not a hardware issue but one relating to the looking task, its parameters, and how they relate to the environment.\n\n### **py:exception:: ManipulationGoalInCollision(*args, **kwargs)**  \nBases: `HighLevelFailure`\n\nThrown when executing a manipulation action results in a collision.\n\n### **py:exception:: ManipulationGoalNotReached(*args, **kwargs)**  \nBases: `ManipulationLowLevelFailure`\n\nThrown when, after executing the action, the goal is still not reached.\n\n### **py:exception:: IKError(pose, base_frame, tip_frame)**  \nBases: `PlanFailure`\n\nThrown when no inverse kinematics solution could be found.\n- **Attributes:**\n  - **message**\n\n### **py:exception:: ManipulationPoseUnreachable(*args, **kwargs)**  \nBases: `ManipulationLowLevelFailure`\n\nThrown when no IK solution can be found.\n\n### **py:exception:: NavigationHighLevelFailure(*args, **kwargs)**  \nBases: `HighLevelFailure`\n\nHigh-level failure produced while navigating the robot, i.e., it is not a hardware issue but one relating to the navigation task, its parameters, and how they relate to the environment.\n\n### **py:exception:: Navigation\n\nGoalInCollision(*args, **kwargs)**  \nBases: `NavigationHighLevelFailure`\n\nNavigation goal cannot be reached because the goal itself is already occupied by some other object.\n\n### **py:exception:: NavigationLowLevelFailure(*args, **kwargs)**  \nBases: `LowLevelFailure`\n\nLow-level failure produced while navigating the robot, i.e., some kind of hardware issue.\n\n### **py:exception:: NavigationGoalNotReached(*args, **kwargs)**  \nBases: `NavigationLowLevelFailure`\n\nThrown when the base moved as a result of the navigation action, but the goal was not reached.\n\n### **py:exception:: NavigationPoseUnreachable(*args, **kwargs)**  \nBases: `NavigationLowLevelFailure`\n\nThrown when the goal pose for navigation is computed to be unreachable.\n\n### **py:exception:: ObjectNowhereToBeFound(*args, **kwargs)**  \nBases: `HighLevelFailure`\n\nThrown when the robot cannot find an object of a given description in its surroundings.\n\n### **py:exception:: ObjectUndeliverable(*args, **kwargs)**  \nBases: `HighLevelFailure`\n\nThrown when no base positioning can assure a reachable pose to place the object from.\n\n### **py:exception:: ObjectUnfetchable(*args, **kwargs)**  \nBases: `HighLevelFailure`\n\nThrown when no base positioning can assure a reachable pose to grasp the object from.\n\n### **py:exception:: ObjectUnreachable(*args, **kwargs)**  \nBases: `HighLevelFailure`\n\nThrown when no IK solution is found for a particular base pose.\n\n### **py:exception:: PerceptionLowLevelFailure(*args, **kwargs)**  \nBases: `LowLevelFailure`\n\nLow-level failure produced while perceiving, i.e., some kind of hardware issue.\n\n### **py:exception:: PerceptionObjectNotFound(*args, **kwargs)**  \nBases: `PerceptionLowLevelFailure`\n\nThrown when an attempt to find an object by perception fails -- and this can still be interpreted as the robot not looking in the right direction, as opposed to the object being absent.\n\n### **py:exception:: PerceptionObjectNotInWorld(*args, **kwargs)**  \nBases: `PerceptionLowLevelFailure`\n\nThrown when an attempt to find an object by perception fails -- and this is because the object can be assumed absent or perhaps is known to be absent due to the setup of a simulation.\n\n### **py:exception:: SearchingFailed(*args, **kwargs)**  \nBases: `HighLevelFailure`\n\nThrown when a searching plan completely gives up.\n\n### **py:exception:: TorsoLowLevelFailure(*args, **kwargs)**  \nBases: `LowLevelFailure`\n\nLow-level failure produced while moving the torso, i.e., some kind of hardware issue.\n\n### **py:exception:: TorsoGoalNotReached(*args, **kwargs)**  \nBases: `TorsoLowLevelFailure`\n\nThrown when the torso moved as a result of a torso action, but the goal was not reached.\n\n### **py:exception:: TorsoGoalUnreachable(*args, **kwargs)**  \nBases: `TorsoLowLevelFailure`\n\nThrown when the goal for the torso is computed to be unreachable.\n\n### **py:exception:: Task(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: Grasping(*args, **kwargs)**  \nBases: `Task`\n\nImplementation of plan failures.\n\n### **py:exception:: Looking(*args, **kwargs)**  \nBases: `Task`\n\nImplementation of plan failures.\n\n### **py:exception:: ObjectPoseMisestimation(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: SuccessfulCompletion(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: ObjectNotFound(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: LocomotorFailure(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: ArmFailure(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: ObjectLost(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: SensorFailure(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: IllPosedGoalFailure(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: CapabilityAbsenceFailure(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: ReachabilityFailure(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: TorsoFailure(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: ConfigurationNotReached(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: Timeout(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: EndEffectorFailure(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: ObjectUnavailable(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: SustainedFailure(*args, **kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: ReasoningError(**kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures.\n\n### **py:exception:: CollisionError(**kwargs)**  \nBases: `PlanFailure`\n\nImplementation of plan failures."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What functionalities are covered in the pycram.world_reasoning section of the PyCRAM documentation?"}, {"role": "assistant", "content": "pycram.world_reasoning  \n\n### **Functions**\n\n- **stable(obj: pycram.world_concepts.world_object.Object) → bool**  \n  Checks if an object is stable in the world. Stability means that its position will not change after simulating physics in the World. This is done by simulating the world for 10 seconds and comparing the previous coordinates with the coordinates after the simulation.\n\n  - **Parameters:**\n    - **obj**: The object to be checked.\n  - **Returns:** True if the object is stable in the world; False otherwise.\n\n- **contact(object1: pycram.world_concepts.world_object.Object, object2: pycram.world_concepts.world_object.Object, return_links: bool = False) → typing_extensions.Union[bool, typing_extensions.Tuple[bool, typing_extensions.List]]**  \n  Checks if two objects are in contact. If `return_links` is True, the output will also contain a list of tuples where the first element is the link name of `object1`, and the second element is the link name of `object2`.\n\n  - **Parameters:**\n    - **object1**: The first object.\n    - **object2**: The second object.\n    - **return_links**: If the respective links on the objects in contact should be returned.\n  - **Returns:** True if the two objects are in contact; False otherwise. If links are returned, a list of links in contact.\n\n- **get_visible_objects(camera_pose: pycram.datastructures.pose.Pose, front_facing_axis: typing_extensions.Optional[typing_extensions.List[float]] = None) → typing_extensions.Tuple[numpy.ndarray, pycram.datastructures.pose.Pose]**  \n  Returns a segmentation mask of the objects visible from the given camera pose and the front-facing axis.\n\n  - **Parameters:**\n    - **camera_pose**: The pose of the camera in the world coordinate frame.\n    - **front_facing_axis**: The axis of the camera frame that faces the front of the robot, given as a list of xyz.\n  - **Returns:** A segmentation mask of the visible objects and the pose of the point exactly 2 meters in front of the camera in the direction of the front-facing axis with respect to the world coordinate frame.\n\n- **visible(obj: pycram.world_concepts.world_object.Object, camera_pose: pycram.datastructures.pose.Pose, front_facing_axis: typing_extensions.Optional[typing_extensions.List[float]] = None, threshold: float = 0.8) → bool**  \n  Checks if an object is visible from a given position. This is achieved by rendering the object alone and counting the visible pixels, then rendering the complete scene and comparing the visible pixels with the absolute count of pixels.\n\n  - **Parameters:**\n    - **obj**: The object for which visibility should be checked.\n    - **camera_pose**: The pose of the camera in the map frame.\n    - **front_facing_axis**: The axis of the camera frame that faces the front of the robot, given as a list of xyz.\n    - **threshold**: The minimum percentage of the object that needs to be visible for this method to return True.\n  - **Returns:** True if the object is visible from the camera position; False otherwise.\n\n- **occluding(obj: pycram.world_concepts.world_object.Object, camera_pose: pycram.datastructures.pose.Pose, front_facing_axis: typing_extensions.Optional[typing_extensions.List[float]] = None) → typing_extensions.List[pycram.world_concepts.world_object.Object]**  \n  Lists all objects that are occluding the given object. This works similarly to the `visible` function. First, the object alone will be rendered and the position of its pixels in the picture will be saved. Afterward, the complete scene will be rendered, and the saved pixel positions will be compared to the actual pixels. If another object is visible in one of the saved pixel positions, it will be marked as occluding.\n\n  - **Parameters:**\n    - **obj**: The object for which occlusion should be checked.\n    - **camera_pose**: The pose of the camera in the world coordinate frame.\n    - **front_facing_axis**: The axis of the camera frame that faces the front of the robot, given as a list of xyz.\n  - **Returns:** A list of occluding objects.\n\n- **reachable(pose_or_object: typing_extensions.Union[pycram.world_concepts.world_object.Object, pycram.datastructures.pose.Pose], robot: pycram.world_concepts.world_object.Object, gripper_name: str, threshold: float = 0.01) → bool**  \n  Checks if the robot can reach a given position. To determine this, inverse kinematics are calculated and applied. Afterward, the distance between the position and the given end effector is calculated. If it is smaller than the threshold, the reasoning query returns True; otherwise, it returns False.\n\n  - **Parameters:**\n    - **pose_or_object**: The position and rotation or object for which reachability should be checked.\n    - **robot**: The robot that should reach for the position.\n    - **gripper_name**: The name of the end effector.\n    - **threshold**: The threshold between the end effector and the position.\n  - **Returns:** True if the end effector is closer than the threshold to the target position; False otherwise.\n\n- **blocking(pose_or_object: typing_extensions.Union[pycram.world_concepts.world_object.Object, pycram.datastructures.pose.Pose], robot: pycram.world_concepts.world_object.Object, gripper_name: str, grasp: str = None) → typing_extensions.Union[typing_extensions.List[pycram.world_concepts.world_object.Object], None]**  \n  Checks if any objects are blocking another object when a robot tries to pick it up. This works similarly to the `reachable` function. First, the inverse kinematics between the robot and the object will be calculated and applied. Then it will be checked if the robot is in contact with any object except the given one. If the given pose or object is not reachable, None will be returned.\n\n  - **Parameters:**\n    - **pose_or_object**: The object or pose for which blocking objects should be found.\n    - **robot**: The robot object that reaches for the object.\n    - **gripper_name**: The name of the end effector of the robot.\n    - **grasp**: The grasp type with which the object should be grasped.\n  - **Returns:** A list of objects the robot is in collision with when reaching for the specified object, or None if the pose or object is not reachable.\n\n- **supporting(object1: pycram.world_concepts.world_object.Object, object2: pycram.world_concepts.world_object.Object) → bool**  \n  Checks if one object is supporting another object. An object supports another object if they are in contact and the second object is above the first one (e.g., a bottle will be supported by a table).\n\n  - **Parameters:**\n    - **object1**: The object that is supported.\n    - **object2**: The object that supports the first object.\n  - **Returns:** True if the second object is in contact with the first one and is above it; False otherwise.\n\n- **link_pose_for_joint_config(obj: pycram.world_concepts.world_object.Object, joint_config: typing_extensions.Dict[str, float], link_name: str) → pycram.datastructures.pose.Pose**  \n  Returns the pose a link would be in if the given joint configuration were applied to the object. This is done by using the respective object in the prospection world and applying the joint configuration to this one. After applying the joint configuration, the link position is taken from there.\n\n  - **Parameters:**\n    - **obj**: The object of which the link is a part.\n    - **joint_config**: Dictionary with the goal joint configuration.\n    - **link_name**: Name of the link for which the pose should be returned.\n  - **Returns:** The pose of the link after applying the joint configuration."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the main features of the pycram.language API as described in the PyCRAM documentation?"}, {"role": "assistant", "content": "pycram.language\n\n\n### **Classes**\n\n- **Language**  \n  Parent class for language expressions. Implements operators as well as methods to reduce the resulting language tree.\n\n- **Repeat**  \n  Executes all children a given number of times.\n\n- **Monitor**  \n  Monitors a Language Expression and interrupts it when the given condition is evaluated to True.\n\n- **Sequential**  \n  Executes all children sequentially; an exception while executing a child does not terminate the whole process.\n\n- **TryInOrder**  \n  Executes all children sequentially; an exception while executing a child does not terminate the whole process.\n\n- **Parallel**  \n  Executes all children in parallel by creating a thread for each child and executing them in the respective threads. All exceptions during execution will be caught, saved to a list, and returned upon completion.\n\n- **TryAll**  \n  Executes all children in parallel by creating a thread for each child and executing them in the respective threads. All exceptions during execution will be caught, saved to a list, and returned upon completion.\n\n- **Code**  \n  Executable code block in a plan.\n\n**Module Contents**  \n\n### **Language**  \nBases: `anytree.NodeMixin`\n\nParent class for language expressions. Implements operators as well as methods to reduce the resulting language tree.\n\n- **Attributes:**\n  - **parallel_blocklist**: `['PickUpAction', 'PlaceAction', 'OpenAction', 'CloseAction', 'TransportAction', 'GraspingAction']`\n  - **do_not_use_giskard**: `['SetGripperAction', 'MoveGripperMotion', 'DetectAction', 'DetectingMotion']`\n  - **block_list**: `typing_extensions.List[int]`  \n    List of thread IDs which should be blocked from execution.\n  - **parent**\n  - **exceptions**\n  - **state**: `None`\n  - **executing_thread**\n  - **threads**: `typing_extensions.List[threading.Thread]`\n  - **interrupted**: `False`\n  - **name**\n\n- **Methods:**\n  - **resolve() → Language**  \n    Dummy method for compatibility with designator descriptions.\n    - **Returns:** Self-reference.\n    \n  - **perform()**  \n    This method should be overwritten in subclasses to implement the behavior of the language expression regarding each child.\n    \n  - **__add__(other: Language) → Sequential**  \n    Language expression for sequential execution.\n    - **Parameters:** `other`: Another Language expression.\n    - **Returns:** A `Sequential` object which is the new root node of the language tree.\n    \n  - **__sub__(other: Language) → TryInOrder**  \n    Language expression for trying in order.\n    - **Parameters:** `other`: Another Language expression.\n    - **Returns:** A `TryInOrder` object which is the new root node of the language tree.\n    \n  - **__or__(other: Language) → Parallel**  \n    Language expression for parallel execution.\n    - **Parameters:** `other`: Another Language expression.\n    - **Returns:** A `Parallel` object which is the new root node of the language tree.\n    \n  - **__xor__(other: Language) → TryAll**  \n    Language expression for trying all executions.\n    - **Parameters:** `other`: Another Language expression.\n    - **Returns:** A `TryAll` object which is the new root node of the language tree.\n    \n  - **__rshift__(other: Language)**  \n    Operator for Monitors, making the Monitor the parent of the other expression.\n    - **Parameters:** `other`: Another Language expression.\n    - **Returns:** The Monitor, which is now the new root node.\n    \n  - **__mul__(other: int)**  \n    Language expression for repeated execution. The other attribute of this operator must be an integer.\n    - **Parameters:** `other`: An integer stating how often the Language expression should be repeated.\n    - **Returns:** A `Repeat` object which is the new root node of the language tree.\n    \n  - **__rmul__(other: int)**  \n    Language expression for repeated execution. The other attribute of this operator must be an integer. This is the reversed operator of `__mul__`, allowing you to write:\n    \n    ```python\n    2 * ParkAction()\n    ```\n    - **Parameters:** `other`: An integer stating how often the Language expression should be repeated.\n    - **Returns:** A `Repeat` object which is the new root node of the language tree.\n    \n  - **simplify() → Language**  \n    Simplifies the language tree by merging nodes that have a parent-child relation and are of the same type.\n    \n  - **merge_nodes(node1: anytree.Node, node2: anytree.Node) → None**  \n    Merges `node1` with `node2` in a tree. The children of `node2` will be re-parented to `node1`, and `node2` will be deleted from the tree.\n    - **Parameters:** \n      - **node1**: Node that should be left in the tree.\n      - **node2**: Node whose children should be appended to `node1` and then deleted.\n    \n  - **interrupt() → None**  \n    Base method for interrupting the execution of a Language expression. To be overwritten in a sub-class.\n\n### **Repeat**  \nBases: `Language`\n\nExecutes all children a given number of times.\n\n- **Attributes:**\n  - **repeat**: `int`\n\n- **Methods:**\n  - **perform()**  \n    Executes all children in a loop as often as stated on initialization.\n    \n  - **interrupt() → None**  \n    Stops the execution of this language expression by setting the `interrupted` variable to True, adding this thread to the block_list in ProcessModule, and interrupting the current Giskard goal.\n\n### **Monitor**  \nBases: `Language`\n\nMonitors a Language Expression and interrupts it when the given condition is evaluated to True.\n\n- **Attributes:**\n  - **kill_event**\n  - **exception_queue**\n\n- **Methods:**\n  - **perform() → typing_extensions.Tuple[pycram.datastructures.enums.State, typing_extensions.Any]**  \n    Starts a new thread that checks the condition and then performs the attached language expression.\n    - **Returns:** The state of the attached language expression, and a list of the results of the children.\n    \n  - **interrupt() → None**  \n    Calls interrupt for each child.\n\n### **Sequential**  \nBases: `Language`\n\nExecutes all children sequentially; an exception while executing a child does not terminate the whole process.\n\n- **Methods:**\n  - **perform() → typing_extensions.Tuple[pycram.datastructures.enums.State, typing_extensions.List[typing_extensions.Any]]**  \n    Calls `perform()` on each child sequentially.\n    - **Returns:** The state and list of results.\n    \n  - **interrupt() → None**  \n    Interrupts the execution of this language expression by setting the `interrupted` variable to True and calling interrupt on the current Giskard goal.\n\n### **TryInOrder**  \nBases: `Language`\n\nExecutes all children sequentially; an exception while executing a child does not terminate the whole process.\n\n- **Methods:**\n  - **perform() → typing_extensions.Tuple[pycram.datastructures.enums.State, typing_extensions.List[typing_extensions.Any]]**  \n    Calls `perform()` on each child sequentially and catches raised exceptions.\n    - **Returns:** The state and list of results.\n    \n  - **interrupt() → None**  \n    Interrupts the execution of this language expression by setting the `interrupted` variable to True, adding the current thread to the block_list in Language, and interrupting the current Giskard goal.\n\n### **Parallel**  \nBases: `Language`\n\nExecutes all children in parallel by creating a thread for each child and executing them in the respective threads.\n\n- **Methods:**\n  - **perform() → typing_extensions.Tuple[pycram.datastructures.enums.State, typing_extensions.List[typing_extensions.Any]]**  \n    Creates a new thread for each child and calls `perform()` of the child in the respective thread.\n    - **Returns:** The state and list of results.\n    \n  - **interrupt() → None**  \n    Interrupts the execution of this language expression by setting the `interrupted` variable to True, adding the thread ID of all parallel execution threads to the block_list in Language, and interrupting the current Giskard goal.\n\n### **TryAll**  \nBases: `Language`\n\nExecutes all children in parallel by creating a thread for each child and executing them in the respective threads.\n\n- **Methods:**\n  - **perform() → typing_extensions.Tuple[pycram.datastructures.enums.State, typing_extensions.List[typing_extensions.Any]]**  \n    Creates a new thread for each child and executes all children in their respective threads.\n    - **Returns:** The state and list of results.\n    \n  - **interrupt() → None**  \n    Interrupts the execution of this language expression by setting the `interrupted` variable to True, adding the thread ID of all parallel execution threads to the block_list in Language, and interrupting the current Giskard goal.\n\n### **Code**  \nBases: `Language`\n\nExecutable code block in a plan.\n\n- **Attributes:**\n  - **function**: `typing_extensions.Callable`  \n  - **kwargs**: `typing_extensions.Dict[str, typing_extensions.Any]`\n\n- **Methods:**\n  - **perform**  \n    This method should be overwritten in subclasses to implement the behavior of the language expression regarding each child.\n    \n  - **execute() → typing_extensions.Any**  \n    Executes the code with its arguments.\n   \n\n - **Returns:** `State.SUCCEEDED`, and anything that the function associated with this object returns.\n    \n  - **interrupt() → None**  \n    Base method for interrupting the execution of a Language expression. To be overwritten in a sub-class."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What functionalities does the pose generator and validator provide in the PyCRAM documentation?"}, {"role": "assistant", "content": "pycram.pose_generator_and_validator  \n========================================\n\n### **Classes**\n\n- **PoseGenerator**  \n  Creates pose candidates from a given costmap. The generator selects the highest values (amount specified by `number_of_samples`) and returns the corresponding positions. Orientations are calculated such that the robot faces the center of the costmap.\n\n### **Functions**\n\n- **visibility_validator(→ bool)**  \n  Validates if the robot can see the target position from a given pose candidate.\n\n- **_in_contact(→ bool)**  \n  Checks if a given robot is in contact with a given object.\n\n- **reachability_validator(→ typing_extensions.Tuple[bool, ...])**  \n  Validates if a target position is reachable for a pose candidate.\n\n- **collision_check(robot, allowed_collision)**  \n  Checks if a given robot collides with any object within the world that it is not allowed to collide with.\n\n**Module Contents**  \n\n### **PoseGenerator**  \nBases: `pycram.costmaps.Costmap`\n\nCreates pose candidates from a given costmap. The generator selects the highest values, the amount is given by `number_of_samples`, and returns the corresponding positions. Orientations are calculated such that the robot faces the center of the costmap.\n\n- **Attributes:**\n  - **current_orientation_generator**: `None`  \n    If no orientation generator is given, this generator is used to generate the orientation of the robot.\n  - **override_orientation_generator**: `None`  \n    Overrides the orientation generator with a custom generator, which will be used regardless of the `current_orientation_generator`.\n  - **costmap**\n  - **number_of_samples**\n  - **orientation_generator**\n\n- **Methods:**\n  - **__iter__() → typing_extensions.Iterable**  \n    A generator that creates pose candidates from a given costmap. The generator selects the highest 100 values and returns the corresponding positions. Orientations are calculated such that the robot faces the center of the costmap.\n    - **Yield:** A tuple of position and orientation.\n    \n  - **height_generator() → float**  \n    - **Static Method**\n    \n  - **generate_orientation(position: typing_extensions.List[float], origin: pycram.datastructures.pose.Pose) → typing_extensions.List[float]**  \n    Generates the orientation for a given position in a costmap. The orientation is calculated such that the robot faces the origin of the costmap. This is done by calculating the arctan between the position in the costmap and the origin of the costmap.\n    - **Parameters:**\n      - **position:** The position in the costmap (already converted to the world coordinate frame).\n      - **origin:** The origin of the costmap (the point which the robot should face).\n    - **Returns:** A quaternion of the calculated orientation.\n\n### **visibility_validator**  \nValidates if the robot can see the target position from a given pose candidate. The target position can either be a position in the world coordinate system or an object in the World. The validation is done by shooting a ray from the camera to the target position and checking that it does not collide with anything else.\n\n- **Parameters:**\n  - **pose:** The pose candidate to be validated.\n  - **robot:** The robot object for which this should be validated.\n  - **object_or_pose:** The target position or object for which the pose candidate should be validated.\n  - **world:** The World instance in which this should be validated.\n- **Returns:** `True` if the target is visible for the robot, otherwise `None`.\n\n### **_in_contact**  \nChecks if a given robot is in contact with a given object.\n\n- **Parameters:**\n  - **robot:** The robot object that should be checked for contact.\n  - **obj:** The object that should be checked for contact with the robot.\n  - **allowed_collision:** A dictionary containing the allowed collisions for links of each object in the world.\n  - **allowed_robot_links:** A list of links of the robot that are allowed to be in contact with the object.\n- **Returns:** `True` if the robot is in contact with the object, otherwise `False`.\n\n### **reachability_validator**  \nValidates if a target position is reachable for a pose candidate. This is done by asking the IK solver if there is a valid solution if the robot stands at the position of the pose candidate. If there is a solution, the validator returns `True`, otherwise `False`.\n\n- **Parameters:**\n  - **pose:** The pose candidate for which reachability should be validated.\n  - **robot:** The robot object in the World for which reachability should be validated.\n  - **target:** The target position or object instance that should be the target for reachability.\n  - **allowed_collision:** A dictionary of objects with which the robot is allowed to collide. Each object correlates to a list of links of which this object consists.\n- **Returns:** A tuple containing `True` if the target is reachable for the robot, otherwise `False`, and a list of results.\n\n### **collision_check**  \nChecks if a given robot collides with any object within the world that it is not allowed to collide with. This is done by iterating over every object within the world and checking if the robot collides with it. Note that the floor will be ignored. If there is a collision with an object not within the allowed collision list, the function returns `True`, otherwise `False`.\n\n- **Parameters:**\n  - **robot:** The robot object in the (Bullet)World where it should be checked for collisions.\n  - **allowed_collision:** A dictionary of objects with which the robot is allowed to collide. Each object correlates to a list of links of which this object consists.\n- **Returns:** `True` if the target is reachable for the robot, otherwise `False`."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What information can I find about the PR2 robot in the PyCRAM documentation?"}, {"role": "assistant", "content": "pycram.robot_descriptions.pr2_description  \n==============================================\n\n### **Attributes**\n\n- **rospack**  \n- **filename**  \n- **pr2_description**  \n- **left_arm**  \n- **left_gripper**  \n- **right_arm**  \n- **right_gripper**  \n- **camera**  \n- **rdm**  \n\n**Module Contents**  \n\n- **pycram.robot_descriptions.pr2_description.rospack**  \n- **pycram.robot_descriptions.pr2_description.filename**  \n- **pycram.robot_descriptions.pr2_description.pr2_description**  \n- **pycram.robot_descriptions.pr2_description.left_arm**  \n- **pycram.robot_descriptions.pr2_description.left_gripper**  \n- **pycram.robot_descriptions.pr2_description.right_arm**  \n- **pycram.robot_descriptions.pr2_description.right_gripper**  \n- **pycram.robot_descriptions.pr2_description.camera**  \n- **pycram.robot_descriptions.pr2_description.rdm**"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What information can I find about the generic object descriptors in the PyCRAM documentation?"}, {"role": "assistant", "content": "pycram.object_descriptors.generic \n======================================\n\n### **Classes**\n\n- **LinkDescription**  \n  A class that represents a link description of an object.\n\n- **JointDescription**  \n  A class that represents the description of a joint.\n\n- **ObjectDescription**  \n  A generic description of an object in the environment. This description can be applied to any object.\n\n**Module Contents**  \n\n### **LinkDescription**  \nBases: `pycram.description.LinkDescription`\n\nA class that represents a link description of an object.\n\n- **Attributes:**\n  - **parsed_description**: `pycram.datastructures.dataclasses.BoxVisualShape`\n  - **_name**: `str`\n\n- **Properties:**\n  - **geometry**: `typing_extensions.Union[pycram.datastructures.dataclasses.VisualShape, None]`  \n    Returns the geometry type of the collision element of this link.\n  - **origin**: `pycram.datastructures.pose.Pose`  \n    Returns the origin of this entity.\n  - **name**: `str`  \n    Returns the name of this entity.\n  - **color**: `pycram.datastructures.dataclasses.Color`\n\n### **JointDescription**  \nBases: `pycram.description.JointDescription`\n\nA class that represents the description of a joint.\n\n- **Properties:**\n  - **type**: `pycram.datastructures.enums.JointType`  \n    Returns the type of this joint.\n  - **axis**: `geometry_msgs.msg.Point`  \n    Returns the axis of this joint, for example, the rotation axis for a revolute joint.\n  - **has_limits**: `bool`  \n    Checks if this joint has limits.  \n    - **Returns:** `True` if the joint has limits, `False` otherwise.\n  - **lower_limit**: `typing_extensions.Union[float, None]`  \n    Returns the lower limit of this joint, or `None` if the joint has no limits.\n  - **upper_limit**: `typing_extensions.Union[float, None]`  \n    Returns the upper limit of this joint, or `None` if the joint has no limits.\n  - **parent_link_name**: `str`  \n    Returns the name of the parent link of this joint.\n  - **child_link_name**: `str`  \n    Returns the name of the child link of this joint.\n  - **origin**: `pycram.datastructures.pose.Pose`  \n    Returns the origin of this entity.\n  - **name**: `str`  \n    Returns the name of this entity.\n\n### **ObjectDescription**  \nBases: `pycram.description.ObjectDescription`\n\nA generic description of an object in the environment. This description can be applied to any object. The current use case involves perceiving objects using RoboKudo and spawning them with specified size and color.\n\n- **Classes:**\n  - **Link**  \n    Bases: `pycram.description.ObjectDescription.Link`, `LinkDescription`  \n    Represents a link of an Object in the World.\n  - **RootLink**  \n    Bases: `pycram.description.ObjectDescription.RootLink`, `Link`  \n    Represents the root link of an Object in the World. It differs from the normal `AbstractLink` class in that the pose and the `tf_frame` is the same as that of the object.\n  - **Joint**  \n    Bases: `pycram.description.ObjectDescription.Joint`, `JointDescription`  \n    Represents a joint of an Object in the World.\n\n- **Attributes:**\n  - **_links**\n\n- **Methods:**\n  - **load_description(path: str) → typing_extensions.Any**  \n    Loads the description from the file at the given path.  \n    - **Parameters:**  \n      - **path:** The path to the source file. If only a filename is provided, the resources directories will be searched.\n  - **generate_from_mesh_file(path: str, name: str) → str**  \n    - **Class Method**  \n    Generates a description file from one of the mesh types defined in the mesh extensions and returns the path of the generated file.  \n    - **Parameters:**  \n      - **path:** The path to the .obj file.  \n      - **name:** The name of the object.  \n    - **Returns:** The path of the generated description file.\n  - **generate_from_description_file(path: str) → str**  \n    - **Class Method**  \n    Preprocesses the given file and returns the preprocessed description string.  \n    - **Parameters:**  \n      - **path:** The path of the file to preprocess.  \n    - **Returns:** The preprocessed description string.\n  - **generate_from_parameter_server(name: str) → str**  \n    - **Class Method**  \n    Preprocesses the description from the ROS parameter server and returns the preprocessed description string.  \n    - **Parameters:**  \n      - **name:** The name of the description on the parameter server.  \n    - **Returns:** The preprocessed description string.\n  - **get_link_by_name(link_name: str) → LinkDescription**  \n    Returns the link description with the given name.\n  - **get_joint_by_name(joint_name: str) → JointDescription**  \n    Returns the joint description with the given name.\n  - **get_root() → str**  \n    Returns the name of the root link of this object.\n  - **get_chain(start_link_name: str, end_link_name: str) → typing_extensions.List[str]**  \n    Returns the chain of links from `start_link_name` to `end_link_name`.\n\n- **Properties:**\n  - **shape_data**: `typing_extensions.List[float]`\n  - **color**: `pycram.datastructures.dataclasses.Color`\n  - **links**: `typing_extensions.List[LinkDescription]`  \n    Returns a list of link descriptions of this object.\n  - **joints**: `typing_extensions.List[JointDescription]`  \n    Returns a list of joint descriptions of this object.\n  - **origin**: `pycram.datastructures.pose.Pose`  \n    Returns the origin of this entity.\n  - **name**: `str`  \n    Returns the name of this entity."}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the key features of the dataclasses in the pycram.datastructures module of the PyCRAM documentation?"}, {"role": "assistant", "content": "pycram.datastructures.dataclasses  \n======================================\n\n### **Classes**\n\n- **Color**  \n  Dataclass for storing rgba_color as an RGBA value.\n\n- **AxisAlignedBoundingBox**  \n  Dataclass for storing an axis-aligned bounding box.\n\n- **CollisionCallbacks**  \n\n- **MultiBody**  \n\n- **VisualShape**  \n  Helper class that provides a standard way to create an ABC using inheritance.\n\n- **BoxVisualShape**  \n  Helper class that provides a standard way to create an ABC using inheritance.\n\n- **SphereVisualShape**  \n  Helper class that provides a standard way to create an ABC using inheritance.\n\n- **CapsuleVisualShape**  \n  Helper class that provides a standard way to create an ABC using inheritance.\n\n- **CylinderVisualShape**  \n  Helper class that provides a standard way to create an ABC using inheritance.\n\n- **MeshVisualShape**  \n  Helper class that provides a standard way to create an ABC using inheritance.\n\n- **PlaneVisualShape**  \n  Helper class that provides a standard way to create an ABC using inheritance.\n\n- **State**  \n  Helper class that provides a standard way to create an ABC using inheritance.\n\n- **LinkState**  \n  Helper class that provides a standard way to create an ABC using inheritance.\n\n- **JointState**  \n  Helper class that provides a standard way to create an ABC using inheritance.\n\n- **ObjectState**  \n  Helper class that provides a standard way to create an ABC using inheritance.\n\n- **WorldState**  \n  Helper class that provides a standard way to create an ABC using inheritance.\n\n**Module Contents**  \n\n### **Functions**\n\n#### `get_point_as_list(point: pycram.datastructures.pose.Point) -> typing_extensions.List[float]`\n   Returns the point as a list.\n   - **Parameters:**\n     - `point`: The point.\n   - **Returns:**  \n     The point as a list.\n\n### **Class Details**\n\n#### **Color**\n   Dataclass for storing rgba_color as an RGBA value. The values are stored as floats between 0 and 1. The default rgba_color is white. 'A' stands for the opacity.\n\n- **Attributes:**\n  - `R`: `float = 1`\n  - `G`: `float = 1`\n  - `B`: `float = 1`\n  - `A`: `float = 1`\n\n- **Methods:**\n  - `from_list(color: typing_extensions.List[float])`: Sets the rgba_color from a list of RGBA values.\n  - `from_rgb(rgb: typing_extensions.List[float])`: Sets the rgba_color from a list of RGB values.\n  - `from_rgba(rgba: typing_extensions.List[float])`: Sets the rgba_color from a list of RGBA values.\n  - `get_rgba() -> typing_extensions.List[float]`: Returns the rgba_color as a list of RGBA values.\n  - `get_rgb() -> typing_extensions.List[float]`: Returns the rgba_color as a list of RGB values.\n\n#### **AxisAlignedBoundingBox**\n   Dataclass for storing an axis-aligned bounding box.\n\n- **Attributes:**\n  - `min_x`: `float`\n  - `min_y`: `float`\n  - `min_z`: `float`\n  - `max_x`: `float`\n  - `max_y`: `float`\n  - `max_z`: `float`\n\n- **Methods:**\n  - `from_min_max(min_point: typing_extensions.List[float], max_point: typing_extensions.List[float])`: Sets the axis-aligned bounding box from a minimum and maximum point.\n  - `get_min_max_points() -> typing_extensions.Tuple[pycram.datastructures.pose.Point, pycram.datastructures.pose.Point]`: Returns the axis-aligned bounding box as a tuple of minimum and maximum points.\n  - `get_min_point() -> pycram.datastructures.pose.Point`: Returns the axis-aligned bounding box as a minimum point.\n  - `get_max_point() -> pycram.datastructures.pose.Point`: Returns the axis-aligned bounding box as a maximum point.\n  - `get_min_max() -> typing_extensions.Tuple[typing_extensions.List[float], typing_extensions.List[float]]`: Returns the axis-aligned bounding box as a tuple of minimum and maximum points.\n  - `get_min() -> typing_extensions.List[float]`: Returns the minimum point of the axis-aligned bounding box.\n  - `get_max() -> typing_extensions.List[float]`: Returns the maximum point of the axis-aligned bounding box.\n\n#### **CollisionCallbacks**\n- **Attributes:**\n  - `on_collision_cb`: `typing_extensions.Callable`\n  - `no_collision_cb`: `typing_extensions.Optional[typing_extensions.Callable] = None`\n\n#### **MultiBody**\n- **Attributes:**\n  - `base_visual_shape_index`: `int`\n  - `base_pose`: `pycram.datastructures.pose.Pose`\n  - `link_visual_shape_indices`: `typing_extensions.List[int]`\n  - `link_poses`: `typing_extensions.List[pycram.datastructures.pose.Pose]`\n  - `link_masses`: `typing_extensions.List[float]`\n  - `link_inertial_frame_poses`: `typing_extensions.List[pycram.datastructures.pose.Pose]`\n  - `link_parent_indices`: `typing_extensions.List[int]`\n  - `link_joint_types`: `typing_extensions.List[pycram.datastructures.enums.JointType]`\n  - `link_joint_axis`: `typing_extensions.List[pycram.datastructures.pose.Point]`\n  - `link_collision_shape_indices`: `typing_extensions.List[int]`\n\n#### **VisualShape**\n   Bases: `abc.ABC`\n   Helper class that provides a standard way to create an ABC using inheritance.\n\n- **Attributes:**\n  - `rgba_color`: `Color`\n  - `visual_frame_position`: `typing_extensions.List[float]`\n\n- **Methods:**\n  - `shape_data() -> typing_extensions.Dict[str, typing_extensions.Any]`: Abstract method to return the shape data of the visual shape (e.g. half extents for a box, radius for a sphere).\n  - **Properties:**\n    - `visual_geometry_type`: `pycram.datastructures.enums.Shape`: Abstract property to return the visual geometry type of the visual shape (e.g. box, sphere).\n\n#### **BoxVisualShape**\n   Bases: `VisualShape`\n   Helper class that provides a standard way to create an ABC using inheritance.\n\n- **Attributes:**\n  - `half_extents`: `typing_extensions.List[float]`\n\n- **Methods:**\n  - `shape_data() -> typing_extensions.Dict[str, typing_extensions.List[float]]`: Returns the shape data of the visual shape (e.g. half extents for a box, radius for a sphere).\n  - **Properties:**\n    - `visual_geometry_type`: `pycram.datastructures.enums.Shape`: Returns the visual geometry type of the visual shape (e.g. box, sphere).\n    - `size`: `typing_extensions.List[float]`\n\n#### **SphereVisualShape**\n   Bases: `VisualShape`\n   Helper class that provides a standard way to create an ABC using inheritance.\n\n- **Attributes:**\n  - `radius`: `float`\n\n- **Methods:**\n  - `shape_data() -> typing_extensions.Dict[str, float]`: Returns the shape data of the visual shape (e.g. radius for a sphere).\n  - **Properties:**\n    - `visual_geometry_type`: `pycram.datastructures.enums.Shape`: Returns the visual geometry type of the visual shape (e.g. sphere).\n\n#### **CapsuleVisualShape**\n   Bases: `VisualShape`\n   Helper class that provides a standard way to create an ABC using inheritance.\n\n- **Attributes:**\n  - `radius`: `float`\n  - `length`: `float`\n\n- **Methods:**\n  - `shape_data() -> typing_extensions.Dict[str, float]`: Returns the shape data of the visual shape (e.g. radius and length for a capsule).\n  - **Properties:**\n    - `visual_geometry_type`: `pycram.datastructures.enums.Shape`: Returns the visual geometry type of the visual shape (e.g. capsule).\n\n#### **CylinderVisualShape**\n   Bases: `CapsuleVisualShape`\n   Helper class that provides a standard way to create an ABC using inheritance.\n\n- **Properties:**\n  - `visual_geometry_type`: `pycram.datastructures.enums.Shape`: Returns the visual geometry type of the visual shape (e.g. cylinder).\n\n#### **MeshVisualShape**\n   Bases: `VisualShape`\n   Helper class that provides a standard way to create an ABC using inheritance.\n\n- **Attributes:**\n  - `scale`: `typing_extensions.List[float]`\n  - `file_name`: `str`\n\n- **Methods:**\n  - `shape_data() -> typing_extensions.Dict[str, typing_extensions.Union[typing_extensions.List[float], str]]`: Returns the shape data of the visual shape (e.g. scale and file name for a mesh).\n  - **Properties:**\n    - `visual_geometry_type`: `pycram.datastructures.enums.Shape`: Returns the visual geometry type of the visual shape (e.g. mesh).\n\n#### **PlaneVisualShape**\n   Bases: `VisualShape`\n   Helper class that provides a standard way to create an ABC using inheritance.\n\n- **Attributes:**\n  - `normal`: `typing_extensions.List[float]`\n\n- **Methods:**\n  - `shape_data() -> typing_extensions.Dict[str, typing_extensions.List[float]]`: Returns the shape data of the visual shape (e.g. normal vector for a plane).\n  - **Properties:**\n    - `visual_geometry_type`: `pycram.datas\n\ntructures.enums.Shape`: Returns the visual geometry type of the visual shape (e.g. plane).\n\n#### **State**\n   Bases: `abc.ABC`\n   Helper class that provides a standard way to create an ABC using inheritance.\n\n#### **LinkState**\n   Bases: `State`\n   Helper class that provides a standard way to create an ABC using inheritance.\n\n- **Attributes:**\n  - `constraint_ids`: `typing_extensions.Dict[pycram.description.Link, int]`\n\n#### **JointState**\n   Bases: `State`\n   Helper class that provides a standard way to create an ABC using inheritance.\n\n- **Attributes:**\n  - `position`: `float`\n\n#### **ObjectState**\n   Bases: `State`\n   Helper class that provides a standard way to create an ABC using inheritance.\n\n- **Attributes:**\n  - `pose`: `pycram.datastructures.pose.Pose`\n  - `attachments`: `typing_extensions.Dict[pycram.world_concepts.world_object.Object, pycram.world_concepts.constraints.Attachment]`\n  - `link_states`: `typing_extensions.Dict[int, LinkState]`\n  - `joint_states`: `typing_extensions.Dict[int, JointState]`\n\n#### **WorldState**\n   Bases: `State`\n   Helper class that provides a standard way to create an ABC using inheritance.\n\n- **Attributes:**\n  - `simulator_state_id`: `int`\n  - `object_states`: `typing_extensions.Dict[str, ObjectState]`"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code."}, {"role": "user", "content": "What are the available enums in the pycram.datastructures.enums section of the PyCRAM documentation?"}, {"role": "assistant", "content": "pycram.datastructures.enums \n================================\n\nModule holding all enums of PyCRAM.\n\n### **Classes**\n\n- **ExecutionType**  \n  Enum for Execution Process Module types.\n\n- **Arms**  \n  Enum for Arms.\n\n- **TaskStatus**  \n  Enum for readable descriptions of a tasks' status.\n\n- **JointType**  \n  Enum for readable joint types.\n\n- **Grasp**  \n  Enum for Grasp orientations.\n\n- **ObjectType**  \n  Enum for Object types to make it easier to identify different objects.\n\n- **State**  \n  Enumeration that describes the result of a language expression.\n\n- **Shape**  \n  Enum for visual shapes of objects.\n\n- **WorldMode**  \n  Enum for the different modes of the world.\n\n- **AxisIdentifier**  \n  Enum for translating the axis name to a vector along that axis.\n\n- **GripperState**  \n  Enum for the different motions of the gripper.\n\n- **GripperType**  \n  Enum for the different types of grippers.\n\n- **PerceptionTechniques**  \n  Enum for techniques used in perception tasks.\n\n- **ImageEnum**  \n  Enum for image switch views on the HSRB display.\n\n**Module Contents**  \n\n### **Class Details**\n\n#### **ExecutionType**\n   Bases: `enum.Enum`  \n   Enum for Execution Process Module types.\n\n- **Attributes:**\n  - `REAL`\n  - `SIMULATED`\n  - `SEMI_REAL`\n\n#### **Arms**\n   Bases: `enum.Enum`  \n   Enum for Arms.\n\n- **Attributes:**\n  - `LEFT`\n  - `RIGHT`\n  - `BOTH`\n\n#### **TaskStatus**\n   Bases: `enum.Enum`  \n   Enum for readable descriptions of a tasks' status.\n\n- **Attributes:**\n  - `CREATED` = 0\n  - `RUNNING` = 1\n  - `SUCCEEDED` = 2\n  - `FAILED` = 3\n\n#### **JointType**\n   Bases: `enum.Enum`  \n   Enum for readable joint types.\n\n- **Attributes:**\n  - `REVOLUTE` = 0\n  - `PRISMATIC` = 1\n  - `SPHERICAL` = 2\n  - `PLANAR` = 3\n  - `FIXED` = 4\n  - `UNKNOWN` = 5\n  - `CONTINUOUS` = 6\n  - `FLOATING` = 7\n\n#### **Grasp**\n   Bases: `enum.Enum`  \n   Enum for Grasp orientations.\n\n- **Attributes:**\n  - `FRONT` = 0\n  - `LEFT` = 1\n  - `RIGHT` = 2\n  - `TOP` = 3\n\n#### **ObjectType**\n   Bases: `enum.Enum`  \n   Enum for Object types to make it easier to identify different objects.\n\n- **Attributes:**\n  - `METALMUG`\n  - `PRINGLES`\n  - `MILK`\n  - `SPOON`\n  - `BOWL`\n  - `BREAKFAST_CEREAL`\n  - `JEROEN_CUP`\n  - `ROBOT`\n  - `ENVIRONMENT`\n  - `GENERIC_OBJECT`\n  - `HUMAN`\n\n#### **State**\n   Bases: `enum.Enum`  \n   Enumeration that describes the result of a language expression.\n\n- **Attributes:**\n  - `SUCCEEDED` = 1\n  - `FAILED` = 0\n  - `RUNNING` = 2\n  - `INTERRUPTED` = 3\n\n#### **Shape**\n   Bases: `enum.Enum`  \n   Enum for visual shapes of objects.\n\n- **Attributes:**\n  - `SPHERE` = 2\n  - `BOX` = 3\n  - `CYLINDER` = 4\n  - `MESH` = 5\n  - `PLANE` = 6\n  - `CAPSULE` = 7\n\n#### **WorldMode**\n   Bases: `enum.Enum`  \n   Enum for the different modes of the world.\n\n- **Attributes:**\n  - `GUI` = 'GUI'\n  - `DIRECT` = 'DIRECT'\n\n#### **AxisIdentifier**\n   Bases: `enum.Enum`  \n   Enum for translating the axis name to a vector along that axis.\n\n- **Attributes:**\n  - `X` = (1, 0, 0)\n  - `Y` = (0, 1, 0)\n  - `Z` = (0, 0, 1)\n\n#### **GripperState**\n   Bases: `enum.Enum`  \n   Enum for the different motions of the gripper.\n\n- **Attributes:**\n  - `OPEN`\n  - `CLOSE`\n\n#### **GripperType**\n   Bases: `enum.Enum`  \n   Enum for the different types of grippers.\n\n- **Attributes:**\n  - `PARALLEL`\n  - `SUCTION`\n  - `FINGER`\n  - `HYDRAULIC`\n  - `PNEUMATIC`\n  - `CUSTOM`\n\n#### **PerceptionTechniques**\n   Bases: `enum.Enum`  \n   Enum for techniques used in perception tasks.\n\n- **Attributes:**\n  - `ALL`\n  - `HUMAN`\n  - `TYPES`\n\n#### **ImageEnum**\n   Bases: `enum.Enum`  \n   Enum for image switch views on the HSRB display.\n\n- **Attributes:**\n  - `HI` = 0\n  - `TALK` = 1\n  - `DISH` = 2\n  - `DONE` = 3\n  - `DROP` = 4\n  - `HANDOVER` = 5\n  - `ORDER` = 6\n  - `PICKING` = 7\n  - `PLACING` = 8\n  - `REPEAT` = 9\n  - `SEARCH` = 10\n  - `WAVING` = 11\n  - `FOLLOWING` = 12\n  - `DRIVINGBACK` = 13\n  - `PUSHBUTTONS` = 14\n  - `FOLLOWSTOP` = 15\n  - `JREPEAT` = 16\n  - `SOFA` = 17\n  - `INSPECT` = 18\n  - `CHAIR` = 37"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code. You will get a Task and world knowledge. Break down the task into a plan with small single task that a robot needs to do in order to achive that higher task."}, {"role": "user", "content": "Can you set the table for breakfast? I want to eat a bowl of cereals with milk. \nWorld Knowledge: robot = Object('pr2', ObjectType.ROBOT, 'pr2.urdf', pose=Pose([1, 2, 0])), apartment = Object('apartment', ObjectType.ENVIRONMENT, 'apartment.urdf'), milk = Object('milk', ObjectType.MILK, 'milk.stl', pose=Pose([2.5, 2, 1.02]), color=[1, 0, 0, 1]), cereal = Object('cereal', ObjectType.BREAKFAST_CEREAL, 'breakfast_cereal.stl', pose=Pose([2.5, 2.3, 1.05]), color=[0, 1, 0, 1]), spoon = Object('spoon', ObjectType.SPOON, 'spoon.stl', pose=Pose([2.4, 2.2, 0.85]), color=[0, 0, 1, 1]), bowl = Object('bowl', ObjectType.BOWL, 'bowl.stl', pose=Pose([2.5, 2.2, 1.02]), color=[1, 1, 0, 1]), apartment.attach(spoon, 'cabinet10_drawer_top')"}, {"role": "assistant", "content": "### Plan zur Umwandlung der Handlungsequenz in PyCramPlanCode\n\n#### Plan 1: Welt und Roboter initialisieren\n- **Beschreibung:** Erstelle eine BulletWorld und lade den Roboter und die Umgebung.\n- **Tool:** Retrieve\n- **Eingabe:** Wie initialisiere ich eine BulletWorld und lade Objekte?\n- **Code:**\n  ```python\n  world = BulletWorld(WorldMode.GUI)\n  robot = Object(\"pr2\", ObjectType.ROBOT, f\"pr2{extension}\", pose=Pose([1, 2, 0]))\n  apartment = Object(\"apartment\", ObjectType.ENVIRONMENT, f\"apartment{extension}\")\n  ```\n\n#### Plan 2: Objekte erstellen\n- **Beschreibung:** Erstelle die Objekte Milch, Müsli, Löffel und Schüssel.\n- **Tool:** Retrieve\n- **Eingabe:** Wie erstelle ich Objekte in PyCram?\n- **Code:**\n  ```python\n  milk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([2.5, 2, 1.02]), color=Color(1, 0, 0, 1))\n  cereal = Object(\"cereal\", ObjectType.BREAKFAST_CEREAL, \"breakfast_cereal.stl\", pose=Pose([2.5, 2.3, 1.05]), color=Color(0, 1, 0, 1))\n  spoon = Object(\"spoon\", ObjectType.SPOON, \"spoon.stl\", pose=Pose([2.4, 2.2, 0.85]), color=Color(0, 0, 1, 1))\n  bowl = Object(\"bowl\", ObjectType.BOWL, \"bowl.stl\", pose=Pose([2.5, 2.2, 1.02]), color=Color(1, 1, 0, 1))\n  ```\n\n#### Plan 3: Objekt-Designatoren erstellen\n- **Beschreibung:** Erstelle Designatoren für den Roboter und die Umgebung.\n- **Tool:** Retrieve\n- **Eingabe:** Wie erstelle ich Objekt-Designatoren in PyCram?\n- **Code:**\n  ```python\n  robot_desig = BelieveObject(names=[\"pr2\"])\n  apartment_desig = BelieveObject(names=[\"apartment\"])\n  ```\n\n#### Plan 4: Arme parken und Torso bewegen\n- **Beschreibung:** Parke beide Arme des Roboters und hebe den Torso.\n- **Tool:** Retrieve\n- **Eingabe:** Wie parke ich die Arme und bewege den Torso in PyCram?\n- **Code:**\n  ```python\n  ParkArmsAction([Arms.BOTH]).resolve().perform()\n  MoveTorsoAction([0.25]).resolve().perform()\n  ```\n\n#### Plan 5: Milch erkennen und transportieren\n- **Beschreibung:** Erkenne die Milch und transportiere sie.\n- **Tool:** Retrieve\n- **Eingabe:** Wie erkenne und transportiere ich Objekte in PyCram?\n- **Code:**\n  ```python\n  milk_desig = move_and_detect(ObjectType.MILK)\n  TransportAction(milk_desig, [Arms.LEFT], [Pose([4.8, 3.55, 0.8])]).resolve().perform()\n  ```\n\n#### Plan 6: Müsli erkennen und transportieren\n- **Beschreibung:** Erkenne das Müsli und transportiere es.\n- **Tool:** Retrieve\n- **Eingabe:** Wie erkenne und transportiere ich Objekte in PyCram?\n- **Code:**\n  ```python\n  cereal_desig = move_and_detect(ObjectType.BREAKFAST_CEREAL)\n  TransportAction(cereal_desig, [Arms.RIGHT], [Pose([5.2, 3.4, 0.8], [0, 0, 1, 1])]).resolve().perform()\n  ```\n\n#### Plan 7: Schüssel erkennen und transportieren\n- **Beschreibung:** Erkenne die Schüssel und transportiere sie.\n- **Tool:** Retrieve\n- **Eingabe:** Wie erkenne und transportiere ich Objekte in PyCram?\n- **Code:**\n  ```python\n  bowl_desig = move_and_detect(ObjectType.BOWL)\n  TransportAction(bowl_desig, [Arms.LEFT], [Pose([5, 3.3, 0.8], [0, 0, 1, 1])]).resolve().perform()\n  ```\n\n#### Plan 8: Schublade öffnen und Löffel erkennen\n- **Beschreibung:** Öffne die Schublade und erkenne den Löffel.\n- **Tool:** Retrieve\n- **Eingabe:** Wie öffne ich Schubladen und erkenne Objekte in PyCram?\n- **Code:**\n  ```python\n  handle_desig = ObjectPart(names=[\"handle_cab10_t\"], part_of=apartment_desig.resolve())\n  drawer_open_loc = AccessingLocation(handle_desig=handle_desig.resolve(), robot_desig=robot_desig.resolve()).resolve()\n  NavigateAction([drawer_open_loc.pose]).resolve().perform()\n  OpenAction(object_designator_description=handle_desig, arms=[drawer_open_loc.arms[0]]).resolve().perform()\n  spoon.detach(apartment)\n  LookAtAction([apartment.get_link_pose(\"handle_cab10_t\")]).resolve().perform()\n  spoon_desig = DetectAction(BelieveObject(types=[ObjectType.SPOON])).resolve().perform()\n  ```\n\n#### Plan 9: Löffel aufheben und Schublade schließen\n- **Beschreibung:** Hebe den Löffel auf und schließe die Schublade.\n- **Tool:** Retrieve\n- **Eingabe:** Wie hebe ich Objekte auf und schließe Schubladen in PyCram?\n- **Code:**\n  ```python\n  pickup_arm = Arms.LEFT if drawer_open_loc.arms[0] == Arms.RIGHT else Arms.RIGHT\n  PickUpAction(spoon_desig, [pickup_arm], [Grasp.TOP]).resolve().perform()\n  ParkArmsAction([Arms.LEFT if pickup_arm == Arms.LEFT else Arms.RIGHT]).resolve().perform()\n  CloseAction(object_designator_description=handle_desig, arms=[drawer_open_loc.arms[0]]).resolve().perform()\n  ```\n\n#### Plan 10: Löffel platzieren und Arme parken\n- **Beschreibung:** Platziere den Löffel und parke die Arme.\n- **Tool:** Retrieve\n- **Eingabe:** Wie platziere ich Objekte und parke die Arme in PyCram?\n- **Code:**\n  ```python\n  spoon_target_pose = Pose([4.85, 3.3, 0.8], [0, 0, 1, 1])\n  placing_loc = CostmapLocation(target=spoon_target_pose, reachable_for=robot_desig.resolve()).resolve()\n  NavigateAction([placing_loc.pose]).resolve().perform()\n  PlaceAction(spoon_desig, [spoon_target_pose], [pickup_arm]).resolve().perform()\n  ParkArmsAction([Arms.BOTH]).resolve().perform()\n  ```\n\n#### Plan 11: Welt schließen\n- **Beschreibung:** Schließe die BulletWorld.\n- **Tool:** Retrieve\n- **Eingabe:** Wie schließe ich die BulletWorld in PyCram?\n- **Code:**\n  ```python\n  world.exit()\n  ```"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code. You will get a Task and world knowledge. Then write a PyCRAM Plan code for it. Respond just with the code."}, {"role": "user", "content": "Can you set the table for breakfast? I want to eat a bowl of cereals with milk. \nWorld Knowledge: robot = Object('pr2', ObjectType.ROBOT, 'pr2.urdf', pose=Pose([1, 2, 0])), apartment = Object('apartment', ObjectType.ENVIRONMENT, 'apartment.urdf'), milk = Object('milk', ObjectType.MILK, 'milk.stl', pose=Pose([2.5, 2, 1.02]), color=[1, 0, 0, 1]), cereal = Object('cereal', ObjectType.BREAKFAST_CEREAL, 'breakfast_cereal.stl', pose=Pose([2.5, 2.3, 1.05]), color=[0, 1, 0, 1]), spoon = Object('spoon', ObjectType.SPOON, 'spoon.stl', pose=Pose([2.4, 2.2, 0.85]), color=[0, 0, 1, 1]), bowl = Object('bowl', ObjectType.BOWL, 'bowl.stl', pose=Pose([2.5, 2.2, 1.02]), color=[1, 1, 0, 1]), apartment.attach(spoon, 'cabinet10_drawer_top')"}, {"role": "assistant", "content": "from pycram.worlds.bullet_world import BulletWorld\nfrom pycram.designators.action_designator import *\nfrom pycram.designators.location_designator import *\nfrom pycram.designators.object_designator import *\nfrom pycram.datastructures.enums import ObjectType, WorldMode\nfrom pycram.datastructures.pose import Pose\nfrom pycram.process_module import simulated_robot, with_simulated_robot\nfrom pycram.object_descriptors.urdf import ObjectDescription\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.datastructures.dataclasses import Color\n\nworld = BulletWorld(WorldMode.GUI)\nrobot = Object(\"pr2\", ObjectType.ROBOT, f\"pr2.urdf\", pose=Pose([1, 2, 0]))\napartment = Object(\"apartment\", ObjectType.ENVIRONMENT, f\"apartment.urdf\")\n\nmilk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([2.5, 2, 1.02]),\n              color=Color(1, 0, 0, 1))\ncereal = Object(\"cereal\", ObjectType.BREAKFAST_CEREAL, \"breakfast_cereal.stl\",\n                pose=Pose([2.5, 2.3, 1.05]), color=Color(0, 1, 0, 1))\nspoon = Object(\"spoon\", ObjectType.SPOON, \"spoon.stl\", pose=Pose([2.4, 2.2, 0.85]),\n               color=Color(0, 0, 1, 1))\nbowl = Object(\"bowl\", ObjectType.BOWL, \"bowl.stl\", pose=Pose([2.5, 2.2, 1.02]),\n              color=Color(1, 1, 0, 1))\napartment.attach(spoon, 'cabinet10_drawer_top')\n\npick_pose = Pose([2.7, 2.15, 1])\n\nrobot_desig = BelieveObject(names=[\"pr2\"])\napartment_desig = BelieveObject(names=[\"apartment\"])\n\n\n@with_simulated_robot\ndef move_and_detect(obj_type):\n    NavigateAction(target_locations=[Pose([1.7, 2, 0])]).resolve().perform()\n\n    LookAtAction(targets=[pick_pose]).resolve().perform()\n\n    object_desig = DetectAction(BelieveObject(types=[obj_type])).resolve().perform()\n\n    return object_desig\n\n\nwith simulated_robot:\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n\n    MoveTorsoAction([0.25]).resolve().perform()\n\n    milk_desig = move_and_detect(ObjectType.MILK)\n\n    TransportAction(milk_desig, [Arms.LEFT], [Pose([4.8, 3.55, 0.8])]).resolve().perform()\n\n    cereal_desig = move_and_detect(ObjectType.BREAKFAST_CEREAL)\n\n    TransportAction(cereal_desig, [Arms.RIGHT], [Pose([5.2, 3.4, 0.8], [0, 0, 1, 1])]).resolve().perform()\n\n    bowl_desig = move_and_detect(ObjectType.BOWL)\n\n    TransportAction(bowl_desig, [Arms.LEFT], [Pose([5, 3.3, 0.8], [0, 0, 1, 1])]).resolve().perform()\n\n    # Finding and navigating to the drawer holding the spoon\n    handle_desig = ObjectPart(names=[\"handle_cab10_t\"], part_of=apartment_desig.resolve())\n    drawer_open_loc = AccessingLocation(handle_desig=handle_desig.resolve(),\n                                        robot_desig=robot_desig.resolve()).resolve()\n\n    NavigateAction([drawer_open_loc.pose]).resolve().perform()\n\n    OpenAction(object_designator_description=handle_desig, arms=[drawer_open_loc.arms[0]]).resolve().perform()\n    spoon.detach(apartment)\n\n    # Detect and pickup the spoon\n    LookAtAction([apartment.get_link_pose(\"handle_cab10_t\")]).resolve().perform()\n\n    spoon_desig = DetectAction(BelieveObject(types=[ObjectType.SPOON])).resolve().perform()\n\n    pickup_arm = Arms.LEFT if drawer_open_loc.arms[0] == Arms.RIGHT else Arms.RIGHT\n    PickUpAction(spoon_desig, [pickup_arm], [Grasp.TOP]).resolve().perform()\n\n    ParkArmsAction([Arms.LEFT if pickup_arm == Arms.LEFT else Arms.RIGHT]).resolve().perform()\n\n    CloseAction(object_designator_description=handle_desig, arms=[drawer_open_loc.arms[0]]).resolve().perform()\n\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n\n    MoveTorsoAction([0.15]).resolve().perform()\n\n    # Find a pose to place the spoon, move and then place it\n    spoon_target_pose = Pose([4.85, 3.3, 0.8], [0, 0, 1, 1])\n    placing_loc = CostmapLocation(target=spoon_target_pose, reachable_for=robot_desig.resolve()).resolve()\n\n    NavigateAction([placing_loc.pose]).resolve().perform()\n\n    PlaceAction(spoon_desig, [spoon_target_pose], [pickup_arm]).resolve().perform()\n\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\nworld.exit()\n"}]}
{"messages": [{"role": "system", "content": "You are a coding expert and know how to write PyCRAM Plan Code. You will get a Task and world knowledge. Then write a PyCRAM Plan code for it. Respond just with the code."}, {"role": "user", "content": "Can you place the cereal on the kitchen island?\nWorld knowledge: [kitchen = Object('kitchen', ObjectType.ENVIRONMENT, 'kitchen.urdf'), robot = Object('pr2', ObjectType.ROBOT, 'pr2.urdf'), cereal = Object('cereal', ObjectType.BREAKFAST_CEREAL, 'breakfast_cereal.stl', pose=Pose([1.4, 1, 0.95]))]"}, {"role": "assistant", "content": "from pycram.worlds.bullet_world import BulletWorld\nfrom pycram.world_concepts.world_object import Object\nfrom pycram.process_module import simulated_robot\nfrom pycram.designators.motion_designator import *\nfrom pycram.designators.location_designator import *\nfrom pycram.designators.action_designator import *\nfrom pycram.designators.object_designator import *\nfrom pycram.datastructures.enums import ObjectType, Arms, Grasp, WorldMode\n\nworld = BulletWorld(WorldMode.GUI)\nkitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\nrobot = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\ncereal = Object(\"cereal\", ObjectType.BREAKFAST_CEREAL, \"breakfast_cereal.stl\", pose=Pose([1.4, 1, 0.95]))\n\ncereal_desig = ObjectDesignatorDescription(names=[\"cereal\"])\nkitchen_desig = ObjectDesignatorDescription(names=[\"kitchen\"])\nrobot_desig = ObjectDesignatorDescription(names=[\"pr2\"]).resolve()\n\nwith simulated_robot:\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n\n    MoveTorsoAction([0.3]).resolve().perform()\n\n    pickup_pose = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot_desig).resolve()\n    pickup_arm = pickup_pose.reachable_arms[0]\n\n    NavigateAction(target_locations=[pickup_pose.pose]).resolve().perform()\n\n    PickUpAction(object_designator_description=cereal_desig, arms=[pickup_arm], grasps=[Grasp.FRONT]).resolve().perform()\n\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n\n    place_island = SemanticCostmapLocation(\"kitchen_island_surface\", kitchen_desig.resolve(), cereal_desig.resolve()).resolve()\n\n    place_stand = CostmapLocation(place_island.pose, reachable_for=robot_desig, reachable_arm=pickup_arm).resolve()\n\n    NavigateAction(target_locations=[place_stand.pose]).resolve().perform()\n\n    PlaceAction(cereal_desig, target_locations=[place_island.pose], arms=[pickup_arm]).resolve().perform()\n\n    ParkArmsAction([Arms.BOTH]).resolve().perform()\n\nworld.exit()"}]}