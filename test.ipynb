{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1fa5ec83fb3fcae",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Test 1 before better examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T13:25:35.698688Z",
     "start_time": "2024-03-27T13:25:27.324061Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May 20 2022 19:44:17\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='base_laser_link']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='wide_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='narrow_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='laser_tilt_link']\n",
      "[WARN] [1711545927.705700]: Failed to import Giskard messages\n",
      "[WARN] [1711545927.709220]: Could not import RoboKudo messages, RoboKudo interface could not be initialized\n",
      "Scalar element defined multiple times: limit\n",
      "Scalar element defined multiple times: limit\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'grasp_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m simulated_robot:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Pick up the cereal\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     pick_up_action \u001b[38;5;241m=\u001b[39m PickUpAction(object_designator_description\u001b[38;5;241m=\u001b[39mcereal_designator, arms\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m], grasps\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrasp_type\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mpick_up_action\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Calculate the target location for placing the cereal (3 steps to the right)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     target_location \u001b[38;5;241m=\u001b[39m Pose([cereal\u001b[38;5;241m.\u001b[39mget_position()\u001b[38;5;241m.\u001b[39mposition[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.6\u001b[39m, cereal\u001b[38;5;241m.\u001b[39mget_position()\u001b[38;5;241m.\u001b[39mposition[\u001b[38;5;241m1\u001b[39m], cereal\u001b[38;5;241m.\u001b[39mget_position()\u001b[38;5;241m.\u001b[39mposition[\u001b[38;5;241m2\u001b[39m]])\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/src/pycram/task.py:283\u001b[0m, in \u001b[0;36mwith_tree.<locals>.handle_tree\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m task_tree\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TaskStatus\u001b[38;5;241m.\u001b[39mCREATED\n\u001b[1;32m    282\u001b[0m task_tree\u001b[38;5;241m.\u001b[39mstart_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m--> 283\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtask_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# if it succeeded set the flag\u001b[39;00m\n\u001b[1;32m    286\u001b[0m task_tree\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TaskStatus\u001b[38;5;241m.\u001b[39mSUCCEEDED\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/src/pycram/language.py:535\u001b[0m, in \u001b[0;36mCode.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    530\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;124;03m    Execute the code with its arguments\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \n\u001b[1;32m    533\u001b[0m \u001b[38;5;124;03m    :returns: Anything that the function associated with this object will return.\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/src/pycram/designators/actions/actions.py:230\u001b[0m, in \u001b[0;36mPickUpActionPerformable.perform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobject_designator\u001b[38;5;241m.\u001b[39mbullet_world_object\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# Get grasp orientation and target pose\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m grasp \u001b[38;5;241m=\u001b[39m \u001b[43mrobot_description\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrasps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_orientation_for_grasp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrasp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# oTm = Object Pose in Frame map\u001b[39;00m\n\u001b[1;32m    232\u001b[0m oTm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39mget_pose()\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/src/pycram/robot_description.py:215\u001b[0m, in \u001b[0;36mGraspingDescription.get_orientation_for_grasp\u001b[0;34m(self, grasp)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_orientation_for_grasp\u001b[39m(\u001b[38;5;28mself\u001b[39m, grasp: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrasps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgrasp\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'grasp_type'"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "\n",
    "from pycram.bullet_world import BulletWorld, Object\n",
    "from pycram.designators.object_designator import BelieveObject\n",
    "from pycram.designators.action_designator import PickUpAction, PlaceAction\n",
    "from pycram.pose import Pose\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.enums import ObjectType\n",
    "\n",
    "#Initialize the BulletWorld\n",
    "world = BulletWorld()\n",
    "\n",
    "#Define objects\n",
    "kitchen = Object('kitchen', ObjectType.ENVIRONMENT, 'kitchen.urdf')\n",
    "robot = Object('pr2', ObjectType.ROBOT, 'pr2.urdf')\n",
    "cereal = Object('cereal', ObjectType.BREAKFAST_CEREAL, 'breakfast_cereal.stl', pose=Pose([1.4, 1, 0.95]))\n",
    "\n",
    "#Create object designators\n",
    "cereal_designator = BelieveObject(names=[\"cereal\"])\n",
    "\n",
    "#Define actions within the simulated_robot context manager\n",
    "with simulated_robot:\n",
    "    # Pick up the cereal\n",
    "    pick_up_action = PickUpAction(object_designator_description=cereal_designator, arms=[\"right\"], grasps=[\"grasp_type\"]).resolve()\n",
    "    pick_up_action.perform()\n",
    "\n",
    "    # Calculate the target location for placing the cereal (3 steps to the right)\n",
    "    target_location = Pose([cereal.get_position().position[0] + 0.6, cereal.get_position().position[1], cereal.get_position().position[2]])\n",
    "\n",
    "    # Place the cereal at the target location\n",
    "    place_action = PlaceAction(object_designator_description=cereal_designator, target_locations=[target_location], arms=[\"right\"]).resolve()\n",
    "    place_action.perform()\n",
    "\n",
    "#Close the BulletWorld\n",
    "world.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c484b6d998450d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T09:21:49.156693Z",
     "start_time": "2024-03-28T09:21:39.166248Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May 20 2022 19:44:17\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='base_laser_link']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='wide_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='narrow_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='laser_tilt_link']\n",
      "[WARN] [1711617699.708743]: Failed to import Giskard messages\n",
      "[WARN] [1711617699.713617]: Could not import RoboKudo messages, RoboKudo interface could not be initialized\n",
      "Scalar element defined multiple times: limit\n",
      "Scalar element defined multiple times: limit\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Object' object has no attribute 'bullet_world_object'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m MoveTorsoAction([\u001b[38;5;241m0.25\u001b[39m])\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mperform()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Pick up the cereal\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m pickup_pose \u001b[38;5;241m=\u001b[39m \u001b[43mCostmapLocation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcereal_desig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreachable_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrobot\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m pickup_arm \u001b[38;5;241m=\u001b[39m pickup_pose\u001b[38;5;241m.\u001b[39mreachable_arms[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     28\u001b[0m NavigateAction(target_locations\u001b[38;5;241m=\u001b[39m[pickup_pose\u001b[38;5;241m.\u001b[39mpose])\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mperform()\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/src/pycram/designators/location_designator.py:144\u001b[0m, in \u001b[0;36mCostmapLocation.ground\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mground\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Location:\n\u001b[1;32m    139\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    Default resolver which returns the first result from the iterator of this instance.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    :return: A resolved location\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/src/pycram/designators/location_designator.py:182\u001b[0m, in \u001b[0;36mCostmapLocation.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m     final_map \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m visible\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisible_for \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreachable_for:\n\u001b[0;32m--> 182\u001b[0m     robot_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisible_for\u001b[38;5;241m.\u001b[39mbullet_world_object \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisible_for \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreachable_for\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbullet_world_object\u001b[49m\n\u001b[1;32m    183\u001b[0m     test_robot \u001b[38;5;241m=\u001b[39m BulletWorld\u001b[38;5;241m.\u001b[39mcurrent_bullet_world\u001b[38;5;241m.\u001b[39mget_shadow_object(robot_object)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Use_shadow_world():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Object' object has no attribute 'bullet_world_object'"
     ]
    }
   ],
   "source": [
    "from pycram.bullet_world import BulletWorld, Object\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.designators.motion_designator import *\n",
    "from pycram.designators.location_designator import *\n",
    "from pycram.designators.action_designator import *\n",
    "from pycram.designators.object_designator import *\n",
    "from pycram.pose import Pose\n",
    "from pycram.enums import ObjectType\n",
    "\n",
    "world = BulletWorld()\n",
    "\n",
    "#Objects\n",
    "kitchen = Object(\"kitchen\", ObjectType.ENVIRONMENT, \"kitchen.urdf\")\n",
    "robot = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")\n",
    "cereal = Object(\"cereal\", ObjectType.BREAKFAST_CEREAL, \"breakfast_cereal.stl\", pose=Pose([1.4, 1, 0.95]))\n",
    "\n",
    "#Object Designators\n",
    "cereal_desig = ObjectDesignatorDescription(names=[\"cereal\"])\n",
    "\n",
    "with simulated_robot:\n",
    "    # Initial actions\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "    MoveTorsoAction([0.25]).resolve().perform()\n",
    "\n",
    "    # Pick up the cereal\n",
    "    pickup_pose = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot).resolve()\n",
    "    pickup_arm = pickup_pose.reachable_arms[0]\n",
    "    NavigateAction(target_locations=[pickup_pose.pose]).resolve().perform()\n",
    "    PickUpAction(object_designator_description=cereal_desig, arms=[pickup_arm], grasps=[\"front\"]).resolve().perform()\n",
    "\n",
    "    # Move 3 steps to the right\n",
    "    motion_designator = MotionDesignator(direction=\"right\", distance=3)\n",
    "    motion_designator.resolve().perform()\n",
    "\n",
    "    # Place the cereal\n",
    "    place_pose = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot).resolve()\n",
    "    NavigateAction(target_locations=[place_pose.pose]).resolve().perform()\n",
    "    PlaceAction(cereal_desig, target_locations=[place_pose.pose], arms=[pickup_arm]).resolve().perform()\n",
    "\n",
    "    # Park the robot's arms again\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "\n",
    "world.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dba70b63323d2a60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:02:54.528740Z",
     "start_time": "2024-04-11T14:02:44.606774Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scalar element defined multiple times: limit\n",
      "Scalar element defined multiple times: limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CODE IMPORT CHECK: FAILED---\n",
      "Execution error: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15201/2632560316.py\", line 66, in <module>\n",
      "    exec(test)\n",
      "  File \"<string>\", line 30, in <module>\n",
      "  File \"/home/julius/ros/ros_ws/src/pycram/src/pycram/designators/location_designator.py\", line 144, in ground\n",
      "    return next(iter(self))\n",
      "  File \"/home/julius/ros/ros_ws/src/pycram/src/pycram/designators/location_designator.py\", line 198, in __iter__\n",
      "    valid, arms = reachability_validator(maybe_pose, test_robot, target_pose,\n",
      "  File \"/home/julius/ros/ros_ws/src/pycram/src/pycram/pose_generator_and_validator.py\", line 157, in reachability_validator\n",
      "    resp = request_ik(target, robot, left_joints, left_gripper)\n",
      "  File \"/home/julius/ros/ros_ws/src/pycram/src/pycram/external_interfaces/ik.py\", line 133, in request_ik\n",
      "    inv = call_ik(base_link, end_effector, target_diff, robot, joints)\n",
      "  File \"/home/julius/ros/ros_ws/src/pycram/src/pycram/external_interfaces/ik.py\", line 90, in call_ik\n",
      "    rospy.wait_for_service(ik_service)\n",
      "  File \"/opt/ros/noetic/lib/python3/dist-packages/rospy/impl/tcpros_service.py\", line 166, in wait_for_service\n",
      "    raise ROSInterruptException(\"rospy shutdown\")\n",
      "rospy.exceptions.ROSInterruptException: rospy shutdown\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "test = \"\"\"from pycram.bullet_world import BulletWorld, Object\n",
    "from pycram.process_module import simulated_robot\n",
    "# Import Statements für Designatoren sind unvollständig.\n",
    "from pycram.designators.motion_designator import *\n",
    "from pycram.designators.location_designator import *\n",
    "from pycram.designators.action_designator import *\n",
    "from pycram.designators.object_designator import *\n",
    "from pycram.enums import ObjectType, Arms\n",
    "from pycram.pose import Pose\n",
    "\n",
    "# Erstellung der BulletWorld\n",
    "world = BulletWorld()\n",
    "\n",
    "# Objekte hinzufügen\n",
    "kitchen = Object('kitchen', ObjectType.ENVIRONMENT, 'kitchen.urdf')\n",
    "robot = Object('pr2', ObjectType.ROBOT, 'pr2.urdf')\n",
    "cereal = Object('cereal', ObjectType.BREAKFAST_CEREAL, 'breakfast_cereal.stl', pose=Pose([1.4, 1, 0.95]))\n",
    "\n",
    "# Designatoren definieren\n",
    "cereal_desig = ObjectDesignatorDescription(names=['cereal'])\n",
    "robot_desig = ObjectDesignatorDescription(names=['pr2']).resolve()\n",
    "\n",
    "# Simulierten Roboter aktivieren\n",
    "with simulated_robot:\n",
    "    # Roboteraktionen\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "    MoveTorsoAction([0.25]).resolve().perform()\n",
    "\n",
    "    # Position für das Aufnehmen der Cerealien bestimmen\n",
    "    pickup_pose = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot_desig).resolve()\n",
    "    pickup_arm = pickup_pose.reachable_arms[0]\n",
    "\n",
    "    # Zum Cerealien navigieren und aufnehmen\n",
    "    NavigateAction(target_locations=[pickup_pose.pose]).resolve().perform()\n",
    "    PickUpAction(object_designator_description=cereal_desig, arms=[pickup_arm], grasps=['front']).resolve().perform()\n",
    "\n",
    "    # Zielposition bestimmen und dorthin bewegen\n",
    "    target_pose = Pose([pickup_pose.pose.position.x + 3, pickup_pose.pose.position.y, pickup_pose.pose.position.z], pickup_pose.pose.orientation)\n",
    "    move_motion = MoveMotion(target=target_pose)\n",
    "    move_motion.perform()\n",
    "\n",
    "    # Cerealien auf der Kücheninsel ablegen\n",
    "    place_island = SemanticCostmapLocation('kitchen_island_surface', kitchen.resolve(), cereal.resolve()).resolve()\n",
    "    PlaceAction(object_designator_description=cereal_desig, target_locations=[place_island.pose], arms=[pickup_arm]).resolve().perform()\n",
    "\n",
    "# Simulation beenden\n",
    "world.exit()\"\"\"\n",
    "\n",
    "\n",
    "test1 = \"\"\"from pycram.bullet_world import BulletWorld, Object\n",
    "from pycram.designators.action_designator import *\n",
    "from pycram.designators.motion_designator import *\n",
    "from pycram.designators.location_designator import *\n",
    "from pycram.designators.object_designator import *\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.pose import Pose\n",
    "from pycram.enums import ObjectType, Arms\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.pose import Pose\n",
    "from pycram.enums import ObjectType, Arms\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Attempt to execute the imports\n",
    "    exec(test)\n",
    "except Exception as e:\n",
    "    print(\"---CODE IMPORT CHECK: FAILED---\")\n",
    "    # Catch any error during execution (e.g., ImportError, SyntaxError)\n",
    "    error = f\"Execution error: {traceback.format_exc()}\"\n",
    "    try:\n",
    "        exec(\"world.exit()\")\n",
    "    except Exception as e:\n",
    "        print(\"No World has been exited\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "428f1377ea1996e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T08:06:22.732001Z",
     "start_time": "2024-04-11T08:06:21.255864Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:45:17\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='base_laser_link']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='wide_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='narrow_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='laser_tilt_link']\n",
      "[WARN] [1712822782.572490]: Failed to import Giskard messages\n",
      "[WARN] [1712822782.579082]: Could not import RoboKudo messages, RoboKudo interface could not be initialized\n"
     ]
    }
   ],
   "source": [
    "test_string = \"\"\"from pycram.bullet_world import BulletWorld, Object\n",
    "from pycram.designators.action_designator import *\n",
    "from pycram.designators.motion_designator import *\n",
    "from pycram.designators.location_designator import *\n",
    "from pycram.designators.object_designator import *\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.pose import Pose\n",
    "from pycram.enums import ObjectType, Arms\"\"\"\n",
    "exec(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256599ee0e3de4d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T09:33:00.801893Z",
     "start_time": "2024-04-11T09:33:00.799685Z"
    }
   },
   "outputs": [],
   "source": [
    "test_string = \"\"\"from pycram.bullet_world import BulletWorld, Object\n",
    "from pycram.designators.action_designator import *\n",
    "from pycram.designators.motion_designator import *\n",
    "from pycram.designators.location_designator import *\n",
    "from pycram.designators.object_designator import *\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.pose import Pose\n",
    "from pycram.enums import ObjectType, Arms\"\"\"\n",
    "try:\n",
    "    # Attempt to execute the imports\n",
    "    exec(test_string)\n",
    "except Exception as e:\n",
    "    print(\"---CODE IMPORT CHECK: FAILED---\")\n",
    "    # Catch any error during execution (e.g., ImportError, SyntaxError)\n",
    "    error = f\"Execution error: {e}\"\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f411a204c1a309d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:24:42.750144Z",
     "start_time": "2024-04-11T14:24:30.894148Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unknown tag \"material\" in /robot[@name='apartment']/link[@name='coffe_machine']/collision[1]\n",
      "Unknown tag \"material\" in /robot[@name='apartment']/link[@name='coffe_machine']/collision[1]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'kitchen_island_surface'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m MoveTorsoAction([\u001b[38;5;241m0.25\u001b[39m])\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mperform()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Navigate to the kitchen\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m kitchen_location \u001b[38;5;241m=\u001b[39m \u001b[43mSemanticCostmapLocation\u001b[49m\u001b[43m(\u001b[49m\u001b[43murdf_link_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkitchen_island_surface\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapartment_desig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfor_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrobot_desig\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m NavigateAction(target_locations\u001b[38;5;241m=\u001b[39m[kitchen_location\u001b[38;5;241m.\u001b[39mpose])\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mperform()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Open the drawer to get the spoon\u001b[39;00m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/src/pycram/designators/location_designator.py:328\u001b[0m, in \u001b[0;36mSemanticCostmapLocation.ground\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mground\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Location:\n\u001b[1;32m    323\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    Default resolver which returns the first element of the iterator of this instance.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m    :return: A resolved location\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/src/pycram/designators/location_designator.py:338\u001b[0m, in \u001b[0;36mSemanticCostmapLocation.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    Creates a costmap on top of a link of an Object and creates positions from it. If there is a specific Object for\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    which the position should be found, a height offset will be calculated which ensures that the bottom of the Object\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    :yield: An instance of SemanticCostmapLocation.Location with the found valid position of the Costmap.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m     sem_costmap \u001b[38;5;241m=\u001b[39m \u001b[43mSemanticCostmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpart_of\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbullet_world_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murdf_link_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m     height_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfor_object:\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/src/pycram/costmaps.py:702\u001b[0m, in \u001b[0;36mSemanticCostmap.__init__\u001b[0;34m(self, object, urdf_link_name, size, resolution, world)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlink: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m urdf_link_name\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolution: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m resolution\n\u001b[0;32m--> 702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morigin: Pose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_link_pose\u001b[49m\u001b[43m(\u001b[49m\u001b[43murdf_link_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/src/pycram/bullet_world.py:1105\u001b[0m, in \u001b[0;36mObject.get_link_pose\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinks\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinks[name] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_pose()\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_current_link_poses\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'kitchen_island_surface'"
     ]
    }
   ],
   "source": [
    "from pycram.bullet_world import BulletWorld, Object\n",
    "from pycram.designators.action_designator import *\n",
    "from pycram.designators.motion_designator import *\n",
    "from pycram.designators.location_designator import *\n",
    "from pycram.designators.object_designator import *\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.pose import Pose\n",
    "from pycram.enums import ObjectType\n",
    "\n",
    "# BulletWorld Definition\n",
    "world = BulletWorld()\n",
    "\n",
    "# Objects\n",
    "robot = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\", pose=Pose([1, 2, 0]))\n",
    "apartment = Object(\"apartment\", ObjectType.ENVIRONMENT, \"apartment.urdf\")\n",
    "milk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([2.5, 2, 1.02]), color=[1, 0, 0, 1])\n",
    "cereal = Object(\"cereal\", ObjectType.BREAKFAST_CEREAL, \"breakfast_cereal.stl\", pose=Pose([2.5, 2.3, 1.05]), color=[0, 1, 0, 1])\n",
    "spoon = Object(\"spoon\", ObjectType.SPOON, \"spoon.stl\", pose=Pose([2.4, 2.2, 0.85]), color=[0, 0, 1, 1])\n",
    "bowl = Object(\"bowl\", ObjectType.BOWL, \"bowl.stl\", pose=Pose([2.5, 2.2, 1.02]), color=[1, 1, 0, 1])\n",
    "\n",
    "# Object Designators\n",
    "robot_desig = BelieveObject(names=[\"pr2\"]).resolve()\n",
    "apartment_desig = BelieveObject(names=[\"apartment\"]).resolve()\n",
    "milk_desig = BelieveObject(names=[\"milk\"]).resolve()\n",
    "cereal_desig = BelieveObject(names=[\"cereal\"]).resolve()\n",
    "spoon_desig = BelieveObject(names=[\"spoon\"]).resolve()\n",
    "bowl_desig = BelieveObject(names=[\"bowl\"]).resolve()\n",
    "\n",
    "with simulated_robot:\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "    MoveTorsoAction([0.25]).resolve().perform()\n",
    "    \n",
    "    # Navigate to the kitchen\n",
    "    kitchen_location = SemanticCostmapLocation(urdf_link_name=\"kitchen_island_surface\", part_of=apartment_desig, for_object=robot_desig).resolve()\n",
    "    NavigateAction(target_locations=[kitchen_location.pose]).resolve().perform()\n",
    "    \n",
    "    # Open the drawer to get the spoon\n",
    "    drawer_handle = ObjectPart(names=[\"sink_area_left_upper_drawer_main\"], part_of=apartment_desig).resolve()\n",
    "    OpenAction(drawer_handle, [Arms.RIGHT]).resolve().perform()\n",
    "    PickUpAction(object_designator_description=spoon_desig, arms=[Arms.RIGHT], grasps=[\"front\"]).resolve().perform()\n",
    "    CloseAction(drawer_handle, [Arms.RIGHT]).resolve().perform()\n",
    "    \n",
    "    # Pick up the bowl\n",
    "    PickUpAction(object_designator_description=bowl_desig, arms=[Arms.LEFT], grasps=[\"front\"]).resolve().perform()\n",
    "    \n",
    "    # Navigate to the dining table\n",
    "    dining_table_location = SemanticCostmapLocation(urdf_link_name=\"dining_table_surface\", part_of=apartment_desig, for_object=bowl_desig).resolve()\n",
    "    NavigateAction(target_locations=[dining_table_location.pose]).resolve().perform()\n",
    "    \n",
    "    # Place the bowl on the dining table\n",
    "    PlaceAction(bowl_desig, target_locations=[dining_table_location.pose], arms=[Arms.LEFT]).resolve().perform()\n",
    "    \n",
    "    # Place the spoon on the dining table\n",
    "    PlaceAction(spoon_desig, target_locations=[dining_table_location.pose], arms=[Arms.RIGHT]).resolve().perform()\n",
    "    \n",
    "    # Pick up the milk and cereal\n",
    "    PickUpAction(object_designator_description=milk_desig, arms=[Arms.LEFT], grasps=[\"front\"]).resolve().perform()\n",
    "    PickUpAction(object_designator_description=cereal_desig, arms=[Arms.RIGHT], grasps=[\"front\"]).resolve().perform()\n",
    "    \n",
    "    # Place the milk and cereal on the dining table\n",
    "    PlaceAction(milk_desig, target_locations=[dining_table_location.pose], arms=[Arms.LEFT]).resolve().perform()\n",
    "    PlaceAction(cereal_desig, target_locations=[dining_table_location.pose], arms=[Arms.RIGHT]).resolve().perform()\n",
    "\n",
    "# Exit the BulletWorld\n",
    "world.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45dce98e3037685f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T11:40:50.391873Z",
     "start_time": "2024-04-30T11:40:37.486128Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:45:17\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='base_laser_link']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='wide_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='narrow_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='laser_tilt_link']\n",
      "[WARN] [1714477238.836198]: Failed to import Giskard messages\n",
      "[WARN] [1714477238.843108]: Could not import RoboKudo messages, RoboKudo interface could not be initialized\n",
      "Unknown tag \"material\" in /robot[@name='apartment']/link[@name='coffe_machine']/collision[1]\n",
      "Unknown tag \"material\" in /robot[@name='apartment']/link[@name='coffe_machine']/collision[1]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m MoveTorsoAction([\u001b[38;5;241m0.25\u001b[39m])\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mperform()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Navigate to and pick up the bowl\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m bowl_location \u001b[38;5;241m=\u001b[39m \u001b[43mCostmapLocation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbowl_desig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreachable_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrobot_desig\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m NavigateAction(target_locations\u001b[38;5;241m=\u001b[39m[bowl_location\u001b[38;5;241m.\u001b[39mpose])\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mperform()\n\u001b[1;32m     32\u001b[0m PickUpAction(object_designator_description\u001b[38;5;241m=\u001b[39mbowl_desig, arms\u001b[38;5;241m=\u001b[39m[bowl_location\u001b[38;5;241m.\u001b[39mreachable_arms[\u001b[38;5;241m0\u001b[39m]], grasps\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfront\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mperform()\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/src/pycram/designators/location_designator.py:144\u001b[0m, in \u001b[0;36mCostmapLocation.ground\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mground\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Location:\n\u001b[1;32m    139\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    Default resolver which returns the first result from the iterator of this instance.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    :return: A resolved location\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/src/pycram/designators/location_designator.py:165\u001b[0m, in \u001b[0;36mCostmapLocation.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m     target_pose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;241m.\u001b[39mbullet_world_object\u001b[38;5;241m.\u001b[39mget_pose()\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     target_pose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m()\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# ground_pose = [[target_pose[0][0], target_pose[0][1], 0], target_pose[1]]\u001b[39;00m\n\u001b[1;32m    168\u001b[0m ground_pose \u001b[38;5;241m=\u001b[39m Pose(target_pose\u001b[38;5;241m.\u001b[39mposition_as_list())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "from pycram.designators.action_designator import *\n",
    "from pycram.designators.location_designator import *\n",
    "from pycram.designators.object_designator import *\n",
    "from pycram.pose import Pose\n",
    "from pycram.bullet_world import BulletWorld, Object\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.enums import ObjectType\n",
    "\n",
    "world = BulletWorld()\n",
    "robot = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\", pose=Pose([1, 2, 0]))\n",
    "apartment = Object(\"apartment\", ObjectType.ENVIRONMENT, \"apartment.urdf\")\n",
    "milk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([2.5, 2, 1.02]), color=[1, 0, 0, 1])\n",
    "cereal = Object(\"cereal\", ObjectType.BREAKFAST_CEREAL, \"breakfast_cereal.stl\", pose=Pose([2.5, 2.3, 1.05]), color=[0, 1, 0, 1])\n",
    "spoon = Object(\"spoon\", ObjectType.SPOON, \"spoon.stl\", pose=Pose([2.4, 2.2, 0.85]), color=[0, 0, 1, 1])\n",
    "bowl = Object(\"bowl\", ObjectType.BOWL, \"bowl.stl\", pose=Pose([2.5, 2.2, 1.02]), color=[1, 1, 0, 1])\n",
    "apartment.attach(spoon, 'cabinet10_drawer_top')\n",
    "\n",
    "robot_desig = BelieveObject(names=[\"pr2\"])\n",
    "apartment_desig = BelieveObject(names=[\"apartment\"])\n",
    "milk_desig = BelieveObject(names=[\"milk\"])\n",
    "cereal_desig = ObjectDesignatorDescription(names=[\"cereal\"])\n",
    "spoon_desig = ObjectDesignatorDescription(names=[\"spoon\"])\n",
    "bowl_desig = ObjectDesignatorDescription(names=[\"bowl\"])\n",
    "\n",
    "with simulated_robot:\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "    MoveTorsoAction([0.25]).resolve().perform()\n",
    "\n",
    "    # Navigate to and pick up the bowl\n",
    "    bowl_location = CostmapLocation(target=bowl_desig.resolve, reachable_for=robot_desig).resolve()\n",
    "    NavigateAction(target_locations=[bowl_location.pose]).resolve().perform()\n",
    "    PickUpAction(object_designator_description=bowl_desig, arms=[bowl_location.reachable_arms[0]], grasps=[\"front\"]).resolve().perform()\n",
    "\n",
    "    # Navigate to and pick up the cereal\n",
    "    cereal_location = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot_desig).resolve()\n",
    "    NavigateAction(target_locations=[cereal_location.pose]).resolve().perform()\n",
    "    PickUpAction(object_designator_description=cereal_desig, arms=[cereal_location.reachable_arms[0]], grasps=[\"front\"]).resolve().perform()\n",
    "\n",
    "    # Navigate to and pick up the milk\n",
    "    milk_location = CostmapLocation(target=milk_desig.resolve(), reachable_for=robot_desig).resolve()\n",
    "    NavigateAction(target_locations=[milk_location.pose]).resolve().perform()\n",
    "    PickUpAction(object_designator_description=milk_desig, arms=[milk_location.reachable_arms[0]], grasps=[\"front\"]).resolve().perform()\n",
    "\n",
    "    # Navigate to and pick up the spoon from the drawer\n",
    "    handle_desig = ObjectPart(names=[\"handle_cab10_t\"], part_of=apartment_desig.resolve())\n",
    "    drawer_open_loc = AccessingLocation(handle_desig=handle_desig.resolve(), robot_desig=robot_desig.resolve()).resolve()\n",
    "    NavigateAction([drawer_open_loc.pose]).resolve().perform()\n",
    "    OpenAction(object_designator_description=handle_desig, arms=[drawer_open_loc.arms[0]]).resolve().perform()\n",
    "    spoon.detach(apartment)\n",
    "    LookAtAction([apartment.get_link_pose(\"handle_cab10_t\")]).resolve().perform()\n",
    "    DetectAction(spoon_desig).resolve().perform()\n",
    "    PickUpAction(spoon_desig, [drawer_open_loc.arms[0]], [\"top\"]).resolve().perform()\n",
    "\n",
    "    # Place all items on the dining table\n",
    "    dining_table_location = SemanticCostmapLocation(urdf_link_name=\"dining_table_surface\", part_of=apartment_desig).resolve()\n",
    "    NavigateAction([dining_table_location.pose]).resolve().perform()\n",
    "    PlaceAction(bowl_desig, [dining_table_location.pose], [bowl_location.reachable_arms[0]]).resolve().perform()\n",
    "    PlaceAction(cereal_desig, [dining_table_location.pose], [cereal_location.reachable_arms[0]]).resolve().perform()\n",
    "    PlaceAction(milk_desig, [dining_table_location.pose], [milk_location.reachable_arms[0]]).resolve().perform()\n",
    "    PlaceAction(spoon_desig, [dining_table_location.pose], [drawer_open_loc.arms[0]]).resolve().perform()\n",
    "\n",
    "world.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f811ee2f7a2c91",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-30T11:34:39.952565Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:45:17\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='base_laser_link']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='wide_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='narrow_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='laser_tilt_link']\n"
     ]
    }
   ],
   "source": [
    "from pycram.designators.action_designator import NavigateAction, LookAtAction, DetectAction, TransportAction, OpenAction, CloseAction\n",
    "from pycram.designators.object_designator import BelieveObject, ObjectPart\n",
    "from pycram.pose import Pose\n",
    "from pycram.enums import Arms\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.bullet_world import BulletWorld, Object\n",
    "from pycram.enums import ObjectType\n",
    "world = BulletWorld()\n",
    "robot = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\", pose=Pose([1, 2, 0]))\n",
    "apartment = Object(\"apartment\", ObjectType.ENVIRONMENT, \"apartment.urdf\")\n",
    "milk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([2.5, 2, 1.02]), color=[1, 0, 0, 1])\n",
    "cereal = Object(\"cereal\", ObjectType.BREAKFAST_CEREAL, \"breakfast_cereal.stl\", pose=Pose([2.5, 2.3, 1.05]), color=[0, 1, 0, 1])\n",
    "spoon = Object(\"spoon\", ObjectType.SPOON, \"spoon.stl\", pose=Pose([2.4, 2.2, 0.85]), color=[0, 0, 1, 1])\n",
    "bowl = Object(\"bowl\", ObjectType.BOWL, \"bowl.stl\", pose=Pose([2.5, 2.2, 1.02]), color=[1, 1, 0, 1])\n",
    "apartment.attach(spoon, 'cabinet10_drawer_top')\n",
    "\n",
    "robot_desig = BelieveObject(names=[\"pr2\"])\n",
    "apartment_desig = BelieveObject(names=[\"apartment\"])\n",
    "\n",
    "with simulated_robot:\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "    MoveTorsoAction([0.25]).resolve().perform()\n",
    "\n",
    "    # Navigate to the cereal\n",
    "    NavigateAction(target_locations=[Pose([2.5, 2.3, 1.05])]).resolve().perform()\n",
    "\n",
    "    # Pick up the cereal\n",
    "    cereal_desig = DetectAction(BelieveObject(names=[\"cereal\"])).resolve().perform()\n",
    "    TransportAction(cereal_desig, [\"right\"], [Pose([2.8, 2.3, 1.05])]).resolve().perform()\n",
    "\n",
    "    # Place the cereal three steps to the right\n",
    "    TransportAction(cereal_desig, [\"right\"], [Pose([3.1, 2.3, 1.05])]).resolve().perform()\n",
    "\n",
    "world.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb8b67a4dae4128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3839354295da1a0f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-30T11:36:00.112951Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:45:17\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='base_laser_link']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='wide_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='narrow_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='laser_tilt_link']\n"
     ]
    }
   ],
   "source": [
    "from pycram.bullet_world import BulletWorld, Object\n",
    "world = BulletWorld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b145276741698d57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T15:26:20.839811Z",
     "start_time": "2024-05-07T15:26:19.172317Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:45:17\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='base_laser_link']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='wide_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='narrow_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='laser_tilt_link']\n",
      "[WARN] [1715095580.541331]: Failed to import Giskard messages\n",
      "[WARN] [1715095580.547716]: Could not import RoboKudo messages, RoboKudo interface could not be initialized\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Arms' from 'pycram.designators.motion_designator' (/home/julius/ros/ros_ws/src/pycram/src/pycram/designators/motion_designator.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycram\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdesignators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlocation_designator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CostmapLocation, SemanticCostmapLocation\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycram\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdesignators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobject_designator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ObjectDesignatorDescription\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycram\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdesignators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmotion_designator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Arms, NavigateAction, ParkArmsAction, MoveTorsoAction, PickUpAction, PlaceAction\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycram\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocess_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simulated_robot\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycram\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pose\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Arms' from 'pycram.designators.motion_designator' (/home/julius/ros/ros_ws/src/pycram/src/pycram/designators/motion_designator.py)"
     ]
    }
   ],
   "source": [
    "from pycram.bullet_world import BulletWorld, Object\n",
    "from pycram.designators.location_designator import CostmapLocation, SemanticCostmapLocation\n",
    "from pycram.designators.object_designator import ObjectDesignatorDescription\n",
    "from pycram.designators.motion_designator import Arms, NavigateAction, ParkArmsAction, MoveTorsoAction, PickUpAction, PlaceAction\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.pose import Pose\n",
    "from pycram.enums import ObjectType\n",
    "# Define the BulletWorld\n",
    "world = BulletWorld()\n",
    "\n",
    "# Define the objects\n",
    "kitchen = Object('kitchen', ObjectType.ENVIRONMENT, 'kitchen.urdf')\n",
    "robot = Object('pr2', ObjectType.ROBOT, 'pr2.urdf')\n",
    "cereal = Object('cereal', ObjectType.BREAKFAST_CEREAL, 'breakfast_cereal.stl', pose=Pose([1.4, 1, 0.95]))\n",
    "\n",
    "# Define the object designators\n",
    "cereal_desig = ObjectDesignatorDescription(names=['cereal']).resolve()\n",
    "robot_desig = ObjectDesignatorDescription(names=['pr2']).resolve()\n",
    "\n",
    "# Actions and moves of the Robot\n",
    "with simulated_robot:\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "    MoveTorsoAction([0.25]).resolve().perform()\n",
    "\n",
    "    # Navigate to the cereal\n",
    "    pickup_pose = CostmapLocation(target=cereal_desig, reachable_for=robot_desig).resolve()\n",
    "    NavigateAction(target_locations=[pickup_pose.pose]).resolve().perform()\n",
    "\n",
    "    # Pick up the cereal\n",
    "    pickup_arm = pickup_pose.reachable_arms[0]\n",
    "    PickUpAction(object_designator_description=cereal_desig, arms=[pickup_arm], grasps=['front']).resolve().perform()\n",
    "\n",
    "    # Calculate new pose three steps to the right\n",
    "    new_pose = Pose([pickup_pose.pose.position.x + 3, pickup_pose.pose.position.y, pickup_pose.pose.position.z], pickup_pose.pose.orientation)\n",
    "\n",
    "    # Place the cereal at the new location\n",
    "    place_stand = CostmapLocation(new_pose, reachable_for=robot_desig, reachable_arm=pickup_arm).resolve()\n",
    "    NavigateAction(target_locations=[place_stand.pose]).resolve().perform()\n",
    "    PlaceAction(cereal_desig, target_locations=[place_stand.pose], arms=[pickup_arm]).resolve().perform()\n",
    "\n",
    "# Close the BulletWorld\n",
    "world.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982ad9938df5aef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:58:28.536470Z",
     "start_time": "2024-05-15T14:57:49.944655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/julius/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22081b8859c34c0fbc78fb1221b0a21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 37\u001b[0m\n\u001b[1;32m     26\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m     27\u001b[0m     messages,\n\u001b[1;32m     28\u001b[0m     add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     29\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m )\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     32\u001b[0m terminators \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     33\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[1;32m     34\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|eot_id|>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m ]\n\u001b[0;32m---> 37\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mterminators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m response \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m][input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:]\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mdecode(response, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/transformers/generation/utils.py:1622\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1614\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1615\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1616\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1617\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1618\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1619\u001b[0m     )\n\u001b[1;32m   1621\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1622\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1637\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1638\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1639\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1640\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1646\u001b[0m     )\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/transformers/generation/utils.py:2791\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2788\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2790\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2791\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2792\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2794\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2795\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2796\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2799\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1211\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1208\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1211\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1224\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1018\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1007\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1008\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1009\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1015\u001b[0m         cache_position,\n\u001b[1;32m   1016\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1018\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1028\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:756\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    754\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    755\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 756\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    759\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:240\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    238\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(down_proj)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "\n",
    "# Eingabetext aus den Argumenten lesen\n",
    "input_text = \"Is there alien life.\"\n",
    "\n",
    "login(token=\".env\")\n",
    "\n",
    "# Llama3 laden\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a physicist.\"},\n",
    "    {\"role\": \"user\", \"content\": input_text},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(tokenizer.decode(response, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a98ae16a5da1695e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T15:35:00.566710Z",
     "start_time": "2024-05-15T15:34:59.074053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/julius/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The argument `from_transformers` is deprecated, and will be removed in optimum 2.0.  Use `export` instead\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ORTModelForCausalLM._from_transformers() got an unexpected keyword argument 'quantize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Llama3-Modell mit Quantisierung laden\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mORTModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_transformers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m nlp \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m outputs \u001b[38;5;241m=\u001b[39m nlp(\n\u001b[1;32m     32\u001b[0m     input_text\n\u001b[1;32m     33\u001b[0m )\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/optimum/onnxruntime/modeling_ort.py:669\u001b[0m, in \u001b[0;36mORTModel.from_pretrained\u001b[0;34m(cls, model_id, export, force_download, use_auth_token, cache_dir, subfolder, config, local_files_only, provider, session_options, provider_options, use_io_binding, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;129m@add_start_docstrings\u001b[39m(FROM_PRETRAINED_START_DOCSTRING)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    637\u001b[0m ):\n\u001b[1;32m    638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03m    provider (`str`, defaults to `\"CPUExecutionProvider\"`):\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03m        ONNX Runtime provider to use for loading the model. See https://onnxruntime.ai/docs/execution-providers/ for\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03m        `ORTModel`: The loaded ORTModel model.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 669\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprovider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_io_binding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_io_binding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ros/ros_ws/src/pycram/venv3.10/lib/python3.10/site-packages/optimum/modeling_base.py:402\u001b[0m, in \u001b[0;36mOptimizedModel.from_pretrained\u001b[0;34m(cls, model_id, export, force_download, use_auth_token, cache_dir, subfolder, config, local_files_only, trust_remote_code, revision, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m     trust_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    400\u001b[0m from_pretrained_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_transformers \u001b[38;5;28;01mif\u001b[39;00m export \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_pretrained\n\u001b[0;32m--> 402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_pretrained_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: ORTModelForCausalLM._from_transformers() got an unexpected keyword argument 'quantize'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from optimum.onnxruntime import ORTModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "import accelerate\n",
    "\n",
    "# Eingabetext aus den Argumenten lesen\n",
    "input_text = \"Is there alien life?\"\n",
    "\n",
    "login(token=\".env\")\n",
    "\n",
    "# Llama3 laden\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "nlp = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "outputs = nlp(\n",
    "    input_text\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(input_text):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a66180e7507fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.bullet_world import BulletWorld, Object\n",
    "from pycram.designators.location_designator import CostmapLocation, SemanticCostmapLocation\n",
    "from pycram.designators.object_designator import BelieveObject, ObjectDesignatorDescription\n",
    "from pycram.designators.motion_designator import NavigateAction, PickUpAction, PlaceAction, ParkArmsAction, MoveTorsoAction\n",
    "from pycram.pose import Pose\n",
    "from pycram.enums import ObjectType\n",
    "# BulletWorld Definition\n",
    "world = BulletWorld()\n",
    "\n",
    "# Objects\n",
    "kitchen = Object('kitchen', ObjectType.ENVIRONMENT, 'kitchen.urdf')\n",
    "robot = Object('pr2', ObjectType.ROBOT, 'pr2.urdf')\n",
    "cereal = Object('cereal', ObjectType.BREAKFAST_CEREAL, 'breakfast_cereal.stl', pose=Pose([1.4, 1, 0.95]))\n",
    "\n",
    "# Object Designators\n",
    "robot_desig = BelieveObject(names=['pr2']).resolve()\n",
    "cereal_desig = BelieveObject(names=['cereal']).resolve()\n",
    "\n",
    "# The 'with simulated_robot:'-Block (defines the Actions and moves of the Robot)\n",
    "with simulated_robot:\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "    MoveTorsoAction([0.25]).resolve().perform()\n",
    "\n",
    "    # Navigate to the cereal\n",
    "    NavigateAction(target_locations=[cereal.get_pose()]).resolve().perform()\n",
    "\n",
    "    # Pick up the cereal\n",
    "    pickup_arm = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot_desig).resolve().reachable_arms[0]\n",
    "    PickUpAction(object_designator_description=cereal_desig, arms=[pickup_arm], grasps=['front']).resolve().perform()\n",
    "\n",
    "    # Define the target location 3 steps to the right\n",
    "    target_location = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot_desig)\n",
    "    target_location.pose.position.x += 3\n",
    "\n",
    "    # Navigate to the target location\n",
    "    NavigateAction(target_locations=[target_location.pose]).resolve().perform()\n",
    "\n",
    "    # Place the cereal at the target location\n",
    "    PlaceAction(cereal_desig, target_locations=[target_location.pose], arms=[pickup_arm]).resolve().perform()\n",
    "\n",
    "    # Park the arms again\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "\n",
    "# BulletWorld Close\n",
    "world.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa8072053ad6419",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T11:23:05.492916Z",
     "start_time": "2024-06-06T11:22:54.724814Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scalar element defined multiple times: limit\n",
      "Scalar element defined multiple times: limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find an object with the type ObjectType.BREAKFAST_CEREAL in the FOV of the robot <class 'pycram.plan_failures.PerceptionObjectNotFound'>\n"
     ]
    }
   ],
   "source": [
    "from pycram.designators.action_designator import *\n",
    "from pycram.designators.location_designator import *\n",
    "from pycram.designators.object_designator import *\n",
    "from pycram.pose import Pose\n",
    "from pycram.bullet_world import BulletWorld, Object\n",
    "from pycram.process_module import simulated_robot, with_simulated_robot\n",
    "from pycram.enums import ObjectType\n",
    "world = BulletWorld()\n",
    "robot = Object('pr2', ObjectType.ROBOT, 'pr2.urdf')\n",
    "kitchen = Object('kitchen', ObjectType.ENVIRONMENT, 'kitchen.urdf')\n",
    "cereal = Object('cereal', ObjectType.BREAKFAST_CEREAL, 'breakfast_cereal.stl', pose=Pose([1.4, 1, 0.95]))\n",
    "\n",
    "robot_desig = ObjectDesignatorDescription(names=['pr2']).resolve()\n",
    "cereal_desig = ObjectDesignatorDescription(names=['cereal'])\n",
    "target_pose = Pose([1.4, 4, 0.95])  # 3 steps to the right\n",
    "target_location = CostmapLocation(target=cereal_desig.resolve(), reachable_for=robot_desig)\n",
    "\n",
    "@with_simulated_robot\n",
    "def move_and_detect(obj_type):\n",
    "    NavigateAction(target_locations=[Pose([1.4, 1, 0.95])]).resolve().perform()\n",
    "    LookAtAction(targets=[Pose([1.4, 1, 0.95])]).resolve().perform()\n",
    "    object_desig = DetectAction(ObjectDesignatorDescription(types=[obj_type])).resolve().perform()\n",
    "    return object_desig\n",
    "\n",
    "try:\n",
    "    with simulated_robot:\n",
    "        ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "        MoveTorsoAction([0.25]).resolve().perform()\n",
    "    \n",
    "        cereal_desig = move_and_detect(ObjectType.BREAKFAST_CEREAL)\n",
    "    \n",
    "        pickup_arm = target_location.reachable_arms[0]\n",
    "        PickUpAction(object_designator_description=cereal_desig, arms=[pickup_arm], grasps=['front']).resolve().perform()\n",
    "    \n",
    "        place_location = CostmapLocation(target_pose, reachable_for=robot_desig, reachable_arm=pickup_arm)\n",
    "        NavigateAction(target_locations=[place_location.pose]).resolve().perform()\n",
    "    \n",
    "        PlaceAction(cereal_desig, target_locations=[target_pose], arms=[pickup_arm]).resolve().perform()\n",
    "    \n",
    "        ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e, type(e))\n",
    "    \n",
    "world.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d27ee0e03b04557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
